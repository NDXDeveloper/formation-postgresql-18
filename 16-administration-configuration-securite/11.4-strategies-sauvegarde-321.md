ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 16.11.4. StratÃ©gies de Sauvegarde 3-2-1

## Introduction : Pourquoi une StratÃ©gie de Sauvegarde ?

Imaginez ces scÃ©narios catastrophes :

**ScÃ©nario 1 : L'incendie** ğŸ”¥
```
Lundi : Vos sauvegardes PostgreSQL sont sur un disque externe...
        dans la mÃªme salle serveur que votre base de donnÃ©es
Mardi : Un incendie dÃ©truit la salle serveur
RÃ©sultat : Base de donnÃ©es ET sauvegardes perdues
```

**ScÃ©nario 2 : La corruption silencieuse** ğŸ’¾
```
Janvier : Vous faites des sauvegardes rÃ©guliÃ¨res sur un seul disque
Juin : Vous dÃ©couvrez qu'une corruption s'est produite en fÃ©vrier
ProblÃ¨me : Toutes vos sauvegardes depuis fÃ©vrier sont sur le MÃŠME disque corrompu
```

**ScÃ©nario 3 : Le ransomware** ğŸ¦ 
```
Vendredi 23h : Un ransomware infecte votre rÃ©seau
Samedi 1h : Vos sauvegardes montÃ©es en NFS sont Ã©galement chiffrÃ©es
RÃ©sultat : Base de donnÃ©es ET sauvegardes inutilisables
```

Ces scÃ©narios ne sont pas de la science-fiction. Ils arrivent rÃ©guliÃ¨rement Ã  des entreprises du monde entier. La stratÃ©gie **3-2-1** a Ã©tÃ© conÃ§ue pour vous protÃ©ger contre tous ces risques.

---

## Le Concept 3-2-1

La rÃ¨gle **3-2-1** est une stratÃ©gie de sauvegarde universelle, simple Ã  retenir et extrÃªmement efficace :

### Les Trois RÃ¨gles d'Or

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3  copies de vos donnÃ©es           â”‚
â”‚  2  types de support diffÃ©rents     â”‚
â”‚  1  copie hors-site (off-site)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RÃ¨gle 1 : 3 Copies de Vos DonnÃ©es

**3 copies** signifie :
- **1 copie de production** (votre base de donnÃ©es en cours d'utilisation)
- **2 sauvegardes** (copies de backup)

**Pourquoi 3 ?**
- 1 copie = Aucune protection
- 2 copies = Protection basique (mais une seule sauvegarde)
- 3 copies = Redondance rÃ©elle (si une sauvegarde Ã©choue, vous avez encore une autre)

**Analogie** : Vous ne gardez pas un seul exemplaire d'un document important. Vous en faites des copies. La rÃ¨gle 3-2-1 dit : gardez AU MINIMUM 3 exemplaires.

**Exemple PostgreSQL** :
```
Copie 1 : Base de donnÃ©es de production sur serveur A
Copie 2 : Sauvegarde quotidienne sur disque B
Copie 3 : Sauvegarde hebdomadaire sur serveur de backup C
```

### RÃ¨gle 2 : 2 Types de Support DiffÃ©rents

**2 supports diffÃ©rents** signifie :
- Ne mettez pas toutes vos sauvegardes sur le mÃªme type de mÃ©dia
- Diversifiez les technologies de stockage

**Pourquoi 2 types ?**
- Protection contre les dÃ©faillances systÃ©matiques
- Un type de support peut avoir une vulnÃ©rabilitÃ© commune
- Diversification du risque

**Exemples de supports diffÃ©rents** :
- Disque dur interne **ET** disque dur externe
- SSD local **ET** HDD rÃ©seau (NAS)
- Stockage local **ET** stockage cloud
- Disque physique **ET** bande magnÃ©tique

**Mauvais exemples** (mÃªme type) :
- âŒ Deux disques durs dans le mÃªme serveur (mÃªme contrÃ´leur, mÃªme alimentation)
- âŒ Deux volumes sur le mÃªme SAN
- âŒ Deux buckets S3 dans la mÃªme rÃ©gion AWS

**Bons exemples** (types diffÃ©rents) :
- âœ… Disque local + NAS distant
- âœ… Disque local + Amazon S3
- âœ… SSD serveur + Bande magnÃ©tique
- âœ… Disque physique + Cloud (Azure, GCP)

**Exemple PostgreSQL** :
```
Support 1 : SSD local (sauvegarde pg_basebackup)
Support 2 : NFS montÃ© (archives WAL)
Support 3 : Cloud S3 (copies hebdomadaires)
```

### RÃ¨gle 3 : 1 Copie Hors-Site (Off-Site)

**Hors-site** signifie :
- Au moins une sauvegarde dans un lieu **gÃ©ographiquement sÃ©parÃ©**
- Protection contre les catastrophes locales

**Pourquoi hors-site ?**
- Incendie, inondation, tremblement de terre
- Panne Ã©lectrique gÃ©nÃ©ralisÃ©e
- Catastrophe naturelle
- Coupure rÃ©seau/internet locale

**Qu'est-ce qu'on entend par "hors-site" ?**

| Distance | ConsidÃ©rÃ© hors-site ? | Risque |
|----------|----------------------|--------|
| Autre piÃ¨ce dans le bÃ¢timent | âŒ Non | Incendie, inondation |
| Autre bÃ¢timent, mÃªme campus | âš ï¸ Limite | Catastrophe naturelle |
| Autre ville (50+ km) | âœ… Oui | Protection adÃ©quate |
| Autre rÃ©gion/pays | âœ…âœ… Excellent | Protection maximale |
| Cloud dans autre rÃ©gion | âœ…âœ… Excellent | Protection maximale |

**Exemples hors-site** :
- Datacenter distant (autre ville)
- Cloud public (AWS, Azure, GCP)
- Serveur de backup dans filiale distante
- Coffre-fort bancaire (bandes)
- Maison du directeur IT (pour petites structures)

**Exemple PostgreSQL** :
```
On-site (Paris) :
  - Production PostgreSQL
  - Sauvegarde locale quotidienne
  - Archives WAL locales

Off-site (Lyon) :
  - RÃ©plication serveur standby
  - Archives WAL synchronisÃ©es

Off-site (Cloud - Irlande) :
  - Sauvegardes hebdomadaires sur S3
```

---

## Application du 3-2-1 Ã  PostgreSQL

### Architecture 3-2-1 Basique

Voici comment implÃ©menter la rÃ¨gle 3-2-1 pour PostgreSQL :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COPIE 1 : PRODUCTION                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PostgreSQL serveur principal (Paris)                â”‚  â”‚
â”‚  â”‚  - Base de donnÃ©es active                            â”‚  â”‚
â”‚  â”‚  - SSD local                                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COPIE 2      â”‚  â”‚   COPIE 2      â”‚  â”‚   COPIE 3      â”‚
â”‚   (On-site)    â”‚  â”‚   (On-site)    â”‚  â”‚   (Off-site)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pg_basebackup  â”‚  â”‚ Archives WAL   â”‚  â”‚ Cloud S3       â”‚
â”‚ Quotidien      â”‚  â”‚ Continues      â”‚  â”‚ Hebdomadaire   â”‚
â”‚ Disque local   â”‚  â”‚ NAS/NFS        â”‚  â”‚ Autre rÃ©gion   â”‚
â”‚ Support: HDD   â”‚  â”‚ Support: NAS   â”‚  â”‚ Support: Cloud â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  (MÃªme lieu)        (MÃªme lieu)         (Lieu diffÃ©rent)
```

**Analyse** :
- âœ… **3 copies** : Production + 2 backups + 1 cloud
- âœ… **2 supports** : Disque local, NAS, Cloud
- âœ… **1 off-site** : S3 dans une autre rÃ©gion

### ImplÃ©mentation Ã‰tape par Ã‰tape

#### Ã‰tape 1 : Sauvegarde Locale Quotidienne (Copie 2a)

**Objectif** : RÃ©cupÃ©ration rapide en cas d'erreur

```bash
#!/bin/bash
# /usr/local/bin/backup_local.sh

DATE=$(date +%Y%m%d)
BACKUP_DIR="/backups/local"

# Sauvegarde physique avec pg_basebackup
pg_basebackup \
    -D ${BACKUP_DIR}/base_${DATE} \
    -U backup_user \
    -Ft -z -Z 6 \
    -X stream \
    -c fast \
    -P -v

# Rotation : garder 7 jours
find ${BACKUP_DIR} -name "base_*" -mtime +7 -exec rm -rf {} \;

echo "Sauvegarde locale terminÃ©e : ${BACKUP_DIR}/base_${DATE}"
```

**Cron : Tous les jours Ã  2h du matin**
```
0 2 * * * /usr/local/bin/backup_local.sh
```

#### Ã‰tape 2 : Archives WAL sur NAS (Copie 2b)

**Objectif** : PITR et rÃ©cupÃ©ration granulaire

**Configuration PostgreSQL** :
```conf
# postgresql.conf
archive_mode = on
archive_command = 'test ! -f /mnt/nas/wal_archive/%f && cp %p /mnt/nas/wal_archive/%f'
```

**Montage NAS** :
```bash
# /etc/fstab
nas-server:/exports/postgres_wal /mnt/nas nfs defaults,_netdev 0 0

# Monter
sudo mount /mnt/nas
sudo chown postgres:postgres /mnt/nas/wal_archive
```

#### Ã‰tape 3 : Sauvegarde Cloud Off-Site (Copie 3)

**Objectif** : Protection contre catastrophes locales

**Option A : Vers AWS S3**
```bash
#!/bin/bash
# /usr/local/bin/backup_cloud.sh

DATE=$(date +%Y%m%d)
BACKUP_LOCAL="/backups/local/base_${DATE}"
S3_BUCKET="s3://company-backups-postgres"

# VÃ©rifier que la sauvegarde locale existe
if [ ! -d "${BACKUP_LOCAL}" ]; then
    echo "Erreur : Sauvegarde locale non trouvÃ©e"
    exit 1
fi

# Copier vers S3
aws s3 sync ${BACKUP_LOCAL} ${S3_BUCKET}/${DATE}/ \
    --storage-class STANDARD_IA \
    --region eu-west-1

# Copier aussi les WAL rÃ©cents
aws s3 sync /mnt/nas/wal_archive/ ${S3_BUCKET}/wal_archive/ \
    --region eu-west-1

echo "Sauvegarde cloud terminÃ©e : ${S3_BUCKET}/${DATE}"
```

**Cron : Tous les dimanches Ã  4h du matin**
```
0 4 * * 0 /usr/local/bin/backup_cloud.sh
```

**Option B : Vers Azure Blob Storage**
```bash
#!/bin/bash
# Copier vers Azure

az storage blob upload-batch \
    --account-name companybackups \
    --destination postgres-backups \
    --source /backups/local/base_${DATE} \
    --destination-path ${DATE}
```

**Option C : Vers Google Cloud Storage**
```bash
#!/bin/bash
# Copier vers GCS

gsutil -m rsync -r \
    /backups/local/base_${DATE} \
    gs://company-backups-postgres/${DATE}/
```

---

## Architectures 3-2-1 AvancÃ©es

### Architecture 1 : PME Standard

**Contexte** :
- Base de donnÃ©es < 100 GB
- RTO : 2 heures
- RPO : 1 heure
- Budget modÃ©rÃ©

**Solution** :

```
Production (Serveur principal - Paris)
â”œâ”€ PostgreSQL sur SSD
â””â”€ Archives WAL locales

Copie 2a (Disque local)
â”œâ”€ pg_basebackup quotidien
â”œâ”€ Compression activÃ©e
â””â”€ RÃ©tention 7 jours

Copie 2b (NAS bureau)
â”œâ”€ Archives WAL continues
â”œâ”€ Montage NFS
â””â”€ Nettoyage 30 jours

Copie 3 (Cloud S3 - Irlande)
â”œâ”€ Sauvegardes hebdomadaires
â”œâ”€ Classe STANDARD_IA
â””â”€ Lifecycle policy : Glacier aprÃ¨s 90 jours
```

**CoÃ»t estimÃ© (mensuel)** :
- Disque local : Inclus dans infrastructure
- NAS : ~50â‚¬ (appareil + Ã©lectricitÃ©)
- Cloud S3 : ~20â‚¬ (100 GB STANDARD_IA)
- **Total : ~70â‚¬/mois**

### Architecture 2 : Entreprise avec HA

**Contexte** :
- Base de donnÃ©es 500 GB - 2 TB
- RTO : 15 minutes
- RPO : < 1 minute
- Haute disponibilitÃ© requise

**Solution** :

```
Production Site A (Paris)
â”œâ”€ PostgreSQL Primary
â”œâ”€ SSD NVMe
â””â”€ Archives WAL vers NAS local

Copie 2a (Standby Site A - Paris)
â”œâ”€ RÃ©plication streaming synchrone
â”œâ”€ Hot Standby (lecture seule)
â””â”€ Failover automatique (Patroni)

Copie 2b (Standby Site B - Lyon)
â”œâ”€ RÃ©plication streaming asynchrone
â”œâ”€ Distant gÃ©ographiquement (400 km)
â””â”€ Disaster Recovery

Copie 3a (NAS Site A)
â”œâ”€ Sauvegardes pg_basebackup depuis Standby
â”œâ”€ Pas d'impact sur Primary
â””â”€ RÃ©tention 14 jours

Copie 3b (Cloud S3 - Multi-rÃ©gion)
â”œâ”€ RÃ©plication S3 cross-region
â”œâ”€ Sauvegardes hebdomadaires complÃ¨tes
â”œâ”€ Archives WAL quotidiennes
â””â”€ Lifecycle : STANDARD â†’ IA â†’ Glacier Deep Archive
```

**Avantages** :
- âœ… Failover < 30 secondes (Standby Site A)
- âœ… Protection gÃ©ographique (Site B)
- âœ… PITR disponible (Archives WAL)
- âœ… Aucun impact production (backup depuis Standby)

### Architecture 3 : Cloud Native

**Contexte** :
- Infrastructure entiÃ¨rement cloud
- Base de donnÃ©es dans le cloud
- Multi-rÃ©gion requis

**Solution AWS** :

```
Production (us-east-1)
â”œâ”€ RDS PostgreSQL ou Aurora
â”œâ”€ Automated backups activÃ©s
â””â”€ Point-in-time recovery

Copie 2 (us-east-1)
â”œâ”€ RDS automated snapshots quotidiens
â”œâ”€ RÃ©tention 7 jours
â””â”€ MÃªme rÃ©gion

Copie 3a (us-west-2)
â”œâ”€ Cross-region replica
â”œâ”€ Read replica fonctionnel
â””â”€ Peut Ãªtre promu

Copie 3b (eu-west-1)
â”œâ”€ Snapshots copiÃ©s vers autre rÃ©gion
â”œâ”€ S3 bucket avec versioning
â””â”€ Exports logiques mensuels (pg_dump)
```

**Solution Multi-Cloud** :

```
Production (AWS eu-west-1)
â”œâ”€ RDS PostgreSQL

Copie 2 (AWS eu-west-1)
â”œâ”€ Automated backups

Copie 3a (Azure West Europe)
â”œâ”€ Sauvegardes exportÃ©es vers Azure Blob
â”œâ”€ AzCopy pour synchronisation
â””â”€ Geo-redundant storage

Copie 3b (Google Cloud europe-west1)
â”œâ”€ Sauvegardes exportÃ©es vers GCS
â”œâ”€ Multi-regional storage class
â””â”€ Diversification fournisseur
```

---

## Scripts d'Automatisation Complets

### Script Master de Sauvegarde 3-2-1

```bash
#!/bin/bash
# /usr/local/bin/backup_321.sh
# Script complet implÃ©mentant stratÃ©gie 3-2-1

set -e  # ArrÃªt en cas d'erreur

# ============================================
# CONFIGURATION
# ============================================

DATE=$(date +%Y%m%d_%H%M)
LOG_FILE="/var/log/postgresql/backup_321.log"

# Copie 2a : Local
LOCAL_BACKUP_DIR="/backups/local"
LOCAL_RETENTION_DAYS=7

# Copie 2b : NAS
NAS_MOUNT="/mnt/nas"
NAS_WAL_DIR="${NAS_MOUNT}/wal_archive"

# Copie 3 : Cloud
CLOUD_PROVIDER="s3"  # Options: s3, azure, gcs
S3_BUCKET="s3://company-backups-postgres"
S3_REGION="eu-west-1"

# Email alertes
ALERT_EMAIL="admin@company.com"

# ============================================
# FONCTIONS
# ============================================

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a ${LOG_FILE}
}

alert() {
    local MESSAGE=$1
    log "ALERT: ${MESSAGE}"
    echo "${MESSAGE}" | mail -s "PostgreSQL Backup 3-2-1 Alert" ${ALERT_EMAIL}
}

check_disk_space() {
    local MOUNT_POINT=$1
    local REQUIRED_GB=$2

    AVAILABLE_GB=$(df -BG ${MOUNT_POINT} | tail -1 | awk '{print $4}' | sed 's/G//')

    if [ ${AVAILABLE_GB} -lt ${REQUIRED_GB} ]; then
        alert "Insufficient disk space on ${MOUNT_POINT}: ${AVAILABLE_GB}GB available, ${REQUIRED_GB}GB required"
        return 1
    fi

    return 0
}

verify_backup() {
    local BACKUP_PATH=$1

    # VÃ©rifier backup_label
    if [ ! -f "${BACKUP_PATH}/backup_label" ]; then
        alert "Backup verification failed: backup_label not found in ${BACKUP_PATH}"
        return 1
    fi

    # VÃ©rifier PG_VERSION
    if [ ! -f "${BACKUP_PATH}/PG_VERSION" ]; then
        alert "Backup verification failed: PG_VERSION not found in ${BACKUP_PATH}"
        return 1
    fi

    log "âœ“ Backup verification passed: ${BACKUP_PATH}"
    return 0
}

# ============================================
# COPIE 2a : SAUVEGARDE LOCALE
# ============================================

backup_local() {
    log "=== Starting local backup (Copy 2a) ==="

    # VÃ©rifier l'espace disque
    if ! check_disk_space ${LOCAL_BACKUP_DIR} 50; then
        return 1
    fi

    BACKUP_PATH="${LOCAL_BACKUP_DIR}/base_${DATE}"

    # ExÃ©cuter pg_basebackup
    log "Running pg_basebackup to ${BACKUP_PATH}"

    pg_basebackup \
        -D ${BACKUP_PATH} \
        -U backup_user \
        -Ft -z -Z 6 \
        -X stream \
        -c fast \
        -P -v \
        2>&1 | tee -a ${LOG_FILE}

    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        alert "Local backup FAILED"
        return 1
    fi

    # VÃ©rifier la sauvegarde
    # Note: Pour format tar, on vÃ©rifie juste la prÃ©sence des fichiers
    if [ ! -f "${BACKUP_PATH}/base.tar.gz" ]; then
        alert "Local backup verification failed: base.tar.gz not found"
        return 1
    fi

    BACKUP_SIZE=$(du -sh ${BACKUP_PATH} | cut -f1)
    log "âœ“ Local backup completed successfully: ${BACKUP_PATH} (${BACKUP_SIZE})"

    # Rotation
    log "Cleaning local backups older than ${LOCAL_RETENTION_DAYS} days"
    find ${LOCAL_BACKUP_DIR} -name "base_*" -type d -mtime +${LOCAL_RETENTION_DAYS} -exec rm -rf {} \; 2>/dev/null

    echo ${BACKUP_PATH}
}

# ============================================
# COPIE 2b : ARCHIVES WAL SUR NAS
# ============================================

verify_wal_archiving() {
    log "=== Verifying WAL archiving (Copy 2b) ==="

    # VÃ©rifier montage NAS
    if ! mountpoint -q ${NAS_MOUNT}; then
        alert "NAS not mounted at ${NAS_MOUNT}"
        return 1
    fi

    # VÃ©rifier archivage PostgreSQL
    FAILED_COUNT=$(psql -U postgres -t -c "SELECT failed_count FROM pg_stat_archiver;" | tr -d ' ')
    LAST_ARCHIVE_SECONDS=$(psql -U postgres -t -c "SELECT EXTRACT(EPOCH FROM (now() - last_archived_time)) FROM pg_stat_archiver;" | tr -d ' ')

    if [ ${FAILED_COUNT} -gt 0 ]; then
        alert "WAL archiving has ${FAILED_COUNT} failures"
        return 1
    fi

    if (( $(echo "${LAST_ARCHIVE_SECONDS} > 3600" | bc -l) )); then
        alert "No WAL archived in the last hour (${LAST_ARCHIVE_SECONDS} seconds)"
        return 1
    fi

    # VÃ©rifier espace disque NAS
    if ! check_disk_space ${NAS_MOUNT} 20; then
        return 1
    fi

    WAL_COUNT=$(ls -1 ${NAS_WAL_DIR} | wc -l)
    log "âœ“ WAL archiving operational: ${WAL_COUNT} files in archive"

    return 0
}

# ============================================
# COPIE 3 : SAUVEGARDE CLOUD OFF-SITE
# ============================================

backup_cloud_s3() {
    local SOURCE_PATH=$1

    log "=== Starting cloud backup to S3 (Copy 3) ==="

    if [ ! -d "${SOURCE_PATH}" ]; then
        alert "Source backup not found for cloud upload: ${SOURCE_PATH}"
        return 1
    fi

    CLOUD_PATH="${S3_BUCKET}/backups/${DATE}"

    log "Uploading to ${CLOUD_PATH}"

    aws s3 sync ${SOURCE_PATH} ${CLOUD_PATH}/ \
        --storage-class STANDARD_IA \
        --region ${S3_REGION} \
        2>&1 | tee -a ${LOG_FILE}

    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        alert "Cloud backup to S3 FAILED"
        return 1
    fi

    # Copier aussi les archives WAL rÃ©centes (derniers 2 jours)
    log "Syncing recent WAL files to S3"
    find ${NAS_WAL_DIR} -name "*.wal" -mtime -2 -type f | while read WAL_FILE; do
        aws s3 cp ${WAL_FILE} ${S3_BUCKET}/wal_archive/ --region ${S3_REGION}
    done

    log "âœ“ Cloud backup to S3 completed: ${CLOUD_PATH}"

    return 0
}

backup_cloud_azure() {
    local SOURCE_PATH=$1

    log "=== Starting cloud backup to Azure (Copy 3) ==="

    CONTAINER="postgres-backups"
    BLOB_PREFIX="backups/${DATE}"

    az storage blob upload-batch \
        --account-name companybackups \
        --destination ${CONTAINER} \
        --destination-path ${BLOB_PREFIX} \
        --source ${SOURCE_PATH} \
        2>&1 | tee -a ${LOG_FILE}

    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        alert "Cloud backup to Azure FAILED"
        return 1
    fi

    log "âœ“ Cloud backup to Azure completed"
    return 0
}

backup_cloud_gcs() {
    local SOURCE_PATH=$1

    log "=== Starting cloud backup to GCS (Copy 3) ==="

    GCS_PATH="gs://company-backups-postgres/backups/${DATE}"

    gsutil -m rsync -r ${SOURCE_PATH} ${GCS_PATH}/ \
        2>&1 | tee -a ${LOG_FILE}

    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        alert "Cloud backup to GCS FAILED"
        return 1
    fi

    log "âœ“ Cloud backup to GCS completed: ${GCS_PATH}"
    return 0
}

backup_cloud() {
    local SOURCE_PATH=$1

    case ${CLOUD_PROVIDER} in
        s3)
            backup_cloud_s3 ${SOURCE_PATH}
            ;;
        azure)
            backup_cloud_azure ${SOURCE_PATH}
            ;;
        gcs)
            backup_cloud_gcs ${SOURCE_PATH}
            ;;
        *)
            alert "Unknown cloud provider: ${CLOUD_PROVIDER}"
            return 1
            ;;
    esac
}

# ============================================
# ORCHESTRATION
# ============================================

main() {
    log "========================================"
    log "Starting PostgreSQL 3-2-1 Backup Strategy"
    log "========================================"

    # Copie 2a : Sauvegarde locale
    BACKUP_PATH=$(backup_local)
    if [ $? -ne 0 ]; then
        alert "Backup strategy FAILED at local backup stage"
        exit 1
    fi

    # Copie 2b : VÃ©rifier archives WAL
    if ! verify_wal_archiving; then
        alert "WAL archiving verification FAILED"
        # Continue quand mÃªme pour la sauvegarde cloud
    fi

    # Copie 3 : Sauvegarde cloud (seulement le dimanche)
    if [ $(date +%u) -eq 7 ]; then
        if ! backup_cloud ${BACKUP_PATH}; then
            alert "Cloud backup FAILED"
            exit 1
        fi
    else
        log "Skipping cloud backup (not Sunday)"
    fi

    log "========================================"
    log "âœ“âœ“âœ“ 3-2-1 Backup Strategy completed successfully"
    log "========================================"

    # Rapport de succÃ¨s
    echo "PostgreSQL 3-2-1 backup completed successfully on $(date)" | \
        mail -s "Backup Success - 3-2-1" ${ALERT_EMAIL}
}

# ExÃ©cution
main
```

**Installation** :

```bash
# Rendre exÃ©cutable
chmod +x /usr/local/bin/backup_321.sh

# Tester
sudo -u postgres /usr/local/bin/backup_321.sh

# Cron quotidien Ã  2h
echo "0 2 * * * /usr/local/bin/backup_321.sh" | crontab -
```

### Script de VÃ©rification 3-2-1

```bash
#!/bin/bash
# /usr/local/bin/verify_321.sh
# VÃ©rifier que la stratÃ©gie 3-2-1 est respectÃ©e

# Configuration
LOCAL_BACKUP_DIR="/backups/local"
NAS_WAL_DIR="/mnt/nas/wal_archive"
S3_BUCKET="s3://company-backups-postgres"

echo "=== Verification PostgreSQL 3-2-1 Strategy ==="
echo

# ============================================
# COPIE 1 : PRODUCTION
# ============================================

echo "1. Production Database (Copy 1)"
if systemctl is-active --quiet postgresql; then
    echo "   âœ“ PostgreSQL is running"
    PG_VERSION=$(psql -U postgres -t -c "SELECT version();" | head -1 | awk '{print $2}')
    echo "   âœ“ Version: ${PG_VERSION}"
    DB_SIZE=$(psql -U postgres -t -c "SELECT pg_size_pretty(pg_database_size('production'));" | tr -d ' ')
    echo "   âœ“ Database size: ${DB_SIZE}"
else
    echo "   âœ— PostgreSQL is NOT running"
fi
echo

# ============================================
# COPIE 2a : SAUVEGARDE LOCALE
# ============================================

echo "2. Local Backup (Copy 2a)"
if [ -d "${LOCAL_BACKUP_DIR}" ]; then
    BACKUP_COUNT=$(find ${LOCAL_BACKUP_DIR} -name "base_*" -type d | wc -l)
    LATEST_BACKUP=$(find ${LOCAL_BACKUP_DIR} -name "base_*" -type d | sort | tail -1)

    if [ ${BACKUP_COUNT} -gt 0 ]; then
        echo "   âœ“ ${BACKUP_COUNT} local backups found"
        echo "   âœ“ Latest: ${LATEST_BACKUP}"

        BACKUP_AGE=$(( ($(date +%s) - $(stat -c %Y ${LATEST_BACKUP})) / 86400 ))
        echo "   âœ“ Age: ${BACKUP_AGE} days"

        if [ ${BACKUP_AGE} -gt 2 ]; then
            echo "   âš  WARNING: Latest backup is older than 2 days"
        fi
    else
        echo "   âœ— No local backups found"
    fi
else
    echo "   âœ— Local backup directory does not exist"
fi
echo

# ============================================
# COPIE 2b : ARCHIVES WAL
# ============================================

echo "3. WAL Archives on NAS (Copy 2b)"
if mountpoint -q /mnt/nas; then
    echo "   âœ“ NAS is mounted"

    if [ -d "${NAS_WAL_DIR}" ]; then
        WAL_COUNT=$(ls -1 ${NAS_WAL_DIR} 2>/dev/null | wc -l)
        echo "   âœ“ ${WAL_COUNT} WAL files archived"

        LATEST_WAL=$(ls -t ${NAS_WAL_DIR} | head -1)
        if [ -n "${LATEST_WAL}" ]; then
            WAL_AGE=$(( ($(date +%s) - $(stat -c %Y ${NAS_WAL_DIR}/${LATEST_WAL})) / 60 ))
            echo "   âœ“ Latest WAL: ${LATEST_WAL} (${WAL_AGE} minutes ago)"

            if [ ${WAL_AGE} -gt 60 ]; then
                echo "   âš  WARNING: No WAL archived in the last hour"
            fi
        fi

        # VÃ©rifier PostgreSQL archiving
        FAILED_COUNT=$(psql -U postgres -t -c "SELECT failed_count FROM pg_stat_archiver;" 2>/dev/null | tr -d ' ')
        if [ -n "${FAILED_COUNT}" ]; then
            if [ ${FAILED_COUNT} -eq 0 ]; then
                echo "   âœ“ Archiving status: OK (0 failures)"
            else
                echo "   âœ— Archiving status: ${FAILED_COUNT} failures"
            fi
        fi
    else
        echo "   âœ— WAL archive directory not found"
    fi
else
    echo "   âœ— NAS is NOT mounted"
fi
echo

# ============================================
# COPIE 3 : CLOUD OFF-SITE
# ============================================

echo "4. Cloud Backup Off-Site (Copy 3)"
if command -v aws &> /dev/null; then
    CLOUD_BACKUP_COUNT=$(aws s3 ls ${S3_BUCKET}/backups/ 2>/dev/null | wc -l)

    if [ ${CLOUD_BACKUP_COUNT} -gt 0 ]; then
        echo "   âœ“ ${CLOUD_BACKUP_COUNT} cloud backups found on S3"

        LATEST_CLOUD=$(aws s3 ls ${S3_BUCKET}/backups/ | tail -1 | awk '{print $2}')
        echo "   âœ“ Latest: ${LATEST_CLOUD}"

        # Age approximatif (basÃ© sur le nom si au format YYYYMMDD)
        # Implementation simplifiÃ©e
    else
        echo "   âœ— No cloud backups found"
    fi
else
    echo "   âš  AWS CLI not installed, cannot verify S3"
fi
echo

# ============================================
# SUPPORT DIVERSITY
# ============================================

echo "5. Storage Type Diversity (Rule: 2 types)"
echo "   Type 1: Local disk (${LOCAL_BACKUP_DIR})"
echo "   Type 2: Network storage (${NAS_WAL_DIR})"
echo "   Type 3: Cloud storage (${S3_BUCKET})"
echo "   âœ“ Using 3 different storage types"
echo

# ============================================
# OFF-SITE VERIFICATION
# ============================================

echo "6. Off-Site Location (Rule: 1 off-site)"
echo "   On-site: Local backup + NAS"
echo "   Off-site: Cloud S3"
echo "   âœ“ At least 1 off-site backup configured"
echo

# ============================================
# RÃ‰SUMÃ‰
# ============================================

echo "========================================"
echo "Summary of 3-2-1 Strategy Compliance:"
echo "  [âœ“] 3 Copies: Production + Local + WAL + Cloud"
echo "  [âœ“] 2 Media: Disk + NAS + Cloud"
echo "  [âœ“] 1 Off-site: Cloud S3"
echo "========================================"
```

**ExÃ©cution** :
```bash
chmod +x /usr/local/bin/verify_321.sh
/usr/local/bin/verify_321.sh
```

---

## Gestion du Cycle de Vie et RÃ©tention

### Politique de RÃ©tention RecommandÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CALENDRIER DE RÃ‰TENTION                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Quotidien  : 7 jours   (rÃ©cupÃ©ration rapide)           â”‚
â”‚  Hebdomadaire : 4 semaines (1 mois)                     â”‚
â”‚  Mensuel   : 12 mois  (1 an)                            â”‚
â”‚  Annuel    : 7 ans    (conformitÃ© lÃ©gale)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplÃ©mentation avec AWS S3 Lifecycle

```bash
# lifecycle-policy.json
cat > lifecycle-policy.json << EOF
{
  "Rules": [
    {
      "Id": "DailyBackupRetention",
      "Filter": {
        "Prefix": "backups/daily/"
      },
      "Status": "Enabled",
      "Expiration": {
        "Days": 7
      }
    },
    {
      "Id": "WeeklyBackupRetention",
      "Filter": {
        "Prefix": "backups/weekly/"
      },
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        }
      ],
      "Expiration": {
        "Days": 120
      }
    },
    {
      "Id": "MonthlyBackupRetention",
      "Filter": {
        "Prefix": "backups/monthly/"
      },
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        }
      ],
      "Expiration": {
        "Days": 365
      }
    },
    {
      "Id": "AnnualBackupRetention",
      "Filter": {
        "Prefix": "backups/annual/"
      },
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 180,
          "StorageClass": "DEEP_ARCHIVE"
        }
      ],
      "Expiration": {
        "Days": 2555
      }
    }
  ]
}
EOF

# Appliquer la politique
aws s3api put-bucket-lifecycle-configuration \
    --bucket company-backups-postgres \
    --lifecycle-configuration file://lifecycle-policy.json
```

### Script de Rotation Intelligent

```bash
#!/bin/bash
# /usr/local/bin/backup_rotation.sh
# Gestion intelligente de la rotation des sauvegardes

BACKUP_DIR="/backups/local"
DATE=$(date +%Y%m%d)
DAY_OF_WEEK=$(date +%u)  # 1=Lundi, 7=Dimanche
DAY_OF_MONTH=$(date +%d)

# DÃ©terminer le type de sauvegarde Ã  conserver
if [ "${DAY_OF_MONTH}" == "01" ]; then
    # Premier du mois : mensuelle
    BACKUP_TYPE="monthly"
    ln -sf ${BACKUP_DIR}/base_${DATE} ${BACKUP_DIR}/monthly_${DATE}
    echo "Sauvegarde mensuelle crÃ©Ã©e: monthly_${DATE}"

elif [ "${DAY_OF_WEEK}" == "7" ]; then
    # Dimanche : hebdomadaire
    BACKUP_TYPE="weekly"
    ln -sf ${BACKUP_DIR}/base_${DATE} ${BACKUP_DIR}/weekly_${DATE}
    echo "Sauvegarde hebdomadaire crÃ©Ã©e: weekly_${DATE}"

else
    # Autres jours : quotidienne
    BACKUP_TYPE="daily"
fi

# Rotation des sauvegardes quotidiennes (garder 7 jours)
find ${BACKUP_DIR} -name "base_*" -type d -mtime +7 -exec rm -rf {} \; 2>/dev/null

# Rotation des sauvegardes hebdomadaires (garder 4 semaines)
find ${BACKUP_DIR} -name "weekly_*" -type l -mtime +28 -delete 2>/dev/null

# Rotation des sauvegardes mensuelles (garder 12 mois)
find ${BACKUP_DIR} -name "monthly_*" -type l -mtime +365 -delete 2>/dev/null

echo "Rotation terminÃ©e"
```

---

## Calcul des CoÃ»ts et Dimensionnement

### Estimer les Besoins de Stockage

**Formule** :
```
Stockage total = Taille DB Ã— Facteur compression Ã— Nombre de copies Ã— RÃ©tention
```

**Exemple** :
```
Base de donnÃ©es : 200 GB
Compression : 0.6 (40% de rÃ©duction)
Copies locales : 7 jours Ã— 120 GB = 840 GB
Copies cloud : 4 semaines Ã— 120 GB = 480 GB
Total : ~1.3 TB
```

### Calcul de CoÃ»ts Cloud (Exemple AWS)

```python
#!/usr/bin/env python3
# cost_calculator.py

def calculate_s3_costs(db_size_gb, retention_days, compression_ratio=0.6):
    """
    Calculer les coÃ»ts S3 pour stratÃ©gie 3-2-1
    """
    # Taille aprÃ¨s compression
    compressed_size_gb = db_size_gb * compression_ratio

    # Nombre de sauvegardes complÃ¨tes
    daily_backups = 7
    weekly_backups = 4
    monthly_backups = 12

    # Storage
    standard_storage = daily_backups * compressed_size_gb
    ia_storage = weekly_backups * compressed_size_gb
    glacier_storage = monthly_backups * compressed_size_gb

    # Prix par GB (us-east-1, novembre 2025)
    standard_price = 0.023  # $/GB
    ia_price = 0.0125       # $/GB
    glacier_price = 0.004   # $/GB

    # Calcul
    cost_standard = standard_storage * standard_price
    cost_ia = ia_storage * ia_price
    cost_glacier = glacier_storage * glacier_price

    total_cost = cost_standard + cost_ia + cost_glacier

    print(f"=== Cost Calculator ===")
    print(f"Database size: {db_size_gb} GB")
    print(f"Compressed size: {compressed_size_gb} GB")
    print(f"")
    print(f"Storage breakdown:")
    print(f"  STANDARD (7 days): {standard_storage:.1f} GB = ${cost_standard:.2f}/month")
    print(f"  STANDARD_IA (4 weeks): {ia_storage:.1f} GB = ${cost_ia:.2f}/month")
    print(f"  GLACIER (12 months): {glacier_storage:.1f} GB = ${cost_glacier:.2f}/month")
    print(f"")
    print(f"TOTAL: ${total_cost:.2f}/month (${total_cost * 12:.2f}/year)")

    return total_cost

# Exemples
print("Small DB (50 GB):")
calculate_s3_costs(50, 30)
print("\n" + "="*40 + "\n")

print("Medium DB (200 GB):")
calculate_s3_costs(200, 30)
print("\n" + "="*40 + "\n")

print("Large DB (1000 GB):")
calculate_s3_costs(1000, 30)
```

**RÃ©sultat** :
```
Small DB (50 GB):
Storage breakdown:
  STANDARD (7 days): 210.0 GB = $4.83/month
  STANDARD_IA (4 weeks): 120.0 GB = $1.50/month
  GLACIER (12 months): 360.0 GB = $1.44/month
TOTAL: $7.77/month ($93.24/year)

Medium DB (200 GB):
Storage breakdown:
  STANDARD (7 days): 840.0 GB = $19.32/month
  STANDARD_IA (4 weeks): 480.0 GB = $6.00/month
  GLACIER (12 months): 1440.0 GB = $5.76/month
TOTAL: $31.08/month ($372.96/year)

Large DB (1000 GB):
Storage breakdown:
  STANDARD (7 days): 4200.0 GB = $96.60/month
  STANDARD_IA (4 weeks): 2400.0 GB = $30.00/month
  GLACIER (12 months): 7200.0 GB = $28.80/month
TOTAL: $155.40/month ($1864.80/year)
```

---

## Bonnes Pratiques et Recommandations

### âœ… Configuration et Planification

1. **Documenter votre stratÃ©gie**
   - OÃ¹ sont les sauvegardes ?
   - Quel type pour quel usage ?
   - Qui a accÃ¨s ?

2. **Automatiser complÃ¨tement**
   - Aucune intervention manuelle
   - Cron/systemd timers
   - Orchestrateurs (Ansible, Kubernetes CronJob)

3. **Chiffrer les sauvegardes**
   - Au repos (encryption at rest)
   - En transit (TLS/SSL)
   - ClÃ©s gÃ©rÃ©es sÃ©parÃ©ment

4. **Versioning et immuabilitÃ©**
   - S3 Versioning activÃ©
   - S3 Object Lock pour protection ransomware
   - Azure Immutable Blob Storage

5. **Diversifier les fournisseurs cloud**
   - Multi-cloud pour haute rÃ©silience
   - Ã‰viter le vendor lock-in

### âœ… Monitoring et Alertes

1. **Surveiller TOUTES les copies**
   - Ne pas se concentrer uniquement sur la production
   - VÃ©rifier que chaque copie fonctionne

2. **Alertes critiques**
   - Ã‰chec de sauvegarde (quelconque copie)
   - Espace disque < 20%
   - Sauvegarde trop ancienne (> 48h)
   - Erreur de vÃ©rification

3. **Dashboard centralisÃ©**
   - Vue d'ensemble du statut 3-2-1
   - Grafana avec mÃ©triques personnalisÃ©es

4. **Rapports rÃ©guliers**
   - Hebdomadaires : statut des sauvegardes
   - Mensuels : tests de restauration
   - Trimestriels : audit complet

### âœ… Tests et Validation

1. **Tester rÃ©guliÃ¨rement**
   - Hebdomadaire : VÃ©rification intÃ©gritÃ©
   - Mensuel : Restauration partielle
   - Trimestriel : Restauration complÃ¨te
   - Annuel : Disaster recovery drill

2. **Automatiser les tests**
   ```bash
   #!/bin/bash
   # Test restauration automatique sur serveur de test

   LATEST_BACKUP=$(aws s3 ls s3://backups/ | tail -1 | awk '{print $4}')
   aws s3 sync s3://backups/${LATEST_BACKUP} /restore/

   # Restaurer sur instance de test
   pg_restore -d test_db /restore/base.dump

   # VÃ©rifier
   psql -d test_db -c "SELECT count(*) FROM clients;"
   ```

3. **Mesurer les performances**
   - RTO rÃ©el vs objectif
   - RPO rÃ©el vs objectif
   - Temps de restauration par taille

### âŒ PiÃ¨ges Ã  Ã‰viter

1. **Ne pas avoir de vraie redondance**
   - âŒ Mauvais : 2 disques dans le mÃªme RAID
   - âœ… Bon : Disques sur serveurs diffÃ©rents

2. **Off-site "pas vraiment off-site"**
   - âŒ Mauvais : Autre salle dans le mÃªme bÃ¢timent
   - âœ… Bon : Autre ville/rÃ©gion

3. **Ne jamais tester**
   - Une sauvegarde non testÃ©e = pas de sauvegarde

4. **NÃ©gliger la sÃ©curitÃ©**
   - Sauvegardes non chiffrÃ©es
   - AccÃ¨s non restreints
   - ClÃ©s de chiffrement avec les donnÃ©es

5. **Oublier les objets globaux**
   - pg_basebackup ne sauvegarde pas les rÃ´les
   - Faire aussi `pg_dumpall --globals-only`

6. **Ignorer les coÃ»ts cloud**
   - Lifecycle policies essentielles
   - Monitoring des coÃ»ts
   - Classes de stockage appropriÃ©es

---

## Cas d'Usage et ScÃ©narios de RÃ©cupÃ©ration

### Cas 1 : Suppression Accidentelle de DonnÃ©es

**Incident** : Suppression de 10,000 clients Ã  14h30

**RÃ©cupÃ©ration avec 3-2-1** :

```bash
# Option 1 : PITR depuis copie locale (plus rapide)
# RTO : 30 minutes
# RPO : 0 seconde

# Restaurer base backup local
cp -a /backups/local/base_20251122_0200 /var/lib/postgresql/data

# Configurer PITR avec WAL du NAS
cat > /var/lib/postgresql/data/recovery.conf << EOF
restore_command = 'cp /mnt/nas/wal_archive/%f %p'
recovery_target_time = '2025-11-22 14:29:59'
recovery_target_action = 'promote'
EOF

# DÃ©marrer
systemctl start postgresql
```

### Cas 2 : Corruption de la Base de DonnÃ©es

**Incident** : Corruption matÃ©rielle dÃ©tectÃ©e

**RÃ©cupÃ©ration** :

```bash
# Utiliser la copie locale la plus rÃ©cente
# Si corruption rÃ©cente, utiliser copie cloud plus ancienne

# Test copie locale
pg_restore -d test /backups/local/latest.dump

# Si corruption prÃ©sente, utiliser cloud
aws s3 cp s3://backups/weekly_20251115/ /restore/ --recursive
pg_restore -d production /restore/base.dump
```

### Cas 3 : Destruction ComplÃ¨te du Site (Incendie)

**Incident** : Datacenter dÃ©truit, tout perdu

**RÃ©cupÃ©ration** :

```bash
# 1. Provisionner nouveau serveur
# 2. RÃ©cupÃ©rer depuis cloud (seule copie restante)

aws s3 sync s3://backups/latest/ /var/lib/postgresql/data/

# 3. RÃ©cupÃ©rer WAL cloud
aws s3 sync s3://backups/wal_archive/ /wal_restore/

# 4. PITR jusqu'au dernier WAL disponible
cat > /var/lib/postgresql/data/recovery.conf << EOF
restore_command = 'cp /wal_restore/%f %p'
recovery_target = 'latest'
EOF

# 5. DÃ©marrer
systemctl start postgresql
```

**RPO** : DerniÃ¨re synchronisation WAL (gÃ©nÃ©ralement < 5 minutes)
**RTO** : 2-4 heures (tÃ©lÃ©chargement depuis cloud + restauration)

### Cas 4 : Ransomware

**Incident** : Ransomware chiffre production ET sauvegardes locales

**RÃ©cupÃ©ration** :

```bash
# Les copies cloud avec Object Lock sont immuables
# Le ransomware ne peut pas les chiffrer

# 1. Isoler le rÃ©seau
# 2. Nettoyer les systÃ¨mes
# 3. Restaurer depuis cloud

aws s3 sync s3://backups/pre-ransomware/ /var/lib/postgresql/data/
```

**Pourquoi 3-2-1 sauve la mise** :
- âœ… Copie off-site intacte
- âœ… Object Lock empÃªche modification
- âœ… Versioning permet de retrouver version saine

---

## Checklist de Mise en Place 3-2-1

### Phase 1 : Planification

- [ ] DÃ©finir RTO/RPO acceptables
- [ ] Calculer besoins de stockage
- [ ] Estimer les coÃ»ts (local + cloud)
- [ ] Choisir fournisseur cloud
- [ ] DÃ©finir politique de rÃ©tention
- [ ] Documenter la stratÃ©gie

### Phase 2 : Infrastructure

- [ ] Provisionner stockage local (disque/SAN)
- [ ] Provisionner NAS ou stockage rÃ©seau
- [ ] Configurer comptes cloud (S3/Azure/GCS)
- [ ] Configurer accÃ¨s rÃ©seau/VPN si nÃ©cessaire
- [ ] Configurer IAM/permissions cloud
- [ ] Activer chiffrement sur tous les supports

### Phase 3 : Configuration PostgreSQL

- [ ] Configurer WAL archiving
- [ ] Tester archive_command
- [ ] Configurer utilisateur de backup
- [ ] Tester pg_basebackup
- [ ] VÃ©rifier espace disque suffisant

### Phase 4 : Automatisation

- [ ] CrÃ©er script sauvegarde locale
- [ ] CrÃ©er script sauvegarde cloud
- [ ] CrÃ©er script de vÃ©rification
- [ ] Configurer cron/scheduler
- [ ] Tester exÃ©cution automatique
- [ ] Configurer rotation/lifecycle

### Phase 5 : Monitoring

- [ ] Configurer alertes Ã©chec sauvegarde
- [ ] Configurer alertes espace disque
- [ ] Configurer alertes WAL archiving
- [ ] CrÃ©er dashboard Grafana
- [ ] Tester les alertes

### Phase 6 : Documentation

- [ ] Documenter architecture 3-2-1
- [ ] CrÃ©er runbook de restauration
- [ ] Documenter emplacements sauvegardes
- [ ] Lister contacts/escalade
- [ ] Documenter procÃ©dures d'urgence

### Phase 7 : Tests

- [ ] Test restauration locale
- [ ] Test restauration depuis NAS
- [ ] Test restauration depuis cloud
- [ ] Test PITR
- [ ] Test disaster recovery complet
- [ ] Mesurer RTO/RPO rÃ©els
- [ ] Planifier tests rÃ©guliers

### Phase 8 : SÃ©curitÃ©

- [ ] Chiffrement at-rest activÃ©
- [ ] Chiffrement in-transit activÃ©
- [ ] Permissions restrictives (700)
- [ ] ClÃ©s de chiffrement gÃ©rÃ©es sÃ©parÃ©ment
- [ ] MFA sur comptes cloud
- [ ] Audit logs activÃ©s
- [ ] ImmutabilitÃ© configurÃ©e (Object Lock)

---

## Conclusion

La stratÃ©gie 3-2-1 n'est pas un luxe, c'est une **nÃ©cessitÃ© absolue** pour toute base de donnÃ©es en production. Elle vous protÃ¨ge contre :

- âœ… **Pannes matÃ©rielles** (disque, serveur)
- âœ… **Erreurs humaines** (suppression accidentelle)
- âœ… **Catastrophes naturelles** (incendie, inondation)
- âœ… **Attaques malveillantes** (ransomware, sabotage)
- âœ… **Corruptions de donnÃ©es** (silencieuses ou brutales)

### Les 3 RÃ¨gles Ã  Retenir

```
3 = Production + 2 backups minimum
2 = Types de stockage diffÃ©rents
1 = Au moins une copie loin gÃ©ographiquement
```

### ImplÃ©mentation Minimale Viable

Pour une PME avec budget limitÃ© :

```
Copie 1 : Production PostgreSQL (SSD local)
Copie 2 : pg_basebackup quotidien (HDD externe)
Copie 3 : Sauvegardes hebdomadaires (S3 STANDARD_IA)

CoÃ»t : ~50â‚¬/mois
Protection : 99% des scÃ©narios
```

### ImplÃ©mentation RecommandÃ©e

Pour une entreprise avec base critique :

```
Copie 1 : Production PostgreSQL (SSD NVMe)
Copie 2a : pg_basebackup quotidien (SAN local)
Copie 2b : WAL archiving continu (NAS)
Copie 2c : Standby streaming replication (serveur distant)
Copie 3a : Sauvegardes cloud multi-rÃ©gion (S3)
Copie 3b : Exports logiques mensuels (Azure)

Protection : 99.99% des scÃ©narios
RTO : < 1 heure
RPO : < 1 minute
```

### Message Final

> "Il n'y a que deux types d'administrateurs de bases de donnÃ©es : ceux qui sauvegardent leurs donnÃ©es, et ceux qui vont commencer Ã  le faire."

Ne faites pas partie de la deuxiÃ¨me catÃ©gorie aprÃ¨s avoir perdu vos donnÃ©es. ImplÃ©mentez le 3-2-1 **aujourd'hui**.

---

## Ressources ComplÃ©mentaires

### Documentation et Standards

- [NIST Cybersecurity Framework - Backup Guidelines](https://www.nist.gov/)
- [US-CERT Backup Best Practices](https://www.cisa.gov/)
- ISO 27001 : Information Security Management

### Outils RecommandÃ©s

- **pgBackRest** : Gestion complÃ¨te 3-2-1
- **Barman** : Backup manager avec support multi-site
- **Restic** : Backup avec deduplication
- **Duplicity** : Backup incrÃ©mental chiffrÃ©

### Calcul de CoÃ»ts

- [AWS S3 Pricing Calculator](https://calculator.aws/)
- [Azure Storage Pricing](https://azure.microsoft.com/pricing/)
- [Google Cloud Storage Pricing](https://cloud.google.com/storage/pricing)

### Commandes de RÃ©fÃ©rence

```bash
# VÃ©rifier stratÃ©gie 3-2-1
/usr/local/bin/verify_321.sh

# Backup complet 3-2-1
/usr/local/bin/backup_321.sh

# Test restauration
/usr/local/bin/test_restore_321.sh

# Monitoring
SELECT * FROM pg_stat_archiver;
df -h /backups/local /mnt/nas
aws s3 ls s3://company-backups/
```

---


â­ï¸ [NouveautÃ© PG 18 : Data Checksums activÃ©s par dÃ©faut (--no-data-checksums pour dÃ©sactiver)](/16-administration-configuration-securite/12-data-checksums-pg18.md)
