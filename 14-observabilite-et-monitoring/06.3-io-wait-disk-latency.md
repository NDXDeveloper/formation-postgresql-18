üîù Retour au [Sommaire](/SOMMAIRE.md)

# 14.6.3. I/O Wait et Disk Latency

## Introduction

**I/O Wait** (attente d'entr√©e/sortie) et **Disk Latency** (latence disque) sont deux m√©triques fondamentales pour comprendre les performances de votre base de donn√©es PostgreSQL. Ces indicateurs r√©v√®lent si votre syst√®me passe trop de temps √† attendre les donn√©es stock√©es sur le disque.

Dans ce chapitre, nous allons d√©mystifier ces concepts souvent mal compris et vous donner les cl√©s pour identifier, mesurer et r√©soudre les probl√®mes de performance li√©s au disque.

---

## Comprendre les Concepts de Base

### Analogie : La Biblioth√®que

Imaginez que vous travaillez dans une biblioth√®que :

**Sc√©nario 1 : Biblioth√®que bien organis√©e**
- Vous demandez un livre
- Le biblioth√©caire le trouve en 5 secondes
- Vous pouvez continuer votre travail rapidement

**Sc√©nario 2 : Biblioth√®que d√©sorganis√©e**
- Vous demandez un livre
- Le biblioth√©caire cherche pendant 10 minutes
- **Vous attendez** sans rien pouvoir faire (I/O Wait)
- Le temps de recherche est long (Latency)

C'est exactement ce qui se passe avec PostgreSQL et le disque !

### Les Acteurs en Pr√©sence

#### 1. Le CPU (Processeur)

Le cerveau de votre serveur qui ex√©cute les calculs et traite les requ√™tes SQL.

**Caract√©ristique :** Ultra-rapide (milliards d'op√©rations par seconde)

#### 2. La RAM (M√©moire)

Le cache o√π sont stock√©es les donn√©es fr√©quemment utilis√©es.

**Caract√©ristique :** Tr√®s rapide (~100 nanosecondes par acc√®s)

#### 3. Le Disque (SSD ou HDD)

Le stockage permanent o√π r√©sident toutes vos donn√©es.

**Caract√©ristique :** Beaucoup plus lent que la RAM
- **SSD** : ~100 microsecondes (1000√ó plus lent que la RAM)
- **HDD** : ~10 millisecondes (100 000√ó plus lent que la RAM)

### Le Probl√®me de Vitesse

PostgreSQL a besoin de donn√©es stock√©es sur le disque, mais :

```
Vitesse CPU    : 1 000 000 000 op√©rations/seconde
Vitesse RAM    :    10 000 000 acc√®s/seconde
Vitesse SSD    :        10 000 acc√®s/seconde
Vitesse HDD    :           100 acc√®s/seconde
```

Le disque est le **goulot d'√©tranglement** majeur des bases de donn√©es.

---

## Qu'est-ce que l'I/O Wait ?

### D√©finition Simple

**I/O Wait** (Input/Output Wait) est le **pourcentage de temps pendant lequel le CPU attend que le disque r√©ponde** au lieu de traiter des donn√©es.

**En termes simples :** C'est du temps perdu √† attendre.

### Visualisation

```
Sans I/O Wait (Id√©al) :
CPU : [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% productif
Disque : Rapide, pas d'attente

Avec I/O Wait (Probl√©matique) :
CPU : [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 50% productif, 50% en attente
       ‚Üë     ‚Üë     ‚Üë     ‚Üë
       Travail Attend Travail Attend
```

Les zones `‚ñë‚ñë‚ñë‚ñë` repr√©sentent le temps o√π le CPU ne fait **rien** et attend simplement que le disque fournisse les donn√©es.

### Pourquoi c'est un Probl√®me

#### Gaspillage de Ressources

Vous payez pour un CPU puissant qui passe la moiti√© de son temps √† attendre !

**Exemple concret :**
- Serveur avec CPU √† 3 GHz (puissant)
- I/O Wait √† 60%
- **R√©sultat :** Vous n'utilisez que 40% de votre CPU

#### Performances D√©grad√©es

Les requ√™tes prennent beaucoup plus de temps √† s'ex√©cuter.

**Exemple :**
- Requ√™te qui devrait prendre 100 ms de calcul CPU
- Avec 80% d'I/O Wait : **500 ms r√©els** (5√ó plus lent)

---

## Qu'est-ce que la Disk Latency ?

### D√©finition Simple

La **Disk Latency** (latence disque) est le **temps n√©cessaire pour que le disque r√©ponde √† une demande de lecture ou d'√©criture**.

**En termes simples :** C'est le d√©lai de r√©ponse du disque.

### Composantes de la Latency

#### 1. Seek Time (Temps de Recherche) - HDD uniquement

Le temps pour que la t√™te de lecture se positionne au bon endroit sur le plateau.

**HDD typique :** 5-10 millisecondes

**SSD :** N/A (pas de pi√®ces mobiles)

#### 2. Rotational Latency (Latence de Rotation) - HDD uniquement

Le temps d'attente pour que le secteur passe sous la t√™te de lecture.

**HDD 7200 RPM :** ~4 millisecondes en moyenne

**SSD :** N/A

#### 3. Transfer Time (Temps de Transfert)

Le temps pour transf√©rer les donn√©es du disque vers la RAM.

**D√©pend de :**
- Taille des donn√©es
- Interface (SATA, NVMe, etc.)
- Bande passante disponible

### Ordres de Grandeur

| Type de Disque | Latency Typique | Utilisation |
|----------------|-----------------|-------------|
| **HDD 7200 RPM** | 10-15 ms | Archivage, backup |
| **HDD 15000 RPM** | 3-5 ms | Serveurs (obsol√®te) |
| **SSD SATA** | 0.1-1 ms | Standard moderne |
| **SSD NVMe** | 0.02-0.1 ms | Haute performance |
| **RAM** | 0.0001 ms (100 ns) | Cache |

**Observation :** M√™me un SSD est 1000√ó plus lent que la RAM !

---

## Impact sur PostgreSQL

### Op√©rations Sensibles √† l'I/O

#### 1. Scans S√©quentiels (Sequential Scans)

Lorsque PostgreSQL doit lire une table enti√®re sans index.

**Exemple :**
```sql
SELECT * FROM big_table WHERE status = 'active';
-- Sans index sur 'status' : scan complet
```

**Impact I/O :** Tr√®s √©lev√© si la table est volumineuse et ne tient pas en cache.

#### 2. Index Scans sur Donn√©es Non Cach√©es

M√™me avec des index, si les donn√©es ne sont pas en cache, il faut les lire depuis le disque.

**Exemple :**
```sql
SELECT * FROM orders WHERE customer_id = 12345;
-- Avec index : rapide si en cache, lent si sur disque
```

#### 3. √âcritures (Writes)

Les `INSERT`, `UPDATE`, `DELETE` doivent √©crire sur le disque.

**Particuli√®rement co√ªteux :**
- √âcriture dans le WAL (Write-Ahead Log)
- Mise √† jour des index
- Checkpoints (synchronisation disque)

#### 4. Checkpoints

Les checkpoints synchronisent les donn√©es de la RAM vers le disque.

**Impact :** Pic d'√©criture disque, potentiellement forte latency.

#### 5. VACUUM

Le nettoyage des lignes mortes n√©cessite de lire et r√©√©crire des pages.

**Impact :** I/O √©lev√©, surtout sur tables volumineuses.

### Sympt√¥mes de Probl√®mes I/O

| Sympt√¥me | Signification |
|----------|---------------|
| Requ√™tes lentes malgr√© bons index | Donn√©es pas en cache, latency √©lev√©e |
| Pics de lenteur r√©guliers | Probablement pendant les checkpoints |
| D√©gradation progressive | Bloat ou cache insuffisant |
| Serveur "idle" mais lent | CPU en I/O Wait |
| Sauvegardes tr√®s longues | Disque satur√© ou lent |

---

## Mesurer l'I/O Wait

### Au Niveau Syst√®me (Linux)

#### 1. La Commande `top`

```bash
top
```

**Regardez la ligne `%Cpu(s)` :**
```
%Cpu(s):  15.2 us,  2.1 sy,  0.0 ni, 45.3 id, 37.4 wa,  0.0 hi,  0.0 si,  0.0 st
                                              ‚Üë‚Üë‚Üë‚Üë
                                              I/O Wait = 37.4%
```

**Interpr√©tation :**
- **us** (user) : 15.2% en calculs utilisateur
- **sy** (system) : 2.1% en appels syst√®me
- **id** (idle) : 45.3% inactif
- **wa** (wait) : **37.4% en attente I/O** ‚Üê Probl√®me !

#### Seuils d'Interpr√©tation

| I/O Wait | √âtat | Action |
|----------|------|--------|
| **< 5%** | üü¢ Normal | RAS |
| **5-15%** | üü° Acceptable | Surveiller |
| **15-30%** | üü† Pr√©occupant | Investiguer |
| **> 30%** | üî¥ Critique | Action urgente |

#### 2. La Commande `iostat`

```bash
iostat -x 2
```

**Sortie exemple :**
```
Device    r/s   w/s   rkB/s   wkB/s  await  svctm  %util
sda      150.0  80.0  6000.0  3200.0  25.50  12.30  95.00
```

**Colonnes importantes :**
- **r/s** : Lectures par seconde
- **w/s** : √âcritures par seconde
- **await** : Temps d'attente moyen (ms) ‚Üê **Latency**
- **%util** : Utilisation du disque (%)

**Interpr√©tation :**
```
await = 25.50 ms  ‚Üí Latency tr√®s √©lev√©e (probl√®me !)
%util = 95%       ‚Üí Disque satur√©
```

#### Seuils pour `await` (Latency)

| Type Disque | Normal | Attention | Probl√®me |
|-------------|--------|-----------|----------|
| **SSD NVMe** | < 1 ms | 1-5 ms | > 5 ms |
| **SSD SATA** | < 5 ms | 5-10 ms | > 10 ms |
| **HDD** | < 10 ms | 10-20 ms | > 20 ms |

#### 3. La Commande `iotop`

Comme `top`, mais pour l'I/O :

```bash
sudo iotop -o
```

**Affiche :**
- Quels processus g√©n√®rent de l'I/O
- Vitesse de lecture/√©criture par processus
- Pourcentage d'I/O par processus

**Utile pour :** Identifier quel processus PostgreSQL consomme le plus d'I/O.

### Au Niveau PostgreSQL

#### 1. Extension pg_stat_statements

Cette extension fournit des statistiques sur les requ√™tes, y compris l'I/O.

**Installation :**
```sql
CREATE EXTENSION pg_stat_statements;
```

**Requ√™te pour voir les requ√™tes consommant le plus d'I/O :**
```sql
SELECT
    query,
    calls,
    total_exec_time / 1000 AS total_time_seconds,
    blk_read_time / 1000 AS io_read_time_seconds,
    blk_write_time / 1000 AS io_write_time_seconds,
    round((blk_read_time + blk_write_time) / total_exec_time * 100, 2) AS io_percent
FROM pg_stat_statements
WHERE total_exec_time > 0
ORDER BY (blk_read_time + blk_write_time) DESC
LIMIT 20;
```

**Colonnes :**
- **io_read_time_seconds** : Temps pass√© √† lire depuis le disque
- **io_write_time_seconds** : Temps pass√© √† √©crire sur le disque
- **io_percent** : Pourcentage du temps total pass√© en I/O

**Interpr√©tation :**
```
io_percent > 50% ‚Üí La requ√™te passe plus de temps en I/O qu'en calcul
‚Üí Optimisation n√©cessaire (index, cache, requ√™te)
```

#### 2. Nouveaut√©s PostgreSQL 18 : Statistiques I/O par Backend

PostgreSQL 18 offre des statistiques I/O d√©taill√©es par processus backend.

**Requ√™te :**
```sql
SELECT
    pid,
    usename,
    application_name,
    state,
    reads,
    writes,
    read_time,
    write_time
FROM pg_stat_io
WHERE backend_type = 'client backend'
ORDER BY read_time + write_time DESC;
```

**Utilit√© :** Identifier les sessions qui g√©n√®rent le plus d'I/O en temps r√©el.

#### 3. Vues Syst√®me pour l'I/O

**pg_statio_user_tables** : Statistiques I/O par table

```sql
SELECT
    schemaname,
    relname,
    heap_blks_read AS disk_reads,
    heap_blks_hit AS cache_hits,
    idx_blks_read AS index_disk_reads,
    idx_blks_hit AS index_cache_hits,
    round(
        (heap_blks_hit::numeric / NULLIF(heap_blks_hit + heap_blks_read, 0)) * 100,
        2
    ) AS cache_hit_ratio
FROM pg_statio_user_tables
WHERE heap_blks_read > 0
ORDER BY heap_blks_read DESC;
```

**Interpr√©tation :**
- **heap_blks_read** √©lev√© ‚Üí Beaucoup de lectures disque sur cette table
- **cache_hit_ratio** faible ‚Üí Donn√©es rarement en cache

---

## Mesurer la Disk Latency

### Au Niveau Syst√®me

#### 1. Avec `iostat` (D√©j√† vu)

```bash
iostat -x 1
```

La colonne **await** donne la latency moyenne.

#### 2. Benchmark avec `fio` (Flexible I/O Tester)

**fio** permet de tester les performances r√©elles de votre disque.

**Installation :**
```bash
sudo apt install fio  # Ubuntu/Debian
```

**Test de Lecture Al√©atoire (Simule lecture BDD) :**
```bash
fio --name=random-read \
    --ioengine=libaio \
    --iodepth=16 \
    --rw=randread \
    --bs=8k \
    --direct=1 \
    --size=1G \
    --numjobs=4 \
    --runtime=60 \
    --group_reporting
```

**R√©sultat exemple :**
```
read: IOPS=25000, BW=195MiB/s (205MB/s)
  lat (usec): min=50, max=5000, avg=250.5
```

**Interpr√©tation :**
- **IOPS** : 25 000 op√©rations de lecture par seconde
- **avg latency** : 250 ¬µs (0.25 ms) ‚Üê Excellent pour un SSD

#### Seuils de Performance

| M√©trique | SSD NVMe | SSD SATA | HDD |
|----------|----------|----------|-----|
| **IOPS Random Read** | 100K-500K | 10K-100K | 100-200 |
| **Latency** | < 0.1 ms | 0.1-1 ms | 5-15 ms |
| **Throughput** | 2-7 GB/s | 500 MB/s | 150 MB/s |

#### 3. Avec `dd` (Rapide mais moins pr√©cis)

```bash
# Test √©criture s√©quentielle
dd if=/dev/zero of=/tmp/testfile bs=1M count=1000 oflag=direct
```

**R√©sultat :**
```
1048576000 bytes (1.0 GB) copied, 2.5 s, 419 MB/s
```

**Utile pour :** V√©rifier rapidement si le disque fonctionne normalement.

### Au Niveau PostgreSQL

#### Extension pg_stat_io (PostgreSQL 13+)

```sql
SELECT * FROM pg_stat_io;
```

**Colonnes pertinentes :**
- **reads** : Nombre de lectures
- **writes** : Nombre d'√©critures
- **read_time** : Temps total de lecture (ms)
- **write_time** : Temps total d'√©criture (ms)

**Calculer la latency moyenne :**
```sql
SELECT
    backend_type,
    reads,
    read_time,
    CASE WHEN reads > 0
        THEN round(read_time::numeric / reads, 2)
        ELSE 0
    END AS avg_read_latency_ms
FROM pg_stat_io
WHERE reads > 0
ORDER BY avg_read_latency_ms DESC;
```

---

## Causes Fr√©quentes de Probl√®mes I/O

### 1. Cache Insuffisant (shared_buffers trop petit)

**Probl√®me :** Les donn√©es les plus utilis√©es ne tiennent pas en m√©moire.

**Sympt√¥me :**
- Cache Hit Ratio < 95%
- I/O Wait √©lev√©

**Solution :**
```ini
# Dans postgresql.conf
shared_buffers = 8GB  # Augmenter (25% de RAM recommand√©)
```

### 2. Requ√™tes Non Optimis√©es

**Probl√®me :** Scans s√©quentiels sur de grosses tables sans index.

**Sympt√¥me :**
```sql
EXPLAIN ANALYZE SELECT * FROM big_table WHERE status = 'active';
-- R√©sultat : Seq Scan on big_table (rows=10000000)
```

**Solution :**
```sql
CREATE INDEX idx_status ON big_table(status);
```

### 3. Disque Lent ou Satur√©

**Probl√®me :** Disque HDD ou SSD vieillissant.

**Sympt√¥me :**
- `iostat` montre `%util` proche de 100%
- `await` tr√®s √©lev√©

**Solution :**
- Migrer vers SSD NVMe
- Utiliser RAID pour parall√©liser les I/O
- Distribuer les donn√©es sur plusieurs disques

### 4. Checkpoints Trop Fr√©quents

**Probl√®me :** Les checkpoints √©crivent massivement sur le disque.

**Sympt√¥me :**
- Pics de lenteur r√©guliers (ex: toutes les 5 minutes)
- Logs montrant des checkpoints fr√©quents

**V√©rification :**
```sql
SELECT
    checkpoints_timed,
    checkpoints_req,
    checkpoint_write_time,
    checkpoint_sync_time
FROM pg_stat_bgwriter;
```

**Solution :**
```ini
# Dans postgresql.conf
max_wal_size = 4GB               # Augmenter
checkpoint_timeout = 15min       # Augmenter
checkpoint_completion_target = 0.9  # Lisser les √©critures
```

### 5. WAL sur le M√™me Disque que les Donn√©es

**Probl√®me :** Les √©critures WAL et les donn√©es se font concurrence.

**Sympt√¥me :**
- Forte contention I/O lors d'√©critures massives

**Solution :**
- Placer le WAL sur un disque d√©di√© (ou partition)
```bash
# D√©placer pg_wal sur un autre disque
mv /var/lib/postgresql/data/pg_wal /mnt/fast-disk/pg_wal
ln -s /mnt/fast-disk/pg_wal /var/lib/postgresql/data/pg_wal
```

### 6. Autovacuum Trop Agressif ou Insuffisant

**Probl√®me 1 (Trop agressif) :**
- Autovacuum consomme trop d'I/O en parall√®le des requ√™tes

**Solution :**
```ini
autovacuum_vacuum_cost_delay = 10ms  # Ralentir l'autovacuum
```

**Probl√®me 2 (Insuffisant) :**
- Bloat √©lev√© ‚Üí Plus de donn√©es √† lire ‚Üí Plus d'I/O

**Solution :**
```sql
-- Voir section 14.6.2 sur le Bloat
```

### 7. RAID Mal Configur√©

**Probl√®me :** RAID software mal param√©tr√© ou RAID hardware avec cache d√©sactiv√©.

**Solution :**
- Activer le write cache sur RAID hardware (avec BBU)
- Utiliser RAID 10 plut√¥t que RAID 5 pour PostgreSQL
- V√©rifier les param√®tres kernel (scheduler I/O)

---

## Optimisations I/O pour PostgreSQL

### 1. Augmenter le Cache PostgreSQL

```ini
# postgresql.conf
shared_buffers = 8GB                # 25% de la RAM
effective_cache_size = 24GB         # 75% de la RAM (estimation pour planificateur)
```

**Effet :** Plus de donn√©es en RAM = Moins d'I/O disque.

### 2. Optimiser les Param√®tres WAL

```ini
# √âcriture WAL
wal_buffers = 16MB                  # Buffer pour WAL
wal_writer_delay = 200ms            # Fr√©quence d'√©criture WAL

# Checkpoints
max_wal_size = 4GB
checkpoint_timeout = 15min
checkpoint_completion_target = 0.9  # Lisser les √©critures sur 90% de l'intervalle
```

**Effet :** R√©duit les pics d'√©criture, am√©liore la latency.

### 3. Utiliser Partitionnement et Tablespaces

**Partitionnement :** Diviser les grosses tables.

```sql
-- Exemple : Table de logs partitionn√©e par mois
CREATE TABLE logs (
    id BIGSERIAL,
    created_at TIMESTAMP,
    message TEXT
) PARTITION BY RANGE (created_at);

-- Partitions
CREATE TABLE logs_2024_11 PARTITION OF logs
    FOR VALUES FROM ('2024-11-01') TO ('2024-12-01');
```

**Tablespaces :** Placer diff√©rentes tables sur diff√©rents disques.

```sql
-- Cr√©er tablespace sur disque rapide
CREATE TABLESPACE fast_storage LOCATION '/mnt/nvme/pg_data';

-- D√©placer table critique
ALTER TABLE critical_table SET TABLESPACE fast_storage;
```

**Effet :** Distribue l'I/O, r√©duit la contention.

### 4. Nouveaut√© PostgreSQL 18 : Sous-syst√®me I/O Asynchrone (AIO)

PostgreSQL 18 introduit l'I/O asynchrone qui peut am√©liorer les performances jusqu'√† **3√ó sur certaines charges**.

**Configuration :**
```ini
# postgresql.conf
io_method = 'async'  # Nouveau d√©faut dans PG 18 (√©tait 'sync')
```

**Principe :** Au lieu d'attendre chaque op√©ration I/O individuellement, PostgreSQL peut lancer plusieurs op√©rations en parall√®le.

**B√©n√©fices :**
- R√©duction de l'I/O Wait
- Meilleur parall√©lisme des lectures
- Am√©lioration significative sur SSD NVMe

**Compatibilit√© :** N√©cessite un kernel Linux r√©cent (>= 5.1 pour io_uring).

### 5. Optimiser les Requ√™tes

#### Utiliser EXPLAIN ANALYZE

```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE customer_id = 123;
```

**Regardez :**
- **Buffers: shared read=XXX** ‚Üí Nombre de blocs lus depuis le disque
- **I/O Timings: read=XX.XX** ‚Üí Temps pass√© en I/O (si track_io_timing=on)

**Activation du tracking I/O :**
```sql
ALTER SYSTEM SET track_io_timing = on;
SELECT pg_reload_conf();
```

#### Ajouter des Index

```sql
-- Avant : Seq Scan (lent)
SELECT * FROM users WHERE email = 'test@example.com';

-- Cr√©er index
CREATE INDEX idx_users_email ON users(email);

-- Apr√®s : Index Scan (rapide, moins d'I/O)
```

### 6. Connection Pooling

**Probl√®me :** Trop de connexions simultan√©es = contention I/O.

**Solution :** Utiliser PgBouncer pour limiter les connexions actives.

```ini
# pgbouncer.ini
default_pool_size = 25        # Nombre de connexions PostgreSQL
max_client_conn = 500         # Nombre de clients accept√©s
pool_mode = transaction       # Mode transaction
```

**Effet :** R√©duit la charge globale, am√©liore les performances I/O.

### 7. Utiliser des SSD et RAID Appropri√©

**Recommandations :**

| Configuration | Usage | Performance |
|---------------|-------|-------------|
| **SSD NVMe seul** | Petite/Moyenne BDD | Excellent |
| **RAID 10 SSD** | Production haute perf | Excellent |
| **RAID 1 SSD** | Production standard | Bon |
| **HDD RAID 10** | Legacy/Budget | Acceptable |
| **HDD seul** | D√©veloppement uniquement | M√©diocre |

**√Ä √©viter :**
- RAID 5/6 pour PostgreSQL (p√©nalit√© √©criture)
- HDD en production moderne
- SSD SATA satur√© (pr√©f√©rer NVMe)

---

## Monitoring en Continu

### M√©triques √† Surveiller

#### 1. I/O Wait (Syst√®me)

**Outil :** Grafana + Node Exporter

**Alerte :**
```
avg(iowait) > 15% pendant 5 minutes ‚Üí Alerte
avg(iowait) > 30% ‚Üí Alerte critique
```

#### 2. Disk Latency (Syst√®me)

**Outil :** Grafana + Node Exporter

**Alerte :**
```
SSD : avg_latency > 5ms ‚Üí Alerte
HDD : avg_latency > 20ms ‚Üí Alerte
```

#### 3. IOPS et Throughput

**M√©triques :**
- Lectures/sec
- √âcritures/sec
- MB/sec lus
- MB/sec √©crits

**Alerte :** D√©tecter les pics anormaux.

#### 4. Checkpoint Frequency (PostgreSQL)

**Requ√™te :**
```sql
SELECT
    checkpoints_timed,
    checkpoints_req,
    round(checkpoints_req::numeric / (checkpoints_timed + checkpoints_req) * 100, 2) AS forced_checkpoint_pct
FROM pg_stat_bgwriter;
```

**Seuil :** `forced_checkpoint_pct` > 10% ‚Üí Augmenter max_wal_size

#### 5. Top Requ√™tes I/O (PostgreSQL)

**Requ√™te automatis√©e :**
```sql
-- √Ä ex√©cuter r√©guli√®rement
SELECT
    substring(query, 1, 80) AS query_short,
    calls,
    round((blk_read_time + blk_write_time) / 1000, 2) AS total_io_seconds,
    round((blk_read_time + blk_write_time) / calls, 2) AS avg_io_ms_per_call
FROM pg_stat_statements
WHERE (blk_read_time + blk_write_time) > 0
ORDER BY (blk_read_time + blk_write_time) DESC
LIMIT 10;
```

### Dashboard Recommand√©

**Panels Grafana :**

1. **I/O Wait %** (Time series)
   - Ligne d'alerte √† 15% et 30%

2. **Disk Latency** (Time series)
   - S√©par√© read/write
   - Ligne d'alerte selon type disque

3. **IOPS** (Time series)
   - Reads + Writes

4. **Throughput MB/s** (Time series)

5. **Top 10 Tables I/O** (Table)
   - Nombre de disk reads par table

6. **Top 10 Queries I/O** (Table)
   - Temps I/O total par requ√™te

7. **Checkpoint Frequency** (Time series)
   - Timed vs Requested

---

## Troubleshooting : Sc√©narios Courants

### Sc√©nario 1 : I/O Wait soudainement √©lev√©

**Sympt√¥mes :**
- I/O Wait passe de 5% √† 40%
- Requ√™tes lentes
- Utilisateurs se plaignent

**Diagnostic :**

```bash
# 1. V√©rifier les processus
sudo iotop -o

# 2. V√©rifier PostgreSQL
SELECT * FROM pg_stat_activity WHERE state = 'active';

# 3. V√©rifier les requ√™tes lentes
SELECT * FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 10;
```

**Causes fr√©quentes :**
- Grosse requ√™te analytique lanc√©e
- VACUUM FULL en cours
- Backup/dump en cours
- Application qui fait du batch processing

**Action :**
- Tuer la requ√™te probl√©matique si n√©cessaire
- Planifier ces op√©rations en heures creuses

### Sc√©nario 2 : Latency √©lev√©e constante

**Sympt√¥mes :**
- `await` dans iostat > 50ms en permanence
- Base de donn√©es globalement lente

**Diagnostic :**

```bash
# V√©rifier √©tat disque
iostat -x 2 10

# V√©rifier RAID
cat /proc/mdstat  # Pour software RAID

# Tester performance disque
fio --name=test --rw=randread --bs=8k --size=1G
```

**Causes fr√©quentes :**
- Disque d√©faillant (√† remplacer)
- RAID d√©grad√©
- Firmware disque obsol√®te
- Saturation I/O constante

**Action :**
- V√©rifier sant√© disque (SMART)
- Remplacer disque si n√©cessaire
- Upgrader vers SSD si HDD

### Sc√©nario 3 : Performances OK puis d√©gradation progressive

**Sympt√¥mes :**
- Performances d√©gradent sur plusieurs jours/semaines
- I/O Wait augmente progressivement

**Diagnostic :**

```sql
-- V√©rifier bloat
SELECT * FROM bloat_monitor;  -- Vue cr√©√©e section 14.6.2

-- V√©rifier cache hit ratio
SELECT * FROM cache_hit_ratio_view;  -- Vue cr√©√©e section 14.6.1

-- V√©rifier taille tables
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 20;
```

**Causes fr√©quentes :**
- Bloat qui s'accumule
- Donn√©es qui grossissent et ne tiennent plus en cache
- Index fragment√©s

**Action :**
- Ex√©cuter VACUUM ANALYZE
- √âventuellement VACUUM FULL en maintenance
- Augmenter shared_buffers si possible
- REINDEX si index tr√®s fragment√©s

---

## Outils Avanc√©s

### 1. pg_stat_kcache (Extension)

Fournit des statistiques syst√®me d√©taill√©es par requ√™te (CPU, I/O physique).

**Installation :**
```sql
CREATE EXTENSION pg_stat_kcache;
```

**Usage :**
```sql
SELECT
    query,
    user_time,
    system_time,
    reads,
    writes
FROM pg_stat_kcache
JOIN pg_stat_statements USING (queryid)
ORDER BY reads + writes DESC
LIMIT 10;
```

### 2. pgBadger

Analyseur de logs PostgreSQL qui g√©n√®re des rapports HTML d√©taill√©s incluant des m√©triques I/O.

**Usage :**
```bash
pgbadger /var/log/postgresql/postgresql-*.log -o report.html
```

**Affiche :**
- Requ√™tes les plus lentes
- I/O par requ√™te
- Distribution temporelle des charges

### 3. pgtune

Outil en ligne pour g√©n√©rer une configuration optimale selon votre mat√©riel.

**URL :** https://pgtune.leopard.in.ua/

**Entr√©es :**
- Type de disque (SSD/HDD)
- RAM disponible
- Type de charge (OLTP/OLAP/Mixed)

**Sortie :** Configuration postgresql.conf recommand√©e.

---

## Questions Fr√©quentes (FAQ)

### Q1 : Est-ce normal d'avoir un peu d'I/O Wait ?

**R√©ponse :** Oui, un I/O Wait de 1-5% est normal et acceptable. C'est au-del√† de 15% que cela devient pr√©occupant.

### Q2 : Mon I/O Wait est √† 0% mais ma base est lente, pourquoi ?

**R√©ponse :** Le probl√®me est ailleurs :
- CPU satur√© (calculs lourds)
- Verrous (locks)
- Requ√™tes mal optimis√©es avec beaucoup de calculs
- R√©seau lent (pour connexions distantes)

### Q3 : SSD vs HDD : quelle diff√©rence en pratique ?

**R√©ponse :**
- **SSD** : Latency < 1ms, parfait pour BDD
- **HDD** : Latency 10-15ms, 10-100√ó plus lent

Pour PostgreSQL, un SSD fait une **diff√©rence √©norme**.

### Q4 : Puis-je avoir 0% d'I/O Wait ?

**R√©ponse :** Th√©oriquement oui, si :
- Toutes les donn√©es tiennent en RAM (cache 100%)
- Pas d'√©critures en cours

En pratique, 0-2% est d√©j√† excellent.

### Q5 : RAID am√©liore-t-il les performances I/O ?

**R√©ponse :** D√©pend du type :
- **RAID 0** : Oui (mais aucune redondance)
- **RAID 1** : Lectures am√©lior√©es, √©critures identiques
- **RAID 10** : Oui, meilleur compromis perf/s√©curit√©
- **RAID 5/6** : P√©nalit√© sur √©critures (√©viter pour PostgreSQL)

### Q6 : track_io_timing a-t-il un impact sur les performances ?

**R√©ponse :** Tr√®s faible (< 1% overhead). Les b√©n√©fices du monitoring d√©passent largement le co√ªt.

```sql
ALTER SYSTEM SET track_io_timing = on;  -- Recommand√©
```

---

## Points Cl√©s √† Retenir

‚úÖ **I/O Wait = Temps o√π le CPU attend le disque**
   - M√©trique syst√®me cruciale
   - Seuils : < 5% OK, > 15% probl√©matique

‚úÖ **Disk Latency = Temps de r√©ponse du disque**
   - SSD : < 1ms, HDD : 10-15ms
   - Mesurable avec iostat (colonne await)

‚úÖ **Impact sur PostgreSQL :**
   - Scans s√©quentiels tr√®s sensibles √† l'I/O
   - Checkpoints = pics d'√©criture disque
   - Cache insuffisant ‚Üí Plus d'I/O

‚úÖ **Mesure :**
   - Syst√®me : top, iostat, iotop
   - PostgreSQL : pg_stat_statements, pg_stat_io
   - PostgreSQL 18 : Statistiques I/O par backend

‚úÖ **Optimisations principales :**
   - Augmenter shared_buffers (cache)
   - Utiliser des index appropri√©s
   - Migrer vers SSD (NVMe si possible)
   - Optimiser checkpoints
   - PostgreSQL 18 : Activer I/O asynchrone

‚úÖ **Monitoring continu essentiel :**
   - Alerte si I/O Wait > 15%
   - Alerte si Latency anormale pour type disque
   - Surveiller top requ√™tes I/O

‚úÖ **Causes fr√©quentes :**
   - Cache trop petit
   - Requ√™tes non optimis√©es
   - Disque lent ou satur√©
   - Bloat excessif
   - Checkpoints trop fr√©quents

---

## Conclusion

L'**I/O Wait** et la **Disk Latency** sont des indicateurs vitaux de la sant√© de votre base de donn√©es PostgreSQL. Un syst√®me avec un I/O Wait √©lev√© ou une latency importante verra ses performances drastiquement r√©duites, peu importe la puissance du CPU ou la qualit√© de vos requ√™tes SQL.

Les points essentiels √† retenir :

1. **Comprendre** : Le disque est le goulot d'√©tranglement principal
2. **Mesurer** : Utiliser iostat, top et pg_stat_statements r√©guli√®rement
3. **Optimiser** : Cache, SSD, index, configuration WAL
4. **Monitorer** : Surveillance continue avec alertes appropri√©es

Les investissements les plus rentables pour r√©duire l'I/O :
- ü•á **Migration vers SSD NVMe** : Impact massif
- ü•à **Augmentation de RAM** : Plus de cache = moins d'I/O
- ü•â **Optimisation requ√™tes et index** : R√©duit les lectures inutiles

Avec PostgreSQL 18 et son nouveau sous-syst√®me I/O asynchrone, les performances I/O peuvent √™tre am√©lior√©es jusqu'√† 3√ó sur certaines charges, rendant le SGBD encore plus performant sur du mat√©riel moderne.

Un monitoring proactif et une bonne compr√©hension de ces m√©triques vous permettront de maintenir votre PostgreSQL rapide et r√©actif, m√™me sous forte charge.

---


‚è≠Ô∏è [Connexions actives et pools satur√©s](/14-observabilite-et-monitoring/06.4-connexions-actives-pools.md)
