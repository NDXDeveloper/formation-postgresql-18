ðŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 14.5. Analyse des logs : Configuration et interprÃ©tation (log_line_prefix, auto_explain)

## Introduction

Les **logs** (journaux) de PostgreSQL sont comme le journal de bord d'un navire : ils enregistrent tout ce qui se passe sur votre serveur de base de donnÃ©es. Bien configurÃ©s et correctement analysÃ©s, ils deviennent votre outil de diagnostic le plus puissant.

Dans cette section, nous allons explorer :
- Comment configurer les logs pour capturer les informations essentielles
- Comment personnaliser le format des logs avec `log_line_prefix`
- Comment utiliser `auto_explain` pour identifier automatiquement les requÃªtes lentes
- Comment interprÃ©ter et analyser efficacement vos logs

**Pourquoi c'est crucial ?** Sans logs bien configurÃ©s, vous Ãªtes aveugle. Avec eux, vous pouvez :
- Diagnostiquer les erreurs et les ralentissements
- Identifier les requÃªtes problÃ©matiques
- Auditer l'activitÃ© (qui fait quoi, quand)
- Analyser les tendances et anticiper les problÃ¨mes

---

## Partie 1 : Comprendre les Logs PostgreSQL

### Qu'est-ce qu'un log ?

Un **log** (ou journal) est un fichier texte oÃ¹ PostgreSQL enregistre des Ã©vÃ©nements, des erreurs, et des informations sur son fonctionnement.

**Analogie** : Les logs sont comme les camÃ©ras de surveillance d'un magasin. Elles enregistrent tout ce qui se passe, et quand il y a un problÃ¨me (vol, incident), vous pouvez revenir en arriÃ¨re et voir exactement ce qui s'est passÃ©.

### Que trouve-t-on dans les logs ?

PostgreSQL peut enregistrer :
- **Erreurs** : Connexions Ã©chouÃ©es, requÃªtes invalides, deadlocks
- **Avertissements** : ProblÃ¨mes potentiels, dÃ©prÃ©ciations
- **Informations** : DÃ©marrage/arrÃªt du serveur, checkpoints, connexions
- **RequÃªtes** : Les requÃªtes SQL exÃ©cutÃ©es (si configurÃ©)
- **Performances** : Temps d'exÃ©cution des requÃªtes lentes
- **Audit** : Qui s'est connectÃ©, quand, depuis oÃ¹

### OÃ¹ sont les logs ?

La localisation des logs dÃ©pend de votre configuration :

**Linux (Debian/Ubuntu)** :
```
/var/log/postgresql/postgresql-18-main.log
```

**Linux (Red Hat/CentOS)** :
```
/var/lib/pgsql/18/data/log/
```

**macOS (Homebrew)** :
```
/opt/homebrew/var/log/postgresql@18.log
```

**Windows** :
```
C:\Program Files\PostgreSQL\18\data\log\
```

Pour trouver l'emplacement exact depuis psql :
```sql
SHOW log_directory;
SHOW log_filename;
```

### Types de destination des logs

PostgreSQL peut envoyer les logs vers diffÃ©rentes destinations :

1. **stderr** : Sortie d'erreur standard (capture par systemd/journald sur Linux)
2. **csvlog** : Format CSV structurÃ© (plus facile Ã  analyser)
3. **jsonlog** : Format JSON (PostgreSQL 15+, idÃ©al pour Elasticsearch/Splunk)
4. **syslog** : SystÃ¨me de logs Unix/Linux centralisÃ©
5. **eventlog** : Journal d'Ã©vÃ©nements Windows

**Configuration recommandÃ©e** :
```conf
# Dans postgresql.conf
logging_collector = on            # Active la collecte de logs
log_destination = 'stderr'        # Ou 'csvlog' pour analyse automatisÃ©e
log_directory = 'log'             # RÃ©pertoire relatif Ã  PGDATA
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'  # Un fichier par dÃ©marrage
log_rotation_age = 1d             # Rotation quotidienne
log_rotation_size = 100MB         # Rotation si > 100 MB
```

---

## Partie 2 : Configurer les Logs - Les ParamÃ¨tres Essentiels

### Vue d'ensemble des paramÃ¨tres de logging

PostgreSQL offre plus de 30 paramÃ¨tres pour contrÃ´ler le logging. Voici les plus importants :

| ParamÃ¨tre | Description | Valeur recommandÃ©e |
|-----------|-------------|-------------------|
| `log_min_messages` | Niveau minimum de messages Ã  logger | `warning` (production) |
| `log_min_error_statement` | Niveau minimum pour logger les requÃªtes avec erreur | `error` |
| `log_min_duration_statement` | Logger les requÃªtes plus lentes que X ms | `1000` (1 seconde) |
| `log_connections` | Logger les connexions | `on` |
| `log_disconnections` | Logger les dÃ©connexions | `on` |
| `log_duration` | Logger la durÃ©e de chaque requÃªte | `off` (utiliser log_min_duration_statement) |
| `log_statement` | Quelles requÃªtes logger | `none` ou `ddl` |
| `log_checkpoints` | Logger les checkpoints | `on` |
| `log_lock_waits` | Logger les attentes de locks | `on` |
| `log_temp_files` | Logger la crÃ©ation de fichiers temporaires | `0` (tous) |

### Configuration dÃ©taillÃ©e : ParamÃ¨tre par paramÃ¨tre

#### 1. log_min_messages

ContrÃ´le le niveau minimum de gravitÃ© des messages Ã  enregistrer.

**Niveaux disponibles (du moins au plus grave)** :
- `DEBUG5`, `DEBUG4`, `DEBUG3`, `DEBUG2`, `DEBUG1` : DÃ©bogage trÃ¨s verbeux
- `INFO` : Informations gÃ©nÃ©rales
- `NOTICE` : Notifications
- `WARNING` : Avertissements
- `ERROR` : Erreurs (transaction annulÃ©e)
- `LOG` : Messages importants pour l'administrateur
- `FATAL` : Erreur grave (connexion fermÃ©e)
- `PANIC` : Erreur critique (arrÃªt du serveur)

**Configuration recommandÃ©e** :
```conf
# DÃ©veloppement
log_min_messages = info

# Production
log_min_messages = warning
```

**Pourquoi ?** En production, `info` gÃ©nÃ¨re trop de logs. `warning` capture les problÃ¨mes importants sans noyer dans les dÃ©tails.

#### 2. log_min_duration_statement

**Le paramÃ¨tre le plus important pour la performance !**

Logger toutes les requÃªtes qui prennent plus de X millisecondes.

```conf
# Logger les requÃªtes de plus de 1 seconde
log_min_duration_statement = 1000

# Logger toutes les requÃªtes (ATTENTION : trÃ¨s verbeux)
log_min_duration_statement = 0

# Ne rien logger (par dÃ©faut)
log_min_duration_statement = -1
```

**Recommandation** :
- **DÃ©veloppement** : 100-500 ms
- **Production** : 1000-5000 ms (1-5 secondes)
- **Analyse ponctuelle** : 0 (toutes les requÃªtes)

**Exemple de log gÃ©nÃ©rÃ©** :
```
2025-11-21 14:32:45 CET [12345]: LOG:  duration: 1234.567 ms  statement: SELECT * FROM orders WHERE created_at > '2025-01-01'
```

#### 3. log_connections et log_disconnections

Enregistre toutes les connexions et dÃ©connexions.

```conf
log_connections = on
log_disconnections = on
```

**UtilitÃ©** :
- Audit de sÃ©curitÃ© (qui se connecte, depuis oÃ¹)
- DÃ©tection d'attaques par force brute
- Identification de connection leaks (connexions jamais fermÃ©es)

**Exemple de logs** :
```
2025-11-21 14:30:12 CET [12340]: LOG:  connection received: host=192.168.1.50 port=54321
2025-11-21 14:30:12 CET [12340]: LOG:  connection authorized: user=webapp database=production application_name=MyApp
2025-11-21 14:35:45 CET [12340]: LOG:  disconnection: session time: 0:05:33.123 user=webapp database=production host=192.168.1.50 port=54321
```

#### 4. log_statement

ContrÃ´le quelles **catÃ©gories** de requÃªtes sont loggÃ©es.

```conf
# Ne rien logger (par dÃ©faut, recommandÃ©)
log_statement = 'none'

# Logger uniquement les DDL (CREATE, ALTER, DROP)
log_statement = 'ddl'

# Logger DDL + DML avec modifications (INSERT, UPDATE, DELETE)
log_statement = 'mod'

# Logger TOUTES les requÃªtes (ATTENTION : trÃ¨s verbeux)
log_statement = 'all'
```

**Recommandation** :
- **Production normale** : `none` (utiliser `log_min_duration_statement` Ã  la place)
- **Audit strict** : `ddl` ou `mod`
- **DÃ©bogage** : `all` (temporairement)

**DiffÃ©rence avec log_min_duration_statement** :
- `log_statement` : BasÃ© sur le **type** de requÃªte
- `log_min_duration_statement` : BasÃ© sur la **durÃ©e** d'exÃ©cution

#### 5. log_checkpoints

Logger les checkpoints (synchronisation de la mÃ©moire vers le disque).

```conf
log_checkpoints = on
```

**Exemple de log** :
```
2025-11-21 14:40:00 CET [12330]: LOG:  checkpoint starting: time
2025-11-21 14:40:15 CET [12330]: LOG:  checkpoint complete: wrote 2456 buffers (15.0%); 0 WAL file(s) added, 0 removed, 3 recycled; write=12.345 s, sync=2.123 s, total=15.123 s; sync files=45, longest=0.456 s, average=0.047 s; distance=45678 kB, estimate=45678 kB
```

**UtilitÃ©** : Identifier si les checkpoints prennent trop de temps (signe de problÃ¨me I/O).

#### 6. log_lock_waits

Logger quand un processus attend un verrou (lock) depuis plus de `deadlock_timeout` (1 seconde par dÃ©faut).

```conf
log_lock_waits = on
deadlock_timeout = 1s
```

**Exemple de log** :
```
2025-11-21 14:45:23 CET [12355]: LOG:  process 12355 still waiting for ShareLock on transaction 123456 after 1000.123 ms
2025-11-21 14:45:23 CET [12355]: DETAIL:  Process holding the lock: 12350. Wait queue: 12355.
2025-11-21 14:45:23 CET [12355]: STATEMENT:  UPDATE accounts SET balance = balance + 100 WHERE id = 42
```

**UtilitÃ©** : Identifier les contentions de locks et les deadlocks potentiels.

#### 7. log_temp_files

Logger la crÃ©ation de fichiers temporaires (quand une requÃªte ne peut pas tenir en mÃ©moire).

```conf
# Logger tous les fichiers temporaires
log_temp_files = 0

# Logger uniquement ceux > 10 MB
log_temp_files = 10240  # En kB
```

**Exemple de log** :
```
2025-11-21 14:50:00 CET [12360]: LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp12360.0", size 524288000
2025-11-21 14:50:00 CET [12360]: STATEMENT:  SELECT * FROM huge_table ORDER BY created_at
```

**UtilitÃ©** : DÃ©tecter les requÃªtes qui nÃ©cessitent trop de mÃ©moire (Ã  optimiser ou augmenter `work_mem`).

---

## Partie 3 : log_line_prefix - Personnaliser le Format des Logs

### Qu'est-ce que log_line_prefix ?

`log_line_prefix` est un **template** qui dÃ©finit le format de chaque ligne de log. C'est comme personnaliser l'affichage d'un relevÃ© bancaire : vous choisissez quelles informations apparaissent et dans quel ordre.

### Format par dÃ©faut

Par dÃ©faut, PostgreSQL utilise un format minimal :
```conf
log_line_prefix = '%m [%p] '
```

RÃ©sultat :
```
2025-11-21 14:32:45 CET [12345] LOG:  statement: SELECT 1
```

**ProblÃ¨me** : Pas assez d'informations pour un diagnostic efficace !

### Les codes de formatage disponibles

Voici les principaux codes (Â« placeholders Â») utilisables dans `log_line_prefix` :

| Code | Description | Exemple |
|------|-------------|---------|
| `%a` | Nom de l'application | `MyApp` |
| `%u` | Nom d'utilisateur | `webapp` |
| `%d` | Nom de la base de donnÃ©es | `production` |
| `%r` | Nom d'hÃ´te/port du client | `192.168.1.50:54321` |
| `%h` | Nom d'hÃ´te du client uniquement | `192.168.1.50` |
| `%p` | Process ID (PID) | `12345` |
| `%t` | Timestamp (sans millisecondes) | `2025-11-21 14:32:45 CET` |
| `%m` | Timestamp (avec millisecondes) | `2025-11-21 14:32:45.123 CET` |
| `%n` | Timestamp (Unix epoch) | `1732195965.123` |
| `%i` | Command tag (type de commande) | `SELECT`, `UPDATE` |
| `%e` | SQLSTATE (code d'erreur) | `42P01` |
| `%c` | Session ID | `66e3d4f2.1234` |
| `%l` | NumÃ©ro de ligne de log par session | `1`, `2`, `3`... |
| `%s` | Timestamp de dÃ©but de session | `2025-11-21 14:30:00 CET` |
| `%v` | Virtual transaction ID | `3/1234` |
| `%x` | Transaction ID (XID) | `123456` |
| `%q` | Pas de sortie (utilisÃ© pour des conditions) | - |
| `%%` | CaractÃ¨re `%` littÃ©ral | `%` |

### Configuration recommandÃ©e pour la production

Voici une configuration complÃ¨te et Ã©quilibrÃ©e :

```conf
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
```

**RÃ©sultat** :
```
2025-11-21 14:32:45 CET [12345]: [1-1] user=webapp,db=production,app=MyApp,client=192.168.1.50 LOG:  statement: SELECT * FROM users WHERE id = 42
```

**Avantages** :
- âœ… Timestamp prÃ©cis (`%t`)
- âœ… PID du processus (`%p`)
- âœ… NumÃ©ro de ligne (`%l`)
- âœ… Contexte complet : utilisateur, base, application, client
- âœ… Facile Ã  parser avec des outils d'analyse

### Configuration enrichie avec transaction ID

Pour le dÃ©bogage avancÃ© ou l'audit strict :

```conf
log_line_prefix = '%m [%p] %q[user=%u,db=%d,app=%a,host=%h] [vxid=%v,txid=%x] '
```

**RÃ©sultat** :
```
2025-11-21 14:32:45.123 CET [12345] [user=webapp,db=production,app=MyApp,host=192.168.1.50] [vxid=3/1234,txid=123456] LOG:  statement: UPDATE accounts SET balance = balance + 100
```

**Informations supplÃ©mentaires** :
- Transaction virtuelle (`vxid`) : Pour corrÃ©ler plusieurs requÃªtes d'une mÃªme transaction
- Transaction ID (`txid`) : L'identifiant de transaction unique

### Configuration pour analyse automatisÃ©e (CSV-like)

Si vous voulez parser les logs avec des scripts :

```conf
log_line_prefix = '%m|%p|%u|%d|%a|%h|%l|'
```

**RÃ©sultat** :
```
2025-11-21 14:32:45 CET|12345|webapp|production|MyApp|192.168.1.50|1|LOG:  statement: SELECT 1
```

**Avantage** : Facile Ã  parser avec `awk`, `cut`, ou des scripts Python.

### Exemples de configurations par cas d'usage

#### DÃ©veloppement local (minimal)
```conf
log_line_prefix = '%t [%p] %q%u@%d '
```

#### Production (Ã©quilibrÃ©)
```conf
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
```

#### Audit de sÃ©curitÃ© (maximal)
```conf
log_line_prefix = '%m [%p] %q[user=%u,db=%d,app=%a,host=%r,session=%c,line=%l] '
```

#### Analyse automatisÃ©e (structurÃ©)
```conf
log_destination = 'csvlog'  # Utiliser le format CSV natif plutÃ´t que log_line_prefix
```

---

## Partie 4 : auto_explain - L'Extension Magique

### Qu'est-ce qu'auto_explain ?

**auto_explain** est une extension PostgreSQL qui **capture automatiquement les plans d'exÃ©cution** (EXPLAIN) des requÃªtes lentes et les Ã©crit dans les logs.

**Analogie** : Imaginez un mÃ©decin qui prend automatiquement votre tempÃ©rature chaque fois que vous avez de la fiÃ¨vre. auto_explain fait la mÃªme chose pour vos requÃªtes : il "radiographie" automatiquement celles qui sont lentes.

**Pourquoi c'est gÃ©nial ?**
- âŒ Sans auto_explain : Vous devez deviner quelles requÃªtes sont lentes, puis manuellement faire `EXPLAIN ANALYZE`
- âœ… Avec auto_explain : PostgreSQL le fait automatiquement et vous avez l'historique dans les logs

### Installation et activation

#### Ã‰tape 1 : Charger l'extension au dÃ©marrage

Ã‰ditez `postgresql.conf` :

```conf
# Charger auto_explain au dÃ©marrage du serveur
shared_preload_libraries = 'auto_explain,pg_stat_statements'  # Si vous avez dÃ©jÃ  pg_stat_statements

# Si c'est la seule extension
shared_preload_libraries = 'auto_explain'
```

**Important** : NÃ©cessite un **redÃ©marrage** du serveur PostgreSQL.

```bash
sudo systemctl restart postgresql
```

#### Ã‰tape 2 : Configurer auto_explain

Toujours dans `postgresql.conf`, ajoutez les paramÃ¨tres de configuration :

```conf
# === Configuration auto_explain ===

# Activer auto_explain (on par dÃ©faut si chargÃ©)
auto_explain.log_min_duration = 1000  # Logger les requÃªtes > 1 seconde (en ms)

# Niveau de dÃ©tail du plan d'exÃ©cution
auto_explain.log_analyze = on         # Inclure les statistiques d'exÃ©cution rÃ©elles
auto_explain.log_buffers = on         # Inclure les statistiques de buffers
auto_explain.log_timing = on          # Inclure le timing dÃ©taillÃ© par nÅ“ud
auto_explain.log_triggers = on        # Inclure les triggers
auto_explain.log_verbose = off        # Mode verbose (trÃ¨s verbeux)

# Format du plan
auto_explain.log_format = 'text'      # Options: 'text', 'xml', 'json', 'yaml'

# Inclure les requÃªtes imbriquÃ©es (dans les fonctions)
auto_explain.log_nested_statements = on

# Ã‰chantillonnage (pour rÃ©duire l'overhead)
auto_explain.sample_rate = 1.0        # 1.0 = 100% des requÃªtes, 0.1 = 10%
```

#### Ã‰tape 3 : Recharger la configuration

```bash
sudo systemctl reload postgresql
# Ou depuis psql :
SELECT pg_reload_conf();
```

**Note** : Contrairement au chargement initial, les modifications de paramÃ¨tres ne nÃ©cessitent qu'un reload, pas un redÃ©marrage.

### Configuration recommandÃ©e par environnement

#### DÃ©veloppement
```conf
auto_explain.log_min_duration = 100   # 100 ms
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.log_timing = on
auto_explain.sample_rate = 1.0        # Tout logger
```

#### Production
```conf
auto_explain.log_min_duration = 5000  # 5 secondes
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.log_timing = off         # RÃ©duit l'overhead
auto_explain.sample_rate = 0.1        # Ã‰chantillonner 10% des requÃªtes lentes
```

#### Analyse ponctuelle (troubleshooting)
```conf
auto_explain.log_min_duration = 0     # Tout logger (temporairement !)
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.log_verbose = on
auto_explain.sample_rate = 1.0
```

### ParamÃ¨tres dÃ©taillÃ©s

#### auto_explain.log_min_duration

Seuil de durÃ©e (en millisecondes) Ã  partir duquel une requÃªte est loggÃ©e.

```conf
# Logger les requÃªtes de plus de 5 secondes
auto_explain.log_min_duration = 5000

# Logger toutes les requÃªtes (ATTENTION : trÃ¨s verbeux)
auto_explain.log_min_duration = 0

# DÃ©sactiver auto_explain
auto_explain.log_min_duration = -1
```

**Recommandation** : Commencez avec 5000 ms (5 secondes) en production, ajustez selon vos besoins.

#### auto_explain.log_analyze

Active `EXPLAIN ANALYZE` (exÃ©cution rÃ©elle) au lieu de `EXPLAIN` simple (estimation).

```conf
auto_explain.log_analyze = on  # RecommandÃ©
```

**DiffÃ©rence** :
- `EXPLAIN` : Estimation du planificateur (rapide, pas d'exÃ©cution)
- `EXPLAIN ANALYZE` : ExÃ©cution rÃ©elle + statistiques (plus lent, plus prÃ©cis)

**Impact** : Ajoute environ 10-20% d'overhead sur la requÃªte loggÃ©e.

#### auto_explain.log_buffers

Inclut les statistiques de buffers (cache hits/misses).

```conf
auto_explain.log_buffers = on  # Fortement recommandÃ©
```

**UtilitÃ©** : Voir combien de donnÃ©es ont Ã©tÃ© lues depuis le disque vs le cache.

#### auto_explain.log_timing

Inclut le timing dÃ©taillÃ© pour chaque nÅ“ud du plan.

```conf
# Production : off (rÃ©duit l'overhead)
auto_explain.log_timing = off

# DÃ©veloppement : on (plus de dÃ©tails)
auto_explain.log_timing = on
```

**Impact** : Peut ajouter 5-10% d'overhead supplÃ©mentaire.

#### auto_explain.sample_rate

Ã‰chantillonne seulement un pourcentage des requÃªtes lentes.

```conf
# Logger 100% des requÃªtes lentes
auto_explain.sample_rate = 1.0

# Logger seulement 10% des requÃªtes lentes (rÃ©duit l'overhead)
auto_explain.sample_rate = 0.1

# Logger 1% (pour trÃ¨s haute charge)
auto_explain.sample_rate = 0.01
```

**UtilitÃ©** : RÃ©duire l'overhead et la taille des logs en haute charge.

### Exemple de log auto_explain

Voici ce que vous verrez dans les logs quand auto_explain capture une requÃªte :

```
2025-11-21 15:30:45 CET [12567]: [1-1] user=webapp,db=production,app=MyApp,client=192.168.1.50 LOG:  duration: 1234.567 ms  plan:
Query Text: SELECT o.*, u.email FROM orders o JOIN users u ON o.user_id = u.id WHERE o.created_at > '2025-01-01' ORDER BY o.created_at DESC LIMIT 100
Hash Join  (cost=1234.56..45678.90 rows=5000 width=200) (actual time=45.123..1200.456 rows=4876 loops=1)
  Hash Cond: (o.user_id = u.id)
  Buffers: shared hit=12345 read=6789
  ->  Index Scan using orders_created_at_idx on orders o  (cost=0.43..34567.89 rows=5000 width=150) (actual time=0.123..800.456 rows=4876 loops=1)
        Index Cond: (created_at > '2025-01-01 00:00:00'::timestamp without time zone)
        Buffers: shared hit=8901 read=3456
  ->  Hash  (cost=987.65..987.65 rows=10000 width=50) (actual time=44.123..44.123 rows=9876 loops=1)
        Buckets: 16384  Batches: 1  Memory Usage: 456kB
        Buffers: shared hit=3444 read=3333
        ->  Seq Scan on users u  (cost=0.00..987.65 rows=10000 width=50) (actual time=0.012..25.678 rows=9876 loops=1)
              Buffers: shared hit=3444 read=3333
Planning Time: 2.345 ms
Execution Time: 1234.567 ms
```

**Informations capturÃ©es** :
- DurÃ©e totale : 1234.567 ms
- Texte de la requÃªte complet
- Plan d'exÃ©cution avec temps rÃ©el par nÅ“ud
- Statistiques de buffers (cache hits vs disk reads)
- Temps de planification vs exÃ©cution

---

## Partie 5 : InterprÃ©ter les Logs

### Anatomie d'une ligne de log

Reprenons notre configuration recommandÃ©e :
```conf
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
```

**Exemple de ligne** :
```
2025-11-21 15:45:23 CET [12678]: [1-1] user=webapp,db=production,app=MyApp,client=192.168.1.50 ERROR:  duplicate key value violates unique constraint "users_email_key"
```

**DÃ©composition** :
1. `2025-11-21 15:45:23 CET` : Timestamp exact
2. `[12678]` : Process ID (PID) du backend
3. `[1-1]` : NumÃ©ro de ligne de log pour cette session
4. `user=webapp` : Utilisateur PostgreSQL
5. `db=production` : Base de donnÃ©es
6. `app=MyApp` : Nom de l'application
7. `client=192.168.1.50` : Adresse IP du client
8. `ERROR:` : Niveau de gravitÃ©
9. Le message d'erreur

### Niveaux de gravitÃ© et leur signification

| Niveau | Signification | Action requise |
|--------|---------------|----------------|
| `DEBUG` | Information de dÃ©bogage | Aucune (dÃ©veloppement uniquement) |
| `INFO` | Information gÃ©nÃ©rale | Aucune |
| `NOTICE` | Notification | Aucune (sauf si rÃ©current) |
| `WARNING` | Avertissement | Investiguer si frÃ©quent |
| `ERROR` | Erreur (transaction annulÃ©e) | VÃ©rifier l'application |
| `LOG` | Message administratif important | Noter, analyser si nÃ©cessaire |
| `FATAL` | Erreur grave (connexion fermÃ©e) | Urgence - investiguer immÃ©diatement |
| `PANIC` | Erreur critique (serveur arrÃªtÃ©) | Urgence maximale - incident majeur |

### Exemples d'erreurs courantes et leur interprÃ©tation

#### Erreur 1 : Violation de contrainte unique

```
ERROR:  duplicate key value violates unique constraint "users_email_key"
DETAIL:  Key (email)=(user@example.com) already exists.
STATEMENT:  INSERT INTO users (email, name) VALUES ('user@example.com', 'John Doe')
```

**InterprÃ©tation** :
- L'application tente d'insÃ©rer un email qui existe dÃ©jÃ 
- La contrainte `users_email_key` empÃªche les doublons

**Actions** :
- VÃ©rifier la logique applicative (valider avant d'insÃ©rer)
- Utiliser `INSERT ... ON CONFLICT` (upsert)

#### Erreur 2 : Deadlock dÃ©tectÃ©

```
ERROR:  deadlock detected
DETAIL:  Process 12678 waits for ShareLock on transaction 123456; blocked by process 12679.
Process 12679 waits for ShareLock on transaction 123457; blocked by process 12678.
HINT:  See server log for query details.
STATEMENT:  UPDATE accounts SET balance = balance - 100 WHERE id = 42
```

**InterprÃ©tation** :
- Deux transactions se bloquent mutuellement
- PostgreSQL a dÃ©tectÃ© le deadlock et annulÃ© une transaction

**Actions** :
- Revoir l'ordre des opÃ©rations dans les transactions
- Utiliser des verrous explicites (`SELECT ... FOR UPDATE`)

#### Erreur 3 : Fichier temporaire crÃ©Ã©

```
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp12678.0", size 524288000
STATEMENT:  SELECT * FROM huge_table ORDER BY created_at
```

**InterprÃ©tation** :
- La requÃªte nÃ©cessite 500 MB de fichiers temporaires (sort sur disque)
- La mÃ©moire allouÃ©e (`work_mem`) n'est pas suffisante

**Actions** :
- Augmenter `work_mem` pour cette session ou globalement
- Ajouter un index sur `created_at`
- Limiter les rÃ©sultats avec `LIMIT`

#### Erreur 4 : Connexion Ã©chouÃ©e

```
FATAL:  password authentication failed for user "webapp"
DETAIL:  Connection matched pg_hba.conf line 95: "host all all 192.168.1.0/24 scram-sha-256"
```

**InterprÃ©tation** :
- Tentative de connexion avec un mauvais mot de passe
- Si frÃ©quent : possible attaque par force brute

**Actions** :
- VÃ©rifier les identifiants de l'application
- Si attaque : bloquer l'IP ou utiliser fail2ban

#### Erreur 5 : Lock wait

```
LOG:  process 12678 still waiting for ShareLock on transaction 123456 after 1000.123 ms
DETAIL:  Process holding the lock: 12679. Wait queue: 12678.
STATEMENT:  UPDATE orders SET status = 'shipped' WHERE id = 42
```

**InterprÃ©tation** :
- Le processus 12678 attend un lock dÃ©tenu par 12679
- Attente de plus de 1 seconde

**Actions** :
- Identifier la requÃªte longue (processus 12679)
- Terminer la transaction bloquante si nÃ©cessaire

### Patterns Ã  surveiller dans les logs

#### Pattern 1 : Connexions frÃ©quentes (connection storm)

```bash
# Compter les connexions par minute
grep "connection authorized" postgresql.log | \
  cut -d' ' -f1-2 | uniq -c | sort -rn
```

**Signe de problÃ¨me** : Plus de 100 connexions/minute de la mÃªme source.

**Causes** :
- Pas de connection pooling
- Application qui ouvre/ferme trop souvent

#### Pattern 2 : RequÃªtes lentes rÃ©currentes

```bash
# Identifier les requÃªtes > 5 secondes
grep "duration:" postgresql.log | \
  awk '$6 > 5000' | \
  cut -d':' -f4- | sort | uniq -c | sort -rn | head -20
```

**Actions** :
- Optimiser ces requÃªtes (index, rÃ©Ã©criture)
- Utiliser `auto_explain` pour analyser

#### Pattern 3 : Erreurs en cascade

```
ERROR:  canceling statement due to user request
ERROR:  current transaction is aborted, commands ignored until end of transaction block
ERROR:  current transaction is aborted, commands ignored until end of transaction block
```

**InterprÃ©tation** :
- Une erreur dans une transaction
- L'application continue d'envoyer des commandes sans gÃ©rer l'erreur

**Actions** :
- AmÃ©liorer la gestion d'erreurs dans le code applicatif

---

## Partie 6 : Outils d'Analyse des Logs

### pgBadger - L'Outil Incontournable

**pgBadger** est un analyseur de logs PostgreSQL qui gÃ©nÃ¨re des rapports HTML dÃ©taillÃ©s.

#### Installation

```bash
# Debian/Ubuntu
sudo apt-get install pgbadger

# macOS
brew install pgbadger

# Ou depuis CPAN
cpan App::pgBadger
```

#### Utilisation basique

```bash
# Analyser un fichier de log
pgbadger /var/log/postgresql/postgresql-18-main.log

# Analyser plusieurs fichiers
pgbadger /var/log/postgresql/postgresql-*.log

# SpÃ©cifier le fichier de sortie
pgbadger -o report.html /var/log/postgresql/postgresql-18-main.log

# Analyser une pÃ©riode spÃ©cifique
pgbadger --begin "2025-11-20 00:00:00" --end "2025-11-21 00:00:00" postgresql.log
```

#### Rapports gÃ©nÃ©rÃ©s

pgBadger gÃ©nÃ¨re un rapport HTML avec :
- **Statistiques globales** : Nombre de requÃªtes, durÃ©e totale, erreurs
- **RequÃªtes les plus lentes** : Top N avec temps moyen/max
- **RequÃªtes les plus frÃ©quentes** : Top N avec nombre d'appels
- **RequÃªtes normalisÃ©es** : AgrÃ©gation des requÃªtes similaires
- **Erreurs et avertissements** : Liste complÃ¨te avec contexte
- **Connexions et sessions** : Patterns de connexion
- **Checkpoints et autovacuum** : ActivitÃ© de maintenance
- **Graphiques temporels** : Ã‰volution au fil du temps

#### Configuration pour pgBadger

Pour des rÃ©sultats optimaux, configurez PostgreSQL pour gÃ©nÃ©rer des logs compatibles :

```conf
# Dans postgresql.conf
log_min_duration_statement = 0       # Logger toutes les requÃªtes (temporairement)
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_checkpoints = on
log_connections = on
log_disconnections = on
log_duration = off
log_lock_waits = on
log_temp_files = 0
log_autovacuum_min_duration = 0
```

**Attention** : `log_min_duration_statement = 0` gÃ©nÃ¨re BEAUCOUP de logs. Ã€ utiliser temporairement pour analyse.

### Autres outils d'analyse

#### 1. grep et scripts shell

**Exemple : Top 10 des erreurs**
```bash
grep "ERROR:" postgresql.log | \
  cut -d':' -f5- | sort | uniq -c | sort -rn | head -10
```

**Exemple : Temps moyen des requÃªtes par heure**
```bash
grep "duration:" postgresql.log | \
  awk '{print $1, $7}' | \
  awk '{h=substr($1,1,13); sum[h]+=$2; count[h]++}
       END {for (h in sum) print h, sum[h]/count[h]}' | sort
```

#### 2. Splunk / ELK Stack

Pour les grandes entreprises, les logs peuvent Ãªtre envoyÃ©s vers :
- **Elasticsearch + Logstash + Kibana (ELK)**
- **Splunk**
- **Datadog Logs**
- **Graylog**

Configuration pour JSON logs (PostgreSQL 15+) :
```conf
log_destination = 'jsonlog'
logging_collector = on
```

#### 3. Extensions PostgreSQL

**pg_stat_statements** : Statistiques agrÃ©gÃ©es des requÃªtes (vu prÃ©cÃ©demment)

```sql
SELECT
    query,
    calls,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

---

## Partie 7 : Bonnes Pratiques et Recommandations

### 1. Configuration par environnement

#### DÃ©veloppement
```conf
log_min_messages = info
log_min_duration_statement = 100
log_statement = 'all'  # Temporairement
log_connections = on
log_disconnections = on

auto_explain.log_min_duration = 100
auto_explain.log_analyze = on
```

#### Production
```conf
log_min_messages = warning
log_min_duration_statement = 5000  # 5 secondes
log_statement = 'ddl'
log_connections = on
log_disconnections = on
log_checkpoints = on
log_lock_waits = on
log_temp_files = 10240  # > 10 MB

auto_explain.log_min_duration = 5000
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.sample_rate = 0.1  # 10%
```

### 2. Rotation des logs

Sans rotation, les logs peuvent remplir le disque !

```conf
# Rotation automatique
logging_collector = on
log_rotation_age = 1d          # Nouveau fichier chaque jour
log_rotation_size = 100MB      # Nouveau fichier si > 100 MB
log_truncate_on_rotation = on  # Ã‰craser l'ancien fichier

# Nom de fichier avec date
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
```

**Ou utiliser logrotate** (Linux) :

```bash
# /etc/logrotate.d/postgresql
/var/log/postgresql/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0640 postgres postgres
    sharedscripts
    postrotate
        /usr/bin/systemctl reload postgresql
    endscript
}
```

### 3. Surveiller la taille des logs

```bash
# VÃ©rifier la taille du rÃ©pertoire de logs
du -sh /var/log/postgresql/

# Surveiller en temps rÃ©el
watch -n 5 'du -sh /var/log/postgresql/'
```

**Alerte si** : Croissance > 1 GB/jour de maniÃ¨re inattendue.

### 4. Activer/DÃ©sactiver temporairement le logging verbeux

Pour une analyse ponctuelle sans redÃ©marrage :

```sql
-- Augmenter temporairement le niveau de log
ALTER SYSTEM SET log_min_duration_statement = 0;
SELECT pg_reload_conf();

-- Analyser pendant quelques minutes...

-- Revenir Ã  la normale
ALTER SYSTEM SET log_min_duration_statement = 5000;
SELECT pg_reload_conf();
```

**Ou au niveau session** :

```sql
-- Uniquement pour cette session
SET log_min_duration_statement = 0;
SET client_min_messages = debug;

-- ExÃ©cuter les requÃªtes Ã  analyser...

-- Revenir Ã  la normale
RESET log_min_duration_statement;
RESET client_min_messages;
```

### 5. SÃ©curitÃ© et confidentialitÃ©

**Attention** : Les logs peuvent contenir des donnÃ©es sensibles !

```conf
# Ne pas logger les mots de passe
log_statement = 'none'  # Ã‰vite de logger les CREATE USER avec mot de passe

# Restreindre l'accÃ¨s aux logs
chmod 600 /var/log/postgresql/*.log
chown postgres:postgres /var/log/postgresql/*.log
```

**Anonymiser les logs** pour les partager :

```bash
# Remplacer les IPs
sed 's/[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}/XXX.XXX.XXX.XXX/g' \
  postgresql.log > postgresql-anonymized.log
```

### 6. Checklist de configuration des logs

- [ ] `logging_collector = on`
- [ ] `log_destination` configurÃ© (stderr ou csvlog)
- [ ] `log_line_prefix` personnalisÃ© avec contexte suffisant
- [ ] `log_min_duration_statement` adaptÃ© Ã  votre charge
- [ ] `log_connections = on`
- [ ] `log_disconnections = on`
- [ ] `log_checkpoints = on`
- [ ] `log_lock_waits = on`
- [ ] `log_temp_files` configurÃ©
- [ ] Rotation des logs activÃ©e
- [ ] `auto_explain` configurÃ© et chargÃ©
- [ ] Tests de gÃ©nÃ©ration et lecture des logs
- [ ] pgBadger installÃ© et testÃ©
- [ ] Monitoring de la taille des logs

---

## Partie 8 : DÃ©pannage et Questions FrÃ©quentes

### Q1 : Les logs ne sont pas gÃ©nÃ©rÃ©s

**Solutions** :
```sql
-- VÃ©rifier que le logging_collector est activÃ©
SHOW logging_collector;

-- VÃ©rifier le rÃ©pertoire de logs
SHOW log_directory;
SHOW log_filename;

-- VÃ©rifier les permissions
ls -la /var/log/postgresql/
```

### Q2 : auto_explain ne fonctionne pas

**Solutions** :
```sql
-- VÃ©rifier que l'extension est chargÃ©e
SHOW shared_preload_libraries;

-- VÃ©rifier la configuration
SHOW auto_explain.log_min_duration;

-- Forcer une requÃªte lente pour tester
SELECT pg_sleep(2);
```

### Q3 : Les logs sont trop volumineux

**Solutions** :
1. Augmenter `log_min_duration_statement` (moins de requÃªtes loggÃ©es)
2. RÃ©duire `auto_explain.sample_rate` (Ã©chantillonnage)
3. DÃ©sactiver `log_statement = 'all'`
4. Configurer une rotation plus agressive

### Q4 : Comment analyser les logs en temps rÃ©el ?

```bash
# Suivre les logs en direct
tail -f /var/log/postgresql/postgresql-18-main.log

# Filtrer les erreurs uniquement
tail -f /var/log/postgresql/postgresql-18-main.log | grep ERROR

# Filtrer les requÃªtes lentes
tail -f /var/log/postgresql/postgresql-18-main.log | grep "duration:"
```

### Q5 : Comment exporter les logs vers un outil centralisÃ© ?

**Option 1 : Filebeat (ELK)**
```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  paths:
    - /var/log/postgresql/*.log
output.elasticsearch:
  hosts: ["localhost:9200"]
```

**Option 2 : rsyslog**
```conf
# Dans postgresql.conf
log_destination = 'syslog'
syslog_facility = 'LOCAL0'
syslog_ident = 'postgres'
```

---

## Conclusion

La configuration et l'analyse des logs PostgreSQL sont des compÃ©tences essentielles pour tout dÃ©veloppeur ou administrateur de bases de donnÃ©es.

### Points clÃ©s Ã  retenir

1. **log_line_prefix** : Personnalisez pour avoir le contexte nÃ©cessaire
2. **log_min_duration_statement** : Le paramÃ¨tre le plus important pour la performance
3. **auto_explain** : Capture automatiquement les plans des requÃªtes lentes
4. **pgBadger** : Outil d'analyse indispensable
5. **Rotation** : Essentielle pour Ã©viter de remplir le disque
6. **Ã‰quilibre** : Loggez suffisamment, mais pas trop (overhead et taille)

### Configuration minimale recommandÃ©e

```conf
# Logging de base
logging_collector = on
log_destination = 'stderr'
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_min_duration_statement = 5000
log_connections = on
log_disconnections = on
log_checkpoints = on
log_lock_waits = on
log_temp_files = 10240

# Rotation
log_rotation_age = 1d
log_rotation_size = 100MB

# auto_explain
shared_preload_libraries = 'auto_explain'
auto_explain.log_min_duration = 5000
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.sample_rate = 0.1
```

### Workflow recommandÃ©

1. **Configurer** les logs dÃ¨s le dÃ©but du projet
2. **Monitorer** rÃ©guliÃ¨rement avec pgBadger ou Ã©quivalent
3. **Analyser** les patterns et anomalies
4. **Optimiser** les requÃªtes identifiÃ©es comme problÃ©matiques
5. **ItÃ©rer** : Ajuster la configuration selon vos besoins

### Ressources complÃ©mentaires

- [Documentation PostgreSQL - Error Reporting and Logging](https://www.postgresql.org/docs/18/runtime-config-logging.html)
- [pgBadger Documentation](https://pgbadger.darold.net/)
- [Guide auto_explain](https://www.postgresql.org/docs/18/auto-explain.html)
- [PostgreSQL Log Analysis Best Practices](https://wiki.postgresql.org/wiki/Logging_Difficult_Queries)

---

**ðŸ’¡ Astuce finale** : CrÃ©ez un script de configuration standardisÃ© pour vos projets :

```bash
#!/bin/bash
# configure_logging.sh

cat >> /etc/postgresql/18/main/postgresql.conf <<EOF

# === Logging Configuration ===
logging_collector = on
log_destination = 'stderr'
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_min_duration_statement = 5000
log_connections = on
log_disconnections = on
log_checkpoints = on
log_lock_waits = on
log_temp_files = 10240
log_rotation_age = 1d
log_rotation_size = 100MB

# === auto_explain ===
shared_preload_libraries = 'auto_explain'
auto_explain.log_min_duration = 5000
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.sample_rate = 0.1
EOF

systemctl restart postgresql
echo "Logging configuration complete!"
```

**ðŸŽ¯ Objectif** : Des logs informatifs, des diagnostics rapides, des applications optimisÃ©es !

â­ï¸ [MÃ©triques vitales](/14-observabilite-et-monitoring/06-metriques-vitales.md)
