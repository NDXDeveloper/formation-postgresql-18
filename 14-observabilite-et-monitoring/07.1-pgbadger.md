ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 14.7.1. pgBadger : Analyse de logs

## Introduction

**pgBadger** est un outil open-source d'analyse de logs PostgreSQL qui transforme les fichiers journaux (logs) bruts et souvent difficiles Ã  lire en rapports HTML visuels et interactifs. C'est l'un des outils les plus populaires de l'Ã©cosystÃ¨me PostgreSQL pour comprendre ce qui se passe dans votre base de donnÃ©es.

### Pourquoi analyser les logs ?

Les logs PostgreSQL contiennent une mine d'informations sur l'activitÃ© de votre base de donnÃ©es :
- Les requÃªtes les plus lentes
- Les erreurs et problÃ¨mes rencontrÃ©s
- Les connexions et dÃ©connexions
- Les opÃ©rations de maintenance (VACUUM, ANALYZE)
- Les checkpoints et leur durÃ©e
- Les verrous (locks) et contentions

Cependant, ces logs sont :
- **Volumineux** : Des milliers, voire millions de lignes par jour
- **Non structurÃ©s** : Format texte difficile Ã  parcourir
- **Techniques** : NÃ©cessitent une expertise pour Ãªtre interprÃ©tÃ©s

**pgBadger rÃ©sout ce problÃ¨me** en analysant automatiquement ces logs et en gÃ©nÃ©rant des rapports visuels comprÃ©hensibles.

---

## Qu'est-ce que pgBadger ?

### DÃ©finition

pgBadger (PostgreSQL Badger) est un **analyseur de logs** Ã©crit en Perl qui :
1. **Lit** les fichiers de logs PostgreSQL
2. **Parse** (analyse syntaxiquement) les entrÃ©es
3. **AgrÃ¨ge** les statistiques
4. **GÃ©nÃ¨re** un rapport HTML interactif avec graphiques et tableaux

### CaractÃ©ristiques principales

| CaractÃ©ristique | Description |
|----------------|-------------|
| **Performance** | Analyse trÃ¨s rapide, mÃªme sur des logs de plusieurs Go |
| **ZÃ©ro dÃ©pendance** | Pas de base de donnÃ©es nÃ©cessaire pour l'analyse |
| **Open Source** | Licence PostgreSQL (libre et gratuit) |
| **Multi-format** | Supporte diffÃ©rents formats de logs PostgreSQL |
| **IncrÃ©mental** | Peut analyser uniquement les nouvelles entrÃ©es |
| **Multi-plateforme** | Fonctionne sur Linux, Windows, macOS |

### Pourquoi "Badger" (blaireau) ?

Le nom fait rÃ©fÃ©rence au blaireau, un animal fouisseur qui creuse pour trouver ce qui est cachÃ©. De la mÃªme maniÃ¨re, pgBadger "fouille" dans les logs pour extraire des informations prÃ©cieuses cachÃ©es dans des milliers de lignes de texte.

---

## Comment fonctionne pgBadger ?

### Architecture et processus

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fichiers de logs   â”‚
â”‚    PostgreSQL       â”‚
â”‚  (postgresql.log)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Lecture
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     pgBadger        â”‚
â”‚   (Analyseur Perl)  â”‚
â”‚                     â”‚
â”‚  â€¢ Parsing          â”‚
â”‚  â€¢ AgrÃ©gation       â”‚
â”‚  â€¢ Calcul stats     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ GÃ©nÃ©ration
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Rapport HTML       â”‚
â”‚  (out.html)         â”‚
â”‚                     â”‚
â”‚  â€¢ Graphiques       â”‚
â”‚  â€¢ Tableaux         â”‚
â”‚  â€¢ Statistiques     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Les Ã©tapes d'analyse

1. **Lecture des logs** : pgBadger ouvre et lit les fichiers de logs PostgreSQL (peut traiter plusieurs fichiers simultanÃ©ment)

2. **Parsing des entrÃ©es** : Chaque ligne de log est analysÃ©e et dÃ©cortiquÃ©e pour extraire :
   - Le timestamp (date et heure)
   - Le type d'Ã©vÃ©nement (requÃªte, erreur, connexion...)
   - Le texte de la requÃªte SQL
   - La durÃ©e d'exÃ©cution
   - L'utilisateur et la base de donnÃ©es concernÃ©s
   - Les messages d'erreur Ã©ventuels

3. **AgrÃ©gation des donnÃ©es** : Les informations sont regroupÃ©es et calculÃ©es :
   - RequÃªtes les plus frÃ©quentes
   - RequÃªtes les plus lentes
   - Temps total passÃ© par type de requÃªte
   - Distribution temporelle de l'activitÃ©

4. **GÃ©nÃ©ration du rapport** : Un fichier HTML est crÃ©Ã© avec :
   - Des graphiques interactifs (courbes, camemberts)
   - Des tableaux triables
   - Des statistiques dÃ©taillÃ©es
   - Des liens pour naviguer rapidement

---

## Configuration prÃ©alable de PostgreSQL

Pour que pgBadger puisse analyser efficacement les logs, PostgreSQL doit Ãªtre correctement configurÃ©.

### ParamÃ¨tres essentiels dans postgresql.conf

#### 1. Activer la journalisation

```ini
# Activer la journalisation
logging_collector = on

# Destination des logs
log_destination = 'stderr'

# RÃ©pertoire des logs
log_directory = 'log'

# Nom des fichiers de logs avec timestamp
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
```

#### 2. Configurer le format des logs

```ini
# Format de ligne recommandÃ© pour pgBadger
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# Alternative plus simple (mais moins complÃ¨te)
# log_line_prefix = '%t [%p]: '
```

**Explication des marqueurs** :
- `%t` : Timestamp (date et heure)
- `%p` : Process ID (PID)
- `%l` : NumÃ©ro de ligne de log
- `%u` : Nom d'utilisateur
- `%d` : Nom de la base de donnÃ©es
- `%a` : Nom de l'application
- `%h` : Hostname/IP du client

#### 3. Logger les requÃªtes lentes

```ini
# Logger les requÃªtes qui prennent plus de 100ms
log_min_duration_statement = 100

# Inclure la durÃ©e d'exÃ©cution
log_duration = off  # DÃ©jÃ  inclus avec log_min_duration_statement
```

#### 4. Logger les erreurs et connexions

```ini
# Logger les erreurs
log_error_verbosity = default

# Logger les connexions/dÃ©connexions
log_connections = on
log_disconnections = on

# Logger les checkpoints
log_checkpoints = on

# Logger les commandes DDL
log_statement = 'ddl'
```

### Compromis entre dÃ©tail et volume

âš ï¸ **Attention** : Plus vous loggez d'informations, plus les fichiers de logs seront volumineux.

| Niveau de logging | Volume de logs | UtilitÃ© |
|-------------------|----------------|---------|
| **Minimal** | Faible | Erreurs seulement, peu d'insights |
| **ModÃ©rÃ©** | Moyen | RequÃªtes lentes (>100ms), erreurs, connexions |
| **DÃ©taillÃ©** | Important | Toutes les requÃªtes, debugging |
| **Verbeux** | TrÃ¨s important | Tout logger (dÃ©veloppement uniquement) |

**Recommandation pour la production** : Niveau modÃ©rÃ© avec `log_min_duration_statement` entre 100ms et 500ms selon votre contexte.

---

## Les rapports pgBadger

### Structure d'un rapport

Un rapport pgBadger typique contient plusieurs sections :

#### 1. **Vue d'ensemble (Overall stats)**

Statistiques globales sur la pÃ©riode analysÃ©e :
- Nombre total de requÃªtes
- Nombre de connexions
- Nombre d'erreurs
- Taille totale des logs analysÃ©s
- PÃ©riode couverte

#### 2. **Connexions (Connections)**

Graphique temporel montrant :
- Le nombre de connexions par heure/jour
- Les pics d'activitÃ©
- Les bases de donnÃ©es les plus sollicitÃ©es
- Les utilisateurs les plus actifs

**Exemple d'insight** : "Pic de connexions tous les jours Ã  9h00 â†’ dÃ©marrage des applications mÃ©tier"

#### 3. **Sessions**

Statistiques sur les sessions :
- DurÃ©e moyenne des sessions
- Sessions les plus longues
- Nombre de sessions par utilisateur/base

#### 4. **Checkpoints**

Informations sur les checkpoints PostgreSQL :
- FrÃ©quence des checkpoints
- DurÃ©e des checkpoints
- Checkpoints planifiÃ©s vs forcÃ©s (trop de checkpoints forcÃ©s = problÃ¨me de configuration)

**Indicateur de santÃ©** : Un ratio Ã©levÃ© de checkpoints forcÃ©s peut indiquer que `max_wal_size` est trop petit.

#### 5. **RequÃªtes (Queries)**

**C'est la section la plus importante** pour l'optimisation :

##### Top des requÃªtes les plus lentes (Slowest queries)
Tableau listant les requÃªtes triÃ©es par temps d'exÃ©cution :
- RequÃªte SQL normalisÃ©e (paramÃ¨tres remplacÃ©s par `$1`, `$2`...)
- Temps d'exÃ©cution moyen
- Temps d'exÃ©cution maximum
- Nombre d'occurrences

**Exemple** :
```
RequÃªte                                          | Temps moyen | Temps max | Occurrences
-------------------------------------------------|-------------|-----------|------------
SELECT * FROM orders WHERE user_id = $1         | 2.3s        | 8.1s      | 1,245
UPDATE products SET stock = stock - $1 WHERE... | 1.8s        | 5.2s      | 892
```

##### Top des requÃªtes les plus frÃ©quentes (Most frequent)
RequÃªtes exÃ©cutÃ©es le plus souvent :
- Identifie les points chauds de votre application
- Permet de prioriser les optimisations (impact maximal)

##### Top des requÃªtes consommant le plus de temps (Time consuming)
Calcul du temps cumulÃ© : `temps moyen Ã— nombre d'exÃ©cutions`

**Exemple de stratÃ©gie d'optimisation** :
- RequÃªte A : 5s en moyenne, exÃ©cutÃ©e 10 fois â†’ 50s au total
- RequÃªte B : 0.5s en moyenne, exÃ©cutÃ©e 1000 fois â†’ 500s au total

**â†’ Optimiser la requÃªte B en prioritÃ©**, mÃªme si elle est individuellement plus rapide !

#### 6. **Erreurs (Errors)**

Liste des erreurs rencontrÃ©es :
- Erreurs de syntaxe SQL
- Violations de contraintes
- Deadlocks
- Timeouts
- Permissions refusÃ©es

Permet d'identifier rapidement les problÃ¨mes applicatifs.

#### 7. **Locks (Verrous)**

Si activÃ© dans les logs :
- Verrous en attente
- Deadlocks dÃ©tectÃ©s
- DurÃ©e d'attente sur verrous

#### 8. **Temporary files**

Fichiers temporaires crÃ©Ã©s :
- Identifie les requÃªtes qui ont besoin de plus de `work_mem`
- Signale un potentiel problÃ¨me de configuration

#### 9. **Vaccum et Autovacuum**

Statistiques sur les opÃ©rations de maintenance :
- Tables les plus souvent "vacuum"
- DurÃ©e des opÃ©rations
- Tables en retard de VACUUM

### Graphiques et visualisations

pgBadger gÃ©nÃ¨re de nombreux graphiques interactifs :

1. **Graphiques temporels** : Courbes montrant l'Ã©volution dans le temps
   - Nombre de requÃªtes par heure
   - Charge CPU estimÃ©e
   - ActivitÃ© de lecture/Ã©criture

2. **Graphiques en camembert** : Distribution
   - RÃ©partition des requÃªtes par type (SELECT, INSERT, UPDATE, DELETE)
   - RÃ©partition par base de donnÃ©es
   - RÃ©partition par utilisateur

3. **Histogrammes** : Distribution statistique
   - Distribution des temps de rÃ©ponse
   - Distribution des tailles de rÃ©sultats

### Navigation dans le rapport

Le rapport HTML est interactif :
- **Sommaire cliquable** en haut de page
- **Tableaux triables** : Cliquez sur les en-tÃªtes de colonne
- **Liens vers les requÃªtes** : Cliquez sur une requÃªte pour voir les dÃ©tails
- **Filtres** : PossibilitÃ© de filtrer par base, utilisateur, etc.

---

## Cas d'usage pratiques de pgBadger

### 1. Diagnostic de performance

**ProblÃ¨me** : "L'application est lente depuis hier"

**Approche avec pgBadger** :
1. GÃ©nÃ©rer un rapport sur les derniÃ¨res 24h
2. Consulter la section "Slowest queries"
3. Identifier les requÃªtes qui ont un temps d'exÃ©cution anormal
4. Analyser le plan d'exÃ©cution de ces requÃªtes (EXPLAIN ANALYZE)
5. Ajouter des index ou rÃ©Ã©crire les requÃªtes

**Exemple de dÃ©couverte** : Une requÃªte qui faisait 50ms fait maintenant 5s â†’ La table a grossi et un index est manquant.

### 2. Identification des points chauds

**Objectif** : Savoir quelles parties de l'application sollicitent le plus la base

**Approche** :
1. Regarder "Most frequent queries"
2. Identifier les patterns rÃ©pÃ©titifs
3. Envisager la mise en cache applicative pour ces requÃªtes
4. Optimiser en prioritÃ© les requÃªtes les plus frÃ©quentes

**Exemple** :
```sql
-- Cette requÃªte est appelÃ©e 50,000 fois par jour
SELECT user_id, username, email FROM users WHERE user_id = $1;
```
â†’ **Solution** : ImplÃ©menter un cache Redis avec TTL de 1h

### 3. Audit de sÃ©curitÃ©

**Utilisation** : Identifier les tentatives de connexion suspectes

**Ce que pgBadger rÃ©vÃ¨le** :
- Connexions Ã©chouÃ©es rÃ©pÃ©tÃ©es (force brute ?)
- Connexions depuis des IP inattendues
- RequÃªtes avec erreurs de permission
- Tentatives d'injection SQL (erreurs de syntaxe suspectes)

### 4. Planification de capacitÃ©

**Question** : "Avons-nous besoin de plus de ressources ?"

**Analyse avec pgBadger** :
- Consulter les graphiques d'activitÃ© temporelle
- Identifier les heures de pointe
- Ã‰valuer le taux de croissance du trafic
- Anticiper les besoins futurs

**Exemple de pattern** :
```
Connexions simultanÃ©es :
- 08h-09h : 50 connexions
- 09h-12h : 200 connexions (pic)
- 12h-14h : 80 connexions
- 14h-18h : 180 connexions
```
â†’ Le serveur doit supporter 200+ connexions. Si limite actuelle = 150, il faut augmenter `max_connections`.

### 5. Validation aprÃ¨s optimisation

**Processus** :
1. GÃ©nÃ©rer un rapport pgBadger **avant** optimisation
2. Appliquer les optimisations (index, rÃ©Ã©criture, configuration)
3. GÃ©nÃ©rer un nouveau rapport pgBadger **aprÃ¨s** optimisation
4. Comparer les mÃ©triques :
   - Temps d'exÃ©cution moyen
   - Temps cumulÃ©
   - Nombre de requÃªtes lentes

**MÃ©thode de comparaison** :
- Sauvegarder les rapports avec des noms datÃ©s : `rapport_2025_11_21_avant.html`, `rapport_2025_11_28_apres.html`
- Comparer visuellement les sections clÃ©s
- Quantifier l'amÃ©lioration : "Temps moyen passÃ© de 2.5s Ã  0.3s â†’ **88% plus rapide**"

### 6. Troubleshooting des erreurs

**ScÃ©nario** : "Des utilisateurs signalent des erreurs intermittentes"

**Investigation** :
1. Ouvrir la section "Errors" du rapport
2. Trier par nombre d'occurrences
3. Identifier les erreurs les plus frÃ©quentes

**Exemples d'erreurs et solutions** :

```
Erreur : "deadlock detected"
â†’ ProblÃ¨me de concurrence, revoir la logique transactionnelle

Erreur : "could not serialize access due to concurrent update"
â†’ Isolation niveau Serializable trop strict, envisager Read Committed

Erreur : "temporary file size exceeds temp_file_limit"
â†’ RequÃªtes trop gourmandes, augmenter work_mem ou optimiser
```

---

## Bonnes pratiques d'utilisation

### 1. Analyser rÃ©guliÃ¨rement

**FrÃ©quence recommandÃ©e** :
- **Quotidien** : Environnement de production critique
- **Hebdomadaire** : Environnement de production standard
- **Mensuel** : Environnement de dÃ©veloppement/staging

**Automatisation** :
Configurer un cron job qui :
1. Lance pgBadger chaque nuit sur les logs de la veille
2. Archive le rapport HTML
3. Envoie une notification si des anomalies sont dÃ©tectÃ©es

### 2. Conserver un historique

**Pourquoi ?**
- Comparer les performances dans le temps
- Identifier les rÃ©gressions
- Correler avec des Ã©vÃ©nements (dÃ©ploiements, montÃ©es de version)

**StratÃ©gie de rÃ©tention** :
- Rapports quotidiens : 30 jours
- Rapports hebdomadaires : 12 semaines
- Rapports mensuels : 12 mois

### 3. DÃ©finir des seuils d'alerte

**CrÃ©er une checklist de revue** :

| MÃ©trique | Seuil d'alerte | Action |
|----------|----------------|--------|
| RequÃªtes > 1s | > 100/jour | Investigation immÃ©diate |
| Checkpoints forcÃ©s | > 10% du total | Augmenter `max_wal_size` |
| Erreurs | > 50/jour | Audit de code |
| Connexions Ã©chouÃ©es | > 20/jour | VÃ©rifier sÃ©curitÃ© |
| Temp files | > 1GB/jour | Revoir `work_mem` |

### 4. Partager les rapports

**Qui doit consulter les rapports ?**
- **DÃ©veloppeurs** : Identifier les requÃªtes Ã  optimiser dans leur code
- **DevOps/SRE** : Surveiller la santÃ© globale du systÃ¨me
- **DBA** : Tuning de configuration et maintenance
- **Product Managers** : Comprendre les patterns d'utilisation

**MÃ©thode** : HÃ©berger les rapports HTML sur un serveur web interne accessible Ã  l'Ã©quipe.

### 5. CorrÃ©ler avec d'autres mÃ©triques

pgBadger ne fonctionne pas en isolation. Combinez avec :
- **MÃ©triques systÃ¨me** : CPU, RAM, I/O (via `pg_stat_kcache`, Prometheus)
- **MÃ©triques applicatives** : Temps de rÃ©ponse, taux d'erreur (APM)
- **Logs applicatifs** : Identifier quelle partie du code gÃ©nÃ¨re les requÃªtes lentes

**Exemple de corrÃ©lation** :
```
pgBadger â†’ Pic de requÃªtes lentes Ã  14h37
Monitoring systÃ¨me â†’ Pic I/O Ã  14h37
Logs applicatifs â†’ Job de synchronisation lancÃ© Ã  14h35
â†’ Conclusion : Le job de synchro sature la base
```

---

## Limites et considÃ©rations

### Limites de pgBadger

1. **DÃ©pend de la configuration des logs**
   - Si PostgreSQL ne log pas assez d'informations, pgBadger ne peut pas les analyser
   - NÃ©cessite `log_line_prefix` bien configurÃ©

2. **Analyse post-mortem uniquement**
   - pgBadger analyse les logs a posteriori
   - Ne fournit pas de monitoring temps rÃ©el
   - DÃ©lai entre l'Ã©vÃ©nement et l'analyse

3. **Pas de recommandations automatiques**
   - pgBadger montre les problÃ¨mes, mais ne les rÃ©sout pas
   - L'interprÃ©tation et les actions correctives sont Ã  la charge de l'administrateur

4. **VolumÃ©trie**
   - Sur de trÃ¨s gros logs (>10GB), l'analyse peut Ãªtre longue
   - Consommation mÃ©moire proportionnelle Ã  la taille des logs

5. **RequÃªtes normalisÃ©es**
   - Les paramÃ¨tres sont remplacÃ©s par `$1`, `$2`...
   - On perd la visibilitÃ© sur les valeurs spÃ©cifiques
   - Impossible de savoir quels utilisateurs ou ID posent problÃ¨me

### Quand utiliser des alternatives ?

| Besoin | Alternative Ã  pgBadger |
|--------|------------------------|
| **Monitoring temps rÃ©el** | pg_stat_statements, Prometheus + Grafana |
| **Alerting automatique** | Prometheus Alertmanager, Datadog |
| **Analyse de requÃªtes en direct** | pg_stat_activity, pg_stat_statements |
| **Profiling dÃ©taillÃ©** | auto_explain, EXPLAIN ANALYZE |
| **APM complet** | New Relic, Datadog APM, Sentry |

### ComplÃ©mentaritÃ© des outils

pgBadger fait partie d'une **stack d'observabilitÃ© complÃ¨te** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stack d'observabilitÃ©               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Temps rÃ©el    â†’ pg_stat_statements, Grafana      â”‚
â”‚ Historique    â†’ pgBadger                         â”‚
â”‚ Profiling     â†’ EXPLAIN, auto_explain            â”‚
â”‚ SystÃ¨me       â†’ pg_stat_kcache, node_exporter    â”‚
â”‚ Applicatif    â†’ APM, Sentry                      â”‚
â”‚ Alerting      â†’ Prometheus Alertmanager          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Utiliser pgBadger en complÃ©ment**, pas en remplacement des autres outils.

---

## Impact sur les performances

### La journalisation a-t-elle un coÃ»t ?

**Oui**, mais gÃ©nÃ©ralement acceptable en production.

#### Impact de log_min_duration_statement

| Valeur | Impact CPU | Impact I/O | Volume logs |
|--------|------------|------------|-------------|
| `0` (tout) | ~5-10% | Important | TrÃ¨s Ã©levÃ© |
| `100ms` | ~1-2% | Faible | ModÃ©rÃ© |
| `1000ms` | <1% | TrÃ¨s faible | Faible |
| `off` | 0% | 0% | Minimal |

**Recommandation** : Commencer Ã  `500ms` et ajuster selon le contexte.

#### Impact de l'analyse par pgBadger

- **Pas d'impact sur PostgreSQL** : pgBadger analyse les fichiers de logs hors ligne
- **Ressources utilisÃ©es** : CPU et mÃ©moire de la machine oÃ¹ pgBadger s'exÃ©cute
- **Peut Ãªtre exÃ©cutÃ© sur un serveur sÃ©parÃ©** : Copier les logs et analyser ailleurs

### Optimiser l'analyse pgBadger

Pour de trÃ¨s gros logs :

1. **Mode incrÃ©mental** : Analyser seulement les nouveaux logs, pas tout le fichier Ã  chaque fois
2. **Analyse parallÃ¨le** : pgBadger peut utiliser plusieurs cÅ“urs CPU
3. **Filtrage prÃ©alable** : Analyser seulement certaines bases ou pÃ©riodes
4. **Compression** : Les logs peuvent Ãªtre compressÃ©s, pgBadger supporte gzip, bzip2, xz

---

## pgBadger dans le workflow DevOps

### IntÃ©gration dans le cycle de dÃ©veloppement

#### 1. DÃ©veloppement

- Analyser les logs de l'environnement de dev
- Identifier les requÃªtes problÃ©matiques avant la mise en production
- Valider que les optimisations fonctionnent

#### 2. Staging

- GÃ©nÃ©rer des rapports aprÃ¨s les tests de charge
- Comparer avec les rapports de production
- Anticiper les problÃ¨mes de performance

#### 3. Production

- Rapports automatiques quotidiens
- Alertes sur les anomalies
- Audit rÃ©gulier des performances

#### 4. Post-mortem

AprÃ¨s un incident :
1. Analyser les logs de la pÃ©riode de l'incident
2. Identifier la cause racine
3. Documenter dans le post-mortem
4. DÃ©finir des actions prÃ©ventives

### Exemple de workflow automatisÃ©

```bash
#!/bin/bash
# Script quotidien de gÃ©nÃ©ration de rapport pgBadger

# 1. DÃ©finir les chemins
LOG_DIR="/var/log/postgresql"
REPORT_DIR="/var/www/pgbadger"
DATE=$(date +%Y-%m-%d)

# 2. Analyser les logs de la veille
pgbadger \
  --incremental \
  --outdir $REPORT_DIR \
  --prefix '%t [%p] %u@%d ' \
  $LOG_DIR/postgresql-$DATE*.log

# 3. VÃ©rifier les seuils d'alerte
SLOW_QUERIES=$(grep -c "duration: [0-9]\{4,\}" $LOG_DIR/postgresql-$DATE*.log)

if [ $SLOW_QUERIES -gt 100 ]; then
  # Envoyer une alerte
  echo "Alert: $SLOW_QUERIES slow queries detected" | mail -s "pgBadger Alert" dba@example.com
fi

# 4. Archiver les anciens rapports (> 30 jours)
find $REPORT_DIR -name "*.html" -mtime +30 -delete
```

---

## Comparaison avec d'autres outils

### pgBadger vs pg_stat_statements

| CritÃ¨re | pgBadger | pg_stat_statements |
|---------|----------|---------------------|
| **Type** | Analyse de logs | Extension PostgreSQL |
| **Temps rÃ©el** | Non (post-mortem) | Oui |
| **Installation** | Externe | IntÃ©grÃ©e |
| **Impact** | ZÃ©ro sur PG | LÃ©ger (~2%) |
| **Richesse** | TrÃ¨s complet | Statistiques seulement |
| **Historique** | IllimitÃ© (logs) | LimitÃ© (mÃ©moire) |
| **Visualisation** | HTML interactif | RequÃªtes SQL |

**ComplÃ©mentaritÃ©** : Utiliser **pg_stat_statements pour le temps rÃ©el**, **pgBadger pour l'analyse approfondie**.

### pgBadger vs Grafana/Prometheus

| CritÃ¨re | pgBadger | Prometheus/Grafana |
|---------|----------|--------------------|
| **Setup** | Simple (1 binaire) | Complexe (stack complÃ¨te) |
| **Temps rÃ©el** | Non | Oui |
| **RequÃªtes SQL** | Oui, dÃ©taillÃ©es | Non (mÃ©triques agrÃ©gÃ©es) |
| **Historique** | Excellent | Bon (rÃ©tention configurable) |
| **Alerting** | Non | Oui |
| **CoÃ»t** | Gratuit | Gratuit (open-source) |

**ComplÃ©mentaritÃ©** : **Prometheus/Grafana pour le monitoring global**, **pgBadger pour l'audit SQL dÃ©taillÃ©**.

### pgBadger vs APM (New Relic, Datadog)

| CritÃ¨re | pgBadger | APM |
|---------|----------|-----|
| **Scope** | Base de donnÃ©es | Applicatif + DB |
| **CoÃ»t** | Gratuit | Payant ($$) |
| **DÃ©tail SQL** | Excellent | Bon |
| **TraÃ§age distribuÃ©** | Non | Oui |
| **CorrÃ©lation app/DB** | Non | Oui |

**ComplÃ©mentaritÃ©** : **APM pour une vue end-to-end**, **pgBadger pour un focus database approfondi**.

---

## Ressources et documentation

### Documentation officielle

- **Site web** : https://pgbadger.darold.net/
- **GitHub** : https://github.com/darold/pgbadger
- **Documentation** : https://pgbadger.darold.net/documentation.html

### Articles et tutoriels

- Blog 2ndQuadrant : SÃ©ries d'articles sur l'optimisation avec pgBadger
- Blog Percona : Best practices PostgreSQL logging
- PostgreSQL Wiki : Logging configuration

### CommunautÃ©

- **Mailing list** : pgsql-general@postgresql.org
- **Reddit** : r/PostgreSQL
- **Discord** : Serveur PostgreSQL francophone et anglophone

---

## Conclusion

### Ce qu'il faut retenir

**pgBadger est un outil indispensable** pour :
âœ… Comprendre l'activitÃ© de votre base PostgreSQL
âœ… Identifier les requÃªtes Ã  optimiser
âœ… Diagnostiquer les problÃ¨mes de performance
âœ… Auditer la sÃ©curitÃ© et les erreurs
âœ… Planifier la capacitÃ©
âœ… Valider les optimisations

**Points clÃ©s** :
- ğŸ“Š GÃ©nÃ¨re des rapports HTML visuels et interactifs
- ğŸ¯ Gratuit, open-source et performant
- ğŸ” Analyse post-mortem (pas de temps rÃ©el)
- âš™ï¸ NÃ©cessite une configuration de logs PostgreSQL appropriÃ©e
- ğŸ¤ ComplÃ©mentaire avec d'autres outils de monitoring

### Prochaines Ã©tapes

AprÃ¨s avoir compris pgBadger, vous pouvez :
1. Configurer correctement les logs PostgreSQL
2. Mettre en place des rapports automatiques quotidiens
3. DÃ©finir des seuils d'alerte adaptÃ©s Ã  votre contexte
4. Combiner avec pg_stat_statements pour une vue complÃ¨te
5. IntÃ©grer dans votre workflow DevOps

**pgBadger transforme les logs bruts en insights actionnables.** C'est un outil simple mais puissant qui doit faire partie de votre boÃ®te Ã  outils PostgreSQL.

---

## Glossaire des termes utilisÃ©s

- **Log** : Fichier journal enregistrant les Ã©vÃ©nements d'une application
- **Parsing** : Analyse syntaxique d'un texte structurÃ©
- **Checkpoint** : Point de sauvegarde garantissant la persistance des donnÃ©es
- **Deadlock** : Verrou circulaire bloquant plusieurs transactions
- **Temp file** : Fichier temporaire crÃ©Ã© pour des opÃ©rations mÃ©moire insuffisantes
- **work_mem** : MÃ©moire allouÃ©e par opÃ©ration de tri/hash
- **Bloat** : Espace perdu dans les tables/index dÃ» Ã  MVCC
- **VACUUM** : OpÃ©ration de nettoyage et rÃ©cupÃ©ration d'espace
- **APM** : Application Performance Monitoring (surveillance des performances)

---


â­ï¸ [pg_stat_kcache : MÃ©triques systÃ¨me (CPU, I/O)](/14-observabilite-et-monitoring/07.2-pg-stat-kcache.md)
