ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 21.2.2 IA et Machine Learning IntÃ©grÃ©s

## Introduction

L'intelligence artificielle et le Machine Learning transforment la faÃ§on dont nous interagissons avec les donnÃ©es. PostgreSQL, grÃ¢ce Ã  son architecture extensible, s'est positionnÃ© comme une base de donnÃ©es de premier choix pour les applications d'IA modernes.

Ce chapitre explore comment PostgreSQL s'intÃ¨gre dans l'Ã©cosystÃ¨me IA/ML, des embeddings vectoriels aux pipelines de Machine Learning, en passant par les architectures RAG (Retrieval Augmented Generation) qui alimentent les chatbots et assistants IA actuels.

---

## Partie 1 : Comprendre les Concepts Fondamentaux

### 1.1 Qu'est-ce qu'un Embedding ?

Un **embedding** (ou plongement vectoriel) est une reprÃ©sentation numÃ©rique d'une donnÃ©e (texte, image, audio) sous forme de vecteur de nombres. Cette reprÃ©sentation capture le **sens** ou les **caractÃ©ristiques** de la donnÃ©e.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Du Texte aux Vecteurs                                â”‚
â”‚                                                                         â”‚
â”‚   Texte original           ModÃ¨le d'embedding         Vecteur           â”‚
â”‚                                                                         â”‚
â”‚   "Le chat dort"    â”€â”€â”€â–º   [OpenAI / Cohere /   â”€â”€â”€â–º  [0.12, -0.45,     â”‚
â”‚                             HuggingFace]               0.78, 0.23,      â”‚
â”‚                                                        ..., -0.31]      â”‚
â”‚                                                        (1536 dimensions)â”‚
â”‚                                                                         â”‚
â”‚   "Le fÃ©lin sommeille" â”€â–º  [MÃªme modÃ¨le]        â”€â”€â”€â–º  [0.11, -0.44,     â”‚
â”‚                                                        0.79, 0.22,      â”‚
â”‚                                                        ..., -0.30]      â”‚
â”‚                                                        (vecteur proche!)â”‚
â”‚                                                                         â”‚
â”‚   âœ Des textes similaires produisent des vecteurs proches               â”‚
â”‚   âœ La distance entre vecteurs = similaritÃ© sÃ©mantique                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Pourquoi Stocker des Vecteurs dans PostgreSQL ?

Traditionnellement, les vecteurs Ã©taient stockÃ©s dans des bases spÃ©cialisÃ©es (Pinecone, Milvus, Weaviate). Mais stocker les vecteurs dans PostgreSQL offre de nombreux avantages :

| Avantage | Description |
|----------|-------------|
| **Unification** | Une seule base pour les donnÃ©es relationnelles ET vectorielles |
| **Transactions ACID** | CohÃ©rence garantie entre mÃ©tadonnÃ©es et vecteurs |
| **SQL familier** | Pas besoin d'apprendre un nouveau langage de requÃªte |
| **Jointures** | Combiner recherche vectorielle et filtres SQL |
| **Ã‰cosystÃ¨me** | BÃ©nÃ©ficier de l'outillage PostgreSQL existant |
| **CoÃ»t** | Ã‰viter une infrastructure supplÃ©mentaire |

### 1.3 La Recherche Vectorielle

La recherche vectorielle trouve les Ã©lÃ©ments les plus **similaires** Ã  une requÃªte, basÃ©e sur la distance entre vecteurs.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Recherche par SimilaritÃ©                             â”‚
â”‚                                                                         â”‚
â”‚   Espace vectoriel (simplifiÃ© en 2D)                                    â”‚
â”‚                                                                         â”‚
â”‚        â–²                                                                â”‚
â”‚        â”‚     â€¢ "voiture rouge"                                          â”‚
â”‚        â”‚                              â€¢ "automobile Ã©carlate"           â”‚
â”‚        â”‚         â˜… RequÃªte:                   (trÃ¨s proche!)            â”‚
â”‚        â”‚           "vÃ©hicule rouge"                                     â”‚
â”‚        â”‚                                                                â”‚
â”‚        â”‚                                                                â”‚
â”‚        â”‚                        â€¢ "maison bleue"                        â”‚
â”‚        â”‚   â€¢ "chat noir"              (Ã©loignÃ©)                         â”‚
â”‚        â”‚                                                                â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º     â”‚
â”‚                                                                         â”‚
â”‚   La recherche retourne les K vecteurs les plus proches de la requÃªte   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.4 MÃ©triques de Distance

Plusieurs mÃ©triques permettent de mesurer la similaritÃ© entre vecteurs :

| MÃ©trique | Symbole | Description | Cas d'usage |
|----------|---------|-------------|-------------|
| **Distance L2 (Euclidienne)** | `<->` | Distance gÃ©omÃ©trique directe | Usage gÃ©nÃ©ral |
| **Produit scalaire (Inner Product)** | `<#>` | Projection d'un vecteur sur l'autre | ModÃ¨les normalisÃ©s |
| **Distance Cosinus** | `<=>` | Angle entre les vecteurs (0-2) | Texte, recommandations |
| **Distance L1 (Manhattan)** | `<+>` | Somme des diffÃ©rences absolues | Cas spÃ©cifiques |

```sql
-- Exemples avec pgvector
-- Distance L2 (plus petit = plus proche)
SELECT * FROM documents ORDER BY embedding <-> query_vector LIMIT 5;

-- Distance Cosinus (plus petit = plus similaire)
SELECT * FROM documents ORDER BY embedding <=> query_vector LIMIT 5;

-- Produit scalaire (plus grand = plus similaire, noter le signe nÃ©gatif)
SELECT * FROM documents ORDER BY embedding <#> query_vector LIMIT 5;
```

---

## Partie 2 : pgvector - L'Extension Vectorielle

### 2.1 PrÃ©sentation de pgvector

**pgvector** est l'extension open-source de rÃ©fÃ©rence pour le stockage et la recherche de vecteurs dans PostgreSQL. CrÃ©Ã©e par Andrew Kane, elle est devenue un standard de l'industrie.

#### Installation

```sql
-- Installer l'extension (nÃ©cessite les droits superuser)
CREATE EXTENSION vector;

-- VÃ©rifier l'installation
SELECT * FROM pg_extension WHERE extname = 'vector';
```

```bash
# Installation sur Ubuntu/Debian
sudo apt install postgresql-17-pgvector

# Installation sur macOS avec Homebrew
brew install pgvector

# Avec Docker (image officielle)
docker run -e POSTGRES_PASSWORD=secret ankane/pgvector
```

### 2.2 Le Type vector

pgvector introduit le type `vector` pour stocker des tableaux de nombres Ã  virgule flottante.

```sql
-- CrÃ©er une table avec une colonne vectorielle
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    titre VARCHAR(255) NOT NULL,
    contenu TEXT,
    embedding vector(1536)    -- Vecteur de 1536 dimensions (OpenAI)
);

-- InsÃ©rer un vecteur
INSERT INTO documents (titre, contenu, embedding)
VALUES (
    'Introduction Ã  PostgreSQL',
    'PostgreSQL est un systÃ¨me de gestion...',
    '[0.12, -0.45, 0.78, ...]'::vector  -- 1536 valeurs
);

-- Ou avec la syntaxe array
INSERT INTO documents (titre, contenu, embedding)
VALUES (
    'Guide SQL',
    'SQL est le langage standard...',
    ARRAY[0.12, -0.45, 0.78, ...]::vector
);
```

#### Dimensions Courantes

| ModÃ¨le | Dimensions | Fournisseur |
|--------|------------|-------------|
| text-embedding-3-small | 1536 | OpenAI |
| text-embedding-3-large | 3072 | OpenAI |
| text-embedding-ada-002 | 1536 | OpenAI |
| embed-english-v3.0 | 1024 | Cohere |
| all-MiniLM-L6-v2 | 384 | HuggingFace |
| bge-large-en | 1024 | BAAI |
| nomic-embed-text | 768 | Nomic |

### 2.3 OpÃ©rations sur les Vecteurs

```sql
-- Distance L2 (Euclidienne)
SELECT embedding <-> '[0.1, 0.2, 0.3]'::vector AS distance_l2
FROM documents;

-- Distance Cosinus
SELECT embedding <=> '[0.1, 0.2, 0.3]'::vector AS distance_cosinus
FROM documents;

-- Produit scalaire (nÃ©gatif pour ORDER BY ASC)
SELECT (embedding <#> '[0.1, 0.2, 0.3]'::vector) * -1 AS similarite
FROM documents;

-- OpÃ©rations mathÃ©matiques
SELECT
    embedding + '[0.1, 0.2, ...]'::vector AS addition,
    embedding - '[0.1, 0.2, ...]'::vector AS soustraction,
    embedding * '[0.1, 0.2, ...]'::vector AS multiplication
FROM documents;

-- Fonctions utilitaires
SELECT
    vector_dims(embedding) AS dimensions,      -- Nombre de dimensions
    vector_norm(embedding) AS norme,           -- Norme L2 du vecteur
    l2_distance(v1, v2) AS distance,          -- Distance L2
    cosine_distance(v1, v2) AS cos_dist,      -- Distance cosinus
    inner_product(v1, v2) AS produit          -- Produit scalaire
FROM documents;
```

### 2.4 Recherche de SimilaritÃ©

```sql
-- Trouver les 5 documents les plus similaires Ã  un vecteur de requÃªte
SELECT
    id,
    titre,
    embedding <=> query_embedding AS distance
FROM documents
ORDER BY embedding <=> query_embedding
LIMIT 5;

-- Recherche avec seuil de distance
SELECT id, titre, embedding <=> query_embedding AS distance
FROM documents
WHERE embedding <=> query_embedding < 0.5  -- Seuil de similaritÃ©
ORDER BY distance
LIMIT 10;

-- Combiner avec des filtres SQL classiques
SELECT id, titre, distance
FROM documents
WHERE categorie = 'technologie'
  AND date_publication > '2024-01-01'
ORDER BY embedding <=> query_embedding
LIMIT 5;
```

### 2.5 Index pour la Recherche Vectorielle

Sans index, la recherche vectorielle effectue un scan complet (exact mais lent). Les index permettent une recherche approximative mais rapide.

#### Index IVFFlat (Inverted File Index)

Divise l'espace en clusters et cherche dans les clusters les plus proches.

```sql
-- CrÃ©er un index IVFFlat
CREATE INDEX idx_documents_embedding_ivf
ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);  -- Nombre de clusters

-- ParamÃ¨tres recommandÃ©s pour 'lists':
-- Jusqu'Ã  1M lignes  : lists = sqrt(n_rows)
-- Plus de 1M lignes  : lists = sqrt(n_rows) ou n_rows / 1000
```

**Options d'opÃ©rateurs** :
- `vector_l2_ops` : Pour distance L2
- `vector_ip_ops` : Pour produit scalaire
- `vector_cosine_ops` : Pour distance cosinus

```sql
-- ContrÃ´ler le nombre de clusters Ã  explorer (trade-off prÃ©cision/vitesse)
SET ivfflat.probes = 10;  -- DÃ©faut: 1, plus = plus prÃ©cis mais plus lent

-- Pour une requÃªte spÃ©cifique
SELECT * FROM documents
ORDER BY embedding <=> query_vector
LIMIT 5;
```

#### Index HNSW (Hierarchical Navigable Small World)

Structure de graphe hiÃ©rarchique, gÃ©nÃ©ralement plus performant que IVFFlat.

```sql
-- CrÃ©er un index HNSW
CREATE INDEX idx_documents_embedding_hnsw
ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- ParamÃ¨tres :
-- m              : Nombre de connexions par nÅ“ud (dÃ©faut: 16)
-- ef_construction: Taille de la liste de candidats lors de la construction (dÃ©faut: 64)
```

```sql
-- ContrÃ´ler la prÃ©cision lors de la recherche
SET hnsw.ef_search = 40;  -- DÃ©faut: 40, plus = plus prÃ©cis mais plus lent
```

#### Comparaison IVFFlat vs HNSW

| CritÃ¨re | IVFFlat | HNSW |
|---------|---------|------|
| **Vitesse de recherche** | Rapide | TrÃ¨s rapide |
| **PrÃ©cision** | Bonne | Excellente |
| **Temps de construction** | Rapide | Lent |
| **Utilisation mÃ©moire** | Faible | Ã‰levÃ©e |
| **Mises Ã  jour** | Performantes | Moins performantes |
| **Cas d'usage** | DonnÃ©es changeantes | DonnÃ©es statiques |

### 2.6 Bonnes Pratiques pgvector

```sql
-- 1. Normaliser les vecteurs pour la distance cosinus
-- (amÃ©liore les performances avec inner product)
UPDATE documents
SET embedding = embedding / vector_norm(embedding)
WHERE vector_norm(embedding) > 0;

-- 2. Utiliser le bon type d'index selon le volume
-- < 10K lignes   : Pas d'index (exact search rapide)
-- 10K - 100K     : IVFFlat avec lists = sqrt(n)
-- > 100K         : HNSW

-- 3. CrÃ©er l'index APRÃˆS l'insertion des donnÃ©es
INSERT INTO documents (titre, embedding) VALUES ...;  -- Insertions massives
CREATE INDEX idx_embedding ON documents USING hnsw (embedding vector_cosine_ops);

-- 4. Surveiller l'utilisation de l'index
EXPLAIN ANALYZE
SELECT * FROM documents
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;
```

---

## Partie 3 : Architectures RAG (Retrieval Augmented Generation)

### 3.1 Qu'est-ce que RAG ?

**RAG** (Retrieval Augmented Generation) est une architecture qui amÃ©liore les rÃ©ponses des LLM (Large Language Models) en leur fournissant du contexte pertinent rÃ©cupÃ©rÃ© depuis une base de connaissances.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Architecture RAG                                       â”‚
â”‚                                                                           â”‚
â”‚   1. INDEXATION (prÃ©paration)                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                    â”‚  â”‚
â”‚   â”‚   Documents    â”€â”€â”€â–º   Chunking    â”€â”€â”€â–º   Embedding   â”€â”€â”€â–º  PG      â”‚  â”‚
â”‚   â”‚   (PDF, Web,         (dÃ©coupage)        (vectorisation)   avec     â”‚  â”‚
â”‚   â”‚    Markdown)                                              pgvector â”‚  â”‚
â”‚   â”‚                                                                    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                           â”‚
â”‚   2. REQUÃŠTE (utilisation)                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                    â”‚  â”‚
â”‚   â”‚   Question     â”€â”€â”€â–º   Embedding   â”€â”€â”€â–º   Recherche    â”€â”€â”€â–º         â”‚  â”‚
â”‚   â”‚   utilisateur         de la             vectorielle       Top K    â”‚  â”‚
â”‚   â”‚                       question          dans PG           docs     â”‚  â”‚
â”‚   â”‚                                                                    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                           â”‚
â”‚   3. GÃ‰NÃ‰RATION                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                    â”‚  â”‚
â”‚   â”‚   Question     â”€â”€â”€â–º      LLM        â”€â”€â”€â–º   RÃ©ponse                 â”‚  â”‚
â”‚   â”‚      +                (GPT-4,              contextualisÃ©e          â”‚  â”‚
â”‚   â”‚   Contexte            Claude,              et prÃ©cise              â”‚  â”‚
â”‚   â”‚   (Top K docs)        Llama)                                       â”‚  â”‚
â”‚   â”‚                                                                    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Pourquoi RAG ?

Les LLM ont des limitations que RAG rÃ©sout :

| ProblÃ¨me LLM | Solution RAG |
|--------------|--------------|
| **Connaissances figÃ©es** | AccÃ¨s Ã  des donnÃ©es Ã  jour |
| **Hallucinations** | RÃ©ponses basÃ©es sur des sources vÃ©rifiables |
| **DonnÃ©es privÃ©es** | IntÃ©gration de documents d'entreprise |
| **CoÃ»t** | Ã‰vite le fine-tuning coÃ»teux |
| **TraÃ§abilitÃ©** | Citations et sources identifiables |

### 3.3 ImplÃ©mentation avec PostgreSQL

#### SchÃ©ma de Base

```sql
-- Table principale des documents
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    titre VARCHAR(255) NOT NULL,
    source VARCHAR(255),              -- URL, chemin fichier, etc.
    contenu_original TEXT,            -- Texte complet
    metadata JSONB DEFAULT '{}',      -- MÃ©tadonnÃ©es flexibles
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Table des chunks (morceaux de documents)
CREATE TABLE chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
    contenu TEXT NOT NULL,            -- Texte du chunk
    embedding vector(1536),           -- Vecteur du chunk
    position INTEGER,                 -- Position dans le document original
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Index pour la recherche vectorielle
CREATE INDEX idx_chunks_embedding ON chunks
USING hnsw (embedding vector_cosine_ops);

-- Index pour les filtres courants
CREATE INDEX idx_chunks_document_id ON chunks(document_id);
CREATE INDEX idx_documents_metadata ON documents USING gin(metadata);
```

#### Fonction de Recherche RAG

```sql
-- Fonction pour rechercher les chunks pertinents
CREATE OR REPLACE FUNCTION recherche_rag(
    query_embedding vector(1536),
    limite INTEGER DEFAULT 5,
    seuil_distance FLOAT DEFAULT 0.8
)
RETURNS TABLE (
    chunk_id INTEGER,
    document_id INTEGER,
    titre VARCHAR,
    contenu TEXT,
    distance FLOAT,
    metadata JSONB
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        c.id AS chunk_id,
        c.document_id,
        d.titre,
        c.contenu,
        (c.embedding <=> query_embedding)::FLOAT AS distance,
        c.metadata || d.metadata AS metadata
    FROM chunks c
    JOIN documents d ON c.document_id = d.id
    WHERE c.embedding <=> query_embedding < seuil_distance
    ORDER BY c.embedding <=> query_embedding
    LIMIT limite;
END;
$$ LANGUAGE plpgsql;

-- Utilisation
SELECT * FROM recherche_rag(
    '[0.12, -0.45, ...]'::vector,  -- Embedding de la question
    5,                              -- Nombre de rÃ©sultats
    0.7                             -- Seuil de similaritÃ©
);
```

#### Recherche Hybride (Vecteurs + Full-Text)

Combiner la recherche sÃ©mantique (vecteurs) et lexicale (full-text) amÃ©liore souvent les rÃ©sultats.

```sql
-- Ajouter une colonne tsvector pour la recherche full-text
ALTER TABLE chunks ADD COLUMN contenu_tsv tsvector
    GENERATED ALWAYS AS (to_tsvector('french', contenu)) STORED;

CREATE INDEX idx_chunks_tsv ON chunks USING gin(contenu_tsv);

-- Fonction de recherche hybride
CREATE OR REPLACE FUNCTION recherche_hybride(
    query_text TEXT,
    query_embedding vector(1536),
    limite INTEGER DEFAULT 5,
    poids_semantic FLOAT DEFAULT 0.7,  -- Poids de la recherche vectorielle
    poids_lexical FLOAT DEFAULT 0.3    -- Poids de la recherche full-text
)
RETURNS TABLE (
    chunk_id INTEGER,
    contenu TEXT,
    score_final FLOAT
) AS $$
BEGIN
    RETURN QUERY
    WITH scores AS (
        SELECT
            c.id,
            c.contenu,
            -- Score sÃ©mantique (convertir distance en similaritÃ©)
            1 - (c.embedding <=> query_embedding) AS score_semantic,
            -- Score lexical (normalisÃ©)
            COALESCE(ts_rank_cd(c.contenu_tsv, plainto_tsquery('french', query_text)), 0) AS score_lexical
        FROM chunks c
        WHERE c.contenu_tsv @@ plainto_tsquery('french', query_text)
           OR c.embedding <=> query_embedding < 0.8
    )
    SELECT
        s.id,
        s.contenu,
        (s.score_semantic * poids_semantic + s.score_lexical * poids_lexical) AS score_final
    FROM scores s
    ORDER BY score_final DESC
    LIMIT limite;
END;
$$ LANGUAGE plpgsql;
```

### 3.4 StratÃ©gies de Chunking

Le dÃ©coupage des documents en chunks est crucial pour la qualitÃ© du RAG.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    StratÃ©gies de Chunking                              â”‚
â”‚                                                                        â”‚
â”‚   1. TAILLE FIXE                                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Chunk 1 (500 tokens) â”‚ Chunk 2 (500 tokens) â”‚ Chunk 3 (500)... â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚   âœ“ Simple  âœ— Peut couper en milieu de phrase                          â”‚
â”‚                                                                        â”‚
â”‚   2. AVEC CHEVAUCHEMENT (Overlap)                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚   â”‚        Chunk 1 (500)          â”‚                                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                     â”‚â—„â”€â”€ Overlap (50) â”€â”€â–ºâ”‚                             â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚             â”‚        Chunk 2 (500)        â”‚                            â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚   âœ“ PrÃ©serve le contexte aux frontiÃ¨res                                â”‚
â”‚                                                                        â”‚
â”‚   3. SÃ‰MANTIQUE (par paragraphe/section)                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚ Introduction â”‚ â”‚ Section 1          â”‚ â”‚ Section 2       â”‚          â”‚
â”‚   â”‚ (variable)   â”‚ â”‚ (variable)         â”‚ â”‚ (variable)      â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚   âœ“ Respecte la structure  âœ— Tailles variables                         â”‚
â”‚                                                                        â”‚
â”‚   4. RÃ‰CURSIF (LangChain style)                                        â”‚
â”‚   Tente de dÃ©couper par: \n\n â†’ \n â†’ . â†’ espace â†’ caractÃ¨re            â”‚
â”‚   âœ“ Ã‰quilibre taille et sens                                           â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```sql
-- Exemple de stockage avec mÃ©tadonnÃ©es de chunking
INSERT INTO chunks (document_id, contenu, position, metadata)
VALUES (
    1,
    'PostgreSQL est un systÃ¨me de gestion de bases de donnÃ©es...',
    0,
    '{
        "chunk_size": 500,
        "overlap": 50,
        "strategy": "recursive",
        "section": "introduction"
    }'::jsonb
);
```

---

## Partie 4 : IntÃ©gration avec les ModÃ¨les d'IA

### 4.1 Architecture d'IntÃ©gration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IntÃ©gration PostgreSQL + IA                        â”‚
â”‚                                                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                      Application                              â”‚   â”‚
â”‚   â”‚   (Python, Node.js, Go, etc.)                                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                           â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚           â–¼               â–¼               â–¼                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚  API        â”‚  â”‚ PostgreSQL  â”‚  â”‚   LLM API   â”‚                   â”‚
â”‚   â”‚  Embedding  â”‚  â”‚ + pgvector  â”‚  â”‚ (OpenAI,    â”‚                   â”‚
â”‚   â”‚  (OpenAI,   â”‚  â”‚             â”‚  â”‚  Anthropic, â”‚                   â”‚
â”‚   â”‚   Cohere)   â”‚  â”‚             â”‚  â”‚  Local)     â”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                       â”‚
â”‚   Flux typique :                                                      â”‚
â”‚   1. Texte â†’ API Embedding â†’ Vecteur                                  â”‚
â”‚   2. Vecteur â†’ PostgreSQL â†’ Documents similaires                      â”‚
â”‚   3. Question + Documents â†’ LLM â†’ RÃ©ponse                             â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Exemple Python avec LangChain

```python
# Installation: pip install langchain langchain-openai pgvector psycopg2-binary

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_postgres import PGVector
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Configuration
CONNECTION_STRING = "postgresql://user:password@localhost:5432/mydb"
COLLECTION_NAME = "documents_rag"

# 1. Initialiser les embeddings
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# 2. Connexion Ã  PostgreSQL avec pgvector
vectorstore = PGVector(
    connection=CONNECTION_STRING,
    embeddings=embeddings,
    collection_name=COLLECTION_NAME,
    use_jsonb=True,
)

# 3. DÃ©couper et indexer des documents
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ".", " ", ""]
)

documents = [...]  # Vos documents
chunks = text_splitter.split_documents(documents)
vectorstore.add_documents(chunks)

# 4. CrÃ©er une chaÃ®ne RAG
llm = ChatOpenAI(model="gpt-4", temperature=0)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    return_source_documents=True
)

# 5. Poser une question
result = qa_chain.invoke({"query": "Qu'est-ce que PostgreSQL ?"})
print(result["result"])
print("Sources:", result["source_documents"])
```

### 4.3 Exemple avec SQL Direct

Pour plus de contrÃ´le, vous pouvez interagir directement avec PostgreSQL :

```python
import psycopg2
import openai
from pgvector.psycopg2 import register_vector

# Connexion PostgreSQL
conn = psycopg2.connect("postgresql://user:password@localhost:5432/mydb")
register_vector(conn)
cur = conn.cursor()

def get_embedding(text: str) -> list:
    """Obtenir l'embedding d'un texte via OpenAI"""
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

def recherche_similaire(question: str, limite: int = 5):
    """Rechercher les documents similaires Ã  une question"""
    # 1. Obtenir l'embedding de la question
    query_embedding = get_embedding(question)

    # 2. Rechercher dans PostgreSQL
    cur.execute("""
        SELECT
            id,
            contenu,
            1 - (embedding <=> %s::vector) AS similarite
        FROM chunks
        ORDER BY embedding <=> %s::vector
        LIMIT %s
    """, (query_embedding, query_embedding, limite))

    return cur.fetchall()

def generer_reponse(question: str, contexte: str) -> str:
    """GÃ©nÃ©rer une rÃ©ponse avec le LLM"""
    response = openai.chat.completions.create(
        model="gpt-4",
        messages=[
            {
                "role": "system",
                "content": f"""RÃ©ponds Ã  la question en utilisant uniquement
                le contexte fourni. Si tu ne peux pas rÃ©pondre avec le contexte,
                dis-le.

                Contexte:
                {contexte}"""
            },
            {"role": "user", "content": question}
        ]
    )
    return response.choices[0].message.content

# Pipeline RAG complet
def rag_query(question: str) -> str:
    # Rechercher les documents pertinents
    resultats = recherche_similaire(question)

    # Construire le contexte
    contexte = "\n\n".join([r[1] for r in resultats])

    # GÃ©nÃ©rer la rÃ©ponse
    reponse = generer_reponse(question, contexte)

    return reponse

# Utilisation
reponse = rag_query("Comment fonctionne la rÃ©plication dans PostgreSQL ?")
print(reponse)
```

### 4.4 ModÃ¨les d'Embedding Locaux

Pour Ã©viter les coÃ»ts des API et garder les donnÃ©es en local :

```python
# Avec sentence-transformers (HuggingFace)
# pip install sentence-transformers

from sentence_transformers import SentenceTransformer

# Charger un modÃ¨le local
model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions, rapide

# GÃ©nÃ©rer des embeddings
texts = ["PostgreSQL est gÃ©nial", "J'aime les bases de donnÃ©es"]
embeddings = model.encode(texts)

# InsÃ©rer dans PostgreSQL
for text, embedding in zip(texts, embeddings):
    cur.execute(
        "INSERT INTO chunks (contenu, embedding) VALUES (%s, %s)",
        (text, embedding.tolist())
    )
conn.commit()
```

```python
# Avec Ollama (modÃ¨les locaux)
# pip install ollama

import ollama

# GÃ©nÃ©rer un embedding avec un modÃ¨le local
response = ollama.embeddings(
    model='nomic-embed-text',
    prompt='PostgreSQL est un SGBD relationnel'
)
embedding = response['embedding']  # 768 dimensions
```

---

## Partie 5 : Extensions et Outils ComplÃ©mentaires

### 5.1 pg_embedding (Neon)

Alternative Ã  pgvector dÃ©veloppÃ©e par Neon, optimisÃ©e pour leur plateforme cloud.

```sql
-- Installation
CREATE EXTENSION embedding;

-- Utilisation similaire Ã  pgvector
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    embedding real[]  -- Utilise des arrays natifs
);

-- Index HNSW
CREATE INDEX ON documents
USING hnsw (embedding ann_cos_ops);
```

### 5.2 pgai (Timescale)

Extension qui intÃ¨gre directement les appels aux API d'IA dans PostgreSQL.

```sql
-- Installation
CREATE EXTENSION pgai;

-- GÃ©nÃ©rer des embeddings directement en SQL !
SELECT openai_embed(
    'text-embedding-3-small',
    'PostgreSQL est fantastique'
);

-- CrÃ©er une colonne avec embedding automatique
ALTER TABLE documents
ADD COLUMN embedding vector(1536)
GENERATED ALWAYS AS (
    openai_embed('text-embedding-3-small', contenu)
) STORED;
```

### 5.3 Outils de l'Ã‰cosystÃ¨me

| Outil | Description | Lien |
|-------|-------------|------|
| **LangChain** | Framework pour applications LLM | langchain.com |
| **LlamaIndex** | Framework RAG spÃ©cialisÃ© | llamaindex.ai |
| **Haystack** | Pipeline NLP open-source | haystack.deepset.ai |
| **Unstructured** | Parsing de documents | unstructured.io |
| **ChromaDB** | Alternative lÃ©gÃ¨re (dev) | trychroma.com |

### 5.4 Plateformes Cloud avec pgvector

| Plateforme | pgvector | Notes |
|------------|----------|-------|
| **Supabase** | âœ… Inclus | Interface graphique, fonctions Edge |
| **Neon** | âœ… Inclus | Serverless, autoscaling |
| **AWS RDS** | âœ… Disponible | Ã€ activer manuellement |
| **Azure Database** | âœ… Disponible | Flexible Server uniquement |
| **Google Cloud SQL** | âœ… Disponible | Ã€ activer |
| **Render** | âœ… Inclus | Simple et abordable |

---

## Partie 6 : Cas d'Usage Concrets

### 6.1 Recherche SÃ©mantique

```sql
-- E-commerce : Rechercher des produits par description
SELECT
    p.nom,
    p.description,
    p.prix,
    p.embedding <=> query_embedding AS distance
FROM produits p
WHERE p.categorie = 'Ã©lectronique'
  AND p.prix BETWEEN 100 AND 500
ORDER BY p.embedding <=> query_embedding
LIMIT 10;

-- Le client cherche "appareil pour Ã©couter de la musique sans fil"
-- Trouve : "Casque Bluetooth Sony", "Ã‰couteurs AirPods", etc.
```

### 6.2 SystÃ¨me de Recommandation

```sql
-- Recommander des articles similaires Ã  ceux consultÃ©s
WITH articles_consultes AS (
    SELECT embedding
    FROM articles
    WHERE id IN (SELECT article_id FROM historique WHERE user_id = 123)
),
centroide AS (
    SELECT AVG(embedding) AS embedding_moyen
    FROM articles_consultes
)
SELECT
    a.id,
    a.titre,
    a.embedding <=> c.embedding_moyen AS distance
FROM articles a, centroide c
WHERE a.id NOT IN (SELECT article_id FROM historique WHERE user_id = 123)
ORDER BY distance
LIMIT 5;
```

### 6.3 DÃ©tection de Duplicatas

```sql
-- Trouver les tickets de support potentiellement dupliquÃ©s
SELECT
    t1.id AS ticket_original,
    t2.id AS ticket_potentiel_doublon,
    t1.titre,
    t2.titre,
    t1.embedding <=> t2.embedding AS similarite
FROM tickets t1
JOIN tickets t2 ON t1.id < t2.id
WHERE t1.embedding <=> t2.embedding < 0.1  -- TrÃ¨s similaires
  AND t1.created_at > NOW() - INTERVAL '7 days'
ORDER BY similarite;
```

### 6.4 Classification Automatique

```sql
-- Classifier automatiquement les documents par catÃ©gorie
WITH categories_embeddings AS (
    SELECT
        categorie,
        AVG(embedding) AS embedding_moyen
    FROM documents_labellises
    GROUP BY categorie
)
SELECT
    d.id,
    d.titre,
    (
        SELECT categorie
        FROM categories_embeddings
        ORDER BY embedding_moyen <=> d.embedding
        LIMIT 1
    ) AS categorie_predite
FROM documents_nouveaux d;
```

---

## Partie 7 : Bonnes Pratiques et ConsidÃ©rations

### 7.1 Performance

```sql
-- 1. Indexer correctement (APRÃˆS les insertions massives)
-- Mauvais : crÃ©er l'index puis insÃ©rer 1M de lignes
-- Bon : insÃ©rer 1M de lignes puis crÃ©er l'index

-- 2. Utiliser des index partiels si possible
CREATE INDEX idx_chunks_recent ON chunks
USING hnsw (embedding vector_cosine_ops)
WHERE created_at > '2024-01-01';

-- 3. Monitorer les performances
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM chunks
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;

-- 4. Ajuster les paramÃ¨tres de recherche
SET hnsw.ef_search = 100;  -- Plus prÃ©cis
SET ivfflat.probes = 20;   -- Plus prÃ©cis
```

### 7.2 Dimensionnement

| Volume de vecteurs | RAM recommandÃ©e | Type d'index |
|-------------------|-----------------|--------------|
| < 10 000 | 2 GB | Aucun (exact) |
| 10 000 - 100 000 | 4-8 GB | IVFFlat |
| 100 000 - 1 M | 16-32 GB | HNSW |
| > 1 M | 64+ GB | HNSW partitionnÃ© |

### 7.3 SÃ©curitÃ© et ConfidentialitÃ©

```sql
-- 1. Chiffrer les donnÃ©es sensibles avant embedding
-- (les embeddings peuvent rÃ©vÃ©ler des informations)

-- 2. Utiliser Row-Level Security pour les donnÃ©es multi-tenant
ALTER TABLE chunks ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation ON chunks
    FOR ALL
    USING (tenant_id = current_setting('app.tenant_id')::integer);

-- 3. Auditer les accÃ¨s aux donnÃ©es vectorielles
CREATE TABLE audit_recherches (
    id SERIAL PRIMARY KEY,
    user_id INTEGER,
    query_hash TEXT,  -- Hash de la requÃªte (pas le texte brut)
    resultats_ids INTEGER[],
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 7.4 CoÃ»ts

| OpÃ©ration | CoÃ»t EstimÃ© (OpenAI) |
|-----------|---------------------|
| Embedding (text-embedding-3-small) | $0.02 / 1M tokens |
| Embedding (text-embedding-3-large) | $0.13 / 1M tokens |
| Stockage PostgreSQL | Variable selon hÃ©bergement |
| RequÃªtes LLM (GPT-4) | $30 / 1M tokens (input) |

> **Conseil** : Pour rÃ©duire les coÃ»ts, utilisez des modÃ¨les d'embedding locaux (sentence-transformers) et cachez les embeddings frÃ©quemment utilisÃ©s.

---

## RÃ©sumÃ©

Ce chapitre a explorÃ© l'intÃ©gration de l'IA et du Machine Learning dans PostgreSQL :

| Concept | Ce qu'il faut retenir |
|---------|----------------------|
| **Embeddings** | ReprÃ©sentation vectorielle du sens |
| **pgvector** | Extension standard pour les vecteurs |
| **Index HNSW/IVFFlat** | Recherche approximative rapide |
| **RAG** | Architecture LLM + recherche vectorielle |
| **Recherche hybride** | Combiner vecteurs et full-text |

### Points ClÃ©s

- PostgreSQL + pgvector est une alternative viable aux bases vectorielles spÃ©cialisÃ©es
- La recherche vectorielle permet une recherche sÃ©mantique puissante
- RAG amÃ©liore les LLM avec des connaissances contextuelles
- Choisissez HNSW pour la performance, IVFFlat pour les donnÃ©es changeantes
- ConsidÃ©rez les modÃ¨les locaux pour la confidentialitÃ© et les coÃ»ts

### L'Avenir

L'intÃ©gration IA/PostgreSQL continue d'Ã©voluer :
- Support natif des vecteurs dans PostgreSQL core (discussions en cours)
- Nouveaux types d'index optimisÃ©s (DiskANN, ScaNN)
- IntÃ©gration plus profonde avec les frameworks ML
- Quantification des vecteurs pour rÃ©duire le stockage

---


â­ï¸ [Cloud-native et distributed PostgreSQL](/21-conclusion-et-perspectives/02.3-cloud-native-distributed.md)
