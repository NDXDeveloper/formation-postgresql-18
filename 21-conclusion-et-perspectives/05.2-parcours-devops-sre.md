üîù Retour au [Sommaire](/SOMMAIRE.md)

# 21.5. Roadmap de Mont√©e en Comp√©tence

## 21.5.2. Parcours DevOps/SRE PostgreSQL

Ce parcours est con√ßu pour guider les professionnels DevOps et SRE (Site Reliability Engineer) dans leur apprentissage de PostgreSQL. L'accent est mis sur le d√©ploiement, l'automatisation, le monitoring, la haute disponibilit√© et la gestion en production plut√¥t que sur le d√©veloppement SQL.

> **Note importante** : Les dur√©es indiqu√©es sont des estimations bas√©es sur un apprentissage r√©gulier. Votre progression peut varier selon votre exp√©rience pr√©alable en administration syst√®me, votre familiarit√© avec les bases de donn√©es et l'intensit√© de votre pratique.

> **Pr√©requis** : Ce parcours suppose une connaissance de base de Linux/Unix, des concepts r√©seau, et id√©alement une familiarit√© avec les outils d'automatisation (Ansible, Terraform) et les conteneurs (Docker).

---

## Phase 1 : Fondations Op√©rationnelles (0-6 mois)

### Objectif de cette phase

Acqu√©rir les comp√©tences essentielles pour installer, configurer et g√©rer une instance PostgreSQL. √Ä la fin de cette phase, vous serez capable de d√©ployer PostgreSQL, comprendre son architecture interne et effectuer les op√©rations de maintenance de base.

### Comp√©tences √† d√©velopper

#### Mois 1-2 : Architecture et Installation

**Comprendre l'architecture PostgreSQL :**

Avant de d√©ployer PostgreSQL, il est essentiel de comprendre comment il fonctionne en interne.

- **Mod√®le client-serveur** : PostgreSQL fonctionne avec un processus principal (postmaster) qui g√®re les connexions entrantes et spawne des processus backend pour chaque connexion client.

- **Processus d'arri√®re-plan essentiels** :
  - `postmaster` : processus principal, g√®re les connexions
  - `background writer` : √©crit les pages modifi√©es sur disque
  - `checkpointer` : cr√©e des points de contr√¥le r√©guliers
  - `walwriter` : √©crit les journaux de transactions (WAL)
  - `autovacuum launcher` : coordonne le nettoyage automatique
  - `stats collector` : collecte les statistiques d'utilisation

- **Gestion de la m√©moire** :
  - `shared_buffers` : cache partag√© entre tous les processus
  - `work_mem` : m√©moire par op√©ration (tri, jointure)
  - `maintenance_work_mem` : m√©moire pour les op√©rations de maintenance
  - `effective_cache_size` : estimation du cache syst√®me disponible

- **Structure physique des donn√©es** :
  - R√©pertoire de donn√©es (`PGDATA`) : contient toutes les donn√©es
  - Fichiers de configuration : `postgresql.conf`, `pg_hba.conf`, `pg_ident.conf`
  - WAL (Write-Ahead Log) : journaux de transactions pour la durabilit√©
  - Tablespaces : emplacements alternatifs pour les donn√©es

**Installation de PostgreSQL :**

- **Installation depuis les paquets officiels** (m√©thode recommand√©e) :
  - D√©p√¥t PGDG (PostgreSQL Global Development Group) pour les versions r√©centes
  - Diff√©rences entre distributions : Debian/Ubuntu, RHEL/CentOS/Rocky, etc.
  - Comprendre ce qui est install√© : binaires, biblioth√®ques, scripts

- **Structure du syst√®me de fichiers apr√®s installation** :
  - `/usr/lib/postgresql/<version>/` : binaires
  - `/etc/postgresql/<version>/<cluster>/` : configuration (Debian)
  - `/var/lib/postgresql/<version>/<cluster>/` : donn√©es (Debian)
  - Variations selon les distributions

- **Initialisation d'un cluster** :
  - Commande `initdb` : cr√©ation du r√©pertoire de donn√©es
  - Options importantes : `--encoding`, `--locale`, `--data-checksums`
  - Nouveaut√© PostgreSQL 18 : checksums activ√©s par d√©faut

- **Gestion du service** :
  - `systemctl` : start, stop, restart, reload, status
  - `pg_ctl` : outil natif PostgreSQL pour le contr√¥le
  - Diff√©rence entre `restart` et `reload` (param√®tres n√©cessitant un red√©marrage)

#### Mois 3-4 : Configuration et S√©curit√© de Base

**Fichiers de configuration essentiels :**

- **postgresql.conf** ‚Äî Configuration principale :

  Param√®tres de connexion :
  - `listen_addresses` : interfaces r√©seau √©cout√©es ('*' pour toutes)
  - `port` : port d'√©coute (d√©faut : 5432)
  - `max_connections` : nombre maximum de connexions simultan√©es

  Param√®tres m√©moire (r√®gles de base pour commencer) :
  - `shared_buffers` : 25% de la RAM syst√®me (maximum ~8GB pour commencer)
  - `effective_cache_size` : 50-75% de la RAM syst√®me
  - `work_mem` : 32-64MB (attention, multipli√© par le nombre d'op√©rations)
  - `maintenance_work_mem` : 256MB-1GB selon la RAM disponible

  Param√®tres WAL :
  - `wal_level` : `replica` pour la r√©plication, `logical` pour la r√©plication logique
  - `max_wal_size` : taille maximale des WAL avant checkpoint
  - `checkpoint_timeout` : intervalle entre checkpoints

- **pg_hba.conf** ‚Äî Contr√¥le d'acc√®s :

  Ce fichier d√©finit qui peut se connecter, depuis o√π, et comment.

  Format d'une ligne :
  ```
  TYPE  DATABASE  USER  ADDRESS  METHOD
  ```

  Types de connexion :
  - `local` : connexions via socket Unix
  - `host` : connexions TCP/IP (SSL ou non)
  - `hostssl` : connexions TCP/IP avec SSL obligatoire
  - `hostnossl` : connexions TCP/IP sans SSL

  M√©thodes d'authentification :
  - `trust` : aucune authentification (JAMAIS en production)
  - `peer` : authentification via le syst√®me (utilisateur Unix = utilisateur PostgreSQL)
  - `md5` : mot de passe hash√© MD5 (d√©pr√©ci√©)
  - `scram-sha-256` : m√©thode recommand√©e pour les mots de passe
  - `cert` : authentification par certificat SSL
  - `ldap` : authentification via annuaire LDAP
  - Nouveaut√© PostgreSQL 18 : `oauth` pour OAuth 2.0

- **pg_ident.conf** ‚Äî Mapping d'utilisateurs :
  - Associer des utilisateurs syst√®me √† des utilisateurs PostgreSQL
  - Utile avec l'authentification `peer` ou `cert`

**S√©curit√© de base :**

- Principe du moindre privil√®ge : chaque application/utilisateur n'a acc√®s qu'√† ce dont il a besoin
- Cr√©er des r√¥les d√©di√©s par application (ne jamais utiliser `postgres` pour les applications)
- Activer SSL/TLS pour les connexions r√©seau
- Restreindre `listen_addresses` aux interfaces n√©cessaires
- Configurer le pare-feu syst√®me (iptables, firewalld, ufw)

**Introduction √† psql pour les op√©rations :**

- Connexion : `psql -h host -p port -U user -d database`
- Commandes m√©ta essentielles :
  - `\l` : lister les bases de donn√©es
  - `\du` : lister les r√¥les
  - `\dt` : lister les tables
  - `\conninfo` : informations de connexion
  - `\x` : affichage √©tendu (pratique pour les vues syst√®me)

#### Mois 5-6 : Maintenance et Sauvegarde de Base

**Comprendre VACUUM :**

VACUUM est l'op√©ration de maintenance la plus importante de PostgreSQL. Elle est n√©cessaire √† cause du fonctionnement de MVCC (Multiversion Concurrency Control).

- **Pourquoi VACUUM est n√©cessaire** :
  - PostgreSQL ne supprime pas imm√©diatement les lignes lors d'un `UPDATE` ou `DELETE`
  - Les anciennes versions restent pour les transactions en cours
  - VACUUM r√©cup√®re cet espace pour une r√©utilisation future
  - Sans VACUUM, la base grossit ind√©finiment ("bloat")

- **Types de VACUUM** :
  - `VACUUM` : marque l'espace comme r√©utilisable, ne bloque pas les lectures/√©critures
  - `VACUUM FULL` : r√©√©crit enti√®rement la table, r√©cup√®re l'espace disque, mais verrouille la table
  - `VACUUM ANALYZE` : combine VACUUM et mise √† jour des statistiques

- **Autovacuum** :
  - Processus automatique qui lance VACUUM et ANALYZE selon les besoins
  - Param√®tres cl√©s : `autovacuum_vacuum_threshold`, `autovacuum_vacuum_scale_factor`
  - Supervision : v√©rifier que l'autovacuum fonctionne correctement
  - Nouveaut√© PostgreSQL 18 : `autovacuum_vacuum_max_threshold` pour les grandes tables

**Comprendre ANALYZE :**

- Met √† jour les statistiques utilis√©es par le planificateur de requ√™tes
- Sans statistiques √† jour, PostgreSQL peut choisir des plans d'ex√©cution inefficaces
- Ex√©cut√© automatiquement par autovacuum, mais peut √™tre lanc√© manuellement apr√®s des imports massifs

**Sauvegardes logiques avec pg_dump :**

- **pg_dump** : sauvegarde une base de donn√©es
  ```bash
  # Format plain SQL (lisible, restaurable avec psql)
  pg_dump -h host -U user dbname > backup.sql

  # Format custom (compress√©, restauration flexible)
  pg_dump -h host -U user -Fc dbname > backup.dump

  # Format directory (parall√©lisable)
  pg_dump -h host -U user -Fd -j 4 dbname -f backup_dir/
  ```

- **Options importantes** :
  - `-Fc` : format custom (recommand√©)
  - `-j N` : parall√©lisation (format directory uniquement)
  - `--schema-only` : structure uniquement
  - `--data-only` : donn√©es uniquement
  - `-t table` : table sp√©cifique
  - `-n schema` : sch√©ma sp√©cifique

- **pg_dumpall** : sauvegarde de l'instance compl√®te
  - Inclut les r√¥les et les tablespaces
  - N√©cessaire pour une restauration compl√®te
  ```bash
  pg_dumpall -h host -U postgres > full_backup.sql
  ```

**Restauration :**

- Depuis un dump SQL plain :
  ```bash
  psql -h host -U user -d dbname < backup.sql
  ```

- Depuis un dump format custom :
  ```bash
  pg_restore -h host -U user -d dbname backup.dump
  ```

- Options utiles de pg_restore :
  - `-j N` : restauration parall√®le
  - `-c` : drop des objets avant cr√©ation
  - `--if-exists` : √©vite les erreurs si objets absents
  - `-t table` : restaurer une table sp√©cifique

**Planification des sauvegardes :**

- Utiliser cron ou systemd timers pour automatiser
- Rotation des sauvegardes (conserver N jours/semaines)
- Tester r√©guli√®rement les restaurations

### Indicateurs de progression (Phase 1)

√Ä la fin de cette phase, vous devriez √™tre capable de :

- Installer PostgreSQL depuis les d√©p√¥ts officiels sur les principales distributions Linux
- Configurer les param√®tres essentiels de `postgresql.conf` et `pg_hba.conf`
- S√©curiser l'acc√®s √† une instance PostgreSQL (SSL, authentification, pare-feu)
- Comprendre le r√¥le de VACUUM et d'autovacuum
- Effectuer des sauvegardes logiques avec pg_dump et les restaurer
- Utiliser psql pour les op√©rations d'administration courantes

### Ressources recommand√©es (Phase 1)

- Documentation officielle PostgreSQL : chapitres "Server Setup and Operation" et "Backup and Restore"
- Wiki PostgreSQL : articles sur la configuration et le tuning
- PGTune (pgtune.leopard.in.ua) : g√©n√©ration de configuration de base

---

## Phase 2 : Op√©rations Avanc√©es et Automatisation (6-12 mois)

### Objectif de cette phase

Ma√Ætriser les op√©rations avanc√©es de maintenance, mettre en place un monitoring efficace, automatiser les d√©ploiements et comprendre les bases de la r√©plication. Vous serez capable de g√©rer PostgreSQL de mani√®re professionnelle avec des outils modernes.

### Comp√©tences √† d√©velopper

#### Mois 7-8 : Monitoring et Observabilit√©

**Vues syst√®me essentielles :**

PostgreSQL expose de nombreuses informations via des vues syst√®me. Les ma√Ætriser est essentiel pour tout DevOps/SRE.

- **pg_stat_activity** ‚Äî Activit√© en temps r√©el :
  ```sql
  SELECT pid, usename, application_name, client_addr,
         state, query_start, query
  FROM pg_stat_activity
  WHERE state != 'idle';
  ```
  - `state` : idle, active, idle in transaction, etc.
  - `wait_event_type` et `wait_event` : ce sur quoi le processus attend
  - `query` : requ√™te en cours (attention aux informations sensibles)

- **pg_stat_database** ‚Äî Statistiques par base :
  - `numbackends` : connexions actives
  - `xact_commit`, `xact_rollback` : transactions
  - `blks_read`, `blks_hit` : acc√®s disque vs cache
  - `tup_returned`, `tup_fetched`, `tup_inserted`, `tup_updated`, `tup_deleted` : activit√©

- **pg_stat_user_tables** ‚Äî Statistiques par table :
  - `seq_scan`, `idx_scan` : scans s√©quentiels vs index
  - `n_tup_ins`, `n_tup_upd`, `n_tup_del` : modifications
  - `n_live_tup`, `n_dead_tup` : tuples vivants vs morts (bloat)
  - `last_vacuum`, `last_autovacuum`, `last_analyze` : derni√®res maintenances

- **pg_stat_user_indexes** ‚Äî Utilisation des index :
  - `idx_scan` : nombre de fois que l'index a √©t√© utilis√©
  - Index avec 0 scans = candidats √† la suppression

- **pg_locks** ‚Äî Verrous actifs :
  ```sql
  SELECT l.pid, l.locktype, l.mode, l.granted,
         a.usename, a.query
  FROM pg_locks l
  JOIN pg_stat_activity a ON l.pid = a.pid;
  ```

**Extension pg_stat_statements :**

Cette extension est indispensable pour identifier les requ√™tes probl√©matiques.

- Installation :
  ```sql
  CREATE EXTENSION pg_stat_statements;
  ```

- Configuration dans `postgresql.conf` :
  ```
  shared_preload_libraries = 'pg_stat_statements'
  pg_stat_statements.track = all
  ```

- Requ√™tes utiles :
  ```sql
  -- Top 10 requ√™tes par temps total
  SELECT query, calls, total_exec_time, mean_exec_time,
         rows, shared_blks_hit, shared_blks_read
  FROM pg_stat_statements
  ORDER BY total_exec_time DESC
  LIMIT 10;
  ```

**M√©triques vitales √† surveiller :**

- **Cache hit ratio** (objectif > 99%) :
  ```sql
  SELECT
    sum(blks_hit) * 100.0 / sum(blks_hit + blks_read) as cache_hit_ratio
  FROM pg_stat_database;
  ```

- **Connexions** :
  - Connexions actives vs `max_connections`
  - Connexions en √©tat "idle in transaction" (probl√©matiques)

- **Bloat** (espace perdu) :
  - Ratio `n_dead_tup / n_live_tup` dans pg_stat_user_tables
  - Outils : `pgstattuple`, requ√™tes d'estimation du bloat

- **R√©plication lag** (si applicable) :
  ```sql
  SELECT client_addr, state, sent_lsn, write_lsn,
         flush_lsn, replay_lsn
  FROM pg_stat_replication;
  ```

- **Transaction ID age** (risque de wraparound) :
  ```sql
  SELECT datname, age(datfrozenxid)
  FROM pg_database
  ORDER BY age DESC;
  ```

**Stack de monitoring :**

- **Prometheus + postgres_exporter** :
  - `postgres_exporter` expose les m√©triques au format Prometheus
  - Configuration : connexion √† PostgreSQL, m√©triques √† collecter
  - Alertes sur les m√©triques critiques

- **Grafana** :
  - Dashboards pour visualiser les m√©triques
  - Dashboards communautaires disponibles (ex: Percona PMM)

- **pgBadger** :
  - Analyse des logs PostgreSQL
  - G√©n√®re des rapports HTML d√©taill√©s
  - Identification des requ√™tes lentes, erreurs, connexions

- **Logging PostgreSQL** :
  - `log_statement` : none, ddl, mod, all
  - `log_min_duration_statement` : logger les requ√™tes lentes
  - `log_line_prefix` : format des lignes de log (inclure timestamp, pid, user, db)

#### Mois 9-10 : Sauvegardes Avanc√©es et PITR

**Sauvegardes physiques avec pg_basebackup :**

Contrairement √† pg_dump (logique), pg_basebackup copie les fichiers physiques de la base.

- **Avantages** :
  - Plus rapide pour les grandes bases
  - Permet le Point-In-Time Recovery (PITR)
  - Base pour la r√©plication

- **Utilisation de base** :
  ```bash
  pg_basebackup -h host -U replication_user \
    -D /path/to/backup -Ft -z -P
  ```
  - `-Ft` : format tar
  - `-z` : compression gzip
  - `-P` : affichage de la progression
  - `-X stream` : inclure les WAL n√©cessaires

**Point-In-Time Recovery (PITR) :**

PITR permet de restaurer la base √† n'importe quel instant dans le pass√©.

- **Principe** :
  1. Restaurer une sauvegarde de base (pg_basebackup)
  2. Rejouer les WAL archiv√©s jusqu'au point souhait√©

- **Configuration de l'archivage WAL** :
  ```
  # postgresql.conf
  archive_mode = on
  archive_command = 'cp %p /path/to/archive/%f'
  ```

- **Restauration PITR** :
  1. Arr√™ter PostgreSQL
  2. Restaurer la sauvegarde de base
  3. Configurer `recovery.signal` et les param√®tres de recovery
  4. D√©marrer PostgreSQL

- **Param√®tres de recovery** :
  ```
  # postgresql.conf (pour la restauration)
  restore_command = 'cp /path/to/archive/%f %p'
  recovery_target_time = '2025-11-15 14:30:00'
  recovery_target_action = 'promote'
  ```

**Outils de sauvegarde avanc√©s :**

- **pgBackRest** :
  - Sauvegardes compl√®tes, diff√©rentielles, incr√©mentales
  - Compression, chiffrement
  - Parall√©lisation
  - Gestion automatique de la r√©tention
  - V√©rification d'int√©grit√©

- **Barman** :
  - D√©velopp√© par 2ndQuadrant/EDB
  - Gestion centralis√©e des sauvegardes
  - Catalogage des sauvegardes
  - Recovery simplifi√©

**Strat√©gie de sauvegarde 3-2-1 :**

- 3 copies des donn√©es
- 2 supports de stockage diff√©rents
- 1 copie hors site (autre datacenter, cloud)

#### Mois 11-12 : Automatisation et Infrastructure as Code

**Ansible pour PostgreSQL :**

- **R√¥les Ansible communautaires** :
  - `geerlingguy.postgresql` : installation de base
  - `ANXS.postgresql` : configuration avanc√©e
  - R√¥les Patroni pour la HA

- **T√¢ches typiques √† automatiser** :
  - Installation et configuration initiale
  - Cr√©ation de bases et utilisateurs
  - D√©ploiement de configuration
  - Mise √† jour des versions mineures

- **Exemple de playbook simplifi√©** :
  ```yaml
  - name: Configure PostgreSQL
    hosts: postgres_servers
    roles:
      - role: postgresql
        postgresql_version: 18
        postgresql_listen_addresses: "*"
        postgresql_max_connections: 200
  ```

**Terraform pour le provisioning :**

- Provisioning d'instances PostgreSQL manag√©es :
  - AWS RDS PostgreSQL
  - Azure Database for PostgreSQL
  - Google Cloud SQL

- Provisioning d'infrastructure pour PostgreSQL self-hosted :
  - VMs, r√©seaux, stockage
  - Load balancers pour la HA

**Docker et PostgreSQL :**

- **Image officielle** : `postgres:18`

- **Configuration via variables d'environnement** :
  - `POSTGRES_PASSWORD` : mot de passe du superuser
  - `POSTGRES_USER` : utilisateur par d√©faut
  - `POSTGRES_DB` : base de donn√©es par d√©faut

- **Volumes pour la persistance** :
  - `/var/lib/postgresql/data` : donn√©es
  - Configuration personnalis√©e via fichiers mont√©s

- **Consid√©rations pour la production** :
  - Stockage persistant appropri√© (pas de stockage √©ph√©m√®re)
  - Configuration m√©moire adapt√©e au conteneur
  - Health checks

- **Docker Compose pour le d√©veloppement** :
  ```yaml
  services:
    postgres:
      image: postgres:18
      environment:
        POSTGRES_PASSWORD: secret
      volumes:
        - pgdata:/var/lib/postgresql/data
      ports:
        - "5432:5432"
  volumes:
    pgdata:
  ```

**Connection Pooling avec PgBouncer :**

PostgreSQL cr√©e un processus par connexion, ce qui limite le nombre de connexions simultan√©es. PgBouncer r√©sout ce probl√®me.

- **Modes de pooling** :
  - `session` : une connexion PostgreSQL par session client
  - `transaction` : partage des connexions entre transactions (recommand√©)
  - `statement` : partage maximal, mais limitations importantes

- **Configuration de base** :
  ```ini
  [databases]
  mydb = host=localhost port=5432 dbname=mydb

  [pgbouncer]
  listen_addr = *
  listen_port = 6432
  auth_type = scram-sha-256
  pool_mode = transaction
  max_client_conn = 1000
  default_pool_size = 20
  ```

- **Dimensionnement** :
  - `default_pool_size` : connexions PostgreSQL par base/utilisateur
  - `max_client_conn` : connexions clients maximum
  - R√®gle : `default_pool_size` √ó nombre de pools < `max_connections` PostgreSQL

### Indicateurs de progression (Phase 2)

√Ä la fin de cette phase, vous devriez √™tre capable de :

- Mettre en place un monitoring complet avec Prometheus/Grafana
- Identifier les requ√™tes probl√©matiques avec pg_stat_statements
- Configurer l'archivage WAL et effectuer des restaurations PITR
- Utiliser pgBackRest ou Barman pour des sauvegardes avanc√©es
- Automatiser les d√©ploiements PostgreSQL avec Ansible
- D√©ployer PostgreSQL dans des conteneurs Docker
- Configurer PgBouncer pour le connection pooling

### Ressources recommand√©es (Phase 2)

- Documentation pgBackRest et Barman
- "PostgreSQL 14 Administration Cookbook"
- Blogs : Percona, 2ndQuadrant/EDB, Crunchy Data
- Ansible Galaxy : r√¥les PostgreSQL communautaires

---

## Phase 3 : Haute Disponibilit√© et Expertise Production (12-24 mois)

### Objectif de cette phase

Ma√Ætriser les architectures haute disponibilit√©, la r√©plication, les migrations majeures et la gestion des incidents. Vous serez capable de concevoir et op√©rer des infrastructures PostgreSQL critiques et de r√©pondre efficacement aux situations de crise.

### Comp√©tences √† d√©velopper

#### Mois 13-16 : R√©plication et Haute Disponibilit√©

**R√©plication physique (Streaming Replication) :**

La r√©plication physique cr√©e une copie exacte du primary sur un ou plusieurs standbys.

- **Concepts cl√©s** :
  - Primary (anciennement master) : accepte les √©critures
  - Standby (anciennement slave) : r√©plique en lecture seule
  - WAL : les modifications sont transmises via les journaux de transaction

- **Configuration du Primary** :
  ```
  # postgresql.conf
  wal_level = replica
  max_wal_senders = 10
  max_replication_slots = 10
  ```

  ```
  # pg_hba.conf
  host replication replication_user standby_ip/32 scram-sha-256
  ```

- **Configuration du Standby** :
  1. Cr√©er avec pg_basebackup :
     ```bash
     pg_basebackup -h primary -U replication_user -D /data -P -R
     ```
  2. Le flag `-R` cr√©e automatiquement `standby.signal` et configure la connexion

- **Synchrone vs Asynchrone** :
  - Asynchrone (d√©faut) : le primary n'attend pas la confirmation du standby
  - Synchrone : le primary attend la confirmation avant de confirmer le commit
  - Trade-off : durabilit√© vs performance

- **Slots de r√©plication** :
  - Garantissent que les WAL n√©cessaires sont conserv√©s
  - Attention : peuvent causer une accumulation de WAL si le standby est d√©connect√©

**R√©plication logique :**

La r√©plication logique permet de r√©pliquer des tables sp√©cifiques et offre plus de flexibilit√©.

- **Cas d'usage** :
  - R√©plication s√©lective (certaines tables seulement)
  - R√©plication entre versions PostgreSQL diff√©rentes
  - Migrations avec temps d'arr√™t minimal

- **Configuration** :
  ```
  # postgresql.conf sur le publisher
  wal_level = logical
  ```

  ```sql
  -- Sur le publisher
  CREATE PUBLICATION my_pub FOR TABLE table1, table2;

  -- Sur le subscriber
  CREATE SUBSCRIPTION my_sub
    CONNECTION 'host=publisher dbname=mydb'
    PUBLICATION my_pub;
  ```

**Solutions de haute disponibilit√© :**

- **Patroni** :
  - Solution de HA la plus populaire
  - Utilise un syst√®me de consensus distribu√© (etcd, Consul, ZooKeeper)
  - Gestion automatique du failover
  - API REST pour le management

  Architecture typique :
  ```
  [etcd cluster] ‚Üê‚Üí [Patroni + PostgreSQL] √ó 3 nodes
                           ‚Üì
                    [HAProxy/PgBouncer]
                           ‚Üì
                    [Applications]
  ```

- **Repmgr** :
  - Plus simple que Patroni
  - Bon pour les environnements moins critiques
  - Failover automatique ou manuel

- **PgPool-II** :
  - Connection pooling + load balancing + failover
  - Alternative tout-en-un, mais plus complexe

**Failover et Promotion :**

- **Promotion manuelle** :
  ```bash
  pg_ctl promote -D /data
  # ou
  SELECT pg_promote();
  ```

- **Avec Patroni** :
  ```bash
  patronictl switchover
  patronictl failover
  ```

- **Consid√©rations post-failover** :
  - Mettre √† jour les cha√Ænes de connexion ou utiliser un VIP/DNS
  - Reconfigurer l'ancien primary comme standby
  - V√©rifier l'int√©grit√© des donn√©es

#### Mois 17-20 : PostgreSQL sur Kubernetes et Cloud

**Kubernetes et PostgreSQL :**

- **StatefulSets** :
  - Identit√© stable pour chaque pod
  - Stockage persistant avec PersistentVolumeClaims
  - Ordre de d√©ploiement/suppression garanti

- **Operators Kubernetes** :

  Les operators automatisent la gestion de PostgreSQL sur Kubernetes.

  - **CloudNativePG** (anciennement Cloud Native PostgreSQL) :
    - D√©velopp√© par EDB
    - Natif Kubernetes, d√©claratif
    - R√©plication, failover automatique, backups

  - **Zalando Postgres Operator** :
    - Utilis√© en production chez Zalando
    - Int√©gration avec Patroni
    - Gestion du connection pooling

  - **Crunchy Postgres Operator (PGO)** :
    - Solution compl√®te de Crunchy Data
    - Monitoring int√©gr√© (pgMonitor)
    - Backups avec pgBackRest

- **Consid√©rations stockage** :
  - Utiliser des StorageClasses performantes (SSD)
  - Attention aux IOPS et √† la latence
  - Ne jamais utiliser de stockage √©ph√©m√®re pour les donn√©es

**PostgreSQL manag√© dans le cloud :**

- **AWS RDS PostgreSQL** :
  - Versions PostgreSQL support√©es
  - Multi-AZ pour la haute disponibilit√©
  - Read replicas pour le scaling en lecture
  - Automated backups et PITR
  - Performance Insights pour le monitoring

- **Amazon Aurora PostgreSQL** :
  - Architecture de stockage distribu√©e
  - Failover plus rapide que RDS standard
  - Aurora Serverless pour les charges variables

- **Azure Database for PostgreSQL** :
  - Options Flexible Server (recommand√©) vs Single Server (legacy)
  - R√©plication en lecture
  - Int√©gration avec Azure Monitor

- **Google Cloud SQL / AlloyDB** :
  - Cloud SQL : PostgreSQL manag√© classique
  - AlloyDB : compatible PostgreSQL avec architecture distribu√©e

- **Trade-offs Managed vs Self-hosted** :

  | Aspect | Managed | Self-hosted |
  |--------|---------|-------------|
  | Maintenance | Provider | Votre √©quipe |
  | Personnalisation | Limit√©e | Totale |
  | Co√ªt | Pr√©visible, souvent plus √©lev√© | Variable, potentiellement moins cher |
  | Extensions | Liste restreinte | Toutes |
  | Contr√¥le | Limit√© | Total |

#### Mois 21-24 : Migrations, Troubleshooting et Expertise

**Migrations de versions majeures :**

- **pg_upgrade** :
  - Migration in-place rapide
  - Modes : `--copy` (copie les fichiers) ou `--link` (liens symboliques, plus rapide)
  - Nouveaut√© PostgreSQL 18 : option `--swap` pour upgrade encore plus rapide
  - Nouveaut√© PostgreSQL 18 : pr√©servation des statistiques
  - Nouveaut√© PostgreSQL 18 : v√©rifications parall√®les avec `--jobs`

  Processus :
  ```bash
  # 1. Arr√™ter l'ancien cluster
  # 2. V√©rifier la compatibilit√©
  pg_upgrade --check -b /old/bin -B /new/bin -d /old/data -D /new/data

  # 3. Effectuer la migration
  pg_upgrade -b /old/bin -B /new/bin -d /old/data -D /new/data

  # 4. D√©marrer le nouveau cluster
  # 5. Analyser les statistiques (ou utiliser les statistiques pr√©serv√©es en PG18)
  ```

- **Migration par r√©plication logique** :
  - Temps d'arr√™t minimal
  - Permet de tester avant le basculement
  - Plus complexe √† mettre en ≈ìuvre

- **Strat√©gie Blue/Green** :
  - Deux environnements identiques
  - Basculement rapide via DNS ou load balancer
  - Possibilit√© de rollback

**Troubleshooting avanc√© :**

- **Probl√®mes de verrous** :
  ```sql
  -- Identifier les sessions bloquantes
  SELECT pg_blocking_pids(pid), * FROM pg_stat_activity
  WHERE wait_event_type = 'Lock';

  -- Terminer une session bloquante (avec pr√©caution)
  SELECT pg_terminate_backend(pid);
  ```

- **Transaction ID Wraparound** :
  - PostgreSQL utilise des identifiants de transaction sur 32 bits
  - √Ä ~2 milliards de transactions, risque de wraparound
  - VACUUM freeze pr√©vient ce probl√®me
  - Alerter si `age(datfrozenxid)` approche 1 milliard

  ```sql
  -- V√©rifier l'√¢ge des transactions
  SELECT datname, age(datfrozenxid),
         2147483647 - age(datfrozenxid) as remaining
  FROM pg_database
  ORDER BY age DESC;
  ```

- **Corruption de donn√©es** :
  - V√©rifier les checksums : `pg_checksums --check -D /data`
  - Nouveaut√© PostgreSQL 18 : checksums activ√©s par d√©faut
  - Outils : `pg_amcheck` pour v√©rifier l'int√©grit√© des index

- **Saturation des connexions** :
  - Identifier les connexions idle in transaction
  - Configurer `idle_in_transaction_session_timeout`
  - Utiliser PgBouncer pour le pooling

- **Requ√™tes lentes** :
  1. Identifier avec pg_stat_statements
  2. Analyser avec EXPLAIN (ANALYZE, BUFFERS)
  3. V√©rifier les index manquants
  4. V√©rifier les statistiques (`ANALYZE`)

**S√©curit√© avanc√©e :**

- **Row-Level Security (RLS)** :
  - Contr√¥le d'acc√®s au niveau des lignes
  - Utile pour le multi-tenant

  ```sql
  ALTER TABLE orders ENABLE ROW LEVEL SECURITY;
  CREATE POLICY tenant_isolation ON orders
    USING (tenant_id = current_setting('app.tenant_id')::int);
  ```

- **Audit avec pgAudit** :
  - Logging d√©taill√© des op√©rations
  - Conformit√© r√©glementaire (SOC2, HIPAA, etc.)

- **Chiffrement** :
  - En transit : SSL/TLS (obligatoire en production)
  - Au repos : chiffrement du syst√®me de fichiers ou TDE (Transparent Data Encryption)
  - Nouveaut√© PostgreSQL 18 : configuration TLS 1.3 avec `ssl_tls13_ciphers`

- **Gestion des secrets** :
  - Ne jamais stocker les mots de passe en clair
  - Utiliser des gestionnaires de secrets (Vault, AWS Secrets Manager, etc.)
  - Rotation r√©guli√®re des credentials

**Documentation et Runbooks :**

- Documenter l'architecture et les d√©cisions
- Cr√©er des runbooks pour les op√©rations courantes :
  - Failover manuel
  - Restauration de sauvegarde
  - Ajout d'un standby
  - R√©ponse aux alertes
- Maintenir un inventaire des instances
- Documenter les d√©pendances et les SLA

### Indicateurs de progression (Phase 3)

√Ä la fin de cette phase, vous devriez √™tre capable de :

- Concevoir et impl√©menter une architecture haute disponibilit√© avec Patroni
- Configurer la r√©plication physique et logique
- D√©ployer PostgreSQL sur Kubernetes avec un operator
- G√©rer des instances PostgreSQL dans le cloud (RDS, Cloud SQL, etc.)
- Effectuer des migrations de versions majeures avec diff√©rentes strat√©gies
- Diagnostiquer et r√©soudre des probl√®mes complexes (locks, wraparound, corruption)
- Mettre en place une s√©curit√© avanc√©e (RLS, audit, chiffrement)
- Documenter et cr√©er des runbooks pour les op√©rations

### Ressources recommand√©es (Phase 3)

- Documentation Patroni, CloudNativePG, Zalando Operator
- "Mastering PostgreSQL" de Hans-J√ºrgen Sch√∂nig
- Conf√©rences : PGConf, KubeCon (sessions PostgreSQL)
- Blogs : Percona, Crunchy Data, EDB, Cybertec
- Formation Kubernetes si pas encore ma√Ætris√©

---

## Conseils Sp√©cifiques pour le Parcours DevOps/SRE

### Privil√©gier la fiabilit√©

En tant que DevOps/SRE, votre priorit√© est la fiabilit√© du service. Cela signifie :
- Toujours avoir des sauvegardes test√©es et restaurables
- Ne jamais d√©ployer une configuration non test√©e en production
- Pr√©f√©rer les approches √©prouv√©es aux solutions innovantes mais risqu√©es

### Automatiser, mais comprendre

L'automatisation est essentielle, mais vous devez comprendre ce que font vos scripts et outils. En cas d'incident, vous devrez peut-√™tre intervenir manuellement.

### Tester les sc√©narios de d√©faillance

Simulez r√©guli√®rement des pannes :
- Failover de la base de donn√©es
- Restauration de sauvegarde
- Perte d'un n≈ìud du cluster

### Monitorer proactivement

N'attendez pas qu'un utilisateur signale un probl√®me. Mettez en place des alertes sur :
- Espace disque
- Connexions
- Lag de r√©plication
- Requ√™tes lentes
- √Çge des transactions (wraparound)

### Documenter tout

La documentation est critique :
- Architecture et diagrammes
- Proc√©dures de recovery
- Contacts et escalade
- Post-mortems des incidents

### Collaborer avec les d√©veloppeurs

Travaillez avec les √©quipes de d√©veloppement pour :
- Optimiser les requ√™tes probl√©matiques
- Planifier les migrations de sch√©ma
- Dimensionner correctement l'infrastructure

---

## R√©capitulatif des Phases

| Phase | P√©riode | Focus Principal | Comp√©tences Cl√©s |
|-------|---------|-----------------|------------------|
| **1. Fondations** | 0-6 mois | Installation, configuration, maintenance de base | Architecture, pg_hba.conf, VACUUM, pg_dump |
| **2. Op√©rations avanc√©es** | 6-12 mois | Monitoring, sauvegardes avanc√©es, automatisation | pg_stat_statements, PITR, pgBackRest, Ansible, Docker, PgBouncer |
| **3. HA et Expertise** | 12-24 mois | Haute disponibilit√©, Kubernetes, cloud, troubleshooting | Patroni, r√©plication, operators K8s, pg_upgrade, s√©curit√© avanc√©e |

---

## Certifications et Reconnaissance

Bien que PostgreSQL n'ait pas de certification officielle comme Oracle ou Microsoft, plusieurs options existent :

- **EnterpriseDB (EDB)** : Certifications PostgreSQL Professional
- **Percona** : Certifications orient√©es performance et op√©rations
- **Cloud providers** : Certifications incluant des modules PostgreSQL (AWS, Azure, GCP)

Ces certifications peuvent valider vos comp√©tences aupr√®s des employeurs, mais l'exp√©rience pratique reste le crit√®re le plus important.

---


‚è≠Ô∏è [Parcours DBA](/21-conclusion-et-perspectives/05.3-parcours-dba.md)
