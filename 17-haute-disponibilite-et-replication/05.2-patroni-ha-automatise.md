ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 17.5.2. Patroni : HA automatisÃ© avec consensus (etcd, Consul)

## Introduction

Dans la section prÃ©cÃ©dente (17.5.1), nous avons vu comment promouvoir manuellement un Standby avec `pg_ctl promote`. Cette approche fonctionne bien pour des environnements simples ou lors de maintenances planifiÃ©es. Cependant, elle prÃ©sente des limites importantes :

- **Intervention humaine requise** : Quelqu'un doit dÃ©tecter la panne et lancer la promotion
- **Temps de rÃ©action lent** : Plusieurs minutes peuvent s'Ã©couler avant l'intervention
- **Risque d'erreur** : Un administrateur peut faire une mauvaise manipulation
- **DisponibilitÃ© nocturne** : Qui intervient Ã  3h du matin ?
- **Split-brain possible** : Sans coordination, deux Primary peuvent coexister

**Patroni** rÃ©sout tous ces problÃ¨mes en automatisant complÃ¨tement le processus de haute disponibilitÃ©.

---

## Qu'est-ce que Patroni ?

### DÃ©finition

**Patroni** est un outil open-source dÃ©veloppÃ© par **Zalando** (la plateforme e-commerce europÃ©enne) pour gÃ©rer automatiquement la haute disponibilitÃ© de PostgreSQL.

**En rÃ©sumÃ©** : Patroni transforme votre cluster PostgreSQL en un systÃ¨me auto-rÃ©parant capable de dÃ©tecter les pannes et de basculer automatiquement vers un Standby sans intervention humaine.

### Philosophie de Patroni

Patroni repose sur trois principes fondamentaux :

1. **Consensus distribuÃ©** : Utilisation d'un systÃ¨me de consensus (etcd, Consul, ZooKeeper) pour dÃ©cider collectivement qui est le Primary
2. **Heartbeat constant** : Surveillance continue de la santÃ© des serveurs
3. **Ã‰lection automatique** : En cas de panne du Primary, Ã©lection automatique d'un nouveau leader

### Analogie Simple

Imaginez une Ã©quipe de footballeurs :
- **Sans Patroni** : Si le capitaine tombe, personne ne sait qui doit prendre le bras de capitaine. Le jeu s'arrÃªte.
- **Avec Patroni** : Si le capitaine tombe, l'Ã©quipe vote immÃ©diatement pour Ã©lire un nouveau capitaine. Le jeu continue sans interruption.

---

## Architecture Patroni : Vue d'Ensemble

### Les Composants

Un cluster Patroni est composÃ© de :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SystÃ¨me de Consensus                   â”‚
â”‚         (etcd, Consul, ou ZooKeeper)                â”‚
â”‚                                                     â”‚
â”‚  Stocke : Qui est le Primary ? Quelle est la        â”‚
â”‚           configuration du cluster ?                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–²
                        â”‚ Heartbeat / Lock
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patroni 1   â”‚ â”‚  Patroni 2   â”‚ â”‚  Patroni 3   â”‚
â”‚  (Primary)   â”‚ â”‚  (Standby)   â”‚ â”‚  (Standby)   â”‚
â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
â”‚ PostgreSQL   â”‚ â”‚ PostgreSQL   â”‚ â”‚ PostgreSQL   â”‚
â”‚   Instance   â”‚ â”‚   Instance   â”‚ â”‚   Instance   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de Fonctionnement

1. **Chaque instance PostgreSQL** a un agent Patroni qui la supervise
2. **Chaque agent Patroni** communique avec le systÃ¨me de consensus
3. **Le systÃ¨me de consensus** stocke l'Ã©tat du cluster (qui est Primary, configuration, etc.)
4. **Un seul Patroni** dÃ©tient le "leader lock" (verrou de leadership) et son PostgreSQL est le Primary
5. **En cas de panne** du Primary, les autres Patroni se battent pour obtenir le lock et promouvoir leur PostgreSQL

---

## Le Concept de Consensus DistribuÃ©

### Qu'est-ce que le Consensus ?

Le **consensus distribuÃ©** est un mÃ©canisme qui permet Ã  plusieurs ordinateurs de s'accorder sur une vÃ©ritÃ© commune, mÃªme en cas de pannes partielles.

**Exemple concret** :
- 3 serveurs doivent dÃ©cider : "Qui est le Primary ?"
- Serveur A dit : "C'est moi !"
- Serveur B dit : "Non, c'est moi !"
- Serveur C dit : "Je vote pour A"

**RÃ©sultat** : Le consensus est atteint. A est le Primary parce qu'il a le support de C (majoritÃ© 2/3).

### Pourquoi le Consensus est Indispensable ?

Sans consensus, vous pourriez avoir :
- **Split-brain** : Deux serveurs se proclament Primary en mÃªme temps
- **IncohÃ©rence** : Les serveurs ne savent pas qui est le Primary
- **Perte de donnÃ©es** : Ã‰critures concurrentes sur deux Primary

**Avec le consensus** :
- **Une seule vÃ©ritÃ©** : Tous les serveurs s'accordent sur qui est le Primary
- **Ã‰lection automatique** : En cas de panne, un nouveau Primary est Ã©lu dÃ©mocratiquement
- **Protection contre le split-brain** : Impossible d'avoir deux Primary

### Le Concept de Quorum

Le **quorum** est le nombre minimum de serveurs nÃ©cessaires pour prendre une dÃ©cision.

**RÃ¨gle gÃ©nÃ©rale** : Quorum = (N / 2) + 1

| Nombre de serveurs | Quorum requis | Pannes tolÃ©rÃ©es |
|--------------------|---------------|-----------------|
| 3                  | 2             | 1               |
| 5                  | 3             | 2               |
| 7                  | 4             | 3               |

**Exemple avec 3 serveurs** :
- Si 2 serveurs sont actifs â†’ DÃ©cision possible (quorum atteint)
- Si 1 seul serveur est actif â†’ Pas de dÃ©cision (quorum non atteint)

**Important** : Utilisez toujours un **nombre impair** de serveurs de consensus pour Ã©viter les situations de "vote Ã©gal".

---

## Les SystÃ¨mes de Consensus : etcd, Consul, ZooKeeper

Patroni supporte trois systÃ¨mes de consensus. Voici leur prÃ©sentation.

### 1. etcd (RecommandÃ©)

**etcd** est un systÃ¨me de stockage clÃ©-valeur distribuÃ© dÃ©veloppÃ© par CoreOS (maintenant Red Hat).

**CaractÃ©ristiques** :
- âœ… **SimplicitÃ©** : Facile Ã  installer et configurer
- âœ… **Performance** : TrÃ¨s rapide pour les opÃ©rations de lecture/Ã©criture
- âœ… **IntÃ©gration Kubernetes** : UtilisÃ© nativement par Kubernetes
- âœ… **API HTTP** : Interface REST simple
- âš ï¸ **MÃ©moire** : Consomme plus de RAM que Consul

**Quand utiliser etcd ?**
- Vous dÃ©ployez dans Kubernetes
- Vous voulez la solution la plus simple
- Vous n'avez pas besoin de Service Discovery avancÃ©

**Architecture typique** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  etcd 1 â”‚  â”‚  etcd 2 â”‚  â”‚  etcd 3 â”‚
â”‚ (Leader)â”‚â—„â”€â”¤         â”‚â—„â”€â”¤         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–²            â–²            â–²
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              Patroni
```

### 2. Consul

**Consul** est un systÃ¨me de Service Discovery et de consensus dÃ©veloppÃ© par HashiCorp.

**CaractÃ©ristiques** :
- âœ… **Service Discovery** : DÃ©couverte automatique des services
- âœ… **Health Checks** : VÃ©rifications de santÃ© intÃ©grÃ©es
- âœ… **Multi-datacenter** : Support natif du multi-DC
- âœ… **UI Web** : Interface graphique pour visualiser le cluster
- âš ï¸ **ComplexitÃ©** : Plus complexe Ã  configurer qu'etcd

**Quand utiliser Consul ?**
- Vous avez dÃ©jÃ  une infrastructure HashiCorp (Vault, Nomad)
- Vous avez besoin de Service Discovery
- Vous gÃ©rez plusieurs datacenters

**Architecture typique** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Consul 1 â”‚  â”‚ Consul 2 â”‚  â”‚ Consul 3 â”‚
â”‚ (Leader) â”‚â—„â”€â”¤          â”‚â—„â”€â”¤          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–²             â–²             â–²
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               Patroni
```

### 3. ZooKeeper

**ZooKeeper** est un systÃ¨me de consensus dÃ©veloppÃ© par Apache, historiquement utilisÃ© par Hadoop.

**CaractÃ©ristiques** :
- âœ… **Mature** : Existe depuis 2008, trÃ¨s stable
- âœ… **Ã‰prouvÃ©** : UtilisÃ© massivement dans le Big Data (Kafka, Hadoop)
- âš ï¸ **ComplexitÃ©** : Configuration complexe
- âš ï¸ **Java** : Requiert la JVM (overhead mÃ©moire)
- âš ï¸ **Moins moderne** : Moins actif que etcd/Consul

**Quand utiliser ZooKeeper ?**
- Vous avez dÃ©jÃ  ZooKeeper dans votre infrastructure (Kafka, HBase)
- Vous voulez la solution la plus mature

**Note** : etcd et Consul sont gÃ©nÃ©ralement prÃ©fÃ©rÃ©s pour les nouvelles installations.

### Comparaison Rapide

| CritÃ¨re | etcd | Consul | ZooKeeper |
|---------|------|--------|-----------|
| **SimplicitÃ©** | â­â­â­â­â­ | â­â­â­ | â­â­ |
| **Performance** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| **FonctionnalitÃ©s** | â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| **PopularitÃ© (2025)** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **Kubernetes** | Natif | Plugin | Plugin |

**Recommandation** : Utilisez **etcd** pour la simplicitÃ©, **Consul** pour les fonctionnalitÃ©s avancÃ©es.

---

## Comment Patroni Fonctionne : Le Cycle de Vie

### 1. DÃ©marrage Initial (Bootstrap)

**ScÃ©nario** : Vous dÃ©marrez Patroni pour la premiÃ¨re fois.

```
1. Patroni dÃ©marre sur les 3 serveurs
2. Chaque Patroni contacte etcd/Consul
3. Patroni constate qu'aucun cluster n'existe
4. Le premier Patroni Ã  obtenir le "initialize lock" :
   - Initialise PostgreSQL (initdb)
   - Se dÃ©clare Primary
   - Enregistre cette information dans etcd/Consul
5. Les autres Patroni :
   - Voient qu'un Primary existe
   - Se configurent automatiquement en Standby
   - DÃ©marrent la rÃ©plication depuis le Primary
```

**RÃ©sultat** : Un cluster PostgreSQL HA est crÃ©Ã© automatiquement !

### 2. Fonctionnement Normal (Heartbeat)

**ScÃ©nario** : Le cluster fonctionne normalement.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Toutes les 10 secondes (par dÃ©faut) :   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Patroni Primary :    â”‚
        â”‚ 1. VÃ©rifie que PG    â”‚
        â”‚    fonctionne        â”‚
        â”‚ 2. Renouvelle le     â”‚
        â”‚    leader lock       â”‚
        â”‚ 3. Met Ã  jour les    â”‚
        â”‚    mÃ©triques         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Patroni Standby :    â”‚
        â”‚ 1. VÃ©rifie que PG    â”‚
        â”‚    fonctionne        â”‚
        â”‚ 2. VÃ©rifie la        â”‚
        â”‚    rÃ©plication       â”‚
        â”‚ 3. Surveille le      â”‚
        â”‚    leader lock       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Concept clÃ© : Le Leader Lock**

Le Primary dÃ©tient un **verrou temporel** (TTL = Time To Live) dans etcd/Consul :
- Le Primary renouvelle ce verrou toutes les 10 secondes
- Si le verrou expire (Primary en panne), il devient disponible
- Les Standby surveillent ce verrou et tentent de l'acquÃ©rir s'il expire

### 3. DÃ©tection de Panne

**ScÃ©nario** : Le Primary tombe en panne.

```
T+0s  : Primary fonctionne normalement
        Leader lock TTL = 30 secondes

T+10s : Primary renouvelle le lock
        Leader lock TTL = 30 secondes

T+15s : Primary tombe en panne âŒ
        (ne peut plus renouveler le lock)

T+30s : Leader lock expire dans etcd/Consul
        Les Standby dÃ©tectent que le lock est disponible
```

**Que surveille Patroni ?**

Sur le Primary :
- PostgreSQL rÃ©pond-il aux connexions ?
- Les processus PostgreSQL sont-ils actifs ?
- Le disque est-il en lecture/Ã©criture ?

Sur les Standby :
- PostgreSQL rÃ©pond-il ?
- La rÃ©plication est-elle active ?
- Le retard de rÃ©plication est-il acceptable ?

### 4. Ã‰lection Automatique (Failover)

**ScÃ©nario** : Le leader lock a expirÃ©. Il faut Ã©lire un nouveau Primary.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1 : Course au Lock                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
Standby 1 : "Je veux Ãªtre Primary !"
Standby 2 : "Moi aussi !"
        â”‚
        â–¼
etcd/Consul : "Le premier qui m'envoie une
               requÃªte obtient le lock"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2 : SÃ©lection du Meilleur Candidat    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
Patroni compare les Standby selon :
1. Timeline PostgreSQL (plus rÃ©cente = mieux)
2. LSN (Log Sequence Number - plus haut = mieux)
3. Score de rÃ©plication (lag, Ã©tat)
        â”‚
        â–¼
Le meilleur candidat obtient le lock
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3 : Promotion                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
1. Patroni exÃ©cute "pg_ctl promote"
2. PostgreSQL passe en mode lecture-Ã©criture
3. Patroni enregistre le nouveau Primary dans etcd
4. Les autres Standby se reconfigurent automatiquement
```

**DurÃ©e typique** : 15-30 secondes (configurable)

### 5. Retour Ã  la Normale

**ScÃ©nario** : L'ancien Primary revient en ligne.

```
1. L'ancien Primary dÃ©marre
2. Patroni dÃ©tecte qu'il Ã©tait Primary avant
3. Patroni interroge etcd/Consul
4. etcd rÃ©pond : "Un nouveau Primary existe dÃ©jÃ "
5. Patroni reconfigure automatiquement l'ancien Primary en Standby
6. L'ancien Primary se synchronise avec le nouveau Primary
7. Le cluster a maintenant 3 serveurs opÃ©rationnels
```

**Important** : Patroni empÃªche automatiquement le split-brain !

---

## Algorithme de SÃ©lection du Leader

### CritÃ¨res de SÃ©lection

Lorsqu'il faut Ã©lire un nouveau Primary, Patroni Ã©value chaque Standby selon :

#### 1. Timeline PostgreSQL

PostgreSQL utilise des **timelines** pour suivre l'historique des promotions.
- Timeline 1 : Le Primary original
- Timeline 2 : AprÃ¨s une premiÃ¨re promotion
- Timeline 3 : AprÃ¨s une deuxiÃ¨me promotion

**RÃ¨gle** : On choisit le Standby avec la timeline la plus Ã©levÃ©e.

#### 2. LSN (Log Sequence Number)

Le **LSN** reprÃ©sente la position dans les WAL.
- Plus le LSN est Ã©levÃ©, plus le Standby a de donnÃ©es rÃ©centes

**Exemple** :
- Standby A : LSN = 0/3000000
- Standby B : LSN = 0/2FFFFFF

**Gagnant** : Standby A (plus de donnÃ©es)

#### 3. Ã‰tat de RÃ©plication

Patroni vÃ©rifie :
- Le Standby est-il en Ã©tat "streaming" ?
- Le Standby a-t-il un retard de rÃ©plication ?
- Le Standby est-il "in sync" (rÃ©plication synchrone) ?

#### 4. Scores PersonnalisÃ©s

Vous pouvez configurer des **prioritÃ©s** manuelles :

```yaml
# Dans la configuration Patroni
tags:
  nofailover: false     # Ce serveur peut devenir Primary
  noloadbalance: false  # Ce serveur peut recevoir des lectures
  clonefrom: true       # Ce serveur peut servir de source pour les clones
  priority: 100         # Score manuel (plus haut = prioritaire)
```

**Exemple** :
- Standby A : priority = 100
- Standby B : priority = 50

â†’ Standby A sera prÃ©fÃ©rÃ© (toutes choses Ã©gales par ailleurs)

### Cas Particuliers

**Tous les Standby sont en retard ?**
- Patroni choisit celui avec le plus petit retard
- Si le retard est trop important (configurable), Patroni peut refuser la promotion

**Aucun Standby disponible ?**
- Patroni attend qu'un Standby devienne disponible
- Pas de Primary = Cluster en lecture seule

---

## Configuration de Patroni

### Structure du Fichier de Configuration

Patroni utilise un fichier YAML (par dÃ©faut : `/etc/patroni/patroni.yml`)

Voici une configuration simplifiÃ©e pour comprendre les concepts :

```yaml
# ============================================
# Section 1 : Identification du NÅ“ud
# ============================================
scope: postgres-cluster    # Nom du cluster
namespace: /service/       # Namespace dans etcd
name: postgres1            # Nom unique de ce nÅ“ud

# ============================================
# Section 2 : API REST de Patroni
# ============================================
restapi:
  listen: 0.0.0.0:8008     # Port pour l'API Patroni
  connect_address: 192.168.1.10:8008

# ============================================
# Section 3 : Connexion au SystÃ¨me de Consensus
# ============================================
etcd:
  hosts:
    - 192.168.1.11:2379    # etcd serveur 1
    - 192.168.1.12:2379    # etcd serveur 2
    - 192.168.1.13:2379    # etcd serveur 3

# ============================================
# Section 4 : Configuration Bootstrap
# ============================================
bootstrap:
  dcs:
    ttl: 30                      # DurÃ©e du leader lock
    loop_wait: 10                # Intervalle de heartbeat
    retry_timeout: 10            # Timeout de retry
    maximum_lag_on_failover: 1048576  # Lag max pour Ãªtre Ã©ligible (1MB)

    postgresql:
      use_pg_rewind: true        # Utiliser pg_rewind pour resynchroniser
      parameters:
        max_connections: 100
        shared_buffers: 256MB

  initdb:
    - encoding: UTF8
    - data-checksums             # Activer les checksums (PostgreSQL 18 par dÃ©faut)

  pg_hba:
    - host replication replicator 0.0.0.0/0 md5
    - host all all 0.0.0.0/0 md5

# ============================================
# Section 5 : Configuration PostgreSQL
# ============================================
postgresql:
  listen: 0.0.0.0:5432
  connect_address: 192.168.1.10:5432
  data_dir: /var/lib/postgresql/14/main
  bin_dir: /usr/lib/postgresql/14/bin

  authentication:
    replication:
      username: replicator
      password: secret123
    superuser:
      username: postgres
      password: admin123

  parameters:
    unix_socket_directories: '/var/run/postgresql'

# ============================================
# Section 6 : Tags et PrioritÃ©s
# ============================================
tags:
  nofailover: false
  noloadbalance: false
  clonefrom: true
  priority: 100
```

### Explication des ParamÃ¨tres ClÃ©s

#### 1. `scope`
Le nom logique de votre cluster. Tous les nÅ“uds du mÃªme cluster doivent avoir le mÃªme `scope`.

#### 2. `ttl` (Time To Live)
DurÃ©e de validitÃ© du leader lock.
- **Valeur par dÃ©faut** : 30 secondes
- **Trop court** : Risque de faux positifs (failover inutiles)
- **Trop long** : Temps de dÃ©tection de panne rallongÃ©

**Recommandation** : 30 secondes pour la production

#### 3. `loop_wait`
Intervalle entre chaque vÃ©rification de santÃ©.
- **Valeur par dÃ©faut** : 10 secondes
- **Impact** : Temps de dÃ©tection de panne = `ttl` - `loop_wait`

#### 4. `maximum_lag_on_failover`
Retard de rÃ©plication maximum acceptÃ© pour qu'un Standby soit Ã©ligible comme Primary.
- **Valeur par dÃ©faut** : 1 MB
- **UtilitÃ©** : EmpÃªche la promotion d'un Standby trÃ¨s en retard

#### 5. `use_pg_rewind`
Active l'utilisation de `pg_rewind` pour resynchroniser un ancien Primary sans reconstruction complÃ¨te.
- **Valeur recommandÃ©e** : `true`
- **Avantage** : RÃ©intÃ©gration rapide de l'ancien Primary

---

## Patroni en Action : Exemples de ScÃ©narios

### ScÃ©nario 1 : Failover Automatique

**Contexte** : Le Primary tombe en panne (crash systÃ¨me, perte rÃ©seau)

```
T+0s   : Primary actif, 2 Standby en rÃ©plication
T+15s  : Primary crash âŒ
T+15s  : Patroni du Primary ne peut plus renouveler le lock
T+30s  : Leader lock expire dans etcd
T+31s  : Standby 1 dÃ©tecte l'expiration
T+32s  : Standby 1 et 2 tentent d'acquÃ©rir le lock
T+33s  : Standby 1 obtient le lock (meilleur LSN)
T+34s  : Patroni exÃ©cute "pg_ctl promote" sur Standby 1
T+40s  : PostgreSQL Standby 1 devient Primary âœ…
T+41s  : Standby 2 dÃ©tecte le nouveau Primary
T+42s  : Standby 2 se reconfigure automatiquement
T+45s  : Cluster opÃ©rationnel avec 1 Primary + 1 Standby
```

**RTO (Recovery Time Objective)** : ~30 secondes

**RPO (Recovery Point Objective)** :
- RÃ©plication asynchrone : Quelques transactions perdues
- RÃ©plication synchrone : 0 perte

### ScÃ©nario 2 : Maintenance PlanifiÃ©e (Switchover)

**Contexte** : Vous voulez faire une maintenance sur le Primary actuel

**Commande Patroni** :
```bash
# Basculer manuellement vers le meilleur Standby
patronictl switchover postgres-cluster

# Patroni demande :
# Master [postgres1]:
# Candidate [postgres2]: postgres2
# When should the switchover take place (e.g. 2024-11-22T10:00 )  [now]:
```

**Ce qui se passe** :
1. Patroni met le Primary actuel en mode lecture seule
2. Attend que les Standby soient Ã  jour
3. Promeut le Standby cible
4. Reconfigure l'ancien Primary en Standby
5. Tout Ã§a en **0 perte de donnÃ©es**

**RTO** : ~5-10 secondes (configurable avec `--scheduled`)

### ScÃ©nario 3 : Retour du Primary Original

**Contexte** : L'ancien Primary (qui avait crashÃ©) redÃ©marre

```
T+0m   : Ancien Primary dÃ©marre
T+0m   : Patroni dÃ©marre et interroge etcd
T+0m   : etcd rÃ©pond : "postgres2 est le Primary maintenant"
T+1m   : Patroni compare les timelines
T+1m   : Timeline ancien Primary = 1, Timeline nouveau Primary = 2
T+2m   : Patroni exÃ©cute "pg_rewind" pour resynchroniser
T+5m   : Ancien Primary devient Standby âœ…
T+5m   : Cluster a maintenant 1 Primary + 2 Standby
```

**Important** : Aucune intervention manuelle nÃ©cessaire !

### ScÃ©nario 4 : Split-Brain PrÃ©vention

**Contexte** : Perte rÃ©seau temporaire (network partition)

```
Situation :
- Primary perd la connexion Ã  etcd (problÃ¨me rÃ©seau)
- Les Standby perdent aussi la connexion au Primary
- Mais les Standby peuvent toujours accÃ©der Ã  etcd

Que fait Patroni ?

Sur le Primary :
1. Patroni ne peut plus renouveler le leader lock
2. Au bout de TTL secondes, Patroni dÃ©tecte la perte du lock
3. Patroni met automatiquement PostgreSQL en PAUSE (lecture seule)
4. Patroni attend de retrouver la connexion Ã  etcd

Sur les Standby :
1. Standby dÃ©tectent l'expiration du leader lock
2. Un Standby acquiert le lock
3. Ce Standby est promu en Primary

RÃ©sultat :
âœ… Un seul Primary Ã  tout moment
âœ… Pas de split-brain
âœ… L'ancien Primary ne peut plus accepter d'Ã©critures
```

**MÃ©canisme de protection** : **Fencing automatique**

---

## Commandes Patroni (patronictl)

Patroni fournit l'utilitaire `patronictl` pour interagir avec le cluster.

### Voir l'Ã‰tat du Cluster

```bash
patronictl -c /etc/patroni/patroni.yml list postgres-cluster

# Sortie :
+ Cluster: postgres-cluster ------+----+-----------+
| Member    | Host         | Role   | State     | TL | Lag in MB |
+-----------+--------------+--------+-----------+----+-----------+
| postgres1 | 192.168.1.10 | Leader | running   |  2 |           |
| postgres2 | 192.168.1.11 | Replica| streaming |  2 |         0 |
| postgres3 | 192.168.1.12 | Replica| streaming |  2 |         0 |
+-----------+--------------+--------+-----------+----+-----------+
```

**InterprÃ©tation** :
- **Leader** : Le Primary actuel
- **Replica** : Les Standby
- **TL** : Timeline PostgreSQL
- **Lag in MB** : Retard de rÃ©plication

### Basculer Manuellement (Switchover)

```bash
# Switchover planifiÃ© vers postgres2
patronictl switchover postgres-cluster --master postgres1 --candidate postgres2
```

### Forcer un Failover (Urgence)

```bash
# En cas d'urgence, forcer le failover immÃ©diatement
patronictl failover postgres-cluster --candidate postgres2 --force
```

### RedÃ©marrer un NÅ“ud

```bash
# RedÃ©marrer PostgreSQL via Patroni
patronictl restart postgres-cluster postgres1
```

### RÃ©intÃ©grer un NÅ“ud (Reinitialize)

```bash
# Si un nÅ“ud est dÃ©synchronisÃ©, le reconstruire
patronictl reinit postgres-cluster postgres1
```

### Mettre en Pause (Maintenance Mode)

```bash
# DÃ©sactiver temporairement l'automatisation Patroni
patronictl pause postgres-cluster

# Le cluster reste en l'Ã©tat actuel, mais Patroni n'intervient plus
```

```bash
# RÃ©activer l'automatisation
patronictl resume postgres-cluster
```

### Voir la Configuration DCS

```bash
# Voir la configuration stockÃ©e dans etcd/Consul
patronictl show-config postgres-cluster
```

---

## Patroni et HAProxy : Load Balancing

Patroni seul ne gÃ¨re pas la redirection des connexions applicatives. Vous devez utiliser un **proxy** ou un **load balancer**.

### Architecture avec HAProxy

```
    Applications
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ HAProxy  â”‚
    â”‚ Port 5000â”‚ â†’ Connexions WRITE â†’ Primary (port 5432)
    â”‚ Port 5001â”‚ â†’ Connexions READ  â†’ Standby 1 ou 2 (port 5432)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼            â–¼
postgres1  postgres2   postgres3
(Primary)  (Standby)   (Standby)
```

### Configuration HAProxy

HAProxy interroge l'**API REST de Patroni** pour savoir qui est le Primary :

```
# /etc/haproxy/haproxy.cfg

frontend postgres_write
    bind *:5000
    default_backend postgres_primary

backend postgres_primary
    option httpchk GET /primary   # Patroni REST API endpoint
    http-check expect status 200
    server postgres1 192.168.1.10:5432 check port 8008
    server postgres2 192.168.1.11:5432 check port 8008
    server postgres3 192.168.1.12:5432 check port 8008

frontend postgres_read
    bind *:5001
    default_backend postgres_replicas

backend postgres_replicas
    option httpchk GET /replica   # Patroni REST API endpoint
    http-check expect status 200
    balance roundrobin
    server postgres2 192.168.1.11:5432 check port 8008
    server postgres3 192.168.1.12:5432 check port 8008
```

### Endpoints Patroni REST API

| Endpoint | RÃ´le | Retour |
|----------|------|--------|
| `/primary` | VÃ©rifie si le nÅ“ud est Primary | 200 si Primary, 503 sinon |
| `/replica` | VÃ©rifie si le nÅ“ud est Standby | 200 si Standby, 503 sinon |
| `/health` | VÃ©rifie si PostgreSQL est en bonne santÃ© | 200 si OK |
| `/read-only` | VÃ©rifie si le nÅ“ud accepte les lectures | 200 si OK |

**Avantage** : HAProxy bascule automatiquement les connexions aprÃ¨s un failover !

---

## Avantages et Limites de Patroni

### âœ… Avantages

**1. Automatisation ComplÃ¨te**
- Pas d'intervention humaine requise 24/7
- Failover en 15-30 secondes

**2. PrÃ©vention du Split-Brain**
- Protection garantie par le consensus
- Fencing automatique

**3. FlexibilitÃ©**
- Switchover planifiÃ© sans perte de donnÃ©es
- Mode pause pour maintenance

**4. ObservabilitÃ©**
- API REST pour monitoring
- IntÃ©gration facile avec Prometheus/Grafana

**5. Ã‰cosystÃ¨me Mature**
- UtilisÃ© en production par des milliers d'entreprises
- CommunautÃ© active
- Compatible Kubernetes (Zalando Operator)

### âš ï¸ Limites et ConsidÃ©rations

**1. ComplexitÃ© Accrue**
- NÃ©cessite d'installer et de maintenir etcd/Consul
- Plus de composants = plus de points de dÃ©faillance potentiels

**2. DÃ©pendance au SystÃ¨me de Consensus**
- Si etcd/Consul tombe, Patroni ne peut plus fonctionner
- Important d'avoir un etcd HA (3+ nÅ“uds)

**3. Latence RÃ©seau**
- Le failover dÃ©pend de la latence rÃ©seau entre les nÅ“uds
- RÃ©seaux lents = temps de failover plus longs

**4. Courbe d'Apprentissage**
- Plus complexe qu'une simple rÃ©plication PostgreSQL
- NÃ©cessite de comprendre les concepts de consensus

**5. Pas de Magie**
- Patroni ne rÃ©sout pas les problÃ¨mes de performance PostgreSQL
- Patroni ne remplace pas les backups

---

## Patroni vs Repmgr vs pg_auto_failover

### Comparaison des Solutions HA

| CritÃ¨re | Patroni | Repmgr | pg_auto_failover |
|---------|---------|--------|------------------|
| **SystÃ¨me de Consensus** | etcd/Consul/ZK | Aucun (tÃ©moin optionnel) | pg_auto_failover monitor |
| **ComplexitÃ©** | Moyenne | Faible | Faible |
| **Automatisation** | ComplÃ¨te | Partielle | ComplÃ¨te |
| **Split-Brain Protection** | Excellent | Bon (avec witness) | Excellent |
| **Kubernetes-Ready** | â­â­â­â­â­ | â­â­ | â­â­â­ |
| **CommunautÃ©** | TrÃ¨s active | Active | Moyenne |
| **Maintenance** | Moyenne | Faible | Faible |

### Quand Utiliser Chaque Solution ?

**Patroni** :
- âœ… Production critique (99.99% uptime)
- âœ… DÃ©ploiement Kubernetes
- âœ… Clusters complexes (5+ nÅ“uds)
- âœ… Multi-datacenter

**Repmgr** :
- âœ… Clusters simples (1 Primary + 2 Standby)
- âœ… Ã‰quipes prÃ©fÃ©rant la simplicitÃ©
- âœ… Failover semi-automatique acceptable

**pg_auto_failover** :
- âœ… Alternative simple Ã  Patroni
- âœ… Pas envie de gÃ©rer etcd/Consul
- âœ… Microsoft/Citus support

---

## Monitoring et Troubleshooting Patroni

### MÃ©triques ClÃ©s Ã  Surveiller

#### 1. Ã‰tat du Leader Lock

```bash
# VÃ©rifier qui dÃ©tient le leader lock
curl http://192.168.1.10:8008/patroni | jq .

# RÃ©ponse :
{
  "state": "running",
  "role": "master",
  "timeline": 2,
  "xlog": {
    "location": 67108864
  }
}
```

#### 2. Retard de RÃ©plication

```bash
patronictl -c /etc/patroni/patroni.yml list postgres-cluster
```

**Alerte** si `Lag in MB` > 100 MB

#### 3. Nombre de Failovers

```bash
# Dans etcd, vÃ©rifier l'historique
etcdctl get /service/postgres-cluster/history --prefix
```

**Alerte** si failovers frÃ©quents (> 1 par jour) â†’ ProblÃ¨me sous-jacent

### Logs Patroni

Les logs Patroni sont essentiels pour diagnostiquer :

```bash
# Logs systemd
journalctl -u patroni -f

# Ou logs fichier
tail -f /var/log/patroni/patroni.log
```

**Ã‰vÃ©nements importants Ã  chercher** :
- `Lock owner`
- `promoted self to leader`
- `demoted self`
- `no healthy members found`

### ProblÃ¨mes Courants

#### ProblÃ¨me 1 : Flapping (Failover RÃ©pÃ©tÃ©s)

**SymptÃ´me** : Le Primary change constamment

**Causes possibles** :
- TTL trop court
- Latence rÃ©seau Ã©levÃ©e
- etcd/Consul surchargÃ©

**Solution** :
```yaml
# Augmenter le TTL
bootstrap:
  dcs:
    ttl: 60  # Au lieu de 30
    loop_wait: 10
```

#### ProblÃ¨me 2 : Standby Ne Se Synchronise Pas

**SymptÃ´me** : Un Standby reste dÃ©synchronisÃ©

**Diagnostic** :
```bash
# Sur le Standby
patronictl reinit postgres-cluster postgres2
```

**Causes** : Corruption, pg_rewind Ã©chouÃ©, manque d'espace disque

#### ProblÃ¨me 3 : etcd Inaccessible

**SymptÃ´me** : Patroni ne peut plus contacter etcd

**Impact** :
- Le Primary se met automatiquement en pause (lecture seule)
- Pas de failover possible

**Solution** :
1. VÃ©rifier la connexion rÃ©seau vers etcd
2. VÃ©rifier les logs etcd
3. RedÃ©marrer etcd si nÃ©cessaire

---

## DÃ©ploiement Patroni en Production

### Architecture de RÃ©fÃ©rence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Load Balancer (HAProxy)            â”‚
â”‚  Port 5000 (WRITE) â”‚ Port 5001 (READ)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patroni 1   â”‚ â”‚  Patroni 2   â”‚ â”‚  Patroni 3   â”‚
â”‚ (Primary)    â”‚ â”‚ (Standby)    â”‚ â”‚ (Standby)    â”‚
â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
â”‚ PostgreSQL   â”‚ â”‚ PostgreSQL   â”‚ â”‚ PostgreSQL   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   etcd Cluster (3 nÅ“uds)  â”‚
        â”‚                           â”‚
        â”‚  etcd1 â”‚ etcd2 â”‚ etcd3    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Checklist de DÃ©ploiement

#### Phase 1 : PrÃ©paration

- [ ] Installer etcd sur 3 serveurs sÃ©parÃ©s
- [ ] VÃ©rifier la connectivitÃ© rÃ©seau entre tous les nÅ“uds
- [ ] PrÃ©parer les serveurs PostgreSQL (OS, disques, rÃ©seau)
- [ ] Configurer le firewall (ports 5432, 8008, 2379)

#### Phase 2 : Installation

- [ ] Installer Patroni sur chaque nÅ“ud PostgreSQL
- [ ] CrÃ©er les fichiers de configuration Patroni
- [ ] Configurer l'authentification PostgreSQL
- [ ] Tester la connexion Ã  etcd

#### Phase 3 : Bootstrap

- [ ] DÃ©marrer Patroni sur le premier nÅ“ud
- [ ] VÃ©rifier l'initialisation de PostgreSQL
- [ ] DÃ©marrer Patroni sur les nÅ“uds suivants
- [ ] VÃ©rifier la rÃ©plication automatique

#### Phase 4 : Load Balancer

- [ ] Installer HAProxy (ou PgBouncer)
- [ ] Configurer les backends avec Patroni REST API
- [ ] Tester les connexions via le load balancer

#### Phase 5 : Validation

- [ ] Test de failover planifiÃ© (switchover)
- [ ] Test de failover non planifiÃ© (kill -9 Primary)
- [ ] Test de split-brain (isolation rÃ©seau)
- [ ] Test de performance (benchmark)

#### Phase 6 : Monitoring

- [ ] Configurer Prometheus + Grafana
- [ ] CrÃ©er les alertes (failover, lag, etcd down)
- [ ] Documenter les runbooks

---

## RÃ©sumÃ© des Concepts ClÃ©s

### Ce qu'il Faut Retenir

**1. Patroni = HA AutomatisÃ©**
- DÃ©tection automatique de panne
- Ã‰lection automatique du nouveau Primary
- PrÃ©vention du split-brain

**2. Consensus DistribuÃ©**
- etcd/Consul/ZooKeeper : Un seul point de vÃ©ritÃ©
- Leader lock : MÃ©canisme de coordination
- Quorum : DÃ©cision Ã  la majoritÃ©

**3. Cycle de Vie Patroni**
- Bootstrap â†’ Fonctionnement normal â†’ Panne â†’ Failover â†’ RÃ©intÃ©gration

**4. RTO & RPO**
- **RTO** : 15-30 secondes (temps de failover)
- **RPO** : 0 (synchrone) ou quelques transactions (asynchrone)

**5. Limites**
- NÃ©cessite etcd/Consul (dÃ©pendance externe)
- Plus complexe qu'une simple rÃ©plication
- NÃ©cessite une bonne architecture rÃ©seau

---

## Pour Aller Plus Loin

Maintenant que vous comprenez Patroni, vous pouvez explorer :

- **DÃ©ploiement Kubernetes** : Zalando PostgreSQL Operator
- **Multi-datacenter** : Patroni avec Consul multi-DC
- **Monitoring avancÃ©** : MÃ©triques Prometheus, dashboards Grafana
- **Backup automatisÃ©** : Integration avec pgBackRest, WAL-G
- **RÃ©plication Logique** : ComplÃ©mentaritÃ© avec Patroni

---

## Conclusion

Patroni rÃ©volutionne la haute disponibilitÃ© PostgreSQL en automatisant complÃ¨tement le processus de failover. Ce qui nÃ©cessitait auparavant une intervention humaine et plusieurs minutes se fait maintenant automatiquement en 15-30 secondes.

**Points essentiels** :
- âœ… Automatisation complÃ¨te du failover
- âœ… Protection garantie contre le split-brain
- âœ… Switchover planifiÃ© sans perte de donnÃ©es
- âœ… IntÃ©gration facile avec HAProxy pour le load balancing
- âœ… Ã‰cosystÃ¨me mature et Ã©prouvÃ© en production

Patroni transforme un cluster PostgreSQL en un systÃ¨me **auto-rÃ©parant** capable de survivre aux pannes sans intervention humaine. C'est aujourd'hui la solution de rÃ©fÃ©rence pour la haute disponibilitÃ© PostgreSQL, utilisÃ©e par des milliers d'entreprises dans le monde.

La complexitÃ© initiale de mise en place est largement compensÃ©e par la tranquillitÃ© d'esprit d'avoir un systÃ¨me capable de se rÃ©parer automatiquement, 24h/24, 7j/7.

---

**Prochaine Ã©tape recommandÃ©e** : Ã‰tudier la section 17.5.3 sur Repmgr pour comparer avec une approche plus lÃ©gÃ¨re de la haute disponibilitÃ©.

â­ï¸ [Repmgr : Gestion de rÃ©plication simplifiÃ©e](/17-haute-disponibilite-et-replication/05.3-repmgr.md)
