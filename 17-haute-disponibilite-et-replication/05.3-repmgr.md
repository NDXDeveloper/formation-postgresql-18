ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 17.5.3. Repmgr : Gestion de rÃ©plication simplifiÃ©e

## Introduction

Dans les sections prÃ©cÃ©dentes, nous avons vu :
- **17.5.1** : La promotion manuelle avec `pg_ctl promote` (intervention humaine)
- **17.5.2** : Patroni avec son automatisation complÃ¨te (mais complexe avec etcd/Consul)

**Repmgr** se positionne entre ces deux approches : il simplifie grandement la gestion de la rÃ©plication PostgreSQL tout en offrant une automatisation partielle, sans nÃ©cessiter de systÃ¨me de consensus externe.

### Qu'est-ce que Repmgr ?

**Repmgr** (Replication Manager) est un outil open-source dÃ©veloppÃ© par **2ndQuadrant** (maintenant EDB) pour :
- Configurer et gÃ©rer la rÃ©plication PostgreSQL de maniÃ¨re simple
- Monitorer l'Ã©tat des nÅ“uds du cluster
- Faciliter le failover (automatique ou manuel)
- Cloner rapidement de nouveaux Standby

**Philosophie** : "Keep it simple" - Repmgr privilÃ©gie la simplicitÃ© sur l'automatisation totale.

---

## Repmgr vs Patroni vs Manuel : Quelle DiffÃ©rence ?

### Comparaison Rapide

| Aspect | Manuel (pg_ctl) | Repmgr | Patroni |
|--------|-----------------|--------|---------|
| **ComplexitÃ©** | Simple | Moyenne | Ã‰levÃ©e |
| **Infrastructure requise** | Aucune | Aucune (optionnel: witness) | etcd/Consul/ZK |
| **Failover automatique** | âŒ Non | âš ï¸ Optionnel | âœ… Oui |
| **Split-brain protection** | âŒ Non | âš ï¸ Partielle | âœ… Excellente |
| **Maintenance** | Faible | Faible | Moyenne |
| **Courbe d'apprentissage** | Courte | Courte | Longue |
| **Cas d'usage** | Dev/Test | Petits clusters | Production critique |

### Positionnement de Repmgr

**Repmgr est idÃ©al pour** :
- âœ… Ã‰quipes qui veulent plus qu'une rÃ©plication manuelle
- âœ… Clusters de petite Ã  moyenne taille (2-5 nÅ“uds)
- âœ… Environnements oÃ¹ la simplicitÃ© prime
- âœ… Budgets limitÃ©s (pas d'infrastructure additionnelle)
- âœ… Failover semi-automatique acceptable (avec intervention humaine)

**Repmgr n'est PAS adaptÃ© pour** :
- âŒ Production ultra-critique (99.99% uptime requis)
- âŒ Clusters trÃ¨s complexes (10+ nÅ“uds)
- âŒ Failover automatique sans supervision humaine obligatoire
- âŒ Architectures multi-datacenter complexes

---

## Architecture de Repmgr

### Vue d'Ensemble

Contrairement Ã  Patroni qui nÃ©cessite etcd/Consul, Repmgr stocke toutes ses mÃ©tadonnÃ©es **directement dans PostgreSQL**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Base de DonnÃ©es "repmgr"            â”‚
â”‚    (mÃ©tadonnÃ©es du cluster stockÃ©es ici)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–²
                     â”‚ Lecture/Ã‰criture
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚
        â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  repmgrd 1   â”‚ â”‚  repmgrd 2   â”‚ â”‚  repmgrd 3   â”‚
â”‚  (daemon)    â”‚ â”‚  (daemon)    â”‚ â”‚  (daemon)    â”‚
â”‚      â”‚       â”‚ â”‚      â”‚       â”‚ â”‚      â”‚       â”‚
â”‚      â–¼       â”‚ â”‚      â–¼       â”‚ â”‚      â–¼       â”‚
â”‚ PostgreSQL 1 â”‚ â”‚ PostgreSQL 2 â”‚ â”‚ PostgreSQL 3 â”‚
â”‚  (Primary)   â”‚ â”‚  (Standby)   â”‚ â”‚  (Standby)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants de Repmgr

#### 1. L'Outil `repmgr`

C'est l'utilitaire en ligne de commande pour :
- Enregistrer les nÅ“uds dans le cluster
- Cloner de nouveaux Standby
- Promouvoir manuellement un Standby
- Afficher l'Ã©tat du cluster

**Analogie** : `repmgr` est comme `patronictl` pour Patroni.

#### 2. Le Daemon `repmgrd`

C'est un processus d'arriÃ¨re-plan qui :
- Surveille l'Ã©tat de PostgreSQL
- DÃ©tecte les pannes (heartbeat)
- Peut dÃ©clencher un failover automatique (si configurÃ©)
- Envoie des notifications

**Analogie** : `repmgrd` est comme l'agent Patroni.

#### 3. La Base de DonnÃ©es `repmgr`

Une base PostgreSQL dÃ©diÃ©e qui stocke :
- La liste des nÅ“uds du cluster
- L'historique des Ã©vÃ©nements (failover, switchover, etc.)
- La configuration du cluster

**Important** : Cette base est rÃ©pliquÃ©e automatiquement avec le reste de PostgreSQL.

#### 4. Le Witness (Optionnel)

Un serveur lÃ©ger qui sert d'**arbitre** en cas de perte de connexion rÃ©seau.

**RÃ´le** : Ã‰viter les faux positifs et amÃ©liorer la dÃ©tection des pannes.

---

## Concepts Fondamentaux de Repmgr

### 1. Enregistrement des NÅ“uds

Chaque nÅ“ud PostgreSQL doit Ãªtre **enregistrÃ©** dans le cluster Repmgr.

**Types de nÅ“uds** :
- **Primary** : Le serveur maÃ®tre (lecture/Ã©criture)
- **Standby** : Les rÃ©plicas (lecture seule)
- **Witness** : Arbitre sans donnÃ©es (optionnel)

**Registre** : La table `repmgr.nodes` contient la liste de tous les nÅ“uds :

```sql
SELECT node_id, node_name, type, active
FROM repmgr.nodes;

 node_id | node_name  |   type   | active
---------+------------+----------+--------
       1 | postgres1  | primary  | t
       2 | postgres2  | standby  | t
       3 | postgres3  | standby  | t
       4 | witness1   | witness  | t
```

### 2. Node ID et PrioritÃ©

Chaque nÅ“ud a :
- **Node ID** : Identifiant unique (entier)
- **PrioritÃ©** : Score pour l'Ã©lection (plus haut = prÃ©fÃ©rÃ©)

**Exemple** :
```ini
node_id=1
node_name='postgres1'
priority=100
```

**Utilisation** : En cas de failover, Repmgr prÃ©fÃ¨re le nÅ“ud avec la prioritÃ© la plus Ã©levÃ©e.

### 3. Ã‰vÃ©nements et Historique

Repmgr enregistre tous les Ã©vÃ©nements importants dans `repmgr.events` :

```sql
SELECT event_timestamp, event, node_name, successful
FROM repmgr.events
ORDER BY event_timestamp DESC
LIMIT 5;

    event_timestamp     |        event        | node_name | successful
------------------------+---------------------+-----------+------------
 2025-11-22 10:15:32+00 | standby_promote     | postgres2 | t
 2025-11-22 10:15:20+00 | repmgrd_failover    | postgres2 | t
 2025-11-22 09:00:00+00 | standby_clone       | postgres3 | t
```

**Avantage** : TraÃ§abilitÃ© complÃ¨te de l'historique du cluster.

### 4. Le TÃ©moin (Witness Node)

Le **witness** est un serveur PostgreSQL spÃ©cial :
- âœ… Ne contient **aucune donnÃ©e utilisateur**
- âœ… Participe aux **dÃ©cisions de failover**
- âœ… TrÃ¨s **lÃ©ger en ressources**

**Pourquoi utiliser un witness ?**

Imaginez ce scÃ©nario :
```
Situation : 1 Primary + 1 Standby dans le mÃªme datacenter

Primary tombe en panne
â†’ Le Standby dÃ©tecte la panne
â†’ Mais comment Ãªtre sÃ»r que c'est bien une panne ?
â†’ Et pas juste une perte de connexion rÃ©seau ?
```

**Avec un witness** (dans un datacenter diffÃ©rent) :
```
Le Standby vÃ©rifie auprÃ¨s du witness :
"Est-ce que tu vois le Primary ?"

Si le witness rÃ©pond "Non" â†’ C'est bien une panne du Primary
Si le witness rÃ©pond "Oui" â†’ C'est juste une coupure rÃ©seau locale
```

**Architecture recommandÃ©e** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Datacenter A â”‚         â”‚ Datacenter B â”‚
â”‚              â”‚         â”‚              â”‚
â”‚  Primary     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  Standby     â”‚
â”‚  Standby     â”‚         â”‚  Witness     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration de Repmgr

### 1. Installation

**Sur Debian/Ubuntu** :
```bash
# Ajouter le dÃ©pÃ´t PostgreSQL officiel
sudo apt install postgresql-contrib-14 repmgr
```

**Sur Red Hat/CentOS** :
```bash
sudo yum install repmgr14
```

### 2. Fichier de Configuration : `repmgr.conf`

Chaque nÅ“ud a son propre fichier `/etc/repmgr/14/repmgr.conf`.

#### Configuration du Primary (Node 1)

```ini
# ==============================================================
# IDENTIFICATION DU NÅ’UD
# ==============================================================
node_id=1
node_name='postgres1'
conninfo='host=192.168.1.10 user=repmgr dbname=repmgr connect_timeout=2'
data_directory='/var/lib/postgresql/14/main'

# ==============================================================
# REPLICATION
# ==============================================================
replication_user='repmgr'

# ==============================================================
# FAILOVER ET PRIORITÃ‰
# ==============================================================
priority=100                    # PrioritÃ© Ã©levÃ©e
failover=automatic             # Failover automatique activÃ©
promote_command='repmgr standby promote -f /etc/repmgr/14/repmgr.conf --log-to-file'
follow_command='repmgr standby follow -f /etc/repmgr/14/repmgr.conf --log-to-file --upstream-node-id=%n'

# ==============================================================
# MONITORING (repmgrd)
# ==============================================================
monitoring_history=yes         # Enregistrer l'historique
monitor_interval_secs=5        # VÃ©rifier toutes les 5 secondes
reconnect_attempts=6           # Essayer 6 fois avant de dÃ©clarer un nÅ“ud mort
reconnect_interval=10          # Attendre 10 secondes entre chaque essai

# ==============================================================
# NOTIFICATIONS
# ==============================================================
event_notification_command='/usr/local/bin/repmgr_notify.sh %n %e %s "%t" "%d"'

# ==============================================================
# LOGGING
# ==============================================================
log_file='/var/log/postgresql/repmgr.log'
log_level=INFO
log_status_interval=300        # Log de statut toutes les 5 minutes
```

#### Configuration du Standby (Node 2)

```ini
node_id=2
node_name='postgres2'
conninfo='host=192.168.1.11 user=repmgr dbname=repmgr connect_timeout=2'
data_directory='/var/lib/postgresql/14/main'

replication_user='repmgr'

priority=90                    # PrioritÃ© lÃ©gÃ¨rement plus faible
failover=automatic
promote_command='repmgr standby promote -f /etc/repmgr/14/repmgr.conf --log-to-file'
follow_command='repmgr standby follow -f /etc/repmgr/14/repmgr.conf --log-to-file --upstream-node-id=%n'

monitoring_history=yes
monitor_interval_secs=5
reconnect_attempts=6
reconnect_interval=10

log_file='/var/log/postgresql/repmgr.log'
log_level=INFO
```

### 3. Configuration PostgreSQL

**ParamÃ¨tres requis dans `postgresql.conf`** :

```ini
# Replication settings
wal_level = replica
max_wal_senders = 10
max_replication_slots = 10
hot_standby = on

# Shared preload libraries
shared_preload_libraries = 'repmgr'
```

**Configuration de `pg_hba.conf`** :

```
# Repmgr connections
local   replication   repmgr                              trust
host    replication   repmgr      127.0.0.1/32            trust
host    replication   repmgr      192.168.1.0/24          scram-sha-256

local   repmgr        repmgr                              trust
host    repmgr        repmgr      127.0.0.1/32            trust
host    repmgr        repmgr      192.168.1.0/24          scram-sha-256
```

### 4. CrÃ©ation de l'Utilisateur Repmgr

```bash
# Sur le Primary
sudo -u postgres createuser -s repmgr
sudo -u postgres createdb repmgr -O repmgr
```

---

## Mise en Place d'un Cluster Repmgr : Ã‰tape par Ã‰tape

### Ã‰tape 1 : Enregistrer le Primary

Sur le serveur Primary (postgres1) :

```bash
# Enregistrer le nÅ“ud Primary
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf primary register

# Sortie attendue :
# INFO: connecting to primary database...
# NOTICE: attempting to install extension "repmgr"
# NOTICE: "repmgr" extension successfully installed
# NOTICE: primary node record (ID: 1) registered
```

**VÃ©rification** :

```bash
# Voir les nÅ“uds enregistrÃ©s
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf cluster show

# Sortie :
#  ID | Name      | Role    | Status    | Upstream | Location | Priority | Timeline | Connection string
# ----+-----------+---------+-----------+----------+----------+----------+----------+--------------------
#  1  | postgres1 | primary | * running |          | default  | 100      | 1        | host=192.168.1.10...
```

### Ã‰tape 2 : Cloner et Enregistrer le Premier Standby

Sur le serveur Standby (postgres2) :

**a) ArrÃªter PostgreSQL s'il tourne** :

```bash
sudo systemctl stop postgresql
```

**b) Vider le rÃ©pertoire de donnÃ©es** (si existant) :

```bash
sudo -u postgres rm -rf /var/lib/postgresql/14/main/*
```

**c) Cloner depuis le Primary** :

```bash
# Dry-run pour vÃ©rifier la configuration
sudo -u postgres repmgr -h 192.168.1.10 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone --dry-run

# Si OK, cloner rÃ©ellement
sudo -u postgres repmgr -h 192.168.1.10 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone

# Sortie :
# NOTICE: destination directory "/var/lib/postgresql/14/main" provided
# INFO: connecting to source node
# NOTICE: checking for available walsenders on the source node (2 required)
# INFO: sufficient walsenders available on the source node
# INFO: successfully connected to source node
# DETAIL: current installation size is 30 MB
# NOTICE: standby clone (using pg_basebackup) complete
# NOTICE: you can now start your PostgreSQL server
```

**d) DÃ©marrer PostgreSQL** :

```bash
sudo systemctl start postgresql
```

**e) Enregistrer le Standby** :

```bash
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby register

# Sortie :
# INFO: connecting to local node "postgres2" (ID: 2)
# INFO: connecting to primary database
# NOTICE: standby node "postgres2" (ID: 2) successfully registered
```

**VÃ©rification** :

```bash
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf cluster show

# Sortie :
#  ID | Name      | Role    | Status    | Upstream  | Priority | Timeline
# ----+-----------+---------+-----------+-----------+----------+----------
#  1  | postgres1 | primary | * running |           | 100      | 1
#  2  | postgres2 | standby |   running | postgres1 | 90       | 1
```

### Ã‰tape 3 : Ajouter un Second Standby (postgres3)

RÃ©pÃ©ter les mÃªmes Ã©tapes que pour postgres2 :

```bash
# Sur postgres3
sudo systemctl stop postgresql
sudo -u postgres rm -rf /var/lib/postgresql/14/main/*
sudo -u postgres repmgr -h 192.168.1.10 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone
sudo systemctl start postgresql
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby register
```

**Cluster final** :

```bash
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf cluster show

#  ID | Name      | Role    | Status    | Upstream  | Priority | Timeline
# ----+-----------+---------+-----------+-----------+----------+----------
#  1  | postgres1 | primary | * running |           | 100      | 1
#  2  | postgres2 | standby |   running | postgres1 | 90       | 1
#  3  | postgres3 | standby |   running | postgres1 | 80       | 1
```

### Ã‰tape 4 : DÃ©marrer le Daemon `repmgrd` (Optionnel mais RecommandÃ©)

Pour activer le failover automatique, dÃ©marrer `repmgrd` sur tous les nÅ“uds :

```bash
# Sur chaque nÅ“ud (postgres1, postgres2, postgres3)
sudo systemctl enable repmgrd
sudo systemctl start repmgrd
sudo systemctl status repmgrd

# VÃ©rifier les logs
tail -f /var/log/postgresql/repmgr.log
```

**Ce que fait `repmgrd`** :
- Surveille l'Ã©tat de PostgreSQL toutes les 5 secondes (configurable)
- DÃ©tecte les pannes du Primary
- DÃ©clenche automatiquement le failover (si `failover=automatic`)

---

## Commandes Repmgr Essentielles

### 1. Afficher l'Ã‰tat du Cluster

```bash
# Vue d'ensemble du cluster
repmgr -f /etc/repmgr/14/repmgr.conf cluster show

# Vue dÃ©taillÃ©e avec informations supplÃ©mentaires
repmgr -f /etc/repmgr/14/repmgr.conf cluster show --verbose
```

### 2. Voir l'Historique des Ã‰vÃ©nements

```bash
# 10 derniers Ã©vÃ©nements
repmgr -f /etc/repmgr/14/repmgr.conf cluster event --limit 10

# Ã‰vÃ©nements d'un nÅ“ud spÃ©cifique
repmgr -f /etc/repmgr/14/repmgr.conf cluster event --node-id=2
```

### 3. Promouvoir Manuellement un Standby

```bash
# Sur le Standby que vous voulez promouvoir
repmgr -f /etc/repmgr/14/repmgr.conf standby promote

# Sortie :
# NOTICE: promoting standby to primary
# DETAIL: promoting server "postgres2" (ID: 2) using "pg_ctl promote"
# NOTICE: waiting up to 60 seconds (parameter "promote_check_timeout") for promotion to complete
# INFO: standby promoted successfully
# NOTICE: STANDBY PROMOTE successful
```

### 4. Reconfigurer un Standby (Follow)

Si un Standby rÃ©plique depuis le mauvais Primary :

```bash
# Reconfigurer pour suivre le nouveau Primary (node ID 2)
repmgr -f /etc/repmgr/14/repmgr.conf standby follow

# Ou spÃ©cifier explicitement le nouveau Primary
repmgr -f /etc/repmgr/14/repmgr.conf standby follow --upstream-node-id=2
```

### 5. Switchover PlanifiÃ©

Pour basculer manuellement vers un Standby sans interruption :

```bash
# Sur le Standby que vous voulez promouvoir (postgres2)
repmgr -f /etc/repmgr/14/repmgr.conf standby switchover

# Repmgr va :
# 1. ArrÃªter le Primary actuel proprement
# 2. Promouvoir le Standby
# 3. Reconfigurer l'ancien Primary en Standby
```

**Options utiles** :

```bash
# Switchover avec confirmation
repmgr -f /etc/repmgr/14/repmgr.conf standby switchover --force

# Dry-run (simulation)
repmgr -f /etc/repmgr/14/repmgr.conf standby switchover --dry-run
```

### 6. Tester la Configuration

```bash
# VÃ©rifier la configuration avant de faire des opÃ©rations
repmgr -f /etc/repmgr/14/repmgr.conf node check

# Sortie :
# Node "postgres2":
#     Server role:                  OK (node is standby)
#     Replication lag:              OK (0 seconds)
#     WAL archiving:                OK (0 pending archive ready files)
#     Downstream servers:           OK (0 downstream nodes attached)
#     Replication slots:            OK (node has no replication slots)
#     Data directory:               OK (configured location "/var/lib/postgresql/14/main")
```

### 7. RÃ©enregistrer un NÅ“ud

Si vous devez reconstruire un nÅ“ud :

```bash
# DÃ©senregistrer
repmgr -f /etc/repmgr/14/repmgr.conf standby unregister --node-id=3

# Cloner Ã  nouveau
repmgr -h 192.168.1.10 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone --force

# RÃ©enregistrer
repmgr -f /etc/repmgr/14/repmgr.conf standby register --force
```

---

## Failover avec Repmgr

### Failover Automatique (avec repmgrd)

**PrÃ©requis** :
- `repmgrd` actif sur tous les nÅ“uds
- `failover=automatic` dans `repmgr.conf`
- `promote_command` et `follow_command` configurÃ©s

**ScÃ©nario** : Le Primary (postgres1) tombe en panne

```
T+0s   : Primary fonctionne normalement
         repmgrd surveille (heartbeat toutes les 5s)

T+15s  : Primary crash âŒ

T+20s  : repmgrd sur postgres2 dÃ©tecte la panne
         (monitor_interval_secs = 5, reconnect_attempts = 6)

T+20s  : repmgrd vÃ©rifie si d'autres nÅ“uds voient le Primary
         (en interrogeant postgres3 et witness si prÃ©sent)

T+21s  : Consensus : Le Primary est vraiment en panne

T+22s  : repmgrd sur postgres2 consulte la prioritÃ© des Standby
         postgres2 (prioritÃ© 90) vs postgres3 (prioritÃ© 80)
         â†’ postgres2 est Ã©lu

T+23s  : repmgrd exÃ©cute promote_command
         â†’ pg_ctl promote sur postgres2

T+30s  : postgres2 devient Primary âœ…

T+31s  : postgres3 dÃ©tecte le nouveau Primary
         repmgrd exÃ©cute follow_command
         â†’ postgres3 se reconfigure pour rÃ©pliquer depuis postgres2

T+35s  : Cluster opÃ©rationnel : postgres2 (Primary) + postgres3 (Standby)
```

**RTO** : 30-60 secondes (selon la configuration)

### Failover Manuel

Si `repmgrd` n'est pas actif ou si vous prÃ©fÃ©rez contrÃ´ler :

**Sur le Standby que vous choisissez (postgres2)** :

```bash
# 1. Promouvoir le Standby
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby promote

# 2. Sur les autres Standby (postgres3), les reconfigurer
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby follow
```

### Protection contre le Split-Brain

Repmgr utilise plusieurs mÃ©canismes :

#### 1. Witness Node

Le witness sert d'arbitre :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primary  â”‚â—„â”€â”€â”€â”€â”¤ Standby  â”‚â—„â”€â”€â”€â”€â”¤ Witness  â”‚
â”‚ (panne)  â”‚  âœ—  â”‚          â”‚  âœ“  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Le Standby demande au Witness :
"Est-ce que tu vois le Primary ?"

Witness : "Non" â†’ Le Primary est vraiment en panne â†’ OK pour promouvoir
Witness : "Oui" â†’ C'est juste une perte de connexion locale â†’ NE PAS promouvoir
```

#### 2. VÃ©rification de l'Ã‰tat du Primary

Avant de promouvoir, Repmgr vÃ©rifie :
- Le Primary rÃ©pond-il aux connexions TCP ?
- Le Primary rÃ©pond-il aux requÃªtes PostgreSQL ?
- Le Primary a-t-il Ã©tÃ© vu rÃ©cemment par d'autres nÅ“uds ?

#### 3. DÃ©sactivation de l'Ancien Primary (Fencing)

Repmgr **ne fait PAS** de fencing automatique comme Patroni.

**Important** : Vous devez vous assurer que l'ancien Primary est bien arrÃªtÃ© avant de promouvoir un Standby.

**Options pour le fencing manuel** :
- Script personnalisÃ© via `event_notification_command`
- Utilisation de STONITH (Shoot The Other Node In The Head)
- Isolation rÃ©seau (dÃ©connecter physiquement)

**Exemple de script de notification** :

```bash
#!/bin/bash
# /usr/local/bin/repmgr_notify.sh

NODE_ID=$1
EVENT=$2
SUCCESS=$3
TIMESTAMP=$4
DETAILS=$5

if [ "$EVENT" = "repmgrd_failover_promote" ]; then
    echo "ALERTE: Failover en cours - Node $NODE_ID promu en Primary"
    # Envoyer une notification Slack/Email
    # Isoler l'ancien Primary via IPMI ou autre
fi
```

---

## Monitoring et ObservabilitÃ©

### 1. Surveillance via `repmgr cluster show`

```bash
# Script de monitoring simple
#!/bin/bash
while true; do
    clear
    date
    repmgr -f /etc/repmgr/14/repmgr.conf cluster show
    sleep 5
done
```

### 2. Analyse des Logs

**Log de repmgr** : `/var/log/postgresql/repmgr.log`

**Ã‰vÃ©nements importants Ã  surveiller** :
- `standby promote` : Promotion d'un Standby
- `repmgrd_failover_promote` : Failover automatique dÃ©clenchÃ©
- `unable to connect` : Perte de connexion
- `reconnecting` : Tentative de reconnexion

**Exemple de log lors d'un failover** :

```
[2025-11-22 10:15:20] [WARNING] unable to connect to node "postgres1" (ID: 1)
[2025-11-22 10:15:30] [NOTICE] attempting to promote node "postgres2" (ID: 2)
[2025-11-22 10:15:32] [INFO] executing: pg_ctl promote
[2025-11-22 10:15:40] [NOTICE] node "postgres2" (ID: 2) promoted to primary
[2025-11-22 10:15:41] [INFO] notifying other nodes of new primary
```

### 3. MÃ©triques Ã  Monitorer

| MÃ©trique | RequÃªte SQL | Seuil d'Alerte |
|----------|-------------|----------------|
| **Retard de rÃ©plication** | `SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;` | > 60 secondes |
| **Nombre de failovers** | `SELECT COUNT(*) FROM repmgr.events WHERE event = 'repmgrd_failover_promote' AND event_timestamp > now() - interval '24 hours';` | > 1 par jour |
| **Ã‰tat des nÅ“uds** | `SELECT node_name, active FROM repmgr.nodes WHERE active = false;` | Si active = false |

### 4. IntÃ©gration avec Prometheus

Repmgr n'a pas d'exporter Prometheus natif, mais vous pouvez :

**Option 1 : Utiliser `postgres_exporter`**

```yaml
# Ajouter des requÃªtes personnalisÃ©es
queries:
  - name: repmgr_nodes
    query: "SELECT node_id, node_name, type, active, priority FROM repmgr.nodes"
    metrics:
      - node_id:
          usage: "LABEL"
          description: "Node ID"
      - active:
          usage: "GAUGE"
          description: "Is node active"
```

**Option 2 : Script shell + node_exporter**

```bash
#!/bin/bash
# Exporter des mÃ©triques Repmgr pour node_exporter

# Nombre de nÅ“uds actifs
ACTIVE_NODES=$(psql -U repmgr -d repmgr -tAc "SELECT COUNT(*) FROM repmgr.nodes WHERE active = true")
echo "repmgr_active_nodes $ACTIVE_NODES"

# Retard de rÃ©plication (si Standby)
if [ "$(psql -tAc 'SELECT pg_is_in_recovery()')" = "t" ]; then
    LAG=$(psql -tAc "SELECT COALESCE(EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())), 0)")
    echo "repmgr_replication_lag_seconds $LAG"
fi
```

---

## ScÃ©narios d'Usage de Repmgr

### ScÃ©nario 1 : Cluster Simple (1 Primary + 1 Standby)

**Configuration minimale** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  postgres1   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  postgres2   â”‚
â”‚  (Primary)   â”‚         â”‚  (Standby)   â”‚
â”‚  Priority:100â”‚         â”‚  Priority:90 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cas d'usage** :
- Petite application
- Backup Ã  chaud (hot standby pour les lectures)
- Disaster recovery simple

**Failover** : Manuel recommandÃ© (car pas de witness)

### ScÃ©nario 2 : Cluster avec Witness (RecommandÃ©)

**Configuration** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  postgres1   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  postgres2   â”‚
â”‚  (Primary)   â”‚         â”‚  (Standby)   â”‚
â”‚  Priority:100â”‚         â”‚  Priority:90 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   witness1   â”‚
          â”‚   (Witness)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantage** : Meilleure dÃ©tection des pannes, rÃ©duction des faux positifs

**Failover** : Automatique possible avec `repmgrd`

### ScÃ©nario 3 : Multi-Standby avec Cascading

**Configuration** :

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  postgres1   â”‚
     â”‚  (Primary)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                   â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  postgres2   â”‚    â”‚  postgres3   â”‚
     â”‚  (Standby)   â”‚    â”‚  (Standby)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  postgres4   â”‚
     â”‚  (Standby)   â”‚ â†’ Cascade depuis postgres2
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantage** : RÃ©duire la charge sur le Primary (postgres4 rÃ©plique depuis postgres2)

**Configuration** :

```bash
# Sur postgres4, cloner depuis postgres2
repmgr -h postgres2 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone --upstream-node-id=2
```

---

## Maintenance et OpÃ©rations Courantes

### 1. Ajouter un Nouveau Standby

```bash
# Sur le nouveau serveur (postgres4)
sudo -u postgres repmgr -h postgres1 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone
sudo systemctl start postgresql
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby register
sudo systemctl start repmgrd
```

### 2. Retirer un Standby du Cluster

```bash
# ArrÃªter repmgrd et PostgreSQL
sudo systemctl stop repmgrd
sudo systemctl stop postgresql

# DÃ©senregistrer du cluster
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby unregister --node-id=4
```

### 3. Reconstruire un Standby DÃ©synchronisÃ©

Si un Standby est trop en retard ou corrompu :

```bash
# Sur le Standby Ã  reconstruire
sudo systemctl stop postgresql
sudo -u postgres rm -rf /var/lib/postgresql/14/main/*
sudo -u postgres repmgr -h postgres1 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone --force
sudo systemctl start postgresql
```

### 4. Switchover PlanifiÃ© (Maintenance du Primary)

```bash
# Sur le Standby cible (postgres2)
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby switchover --dry-run

# Si OK, exÃ©cuter rÃ©ellement
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby switchover

# Repmgr va :
# 1. VÃ©rifier que le switchover est possible
# 2. ArrÃªter le Primary actuel
# 3. Promouvoir postgres2
# 4. Reconfigurer l'ancien Primary en Standby
```

**RTO** : ~10-30 secondes avec 0 perte de donnÃ©es

### 5. RÃ©intÃ©grer l'Ancien Primary aprÃ¨s Panne

AprÃ¨s un failover, l'ancien Primary doit Ãªtre rÃ©intÃ©grÃ© :

**Option 1 : Reconstruction ComplÃ¨te** (sÃ»r mais lent)

```bash
# Sur l'ancien Primary (postgres1)
sudo systemctl stop postgresql
sudo -u postgres rm -rf /var/lib/postgresql/14/main/*
sudo -u postgres repmgr -h postgres2 -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone
sudo systemctl start postgresql
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby register --force
```

**Option 2 : pg_rewind** (rapide mais nÃ©cessite pg_rewind activÃ©)

```bash
# Sur l'ancien Primary
sudo systemctl stop postgresql

# ExÃ©cuter pg_rewind pour resynchroniser
sudo -u postgres pg_rewind \
  --target-pgdata=/var/lib/postgresql/14/main \
  --source-server="host=postgres2 port=5432 user=repmgr dbname=postgres" \
  --progress

# Reconfigurer en Standby
sudo -u postgres repmgr -f /etc/repmgr/14/repmgr.conf standby register --force
sudo systemctl start postgresql
```

---

## Troubleshooting Repmgr

### ProblÃ¨me 1 : "unable to connect to primary"

**SymptÃ´me** : Standby ne peut pas se connecter au Primary

**Diagnostic** :

```bash
# Tester la connexion PostgreSQL
psql -h postgres1 -U repmgr -d repmgr

# VÃ©rifier pg_hba.conf sur le Primary
# Doit contenir :
# host repmgr repmgr 192.168.1.0/24 scram-sha-256
```

**Causes courantes** :
- Firewall bloquant le port 5432
- pg_hba.conf incorrect
- Mot de passe incorrect

### ProblÃ¨me 2 : "insufficient walsenders available"

**SymptÃ´me** : Impossible de cloner un nouveau Standby

**Cause** : `max_wal_senders` trop faible dans `postgresql.conf`

**Solution** :

```ini
# postgresql.conf
max_wal_senders = 10  # Au moins Ã©gal au nombre de Standby + 2
```

```bash
# Recharger la configuration
sudo systemctl reload postgresql
```

### ProblÃ¨me 3 : Failover Automatique Ne Se DÃ©clenche Pas

**Diagnostic** :

```bash
# VÃ©rifier que repmgrd tourne
sudo systemctl status repmgrd

# VÃ©rifier les logs
tail -f /var/log/postgresql/repmgr.log
```

**Causes courantes** :
- `failover=automatic` non dÃ©fini
- `promote_command` mal configurÃ©
- Pas assez de nÅ“uds actifs pour atteindre le quorum
- Witness indisponible

### ProblÃ¨me 4 : Split-Brain DÃ©tectÃ©

**SymptÃ´me** : Deux nÅ“uds se considÃ¨rent Primary

**DÃ©tection** :

```bash
# Sur chaque nÅ“ud
psql -c "SELECT pg_is_in_recovery();"

# Si les deux retournent 'f' (false) â†’ Split-brain !
```

**RÃ©solution** :

1. **Identifier le bon Primary** (celui avec les donnÃ©es les plus rÃ©centes)
2. **ArrÃªter immÃ©diatement le faux Primary**
3. **Reconstruire le faux Primary en Standby**

```bash
# Sur le faux Primary
sudo systemctl stop postgresql
sudo -u postgres rm -rf /var/lib/postgresql/14/main/*
sudo -u postgres repmgr -h <bon_primary> -U repmgr -d repmgr \
  -f /etc/repmgr/14/repmgr.conf standby clone
sudo systemctl start postgresql
```

---

## Repmgr et Load Balancing

Repmgr ne gÃ¨re pas lui-mÃªme le routage des connexions. Utilisez :

### Option 1 : HAProxy

Similaire Ã  la configuration avec Patroni, mais en interrogeant directement PostgreSQL :

```
# /etc/haproxy/haproxy.cfg

backend postgres_primary
    option pgsql-check user repmgr
    server postgres1 192.168.1.10:5432 check
    server postgres2 192.168.1.11:5432 check backup
    server postgres3 192.168.1.12:5432 check backup

backend postgres_replicas
    option pgsql-check user repmgr
    balance roundrobin
    server postgres2 192.168.1.11:5432 check
    server postgres3 192.168.1.12:5432 check
```

### Option 2 : PgBouncer + Scripts

Utiliser un script qui interroge `repmgr cluster show` pour dÃ©terminer le Primary :

```bash
#!/bin/bash
# get_primary.sh

PRIMARY=$(repmgr -f /etc/repmgr/14/repmgr.conf cluster show --csv \
  | grep primary | cut -d',' -f2)

echo $PRIMARY
```

Reconfigurer PgBouncer dynamiquement en fonction du rÃ©sultat.

### Option 3 : DNS Dynamique

Utiliser un script qui met Ã  jour un enregistrement DNS en cas de failover :

```bash
# Script dÃ©clenchÃ© par event_notification_command

if [ "$EVENT" = "repmgrd_failover_promote" ]; then
    # Mettre Ã  jour le DNS pour pointer vers le nouveau Primary
    aws route53 change-resource-record-sets ...
fi
```

---

## Avantages et Limites de Repmgr

### âœ… Avantages

**1. SimplicitÃ©**
- Pas de dÃ©pendance externe (etcd, Consul)
- Configuration plus simple que Patroni
- Courbe d'apprentissage courte

**2. LÃ©gÃ¨retÃ©**
- Faible overhead (daemon lÃ©ger)
- Pas d'infrastructure additionnelle Ã  maintenir

**3. FlexibilitÃ©**
- Failover automatique ou manuel au choix
- Compatible avec PostgreSQL vanilla (pas de fork)

**4. IntÃ©gration PostgreSQL**
- MÃ©tadonnÃ©es stockÃ©es dans PostgreSQL
- Utilise les mÃ©canismes natifs de rÃ©plication

**5. MaturitÃ©**
- Existe depuis 2010
- UtilisÃ© en production par de nombreuses entreprises

### âš ï¸ Limites et ConsidÃ©rations

**1. Protection Split-Brain Partielle**
- Moins robuste que Patroni avec consensus
- NÃ©cessite un witness pour Ãªtre fiable
- Pas de fencing automatique

**2. Failover Moins Rapide**
- RTO de 30-60 secondes (vs 15-30s pour Patroni)
- DÃ©pend de la configuration `reconnect_attempts`

**3. Automatisation LimitÃ©e**
- Pas de reconfiguration automatique des applications
- NÃ©cessite HAProxy ou script pour le routage

**4. Moins AdaptÃ© aux Grandes Ã‰chelles**
- Clusters 10+ nÅ“uds : Patroni recommandÃ©
- Multi-datacenter complexe : Patroni prÃ©fÃ©rable

**5. Moins Kubernetes-Friendly**
- Pas d'Operator natif comme Patroni (Zalando)
- NÃ©cessite plus de travail pour l'intÃ©gration K8s

---

## Repmgr vs Patroni : Tableau Comparatif DÃ©taillÃ©

| CritÃ¨re | Repmgr | Patroni |
|---------|--------|---------|
| **Infrastructure requise** | Aucune (+ witness optionnel) | etcd/Consul/ZK (obligatoire) |
| **ComplexitÃ© d'installation** | â­â­ Faible | â­â­â­â­ Ã‰levÃ©e |
| **ComplexitÃ© de maintenance** | â­â­ Faible | â­â­â­ Moyenne |
| **Failover automatique** | âœ… Oui (avec repmgrd) | âœ… Oui (natif) |
| **RTO (temps de failover)** | 30-60 secondes | 15-30 secondes |
| **Split-brain protection** | âš ï¸ Partielle (nÃ©cessite witness) | âœ… Excellente (consensus) |
| **Fencing automatique** | âŒ Non (manuel) | âœ… Oui |
| **Kubernetes-ready** | âš ï¸ Partiel | âœ… Excellent (Operators) |
| **Clonage de Standby** | âœ… TrÃ¨s simple (`standby clone`) | âš ï¸ Plus complexe |
| **Switchover planifiÃ©** | âœ… TrÃ¨s simple (`switchover`) | âœ… Simple |
| **Stockage mÃ©tadonnÃ©es** | PostgreSQL (rÃ©pliquÃ©) | etcd/Consul (externe) |
| **ObservabilitÃ©** | âš ï¸ Logs + SQL | âœ… API REST + Logs |
| **CommunautÃ©** | Active (EDB) | TrÃ¨s active (Zalando, cloud vendors) |
| **Cas d'usage optimal** | PME, petits clusters (2-5 nÅ“uds) | Entreprise, grands clusters (5+ nÅ“uds) |
| **CoÃ»t infrastructure** | ğŸ’° Faible | ğŸ’°ğŸ’° Moyen |

---

## Checklist de DÃ©ploiement Repmgr en Production

### Phase 1 : PrÃ©paration

- [ ] Installer PostgreSQL sur tous les nÅ“uds
- [ ] Installer Repmgr sur tous les nÅ“uds
- [ ] Configurer `postgresql.conf` (wal_level, max_wal_senders, etc.)
- [ ] Configurer `pg_hba.conf` pour autoriser les connexions repmgr
- [ ] CrÃ©er l'utilisateur `repmgr` et la base `repmgr`

### Phase 2 : Configuration

- [ ] CrÃ©er `/etc/repmgr/14/repmgr.conf` sur chaque nÅ“ud
- [ ] DÃ©finir les prioritÃ©s des nÅ“uds
- [ ] Configurer les commandes de failover
- [ ] Configurer les notifications (email, Slack)

### Phase 3 : Mise en Place du Cluster

- [ ] Enregistrer le Primary (`primary register`)
- [ ] Cloner le premier Standby (`standby clone`)
- [ ] Enregistrer le premier Standby (`standby register`)
- [ ] Cloner et enregistrer les Standby suivants
- [ ] (Optionnel) Configurer et enregistrer un witness

### Phase 4 : Automatisation (Optionnel)

- [ ] DÃ©marrer `repmgrd` sur tous les nÅ“uds
- [ ] Tester le failover automatique en environnement de test
- [ ] Valider les logs et notifications

### Phase 5 : Load Balancing

- [ ] Installer HAProxy ou PgBouncer
- [ ] Configurer les backends (Primary / Replicas)
- [ ] Tester les connexions via le load balancer

### Phase 6 : Tests

- [ ] Test de switchover planifiÃ©
- [ ] Test de failover non planifiÃ© (kill -9 du Primary)
- [ ] Test de rÃ©intÃ©gration de l'ancien Primary
- [ ] Test de clonage d'un nouveau Standby
- [ ] Test de split-brain (avec witness)

### Phase 7 : Monitoring

- [ ] Configurer la surveillance des logs Repmgr
- [ ] Configurer des alertes (replication lag, failovers)
- [ ] IntÃ©grer avec Prometheus/Grafana (si applicable)
- [ ] Documenter les runbooks d'intervention

### Phase 8 : Documentation

- [ ] Documenter l'architecture du cluster
- [ ] Documenter les procÃ©dures de failover
- [ ] Documenter les procÃ©dures de maintenance
- [ ] Former l'Ã©quipe

---

## RÃ©sumÃ© des Concepts ClÃ©s

### Ce qu'il Faut Retenir

**1. Repmgr = SimplicitÃ© et EfficacitÃ©**
- Pas de dÃ©pendance externe (etcd/Consul)
- MÃ©tadonnÃ©es stockÃ©es dans PostgreSQL
- Outil idÃ©al pour les clusters de petite Ã  moyenne taille

**2. Composants Principaux**
- **repmgr** : CLI pour la gestion
- **repmgrd** : Daemon pour la surveillance et le failover automatique
- **Base repmgr** : Stockage des mÃ©tadonnÃ©es

**3. OpÃ©rations Essentielles**
- `standby clone` : Cloner un Standby
- `standby promote` : Promouvoir manuellement
- `standby switchover` : Basculement planifiÃ©
- `cluster show` : Ã‰tat du cluster

**4. Failover**
- Automatique possible avec `repmgrd`
- Witness recommandÃ© pour Ã©viter les faux positifs
- Pas de fencing automatique (Ã  gÃ©rer manuellement)

**5. Limites**
- Protection split-brain moins robuste que Patroni
- NÃ©cessite supervision humaine pour les grandes Ã©chelles
- Load balancing externe requis (HAProxy, PgBouncer)

---

## Pour Aller Plus Loin

Maintenant que vous comprenez Repmgr, vous pouvez explorer :

- **RÃ©plication Logique** : ComplÃ©mentaritÃ© avec la rÃ©plication physique
- **Backup avec pgBackRest** : IntÃ©gration avec Repmgr
- **Monitoring AvancÃ©** : Grafana dashboards pour Repmgr
- **Barman** : Backup et recovery manager compatible Repmgr
- **HAProxy Advanced** : Load balancing intelligent basÃ© sur les mÃ©triques

---

## Conclusion

Repmgr est une excellente solution pour gÃ©rer la haute disponibilitÃ© PostgreSQL de maniÃ¨re simple et efficace. Sa philosophie "Keep it simple" en fait un choix idÃ©al pour :

- Les Ã©quipes qui dÃ©butent avec la HA PostgreSQL
- Les clusters de petite Ã  moyenne taille
- Les environnements oÃ¹ la simplicitÃ© prime sur l'automatisation totale

**Points forts** :
- âœ… Installation et configuration simples
- âœ… Pas d'infrastructure externe Ã  maintenir
- âœ… Excellent pour cloner et gÃ©rer des Standby
- âœ… Switchover planifiÃ© trÃ¨s simple
- âœ… CoÃ»t total de possession faible

**Quand prÃ©fÃ©rer Patroni ?**
- Production ultra-critique (99.99%+ uptime)
- Clusters trÃ¨s complexes (10+ nÅ“uds)
- DÃ©ploiements Kubernetes
- NÃ©cessitÃ© de fencing automatique garanti

Repmgr reste une solution mature, stable et largement utilisÃ©e en production. Pour de nombreux cas d'usage, sa simplicitÃ© est un atout majeur qui compense largement ses limites par rapport Ã  des solutions plus complexes comme Patroni.

---

**Prochaine Ã©tape recommandÃ©e** : Comparer ces solutions de HA avec l'architecture globale dans la section 17.6 sur les architectures HA.

â­ï¸ [Architectures HA](/17-haute-disponibilite-et-replication/06-architectures-ha.md)
