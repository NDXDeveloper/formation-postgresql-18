üîù Retour au [Sommaire](/SOMMAIRE.md)

# 17.6.2. Quorum-based Commit

## Introduction

Dans la section pr√©c√©dente, nous avons vu que la r√©plication synchrone offre une protection maximale contre la perte de donn√©es, mais pr√©sente un risque majeur : **si votre unique serveur Standby synchrone tombe en panne, toutes vos √©critures sont bloqu√©es**. C'est ce qu'on appelle un "point de d√©faillance unique" (Single Point of Failure - SPOF).

Le **Quorum-based commit** (commit bas√© sur le quorum) est une solution √©l√©gante √† ce probl√®me. Au lieu d'attendre un seul serveur sp√©cifique, PostgreSQL attend la confirmation d'un **nombre minimum de serveurs parmi un groupe**. C'est comme dire : "Je veux que mes donn√©es soient pr√©sentes sur au moins 2 serveurs parmi mes 3 Standby, peu importe lesquels".

Cette approche offre le meilleur √©quilibre entre fiabilit√©, disponibilit√© et tol√©rance aux pannes.

---

## Qu'est-ce qu'un Quorum ? Analogie Simple

Imaginez que vous organisez une r√©union importante et que vous voulez prendre une d√©cision :

**Sans quorum (r√©plication synchrone classique) :**
- "La d√©cision n'est valid√©e QUE si Jean est pr√©sent"
- Probl√®me : Si Jean est malade, aucune d√©cision ne peut √™tre prise

**Avec quorum :**
- "La d√©cision est valid√©e si au moins 2 personnes parmi Jean, Marie et Paul sont pr√©sentes"
- Avantage : Si Jean est malade, Marie et Paul peuvent valider la d√©cision
- La r√©union peut continuer m√™me si quelqu'un est absent

C'est exactement le m√™me principe avec PostgreSQL : au lieu de d√©pendre d'un serveur unique, vous attendez qu'un **nombre minimum de serveurs** (le quorum) confirment avoir re√ßu les donn√©es.

---

## Le Probl√®me de la R√©plication Synchrone Classique

### Sc√©nario de d√©faillance

Reprenons l'architecture synchrone simple :

```
Primary ‚Üí Standby1 (synchrone)
```

**Que se passe-t-il si Standby1 tombe en panne ?**

1. Le Primary tente d'envoyer les modifications √† Standby1
2. Standby1 ne r√©pond pas
3. Le Primary **attend ind√©finiment** (comportement par d√©faut)
4. **Toutes les √©critures sont bloqu√©es** ‚ùå
5. Votre application est en panne

**Options de mitigation classiques :**

- **Intervention manuelle** : Un administrateur doit reconfigurer le Primary pour retirer Standby1 de la liste synchrone
- **Timeout** : Configurer un timeout apr√®s lequel le Primary abandonne (mais cela peut entra√Æner une perte de donn√©es)
- **Basculer en asynchrone** : Modifier `synchronous_commit` (mais on perd la garantie de r√©plication)

Aucune de ces solutions n'est id√©ale : elles n√©cessitent soit une intervention humaine, soit un compromis sur la fiabilit√©.

---

## Le Quorum-Based Commit : La Solution

### Principe de fonctionnement

Avec le quorum, vous configurez PostgreSQL ainsi :

```
Primary ‚Üí Standby1
       ‚Üí Standby2
       ‚Üí Standby3

Configuration : "ANY 2 (Standby1, Standby2, Standby3)"
```

**Signification :** Le Primary attend la confirmation d'**au moins 2 serveurs parmi les 3**, peu importe lesquels.

**Sc√©narios de fonctionnement :**

| √âtat des Standby | R√©sultat |
|------------------|----------|
| Standby1 ‚úÖ, Standby2 ‚úÖ, Standby3 ‚úÖ | Commit r√©ussi (3 confirmations) |
| Standby1 ‚úÖ, Standby2 ‚úÖ, Standby3 ‚ùå | Commit r√©ussi (2 confirmations) ‚úÖ |
| Standby1 ‚úÖ, Standby2 ‚ùå, Standby3 ‚úÖ | Commit r√©ussi (2 confirmations) ‚úÖ |
| Standby1 ‚ùå, Standby2 ‚úÖ, Standby3 ‚úÖ | Commit r√©ussi (2 confirmations) ‚úÖ |
| Standby1 ‚úÖ, Standby2 ‚ùå, Standby3 ‚ùå | Commit bloqu√© (1 seule confirmation) ‚ùå |

**Avantage majeur :** Un seul Standby en panne n'emp√™che plus les √©critures !

---

## Syntaxe de Configuration

PostgreSQL propose deux syntaxes pour d√©finir un quorum :

### 1. Syntaxe ANY (Quorum souple)

```conf
synchronous_standby_names = 'ANY N (liste_de_serveurs)'
```

**N** = Nombre minimum de serveurs qui doivent confirmer

**Exemple :**
```conf
synchronous_standby_names = 'ANY 2 (standby1, standby2, standby3)'
```
- Attend **au moins 2** confirmations parmi les 3 serveurs
- Peu importe lesquels

**Cas d'usage :** Haute disponibilit√© avec tol√©rance aux pannes

### 2. Syntaxe FIRST (Priorit√© stricte)

```conf
synchronous_standby_names = 'FIRST N (liste_de_serveurs)'
```

**N** = Nombre de serveurs dans l'ordre de priorit√©

**Exemple :**
```conf
synchronous_standby_names = 'FIRST 2 (standby1, standby2, standby3)'
```
- Attend les confirmations de **standby1 ET standby2** (les 2 premiers)
- standby3 n'est utilis√© que si standby1 ou standby2 tombe

**Cas d'usage :** Priorisation g√©ographique ou mat√©rielle

### 3. Syntaxe legacy (un seul serveur)

```conf
synchronous_standby_names = 'standby1'
```
- Attend uniquement standby1 (comportement classique)
- **Ne prot√®ge pas contre la panne du Standby**

---

## Comparaison des Syntaxes

### Exemple avec 3 Standby

```
Primary ‚Üí Standby1 (local, SSD rapide)
       ‚Üí Standby2 (local, SSD rapide)
       ‚Üí Standby3 (distant, HDD)
```

**Configuration ANY 2 :**
```conf
synchronous_standby_names = 'ANY 2 (standby1, standby2, standby3)'
```

**Comportement :**
- Si Standby1 et Standby2 r√©pondent vite ‚Üí Commit rapide ‚úÖ
- Si Standby1 est lent ‚Üí Primary utilise Standby2 et Standby3 ‚úÖ
- M√™me si Standby3 est lent, √ßa ne bloque pas si Standby1 et Standby2 r√©pondent

**Avantage :** Utilise toujours les serveurs les plus rapides disponibles

---

**Configuration FIRST 2 :**
```conf
synchronous_standby_names = 'FIRST 2 (standby1, standby2, standby3)'
```

**Comportement :**
- Primary attend **TOUJOURS** Standby1 ET Standby2
- Standby3 n'est jamais utilis√© tant que les deux premiers fonctionnent
- Si Standby1 tombe ‚Üí Primary attend Standby2 ET Standby3

**Avantage :** Contr√¥le pr√©cis de quels serveurs doivent √™tre synchrones (utile pour des raisons g√©ographiques)

---

## Calcul du Quorum : Trouver le Bon Nombre

### R√®gle de base : Majorit√©

Une r√®gle courante en syst√®mes distribu√©s est d'utiliser la **majorit√©** (plus de 50%) pour garantir la coh√©rence.

**Formule :** Quorum = (Nombre total de serveurs / 2) + 1

| Total serveurs | Quorum recommand√© | Tol√©rance aux pannes |
|----------------|-------------------|----------------------|
| 1 Primary + 1 Standby | 1 (= 100%) | 0 serveur |
| 1 Primary + 2 Standby | 2 (= 67%) | 1 serveur |
| 1 Primary + 3 Standby | 2 (= 50%) | 1 serveur |
| 1 Primary + 4 Standby | 3 (= 60%) | 1 serveur |
| 1 Primary + 5 Standby | 3 (= 50%) | 2 serveurs |

**Note importante :** Le Primary compte dans le total ! Avec 1 Primary + 2 Standby = 3 serveurs au total.

### Cas pratiques de dimensionnement

**Cas 1 : Architecture minimale haute disponibilit√©**
```
1 Primary + 2 Standby
Quorum = 2 (ANY 2)
Tol√©rance : 1 serveur en panne
```
‚úÖ Configuration minimale recommand√©e pour la production

**Cas 2 : Architecture multi-datacenter**
```
1 Primary (DC1) + 2 Standby (DC1) + 1 Standby (DC2)
Quorum = 2 (ANY 2)
Tol√©rance : 1 serveur + perte compl√®te du DC2
```
‚úÖ Protection g√©ographique avec performance pr√©serv√©e

**Cas 3 : Architecture haute disponibilit√© avanc√©e**
```
1 Primary + 4 Standby
Quorum = 3 (ANY 3)
Tol√©rance : 2 serveurs en panne simultan√©es
```
‚úÖ Niveau de protection maximum (pour applications critiques)

---

## Configuration Compl√®te : Exemple Pas √† Pas

### Architecture cible

```
Primary (production)
  ‚îú‚îÄ‚îÄ Standby1 (m√™me datacenter, r√©plication synchrone)
  ‚îú‚îÄ‚îÄ Standby2 (m√™me datacenter, r√©plication synchrone)
  ‚îî‚îÄ‚îÄ Standby3 (datacenter distant, r√©plication asynchrone)

Objectif : Quorum de 2 sur les Standby locaux
```

### √âtape 1 : Configuration sur le Primary

√âditez `postgresql.conf` sur le Primary :

```conf
# Activer la r√©plication
wal_level = replica
max_wal_senders = 10
wal_keep_size = 1GB

# Configuration du quorum synchrone
synchronous_standby_names = 'ANY 2 (standby1, standby2, standby3)'
synchronous_commit = on

# Param√®tres de s√©curit√©
max_replication_slots = 10
```

**Explication :**
- `synchronous_standby_names` : D√©finit le quorum (2 confirmations minimum)
- `synchronous_commit = on` : Active le mode synchrone
- Les 3 Standby sont list√©s, mais seuls 2 doivent confirmer

### √âtape 2 : Configuration sur les Standby

Sur **Standby1**, dans `postgresql.conf` :

```conf
# Mode Standby
hot_standby = on
primary_conninfo = 'host=primary_ip port=5432 user=replicator password=xxx application_name=standby1'
```

Sur **Standby2**, dans `postgresql.conf` :

```conf
hot_standby = on
primary_conninfo = 'host=primary_ip port=5432 user=replicator password=xxx application_name=standby2'
```

Sur **Standby3**, dans `postgresql.conf` :

```conf
hot_standby = on
primary_conninfo = 'host=primary_ip port=5432 user=replicator password=xxx application_name=standby3'
```

**Point crucial :** `application_name` doit correspondre aux noms dans `synchronous_standby_names` !

### √âtape 3 : Red√©marrage et v√©rification

```bash
# Sur le Primary
sudo systemctl restart postgresql

# V√©rifier la configuration
psql -U postgres -c "SHOW synchronous_standby_names;"
```

**R√©sultat attendu :**
```
 synchronous_standby_names
---------------------------
 ANY 2 (standby1, standby2, standby3)
```

### √âtape 4 : V√©rifier l'√©tat de la r√©plication

```sql
SELECT
    application_name,
    state,
    sync_state,
    sync_priority
FROM pg_stat_replication
ORDER BY sync_priority;
```

**R√©sultat attendu :**

| application_name | state | sync_state | sync_priority |
|------------------|-------|------------|---------------|
| standby1 | streaming | quorum | 1 |
| standby2 | streaming | quorum | 1 |
| standby3 | streaming | quorum | 1 |

**Note :** Avec `ANY`, tous les Standby ont la m√™me priorit√© (1). Le Primary choisit dynamiquement les 2 premiers qui r√©pondent.

---

## Surveillance et M√©triques

### V√©rifier le statut du quorum en temps r√©el

```sql
-- Vue compl√®te de l'√©tat de r√©plication
SELECT
    application_name,
    client_addr,
    state,
    sync_state,
    sync_priority,
    pg_wal_lsn_diff(pg_current_wal_lsn(), sent_lsn) AS send_lag_bytes,
    pg_wal_lsn_diff(sent_lsn, flush_lsn) AS flush_lag_bytes,
    pg_wal_lsn_diff(flush_lsn, replay_lsn) AS replay_lag_bytes,
    write_lag,
    flush_lag,
    replay_lag
FROM pg_stat_replication
ORDER BY sync_priority, application_name;
```

**Interpr√©tation :**

- **sync_state = 'quorum'** : Le Standby fait partie du quorum
- **sync_state = 'async'** : Le Standby est en mode asynchrone (si plus de serveurs que requis)
- **state = 'streaming'** : Le Standby re√ßoit activement les donn√©es
- **lag_* faibles** : La r√©plication est √† jour

### Alertes essentielles √† configurer

**Alerte 1 : Nombre de Standby synchrones insuffisant**

```sql
SELECT COUNT(*) AS standby_count
FROM pg_stat_replication
WHERE sync_state IN ('sync', 'quorum') AND state = 'streaming';
```

**Seuil d'alerte :** Si `standby_count < 2` (dans notre exemple avec quorum de 2)

**Action :** Intervention imm√©diate - risque de blocage des √©critures si un autre Standby tombe

---

**Alerte 2 : Lag de r√©plication √©lev√©**

```sql
SELECT
    application_name,
    EXTRACT(EPOCH FROM write_lag) AS write_lag_seconds
FROM pg_stat_replication
WHERE sync_state = 'quorum'
    AND write_lag > INTERVAL '5 seconds';
```

**Seuil d'alerte :** `write_lag > 5 secondes`

**Action :** V√©rifier la performance r√©seau et la charge du Standby

---

**Alerte 3 : D√©connexion d'un Standby quorum**

```sql
-- √Ä ex√©cuter r√©guli√®rement (via un monitoring externe)
SELECT COUNT(*) AS connected_quorum_standbys
FROM pg_stat_replication
WHERE sync_state = 'quorum';
```

**Seuil d'alerte :** Si le nombre descend en dessous du quorum configur√©

---

### Script de monitoring complet

Voici un script SQL √† ex√©cuter p√©riodiquement (ex: toutes les minutes) :

```sql
-- Monitoring complet du quorum
WITH quorum_config AS (
    SELECT current_setting('synchronous_standby_names') AS config
),
expected_quorum AS (
    -- Extraire le nombre du quorum (simplifi√©, suppose format ANY N)
    SELECT
        CASE
            WHEN config ~ 'ANY (\d+)'
            THEN (regexp_match(config, 'ANY (\d+)'))[1]::int
            ELSE 1
        END AS required_standbys
    FROM quorum_config
),
current_status AS (
    SELECT
        COUNT(*) FILTER (WHERE sync_state = 'quorum' AND state = 'streaming') AS active_quorum_standbys,
        COUNT(*) AS total_standbys,
        MAX(EXTRACT(EPOCH FROM write_lag)) AS max_lag_seconds
    FROM pg_stat_replication
)
SELECT
    cs.active_quorum_standbys,
    eq.required_standbys,
    cs.active_quorum_standbys >= eq.required_standbys AS quorum_healthy,
    cs.total_standbys,
    COALESCE(cs.max_lag_seconds, 0) AS max_lag_seconds,
    CASE
        WHEN cs.active_quorum_standbys < eq.required_standbys THEN 'CRITICAL - Quorum not met'
        WHEN cs.max_lag_seconds > 10 THEN 'WARNING - High replication lag'
        ELSE 'OK'
    END AS health_status
FROM current_status cs, expected_quorum eq;
```

**Exemple de r√©sultat :**

| active_quorum_standbys | required_standbys | quorum_healthy | total_standbys | max_lag_seconds | health_status |
|------------------------|-------------------|----------------|----------------|-----------------|---------------|
| 2 | 2 | true | 3 | 0.003 | OK |

---

## Sc√©narios de Panne et Comportement

### Sc√©nario 1 : Un Standby tombe (le plus courant)

**Situation :**
```
Primary ‚úÖ
Standby1 ‚ùå (panne)
Standby2 ‚úÖ
Standby3 ‚úÖ

Configuration : ANY 2
```

**Comportement :**
1. Le Primary d√©tecte que Standby1 ne r√©pond plus
2. Il continue d'attendre Standby2 et Standby3
3. Le quorum est toujours atteint (2 serveurs fonctionnels)
4. ‚úÖ Les √©critures continuent normalement
5. Pas d'intervention n√©cessaire

**Impact :** Aucun (c'est tout l'int√©r√™t du quorum !)

---

### Sc√©nario 2 : Deux Standby tombent simultan√©ment

**Situation :**
```
Primary ‚úÖ
Standby1 ‚ùå
Standby2 ‚ùå
Standby3 ‚úÖ

Configuration : ANY 2
```

**Comportement :**
1. Le Primary ne peut plus atteindre le quorum de 2
2. ‚ö†Ô∏è Toutes les √©critures se bloquent
3. Le Primary attend ind√©finiment (comportement par d√©faut)
4. Intervention humaine n√©cessaire

**Actions possibles :**
- **R√©parer rapidement** un des Standby en panne
- **R√©duire temporairement le quorum** :
  ```sql
  ALTER SYSTEM SET synchronous_standby_names = 'ANY 1 (standby1, standby2, standby3)';
  SELECT pg_reload_conf();
  ```
- **Passer en mode asynchrone temporairement** :
  ```sql
  ALTER SYSTEM SET synchronous_standby_names = '';
  SELECT pg_reload_conf();
  ```

---

### Sc√©nario 3 : Lag important sur un Standby

**Situation :**
```
Primary ‚úÖ
Standby1 ‚úÖ (lag: 2ms)
Standby2 ‚úÖ (lag: 2ms)
Standby3 ‚úÖ (lag: 500ms - r√©seau satur√©)

Configuration : ANY 2
```

**Comportement :**
1. Le Primary envoie les donn√©es aux 3 Standby
2. Standby1 et Standby2 r√©pondent en 2ms
3. Le quorum est atteint sans attendre Standby3
4. ‚úÖ Les √©critures ne sont pas ralenties par Standby3

**Avantage du ANY :** Le Primary utilise toujours les serveurs les plus rapides pour satisfaire le quorum

---

### Sc√©nario 4 : Maintenance planifi√©e

**Objectif :** Mettre Standby1 hors ligne pour maintenance

**Proc√©dure :**

1. **V√©rifier que le quorum peut √™tre maintenu :**
   ```sql
   -- Il doit y avoir au moins 3 Standby fonctionnels
   SELECT COUNT(*) FROM pg_stat_replication WHERE state = 'streaming';
   ```

2. **Arr√™ter Standby1 :**
   ```bash
   # Sur Standby1
   sudo systemctl stop postgresql
   ```

3. **V√©rifier que le quorum est toujours satisfait :**
   ```sql
   -- Sur le Primary
   SELECT * FROM pg_stat_replication;
   -- Doit afficher Standby2 et Standby3 en √©tat 'quorum'
   ```

4. **Effectuer la maintenance sur Standby1**

5. **Red√©marrer Standby1 :**
   ```bash
   sudo systemctl start postgresql
   ```

6. **V√©rifier la r√©int√©gration :**
   ```sql
   SELECT * FROM pg_stat_replication;
   -- Standby1 doit r√©appara√Ætre en √©tat 'quorum'
   ```

**Impact sur les utilisateurs :** Aucun, gr√¢ce au quorum !

---

## Avantages du Quorum-Based Commit

### ‚úÖ 1. Haute disponibilit√©

- Tol√©rance √† la panne d'un ou plusieurs Standby (selon le dimensionnement)
- Pas de point de d√©faillance unique
- Maintenance sans interruption de service

### ‚úÖ 2. Garantie de durabilit√©

- Les donn√©es valid√©es sont pr√©sentes sur au moins N serveurs
- Protection contre la perte de donn√©es m√™me en cas de pannes multiples
- RPO = 0 (aucune perte de transaction valid√©e)

### ‚úÖ 3. Performance optimale

- Utilisation automatique des serveurs les plus rapides
- Pas de ralentissement d√ª √† un Standby lent
- Latence = latence du Ni√®me serveur le plus rapide (et non du plus lent)

### ‚úÖ 4. Flexibilit√© op√©rationnelle

- Ajout/retrait de Standby sans interruption
- Maintenance simplifi√©e
- Scaling horizontal naturel

### ‚úÖ 5. R√©silience au r√©seau

- Un probl√®me r√©seau vers un Standby n'impacte pas les autres
- Tol√©rance aux micro-coupures
- Adaptation automatique aux conditions r√©seau

---

## Inconv√©nients et Limitations

### ‚ö†Ô∏è 1. Complexit√© op√©rationnelle accrue

- Configuration plus complexe qu'une r√©plication simple
- N√©cessite une surveillance plus sophistiqu√©e
- Plus de serveurs √† g√©rer

**Mitigation :** Utiliser des outils d'automatisation (Patroni, Ansible)

### ‚ö†Ô∏è 2. Co√ªt mat√©riel

- N√©cessite au minimum 3 serveurs (1 Primary + 2 Standby)
- Recommandation : 4 serveurs pour tol√©rer 1 panne (1 Primary + 3 Standby)

**Justification :** Le co√ªt est compens√© par la disponibilit√© et la protection des donn√©es

### ‚ö†Ô∏è 3. Impact performance selon le quorum

- Plus le quorum est √©lev√©, plus l'impact sur les performances est important
- Latence = celle du Ni√®me serveur le plus rapide (N = taille du quorum)

**Exemple :**
- Quorum de 2 avec lags [2ms, 3ms, 50ms] ‚Üí Latence = 3ms
- Quorum de 3 avec lags [2ms, 3ms, 50ms] ‚Üí Latence = 50ms

### ‚ö†Ô∏è 4. Pas de protection contre les erreurs logiques

- Si vous supprimez accidentellement des donn√©es, elles seront supprim√©es partout
- Le quorum ne prot√®ge que contre les pannes mat√©rielles
- N√©cessite des sauvegardes r√©guli√®res (backups)

---

## Cas d'Usage Recommand√©s

### ‚úÖ Cas 1 : Applications critiques multi-datacenter

**Architecture :**
```
DC1: 1 Primary + 2 Standby
DC2: 1 Standby
Configuration : ANY 2
```

**Avantages :**
- Protection locale contre les pannes (quorum dans DC1)
- Protection g√©ographique (Standby dans DC2)
- Performance optimale (quorum local)

---

### ‚úÖ Cas 2 : SaaS avec SLA √©lev√©

**Architecture :**
```
1 Primary + 3 Standby (m√™me r√©gion)
Configuration : ANY 2
```

**Avantages :**
- Garantie de disponibilit√© 99.99%
- Maintenance sans interruption
- Tol√©rance √† 1 panne serveur

---

### ‚úÖ Cas 3 : Finance / E-commerce

**Architecture :**
```
1 Primary + 4 Standby
Configuration : ANY 3
```

**Avantages :**
- Protection maximale (RPO = 0)
- Tol√©rance √† 2 pannes simultan√©es
- Conformit√© r√©glementaire

---

### ‚ùå Cas o√π le quorum n'est PAS recommand√©

**1. Petite application / Budget limit√©**
- Le co√ªt de 3+ serveurs n'est pas justifi√©
- Alternative : R√©plication asynchrone simple

**2. Infrastructure g√©ographiquement distribu√©e**
- Latence r√©seau trop √©lev√©e entre datacenters
- Alternative : Synchrone local + Asynchrone distant

**3. Tr√®s fort volume d'√©critures**
- L'impact performance du quorum peut √™tre probl√©matique
- Alternative : R√©plication asynchrone avec monitoring renforc√©

---

## Bonnes Pratiques

### üéØ Dimensionnement optimal

**R√®gle d'or :** Minimum 3 serveurs (1 Primary + 2 Standby) avec quorum = 2

**Recommandations par niveau de criticit√© :**

| Criticit√© | Configuration minimale | Quorum | Tol√©rance |
|-----------|------------------------|--------|-----------|
| Standard | 1 Primary + 2 Standby | ANY 2 | 1 panne |
| √âlev√©e | 1 Primary + 3 Standby | ANY 2 | 1 panne |
| Critique | 1 Primary + 4 Standby | ANY 3 | 2 pannes |

### üéØ Placement g√©ographique

**Architecture hybride recommand√©e :**
```
DC1 (Local):
  - Primary
  - Standby1
  - Standby2

DC2 (Distant):
  - Standby3 (asynchrone)

Configuration : ANY 2 (standby1, standby2, standby3)
```

**Astuce :** M√™me si Standby3 est list√© dans le quorum, il ne ralentira pas les commits car Standby1 et Standby2 r√©pondront toujours plus vite.

### üéØ Surveillance proactive

Configurez des alertes pour :
- Nombre de Standby actifs < quorum + 1
- Lag de r√©plication > seuil acceptable
- D√©connexion d'un Standby
- Espace disque faible (WAL accumulation)

### üéØ Tests r√©guliers

**Testez mensuellement :**
1. Arr√™t d'un Standby ‚Üí V√©rifier que le service continue
2. Arr√™t de deux Standby ‚Üí V√©rifier le comportement de blocage
3. Temps de r√©cup√©ration apr√®s r√©int√©gration d'un Standby

### üéØ Documentation

Documentez :
- La topologie compl√®te de r√©plication
- La proc√©dure de r√©duction temporaire du quorum (urgence)
- Les contacts et proc√©dures d'escalade
- Les runbooks de panne

---

## Migration vers le Quorum : Guide Pratique

### √âtape 1 : Ajouter des Standby suppl√©mentaires

Si vous avez actuellement 1 Primary + 1 Standby :

```bash
# Cr√©er une deuxi√®me replica
pg_basebackup -h primary_ip -D /var/lib/postgresql/14/main -U replicator -P -v -R -X stream
```

### √âtape 2 : V√©rifier la r√©plication

```sql
SELECT * FROM pg_stat_replication;
```

Attendez que tous les Standby soient en √©tat `streaming` et √† jour.

### √âtape 3 : Modifier la configuration

```sql
-- Sur le Primary
ALTER SYSTEM SET synchronous_standby_names = 'ANY 2 (standby1, standby2)';
SELECT pg_reload_conf();
```

### √âtape 4 : V√©rifier la nouvelle configuration

```sql
SHOW synchronous_standby_names;
SELECT application_name, sync_state FROM pg_stat_replication;
```

### √âtape 5 : Tester

```sql
-- Simuler une √©criture
INSERT INTO test_table VALUES (NOW());

-- V√©rifier qu'elle est bien r√©pliqu√©e
-- (sur les Standby)
SELECT * FROM test_table ORDER BY 1 DESC LIMIT 1;
```

### √âtape 6 : Tester la r√©silience

Arr√™tez un Standby et v√©rifiez que les √©critures continuent.

---

## Conclusion

Le **Quorum-based commit** est une √©volution majeure de la r√©plication synchrone dans PostgreSQL. Il offre le meilleur √©quilibre entre :

- **Fiabilit√©** : Aucune perte de donn√©es (RPO = 0)
- **Disponibilit√©** : Tol√©rance aux pannes de serveurs
- **Performance** : Utilisation des serveurs les plus rapides

**Points cl√©s √† retenir :**

1. ‚úÖ **ANY N** est g√©n√©ralement le meilleur choix (utilise les serveurs les plus rapides)
2. ‚úÖ **Minimum 3 serveurs** (1 Primary + 2 Standby) pour b√©n√©ficier du quorum
3. ‚úÖ **Surveillance essentielle** : Alerter si le nombre de Standby < quorum + 1
4. ‚úÖ **Testez r√©guli√®rement** les sc√©narios de panne
5. ‚úÖ **Documentez** votre architecture et vos proc√©dures

Le quorum transforme la r√©plication synchrone d'une solution fragile (avec point de d√©faillance unique) en une architecture v√©ritablement hautement disponible. C'est aujourd'hui la **configuration recommand√©e** pour toute application critique n√©cessitant une protection maximale contre la perte de donn√©es.

---

**Prochaine section :** 17.7. Monitoring avanc√© de la r√©plication

**Ressources compl√©mentaires :**
- Documentation officielle : [synchronous_standby_names](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-SYNCHRONOUS-STANDBY-NAMES)
- Section 17.2 : R√©plication Physique (Streaming Replication)
- Section 14 : Observabilit√© et Monitoring

‚è≠Ô∏è [Load balancing avec HAProxy ou PgPool-II](/17-haute-disponibilite-et-replication/06.3-load-balancing.md)
