ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 17.3.2. Cas d'Usage : Migrations et RÃ©plication SÃ©lective

## Introduction

La rÃ©plication logique PostgreSQL est un outil exceptionnellement polyvalent qui va bien au-delÃ  de la simple copie de donnÃ©es. Dans cette section, nous allons explorer deux cas d'usage majeurs qui dÃ©montrent toute la puissance et la flexibilitÃ© de ce mÃ©canisme :

1. **Les migrations de bases de donnÃ©es** : Comment dÃ©placer vos donnÃ©es d'un serveur Ã  un autre sans interruption de service
2. **La rÃ©plication sÃ©lective** : Comment ne rÃ©pliquer que les donnÃ©es pertinentes selon vos besoins mÃ©tier

Ces deux scÃ©narios sont parmi les plus frÃ©quents en production et illustrent parfaitement pourquoi la rÃ©plication logique est devenue un standard de l'industrie.

---

## Partie 1 : Migrations de Bases de DonnÃ©es

### Qu'est-ce qu'une Migration de Base de DonnÃ©es ?

Une **migration de base de donnÃ©es** consiste Ã  transfÃ©rer une base de donnÃ©es d'un environnement Ã  un autre. Cela peut Ãªtre :
- D'un serveur physique vers le cloud
- D'une version PostgreSQL ancienne vers une version plus rÃ©cente
- D'un data center vers un autre
- D'un fournisseur cloud vers un autre
- D'une architecture on-premise vers un SaaS managÃ©

### Le DÃ©fi des Migrations Traditionnelles

#### Approche "Stop-and-Copy" (Ancienne MÃ©thode)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ArrÃªter l'application                    â”‚  âŒ Downtime
â”‚ 2. Faire un dump de la base (pg_dump)       â”‚  â±ï¸ Plusieurs heures
â”‚ 3. TransfÃ©rer le dump vers le nouveau       â”‚  â±ï¸ DÃ©pend de la bande passante
â”‚ 4. Restaurer sur le nouveau serveur         â”‚  â±ï¸ Plusieurs heures
â”‚ 5. VÃ©rifier l'intÃ©gritÃ©                     â”‚  â±ï¸ Quelques minutes
â”‚ 6. RedÃ©marrer l'application                 â”‚  âœ… Service restaurÃ©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total downtime : De quelques heures Ã  plusieurs jours pour de trÃ¨s grandes bases
```

**ProblÃ¨mes** :
- âŒ Interruption de service prolongÃ©e
- âŒ Risque Ã©levÃ© en cas d'Ã©chec (retour en arriÃ¨re complexe)
- âŒ Stress pour les Ã©quipes (migration en "big bang")
- âŒ Perte de revenus pendant l'interruption
- âŒ ExpÃ©rience utilisateur dÃ©gradÃ©e

### La Solution : Migration avec RÃ©plication Logique (Zero-Downtime)

La rÃ©plication logique permet une approche progressive et sans interruption de service :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1 : PrÃ©paration (serveur opÃ©rationnel)â”‚
â”‚ - Configurer la rÃ©plication                 â”‚
â”‚ - Copie initiale des donnÃ©es                â”‚
â”‚                                             â”‚
â”‚ Phase 2 : Synchronisation (serveur opÃ©r.)   â”‚
â”‚ - RÃ©plication continue                      â”‚
â”‚ - Les deux serveurs restent synchronisÃ©s    â”‚
â”‚                                             â”‚
â”‚ Phase 3 : Bascule (downtime : secondes)     â”‚
â”‚ - Rediriger l'application                   â”‚
â”‚ - VÃ©rification rapide                       â”‚
â”‚                                             â”‚
â”‚ Phase 4 : Validation et nettoyage           â”‚
â”‚ - Surveillance du nouveau serveur           â”‚
â”‚ - Suppression de la rÃ©plication             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total downtime : Quelques secondes Ã  quelques minutes maximum
```

### Cas d'Usage 1 : Migration Cloud avec Zero-Downtime

#### ScÃ©nario RÃ©el

**Contexte** :
- Entreprise e-commerce avec 50 000 commandes/jour
- Base PostgreSQL 15 sur serveur physique (2 To de donnÃ©es)
- Migration vers AWS RDS PostgreSQL 18
- Contrainte : interruption de service < 5 minutes

#### Architecture de Migration

```
                    Phase 1-2 : RÃ©plication Active
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                           â”‚
â”‚  [Serveur On-Premise]                [AWS RDS]            â”‚
â”‚   PostgreSQL 15                      PostgreSQL 18        â”‚
â”‚   Base : ecommerce                   Base : ecommerce     â”‚
â”‚                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚ Tables     â”‚â”€â”€â”€â”€ Publication â”€â”€>â”‚ Tables     â”‚        â”‚
â”‚   â”‚ (Source)   â”‚                    â”‚ (RÃ©plica)  â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚        â–²                                                  â”‚
â”‚        â”‚                                                  â”‚
â”‚   [Application]                                           â”‚
â”‚   (Ã‰crit/Lit ici)                                         â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    Phase 3 : AprÃ¨s Bascule
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                           â”‚
â”‚  [Serveur On-Premise]                [AWS RDS]            â”‚
â”‚   PostgreSQL 15                      PostgreSQL 18        â”‚
â”‚   (sera dÃ©sactivÃ©)                   Base : ecommerce     â”‚
â”‚                                                           â”‚
â”‚                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                      â”‚ Tables     â”‚       â”‚
â”‚                                      â”‚ (Master)   â”‚       â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â–²               â”‚
â”‚                                           â”‚               â”‚
â”‚                                      [Application]        â”‚
â”‚                                      (Ã‰crit/Lit ici)      â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Ã‰tape par Ã‰tape : Migration ComplÃ¨te

##### Ã‰tape 1 : PrÃ©paration du Serveur Source (On-Premise)

```sql
-- 1.1. Connexion au serveur source
psql -h serveur-onpremise.local -U postgres -d ecommerce

-- 1.2. VÃ©rification et ajustement de la configuration
-- Dans postgresql.conf (redÃ©marrage requis si modifications nÃ©cessaires)
ALTER SYSTEM SET wal_level = 'logical';
ALTER SYSTEM SET max_replication_slots = 5;
ALTER SYSTEM SET max_wal_senders = 5;

-- RedÃ©marrer PostgreSQL si nÃ©cessaire
-- sudo systemctl restart postgresql

-- 1.3. CrÃ©ation d'un utilisateur dÃ©diÃ© Ã  la rÃ©plication
CREATE ROLE replication_user WITH LOGIN PASSWORD 'secure_password_2024' REPLICATION;

-- 1.4. Accorder les permissions sur toutes les tables nÃ©cessaires
GRANT SELECT ON ALL TABLES IN SCHEMA public TO replication_user;
GRANT USAGE ON SCHEMA public TO replication_user;

-- 1.5. Configurer pg_hba.conf pour autoriser la connexion depuis AWS
-- Ajouter une ligne (adapter l'IP en fonction de votre VPN/VPC)
-- host    ecommerce    replication_user    10.0.0.0/8    scram-sha-256

-- 1.6. Recharger la configuration
SELECT pg_reload_conf();

-- 1.7. CrÃ©er la publication pour toutes les tables
CREATE PUBLICATION pub_migration FOR ALL TABLES;

-- Alternative : publication sÃ©lective si toutes les tables ne sont pas nÃ©cessaires
-- CREATE PUBLICATION pub_migration FOR TABLE commandes, produits, clients, inventaire;

-- 1.8. VÃ©rification
SELECT * FROM pg_publication WHERE pubname = 'pub_migration';
SELECT * FROM pg_publication_tables WHERE pubname = 'pub_migration';
```

##### Ã‰tape 2 : PrÃ©paration du Serveur Destination (AWS RDS)

```sql
-- 2.1. Connexion au serveur AWS RDS
psql -h ecommerce.abc123.us-east-1.rds.amazonaws.com -U postgres -d ecommerce

-- 2.2. CrÃ©er la structure de base (schÃ©ma)
-- Option A : Restaurer un dump sans donnÃ©es
-- pg_dump -h serveur-onpremise.local -U postgres -d ecommerce --schema-only > schema.sql
-- psql -h ecommerce.abc123.us-east-1.rds.amazonaws.com -U postgres -d ecommerce -f schema.sql

-- Option B : Utiliser un outil de migration de schÃ©ma
-- Option C : Scripts DDL manuels

-- 2.3. VÃ©rifier que toutes les tables ont des clÃ©s primaires
SELECT
    schemaname,
    tablename
FROM pg_tables
WHERE schemaname = 'public'
AND tablename NOT IN (
    SELECT tablename
    FROM pg_indexes
    WHERE indexdef LIKE '%PRIMARY KEY%'
);

-- Si des tables n'ont pas de PK, en ajouter :
-- ALTER TABLE ma_table ADD PRIMARY KEY (id);

-- 2.4. Ajuster les paramÃ¨tres pour optimiser la rÃ©plication initiale
ALTER SYSTEM SET max_logical_replication_workers = 8;
ALTER SYSTEM SET max_sync_workers_per_subscription = 4;

-- Sur RDS, appliquer immÃ©diatement :
SELECT pg_reload_conf();
```

##### Ã‰tape 3 : CrÃ©ation de la Subscription et Copie Initiale

```sql
-- 3.1. Toujours sur le serveur AWS RDS
-- CrÃ©er la subscription (la copie initiale va dÃ©marrer automatiquement)
CREATE SUBSCRIPTION sub_migration
CONNECTION 'host=serveur-onpremise.local port=5432 dbname=ecommerce user=replication_user password=secure_password_2024 sslmode=require'
PUBLICATION pub_migration
WITH (
    copy_data = true,           -- Copier les donnÃ©es existantes
    create_slot = true,         -- CrÃ©er automatiquement le slot
    enabled = true,             -- Activer immÃ©diatement
    slot_name = 'sub_migration_slot'
);

-- 3.2. Surveiller la progression de la copie initiale
SELECT
    subname,
    pid,
    relid::regclass AS table_name,
    phase,
    received_lsn,
    last_msg_receipt_time
FROM pg_stat_subscription
JOIN pg_subscription_rel ON pg_subscription.oid = pg_subscription_rel.srsubid
WHERE subname = 'sub_migration';

-- 3.3. VÃ©rifier l'Ã©tat global
SELECT
    subname,
    pid,
    received_lsn,
    latest_end_lsn,
    last_msg_receipt_time
FROM pg_stat_subscription;

-- Phase 'i' = initializing (copie initiale en cours)
-- Phase 'r' = replicating (rÃ©plication continue active)
-- Phase 'd' = data is being copied (copie de table spÃ©cifique)
-- Phase 's' = synchronized (synchronisÃ©)
```

##### Ã‰tape 4 : Surveillance de la Synchronisation (Phase Cruciale)

```sql
-- 4.1. Surveiller le lag de rÃ©plication (sur AWS RDS)
SELECT
    subname,
    pg_size_pretty(
        pg_wal_lsn_diff(latest_end_lsn, received_lsn)
    ) AS replication_lag_bytes,
    latest_end_time - last_msg_receipt_time AS time_lag
FROM pg_stat_subscription
WHERE subname = 'sub_migration';

-- 4.2. VÃ©rifier le slot de rÃ©plication (sur serveur source)
SELECT
    slot_name,
    database,
    active,
    restart_lsn,
    confirmed_flush_lsn,
    pg_size_pretty(
        pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)
    ) AS retained_wal_size
FROM pg_replication_slots
WHERE slot_name = 'sub_migration_slot';

-- 4.3. Compter les lignes pour vÃ©rification (les deux serveurs)
-- Sur source :
SELECT 'commandes' AS table_name, COUNT(*) FROM commandes
UNION ALL
SELECT 'produits', COUNT(*) FROM produits
UNION ALL
SELECT 'clients', COUNT(*) FROM clients;

-- Sur destination (mÃªme requÃªte) :
-- Les nombres doivent converger et devenir identiques

-- 4.4. CrÃ©er un script de monitoring automatique (exemple bash)
-- Sauvegarder dans monitor_replication.sh :
```

```bash
#!/bin/bash
# monitor_replication.sh - Surveiller le lag de rÃ©plication

DEST_HOST="ecommerce.abc123.us-east-1.rds.amazonaws.com"
DEST_USER="postgres"
DEST_DB="ecommerce"

while true; do
    echo "=== $(date) ==="

    psql -h $DEST_HOST -U $DEST_USER -d $DEST_DB -t -c "
        SELECT
            'Lag: ' || COALESCE(
                pg_size_pretty(pg_wal_lsn_diff(latest_end_lsn, received_lsn)),
                '0 bytes'
            ) AS lag,
            'Last received: ' || last_msg_receipt_time
        FROM pg_stat_subscription
        WHERE subname = 'sub_migration';
    "

    sleep 10
done
```

```sql
-- 4.5. CritÃ¨re de validation : lag < 1 MB et stable
-- Une fois ce critÃ¨re atteint, la migration peut Ãªtre planifiÃ©e
```

##### Ã‰tape 5 : Planification de la Bascule (Cutover)

**Checklist Pre-Bascule** :

```
â–¡ Le lag de rÃ©plication est infÃ©rieur Ã  1 MB
â–¡ La rÃ©plication est stable depuis au moins 24 heures
â–¡ Les comptages de lignes sont identiques
â–¡ Les Ã©quipes sont informÃ©es et disponibles
â–¡ Un plan de rollback est documentÃ©
â–¡ Les scripts de bascule sont testÃ©s en staging
â–¡ Une fenÃªtre de maintenance est planifiÃ©e (mÃªme si courte)
â–¡ Les sauvegardes sont Ã  jour sur les deux serveurs
â–¡ Les endpoints DNS/Load Balancer sont prÃ©parÃ©s
â–¡ Les paramÃ¨tres de connexion applicatifs sont prÃªts
```

##### Ã‰tape 6 : ExÃ©cution de la Bascule (D-Day)

**Timeline de Bascule (Exemple : FenÃªtre de 23h00 Ã  23h15)** :

```
T-15 min (22h45) : Notification aux utilisateurs
â”œâ”€ "Maintenance planifiÃ©e dans 15 minutes"
â”œâ”€ DerniÃ¨re vÃ©rification du lag

T-5 min (22h55) : PrÃ©paration finale
â”œâ”€ Mode lecture seule sur l'application (optionnel)
â”œâ”€ DerniÃ¨re vÃ©rification lag < 100 KB

T-0 (23h00) : DÃ‰BUT DE LA BASCULE
â”œâ”€ 23h00:00 â†’ Passer l'application en mode maintenance
â”œâ”€ 23h00:30 â†’ Attendre que les transactions en cours se terminent
â”œâ”€ 23h01:00 â†’ VÃ©rifier que le lag est Ã  0

T+1 min (23h01) : ArrÃªt de la rÃ©plication
â”œâ”€ Sur AWS RDS : ALTER SUBSCRIPTION sub_migration DISABLE;
â”œâ”€ Sur Source : VÃ©rifier qu'aucune nouvelle transaction n'arrive

T+2 min (23h02) : Validation finale des donnÃ©es
â”œâ”€ Comptage des lignes (automatisÃ©)
â”œâ”€ VÃ©rification d'intÃ©gritÃ© rÃ©fÃ©rentielle
â”œâ”€ Tests de requÃªtes critiques

T+3 min (23h03) : Reconfiguration applicative
â”œâ”€ Changer la chaÃ®ne de connexion vers AWS RDS
â”œâ”€ RedÃ©marrer les services applicatifs

T+5 min (23h05) : Tests de validation
â”œâ”€ Test de connexion
â”œâ”€ Test d'Ã©criture (INSERT test)
â”œâ”€ Test de lecture (SELECT test)
â”œâ”€ Test des APIs critiques

T+7 min (23h07) : Mise en production
â”œâ”€ Retirer le mode maintenance
â”œâ”€ Activer le monitoring renforcÃ©
â”œâ”€ Surveillance des logs applicatifs

T+10 min (23h10) : Validation post-bascule
â”œâ”€ VÃ©rifier les mÃ©triques (connexions, CPU, I/O)
â”œâ”€ Tester les fonctionnalitÃ©s critiques
â”œâ”€ Confirmer avec les Ã©quipes mÃ©tier

T+15 min (23h15) : FIN DE LA FENÃŠTRE
â””â”€ Migration terminÃ©e avec succÃ¨s
```

**Scripts SQL de Bascule** :

```sql
-- SCRIPT 1 : Sur AWS RDS - DÃ©sactivation de la subscription
-- Ã€ exÃ©cuter Ã  T+1 min
ALTER SUBSCRIPTION sub_migration DISABLE;

-- SCRIPT 2 : Validation des donnÃ©es (sur AWS RDS)
-- Comptage automatisÃ©
DO $$
DECLARE
    source_count BIGINT;
    dest_count BIGINT;
    table_rec RECORD;
BEGIN
    FOR table_rec IN
        SELECT tablename
        FROM pg_tables
        WHERE schemaname = 'public'
    LOOP
        EXECUTE format('SELECT COUNT(*) FROM %I', table_rec.tablename) INTO dest_count;
        RAISE NOTICE 'Table % : % rows', table_rec.tablename, dest_count;
    END LOOP;
END $$;

-- SCRIPT 3 : Test d'Ã©criture (sur AWS RDS)
-- VÃ©rifier que les Ã©critures fonctionnent
CREATE TABLE test_write_check (
    id SERIAL PRIMARY KEY,
    test_time TIMESTAMP DEFAULT NOW(),
    test_data TEXT
);

INSERT INTO test_write_check (test_data) VALUES ('Migration test - Ã©criture OK');
SELECT * FROM test_write_check;
DROP TABLE test_write_check;

-- SCRIPT 4 : VÃ©rification de l'intÃ©gritÃ© rÃ©fÃ©rentielle
SELECT
    conname AS constraint_name,
    conrelid::regclass AS table_name,
    confrelid::regclass AS referenced_table
FROM pg_constraint
WHERE contype = 'f';
-- Toutes les contraintes FK doivent Ãªtre intactes
```

##### Ã‰tape 7 : Surveillance Post-Bascule

```sql
-- 7.1. Monitoring des performances (premiÃ¨res 24 heures)
-- Sur AWS RDS

-- ActivitÃ© des connexions
SELECT
    count(*) AS active_connections,
    state,
    wait_event_type
FROM pg_stat_activity
WHERE datname = 'ecommerce'
GROUP BY state, wait_event_type;

-- Cache hit ratio (doit Ãªtre > 95%)
SELECT
    sum(heap_blks_hit) / nullif(sum(heap_blks_hit + heap_blks_read), 0) * 100 AS cache_hit_ratio
FROM pg_statio_user_tables;

-- RequÃªtes lentes (nÃ©cessite pg_stat_statements)
SELECT
    query,
    calls,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- 7.2. Alertes Ã  configurer
-- - CPU > 70% pendant > 5 minutes
-- - Connexions actives > 80% de max_connections
-- - Cache hit ratio < 90%
-- - Slow queries > 1 seconde
-- - Disk space < 20%
```

##### Ã‰tape 8 : Nettoyage et DÃ©sactivation de l'Ancien Serveur

```sql
-- 8.1. AprÃ¨s validation complÃ¨te (J+7), nettoyer la rÃ©plication

-- Sur AWS RDS (destination) :
DROP SUBSCRIPTION sub_migration;

-- Sur serveur source (on-premise) :
DROP PUBLICATION pub_migration;

-- Supprimer le slot de rÃ©plication (si pas auto-supprimÃ©)
SELECT pg_drop_replication_slot('sub_migration_slot');

-- 8.2. Archivage de l'ancien serveur
-- - Conserver pendant 30 jours minimum
-- - Faire un backup final complet
-- - Documenter pour audit
-- - Planifier dÃ©sactivation dÃ©finitive
```

##### Plan de Rollback (En Cas de ProblÃ¨me)

**Si la bascule Ã©choue pendant la fenÃªtre** :

```sql
-- OPTION 1 : Retour immÃ©diat vers le serveur source
-- 1. Reconfigurer l'application vers serveur-onpremise.local
-- 2. Retirer le mode maintenance
-- 3. Analyser la cause du problÃ¨me
-- 4. Replanifier la migration

-- OPTION 2 : Si des Ã©critures ont eu lieu sur AWS RDS
-- Cette situation est plus complexe et nÃ©cessite une rÃ©plication inverse

-- Sur l'ancien serveur source (on-premise) :
CREATE SUBSCRIPTION sub_rollback
CONNECTION 'host=ecommerce.abc123.us-east-1.rds.amazonaws.com ...'
PUBLICATION pub_rollback;  -- Ã€ crÃ©er sur AWS

-- Attention : Risque de conflits de donnÃ©es !
-- Analyser soigneusement avant de fusionner
```

### Cas d'Usage 2 : Migration entre Versions PostgreSQL

#### ScÃ©nario : PostgreSQL 13 â†’ PostgreSQL 18

**Contexte** :
- Base de production sur PostgreSQL 13 (fin de support en 2025)
- Migration vers PostgreSQL 18 requise
- ImpossibilitÃ© d'utiliser `pg_upgrade` en raison de l'architecture distribuÃ©e

**Avantages de la rÃ©plication logique pour ce cas** :

- âœ… **Migration progressive** : Tester PostgreSQL 18 avec vos donnÃ©es rÃ©elles avant la bascule
- âœ… **Validation des performances** : Comparer les plans d'exÃ©cution entre versions
- âœ… **CompatibilitÃ© applicative** : Tester l'application contre PG18 en parallÃ¨le
- âœ… **Rollback facile** : Retour instantanÃ© vers PG13 en cas de problÃ¨me

**Points d'Attention SpÃ©cifiques** :

```sql
-- 1. VÃ©rifier les changements incompatibles entre versions
-- Consulter les release notes PostgreSQL 14, 15, 16, 17, 18

-- 2. Tester les extensions
-- Certaines extensions peuvent ne pas Ãªtre disponibles en PG18
SELECT name, default_version, installed_version
FROM pg_available_extensions
WHERE installed_version IS NOT NULL;

-- 3. Analyser les deprecated features
-- Par exemple : L'authentification md5 est dÃ©prÃ©ciÃ©e, utiliser scram-sha-256

-- 4. Valider les performances
-- CrÃ©er des benchmarks avant/aprÃ¨s avec pgbench ou des requÃªtes rÃ©elles
```

---

## Partie 2 : RÃ©plication SÃ©lective

### Qu'est-ce que la RÃ©plication SÃ©lective ?

La **rÃ©plication sÃ©lective** consiste Ã  ne rÃ©pliquer qu'une partie des donnÃ©es d'une base vers une autre, selon des critÃ¨res prÃ©cis :
- Certaines tables seulement
- Certaines colonnes d'une table
- Certaines lignes selon un filtre WHERE
- Certaines opÃ©rations (INSERT mais pas DELETE)

Cette approche est essentielle pour :
- Respecter les contraintes de conformitÃ© (RGPD, HIPAA, etc.)
- Optimiser les coÃ»ts (ne stocker que ce qui est nÃ©cessaire)
- AmÃ©liorer les performances (rÃ©duire le volume de donnÃ©es)
- CrÃ©er des environnements spÃ©cialisÃ©s (analytics, reporting, dev)

### Cas d'Usage 3 : SÃ©paration OLTP / OLAP

#### ScÃ©nario : Base de Reporting DÃ©diÃ©e

**Contexte** :
- Base OLTP : PostgreSQL en production avec transactions intensives
- Besoin : Une base OLAP pour analytics et Business Intelligence
- Contrainte : Ne pas impacter les performances de production

**Architecture** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BASE DE PRODUCTION                     â”‚
â”‚                        (OLTP)                             â”‚
â”‚   - Transactions en temps rÃ©el                            â”‚
â”‚   - Ã‰critures frÃ©quentes                                  â”‚
â”‚   - DonnÃ©es opÃ©rationnelles                               â”‚
â”‚                                                           â”‚
â”‚   Tables :                                                â”‚
â”‚   â”œâ”€ commandes (toutes colonnes)                          â”‚
â”‚   â”œâ”€ clients (toutes colonnes)                            â”‚
â”‚   â”œâ”€ produits (toutes colonnes)                           â”‚
â”‚   â”œâ”€ logs_audit (NON rÃ©pliquÃ©)                            â”‚
â”‚   â”œâ”€ sessions_temp (NON rÃ©pliquÃ©)                         â”‚
â”‚   â””â”€ cache_redis (NON rÃ©pliquÃ©)                           â”‚
â”‚                                                           â”‚
â”‚        â”‚                                                  â”‚
â”‚        â”‚ Publication SÃ©lective                            â”‚
â”‚        â”‚ (tables opÃ©rationnelles uniquement)              â”‚
â”‚        â–¼                                                  â”‚
â”‚                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚        RÃ©plication Logique             â”‚              â”‚
â”‚   â”‚  (async, sans impact sur production)   â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                           â”‚
â”‚        â–¼                                                  â”‚
â”‚                                                           â”‚
â”‚                  BASE DE REPORTING                        â”‚
â”‚                       (OLAP)                              â”‚
â”‚   - AgrÃ©gations lourdes                                   â”‚
â”‚   - Lectures complexes                                    â”‚
â”‚   - Historisation longue                                  â”‚
â”‚                                                           â”‚
â”‚   Tables :                                                â”‚
â”‚   â”œâ”€ commandes (rÃ©pliquÃ©es)                               â”‚
â”‚   â”œâ”€ clients (rÃ©pliquÃ©es)                                 â”‚
â”‚   â”œâ”€ produits (rÃ©pliquÃ©es)                                â”‚
â”‚   â”œâ”€ vues_materialisees (locales)                         â”‚
â”‚   â”œâ”€ agregations (locales)                                â”‚
â”‚   â””â”€ cubes_olap (locaux)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ImplÃ©mentation** :

```sql
-- ===== SUR LA BASE DE PRODUCTION (OLTP) =====

-- 1. CrÃ©er une publication sÃ©lective (seulement les tables mÃ©tier)
CREATE PUBLICATION pub_reporting
FOR TABLE
    commandes,
    clients,
    produits,
    categories,
    paiements
WITH (publish = 'insert, update');  -- Pas de DELETE pour conserver l'historique

-- Note : Les tables logs_audit, sessions_temp ne sont PAS dans la publication

-- 2. VÃ©rifier la publication
SELECT * FROM pg_publication_tables WHERE pubname = 'pub_reporting';


-- ===== SUR LA BASE DE REPORTING (OLAP) =====

-- 1. CrÃ©er le mÃªme schÃ©ma (seulement les tables nÃ©cessaires)
-- Les tables peuvent avoir des index diffÃ©rents, optimisÃ©s pour le reporting

CREATE TABLE commandes (
    id SERIAL PRIMARY KEY,
    client_id INT NOT NULL,
    date_commande TIMESTAMP NOT NULL,
    montant_total NUMERIC(10,2),
    statut VARCHAR(50),
    -- Index optimisÃ© pour analytics
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_commandes_date ON commandes(date_commande);
CREATE INDEX idx_commandes_client ON commandes(client_id);
CREATE INDEX idx_commandes_created ON commandes(created_at);

-- RÃ©pÃ©ter pour autres tables...

-- 2. CrÃ©er la subscription
CREATE SUBSCRIPTION sub_reporting
CONNECTION 'host=prod-db.example.com port=5432 dbname=production user=replication_user password=xxx sslmode=require'
PUBLICATION pub_reporting
WITH (
    copy_data = true,
    synchronous_commit = 'off'  -- Async pour ne pas ralentir la prod
);

-- 3. CrÃ©er des vues matÃ©rialisÃ©es pour l'analytics (local uniquement)
CREATE MATERIALIZED VIEW mv_ventes_par_jour AS
SELECT
    DATE(date_commande) AS jour,
    COUNT(*) AS nombre_commandes,
    SUM(montant_total) AS ca_jour,
    AVG(montant_total) AS panier_moyen
FROM commandes
WHERE statut = 'payee'
GROUP BY DATE(date_commande);

CREATE INDEX ON mv_ventes_par_jour(jour);

-- RafraÃ®chir pÃ©riodiquement (via cron ou pg_cron)
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_ventes_par_jour;
```

**Avantages de cette Architecture** :

- âœ… **Isolation des charges** : Les requÃªtes analytics n'impactent pas la production
- âœ… **Optimisation diffÃ©renciÃ©e** : Index et structures adaptÃ©s Ã  chaque usage
- âœ… **FlexibilitÃ©** : PossibilitÃ© d'agrÃ©ger, transformer, archiver cÃ´tÃ© OLAP
- âœ… **CoÃ»t optimisÃ©** : Le serveur OLAP peut Ãªtre dimensionnÃ© diffÃ©remment

### Cas d'Usage 4 : RÃ©plication GÃ©ographique avec Filtrage

#### ScÃ©nario : Application Multi-RÃ©gions

**Contexte** :
- Application SaaS mondiale
- Chaque rÃ©gion ne doit voir que ses propres donnÃ©es (conformitÃ© RGPD)
- Base centrale + bases rÃ©gionales

**Architecture** :

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   BASE CENTRALE     â”‚
                    â”‚   (Toutes rÃ©gions)  â”‚
                    â”‚                     â”‚
                    â”‚  Table: commandes   â”‚
                    â”‚  - id               â”‚
                    â”‚  - client_id        â”‚
                    â”‚  - region: 'EU'/'US'â”‚
                    â”‚  - montant          â”‚
                    â”‚  - ...              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ Publications avec WHERE
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼              â–¼              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  BASE EU   â”‚  â”‚  BASE US   â”‚  â”‚  BASE APAC â”‚
     â”‚  (Europe)  â”‚  â”‚ (AmÃ©rique) â”‚  â”‚   (Asie)   â”‚
     â”‚            â”‚  â”‚            â”‚  â”‚            â”‚
     â”‚ Seulement  â”‚  â”‚ Seulement  â”‚  â”‚ Seulement  â”‚
     â”‚ region='EU'â”‚  â”‚ region='US'â”‚  â”‚region='APACâ”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ImplÃ©mentation avec Row-Level Filtering** :

```sql
-- ===== SUR LA BASE CENTRALE =====

-- 1. Publication pour l'Europe (avec filtre WHERE)
CREATE PUBLICATION pub_europe
FOR TABLE commandes WHERE (region = 'EU'),
         clients WHERE (region = 'EU'),
         produits;  -- Tous les produits dans toutes les rÃ©gions

-- 2. Publication pour les USA
CREATE PUBLICATION pub_usa
FOR TABLE commandes WHERE (region = 'US'),
         clients WHERE (region = 'US'),
         produits;

-- 3. Publication pour l'Asie-Pacifique
CREATE PUBLICATION pub_apac
FOR TABLE commandes WHERE (region = 'APAC'),
         clients WHERE (region = 'APAC'),
         produits;

-- VÃ©rification
SELECT
    pubname,
    schemaname,
    tablename,
    rowfilter
FROM pg_publication_tables
WHERE pubname LIKE 'pub_%';


-- ===== SUR CHAQUE BASE RÃ‰GIONALE =====

-- Base Europe :
CREATE SUBSCRIPTION sub_europe
CONNECTION 'host=central-db.example.com ...'
PUBLICATION pub_europe;

-- Base USA :
CREATE SUBSCRIPTION sub_usa
CONNECTION 'host=central-db.example.com ...'
PUBLICATION pub_usa;

-- Base APAC :
CREATE SUBSCRIPTION sub_apac
CONNECTION 'host=central-db.example.com ...'
PUBLICATION pub_apac;
```

**Validation du Filtrage** :

```sql
-- Sur la base centrale :
SELECT region, COUNT(*) FROM commandes GROUP BY region;
-- RÃ©sultat :
--  region | count
-- --------+-------
--  EU     | 15000
--  US     | 22000
--  APAC   | 8000

-- Sur la base Europe :
SELECT region, COUNT(*) FROM commandes GROUP BY region;
-- RÃ©sultat :
--  region | count
-- --------+-------
--  EU     | 15000
-- âœ… Seulement les donnÃ©es europÃ©ennes !

-- Sur la base USA :
SELECT region, COUNT(*) FROM commandes GROUP BY region;
-- RÃ©sultat :
--  region | count
-- --------+-------
--  US     | 22000
-- âœ… Seulement les donnÃ©es amÃ©ricaines !
```

### Cas d'Usage 5 : RÃ©plication Partielle pour Environnement de DÃ©veloppement

#### ScÃ©nario : Environnement de Dev avec DonnÃ©es RÃ©elles AnonymisÃ©es

**Contexte** :
- Les dÃ©veloppeurs ont besoin de donnÃ©es rÃ©alistes
- ImpossibilitÃ© de copier toute la production (trop volumineuse + donnÃ©es sensibles)
- Solution : RÃ©plication sÃ©lective + anonymisation

**ImplÃ©mentation** :

```sql
-- ===== SUR LA BASE DE PRODUCTION =====

-- 1. CrÃ©er une publication sans colonnes sensibles
CREATE PUBLICATION pub_dev_safe
FOR TABLE
    commandes (id, date_commande, montant_total, statut),  -- Sans adresse livraison
    produits,  -- Table complÃ¨te (pas de donnÃ©es sensibles)
    categories;

-- 2. Exclure les tables sensibles
-- clients, paiements, logs_audit ne sont PAS dans la publication


-- ===== SUR LA BASE DE DÃ‰VELOPPEMENT =====

-- 1. CrÃ©er les tables avec structure identique
CREATE TABLE commandes (
    id INT PRIMARY KEY,
    date_commande TIMESTAMP,
    montant_total NUMERIC(10,2),
    statut VARCHAR(50),
    -- colonnes sensibles absentes
    created_at TIMESTAMP DEFAULT NOW()
);

-- 2. CrÃ©er la subscription avec limitation du volume
CREATE SUBSCRIPTION sub_dev
CONNECTION 'host=prod-db.example.com ...'
PUBLICATION pub_dev_safe
WITH (
    copy_data = true,
    synchronous_commit = 'off'
);

-- 3. Anonymiser les donnÃ©es aprÃ¨s copie initiale (si nÃ©cessaire)
-- Exemple : Remplacer les emails par des fakes
UPDATE clients
SET email = 'user' || id || '@example.com'
WHERE email NOT LIKE '%@example.com';

-- 4. Limiter la rÃ©tention des donnÃ©es (purge pÃ©riodique)
-- Via un CRON job ou pg_cron
DELETE FROM commandes
WHERE date_commande < NOW() - INTERVAL '90 days';
```

### Cas d'Usage 6 : RÃ©plication avec Transformation de Colonnes

#### ScÃ©nario : Anonymisation Ã  la VolÃ©e

**ProblÃ©matique** :
- Besoin de rÃ©pliquer des donnÃ©es pour analytics
- Certaines colonnes doivent Ãªtre anonymisÃ©es (RGPD)

**Solution : Utiliser des Triggers CÃ´tÃ© Destination** :

```sql
-- ===== SUR LA BASE DE DESTINATION (ANALYTICS) =====

-- 1. Tables crÃ©Ã©es avec colonnes identiques
CREATE TABLE clients (
    id INT PRIMARY KEY,
    nom VARCHAR(100),
    prenom VARCHAR(100),
    email VARCHAR(200),
    telephone VARCHAR(20),
    adresse TEXT,
    ville VARCHAR(100),
    code_postal VARCHAR(10),
    created_at TIMESTAMP
);

-- 2. CrÃ©er un trigger d'anonymisation
CREATE OR REPLACE FUNCTION anonymize_pii()
RETURNS TRIGGER AS $$
BEGIN
    -- Anonymiser les donnÃ©es personnelles
    NEW.nom := 'CLIENT_' || NEW.id;
    NEW.prenom := 'ANONYME';
    NEW.email := 'anonyme' || NEW.id || '@example.com';
    NEW.telephone := '0600000000';
    NEW.adresse := 'Adresse anonymisÃ©e';

    -- Conserver ville et code postal pour analytics gÃ©ographiques
    -- (pas de donnÃ©es personnelles identifiables)

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- 3. Attacher le trigger
CREATE TRIGGER trg_anonymize_clients
BEFORE INSERT OR UPDATE ON clients
FOR EACH ROW
EXECUTE FUNCTION anonymize_pii();

-- 4. CrÃ©er la subscription (les donnÃ©es seront auto-anonymisÃ©es)
CREATE SUBSCRIPTION sub_analytics_anonymized
CONNECTION 'host=prod-db.example.com ...'
PUBLICATION pub_clients;

-- Test : Les donnÃ©es insÃ©rÃ©es sont automatiquement anonymisÃ©es
SELECT id, nom, prenom, email, ville FROM clients LIMIT 5;
-- RÃ©sultat :
--  id  |    nom     |  prenom  |          email           |   ville
-- -----+------------+----------+--------------------------+-----------
--  1   | CLIENT_1   | ANONYME  | anonyme1@example.com     | Paris
--  2   | CLIENT_2   | ANONYME  | anonyme2@example.com     | Lyon
```

### Cas d'Usage 7 : RÃ©plication Multi-Sources (Consolidation)

#### ScÃ©nario : AgrÃ©gation de DonnÃ©es depuis Plusieurs Bases

**Contexte** :
- Plusieurs filiales avec leurs propres bases PostgreSQL
- Besoin d'agrÃ©ger toutes les donnÃ©es dans une base centrale pour reporting

**Architecture** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FILIALE A   â”‚   â”‚  FILIALE B   â”‚   â”‚  FILIALE C   â”‚
â”‚  (Region 1)  â”‚   â”‚  (Region 2)  â”‚   â”‚  (Region 3)  â”‚
â”‚              â”‚   â”‚              â”‚   â”‚              â”‚
â”‚  Commandes   â”‚   â”‚  Commandes   â”‚   â”‚  Commandes   â”‚
â”‚  Clients     â”‚   â”‚  Clients     â”‚   â”‚  Clients     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â”‚ Publication      â”‚ Publication      â”‚ Publication
       â”‚                  â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  BASE CENTRALE â”‚
                 â”‚   (Reporting)  â”‚
                 â”‚                â”‚
                 â”‚  3 Subscriptions
                 â”‚                â”‚
                 â”‚  commandes_a   â”‚
                 â”‚  commandes_b   â”‚
                 â”‚  commandes_c   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ImplÃ©mentation** :

```sql
-- ===== SUR CHAQUE BASE FILIALE (A, B, C) =====

-- Filiale A :
CREATE PUBLICATION pub_filiale_a FOR TABLE commandes, clients;

-- Filiale B :
CREATE PUBLICATION pub_filiale_b FOR TABLE commandes, clients;

-- Filiale C :
CREATE PUBLICATION pub_filiale_c FOR TABLE commandes, clients;


-- ===== SUR LA BASE CENTRALE =====

-- 1. CrÃ©er des tables distinctes par source (pour Ã©viter les conflits de PK)
CREATE TABLE commandes_filiale_a (
    LIKE commandes INCLUDING ALL,
    source_filiale VARCHAR(10) DEFAULT 'A'
);

CREATE TABLE commandes_filiale_b (
    LIKE commandes INCLUDING ALL,
    source_filiale VARCHAR(10) DEFAULT 'B'
);

CREATE TABLE commandes_filiale_c (
    LIKE commandes INCLUDING ALL,
    source_filiale VARCHAR(10) DEFAULT 'C'
);

-- 2. CrÃ©er les subscriptions
CREATE SUBSCRIPTION sub_filiale_a
CONNECTION 'host=filiale-a.example.com ...'
PUBLICATION pub_filiale_a;

CREATE SUBSCRIPTION sub_filiale_b
CONNECTION 'host=filiale-b.example.com ...'
PUBLICATION pub_filiale_b;

CREATE SUBSCRIPTION sub_filiale_c
CONNECTION 'host=filiale-c.example.com ...'
PUBLICATION pub_filiale_c;

-- 3. CrÃ©er une vue unifiÃ©e pour le reporting
CREATE VIEW commandes_toutes_filiales AS
SELECT *, 'A' AS filiale FROM commandes_filiale_a
UNION ALL
SELECT *, 'B' AS filiale FROM commandes_filiale_b
UNION ALL
SELECT *, 'C' AS filiale FROM commandes_filiale_c;

-- 4. RequÃªtes analytics sur la vue unifiÃ©e
SELECT
    filiale,
    COUNT(*) AS nombre_commandes,
    SUM(montant_total) AS ca_total
FROM commandes_toutes_filiales
GROUP BY filiale;
```

---

## Partie 3 : Bonnes Pratiques et PiÃ¨ges Ã  Ã‰viter

### Bonnes Pratiques pour les Migrations

#### 1. Planification

âœ… **Faire un dry-run complet** :
- Tester la migration sur une copie de production
- ChronomÃ©trer chaque Ã©tape
- Documenter les problÃ¨mes rencontrÃ©s

âœ… **PrÃ©parer un runbook dÃ©taillÃ©** :
- SÃ©quence exacte des commandes
- Scripts SQL prÃªts Ã  l'exÃ©cution
- NumÃ©ros de tÃ©lÃ©phone des personnes-clÃ©s
- Plan de rollback clair

âœ… **Communiquer largement** :
- Informer les parties prenantes
- PrÃ©voir une fenÃªtre de maintenance (mÃªme si courte)
- Avoir une personne de chaque Ã©quipe disponible

#### 2. Validation

âœ… **Valider la copie initiale** :
```sql
-- Script de validation automatique
DO $$
DECLARE
    table_rec RECORD;
    source_count BIGINT;
    dest_count BIGINT;
BEGIN
    FOR table_rec IN
        SELECT tablename
        FROM pg_tables
        WHERE schemaname = 'public'
    LOOP
        -- Compter sur source (via dblink ou script externe)
        -- Compter sur destination
        EXECUTE format('SELECT COUNT(*) FROM %I', table_rec.tablename) INTO dest_count;

        -- Comparer et logger
        RAISE NOTICE 'Table %: % rows', table_rec.tablename, dest_count;
    END LOOP;
END $$;
```

âœ… **Tester les performances** :
```sql
-- Comparer les plans d'exÃ©cution critiques
EXPLAIN (ANALYZE, BUFFERS)
SELECT ... FROM ... WHERE ...;

-- ExÃ©cuter sur les deux serveurs et comparer
```

#### 3. Monitoring

âœ… **Surveiller pendant et aprÃ¨s** :
- Lag de rÃ©plication
- Utilisation CPU/RAM/Disque
- Connexions actives
- Slow queries
- Erreurs dans les logs

### PiÃ¨ges Ã  Ã‰viter

#### âŒ PiÃ¨ge 1 : Oublier les SÃ©quences

**ProblÃ¨me** :
Les sÃ©quences ne sont pas rÃ©pliquÃ©es automatiquement. Si le serveur destination gÃ©nÃ¨re des IDs, vous aurez des conflits.

**Solution** :
```sql
-- AprÃ¨s la bascule, synchroniser les sÃ©quences
SELECT setval('commandes_id_seq', (SELECT MAX(id) FROM commandes));
SELECT setval('clients_id_seq', (SELECT MAX(id) FROM clients));
-- RÃ©pÃ©ter pour toutes les sÃ©quences
```

#### âŒ PiÃ¨ge 2 : DDL Non RÃ©pliquÃ©s

**ProblÃ¨me** :
Les changements de schÃ©ma (ALTER TABLE, CREATE INDEX) ne sont pas rÃ©pliquÃ©s.

**Solution** :
- Appliquer manuellement les DDL sur les deux serveurs
- Documenter tous les changements de schÃ©ma
- Utiliser un outil de migration de schÃ©ma (Flyway, Liquibase)

```sql
-- ProcÃ©dure recommandÃ©e pour un ALTER TABLE en production :
-- 1. Appliquer sur le serveur destination AVANT la bascule
-- 2. Appliquer sur le serveur source
-- 3. Attendre la synchronisation
-- 4. ProcÃ©der Ã  la bascule
```

#### âŒ PiÃ¨ge 3 : Slots de RÃ©plication qui Grossissent

**ProblÃ¨me** :
Si une subscription est arrÃªtÃ©e, le slot continue de retenir le WAL, risquant de saturer le disque.

**Solution** :
```sql
-- Surveiller rÃ©guliÃ¨rement
SELECT
    slot_name,
    pg_size_pretty(
        pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)
    ) AS retained_wal
FROM pg_replication_slots;

-- Supprimer les slots inutilisÃ©s
SELECT pg_drop_replication_slot('slot_name');
```

#### âŒ PiÃ¨ge 4 : Conflits de ClÃ©s Primaires

**ProblÃ¨me** :
Si les deux serveurs gÃ©nÃ¨rent des ID simultanÃ©ment, vous aurez des conflits.

**Solution** :
```sql
-- Option 1 : Utiliser des plages d'ID distinctes
-- Serveur A : 1-1000000000
ALTER SEQUENCE commandes_id_seq RESTART WITH 1 INCREMENT BY 2;

-- Serveur B : 2-1000000001
ALTER SEQUENCE commandes_id_seq RESTART WITH 2 INCREMENT BY 2;

-- Option 2 : Utiliser UUID au lieu d'ID sÃ©quentiels
CREATE TABLE commandes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    ...
);

-- Option 3 (PostgreSQL 18) : Utiliser UUIDv7 (triÃ© temporellement)
CREATE TABLE commandes (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v7(),
    ...
);
```

#### âŒ PiÃ¨ge 5 : NÃ©gliger les Extensions

**ProblÃ¨me** :
Les extensions doivent Ãªtre installÃ©es sur le serveur destination AVANT la rÃ©plication.

**Solution** :
```sql
-- Lister les extensions sur le source
SELECT * FROM pg_extension;

-- Installer sur la destination (avant la subscription)
CREATE EXTENSION IF NOT EXISTS postgis;
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
CREATE EXTENSION IF NOT EXISTS pg_trgm;
```

### Checklist de Migration (RÃ©capitulatif)

**Phase PrÃ©paration** :
```
â–¡ Analyser la base source (taille, volume, structure)
â–¡ Dimensionner le serveur destination
â–¡ Tester la migration sur un environnement de staging
â–¡ PrÃ©parer les scripts SQL
â–¡ Documenter le runbook
â–¡ Configurer le monitoring
â–¡ Former les Ã©quipes
â–¡ Planifier une fenÃªtre de maintenance
```

**Phase ExÃ©cution** :
```
â–¡ CrÃ©er la publication sur le source
â–¡ CrÃ©er les structures sur la destination
â–¡ CrÃ©er la subscription
â–¡ Surveiller la copie initiale
â–¡ Attendre la synchronisation (lag < 1 MB)
â–¡ Valider les donnÃ©es
â–¡ Effectuer la bascule
â–¡ Tester les fonctionnalitÃ©s critiques
â–¡ Activer le monitoring renforcÃ©
```

**Phase Post-Migration** :
```
â–¡ Surveiller les performances (24-48h)
â–¡ Valider avec les Ã©quipes mÃ©tier
â–¡ Documenter les incidents/rÃ©solutions
â–¡ Nettoyer la rÃ©plication (aprÃ¨s validation)
â–¡ Archiver l'ancien serveur
â–¡ Mise Ã  jour de la documentation
```

---

## Conclusion

La rÃ©plication logique PostgreSQL, grÃ¢ce aux mÃ©canismes de **publications** et **subscriptions**, offre une flexibilitÃ© inÃ©galÃ©e pour :

1. **Migrer** des bases de donnÃ©es sans interruption de service
2. **RÃ©pliquer sÃ©lectivement** exactement les donnÃ©es nÃ©cessaires
3. **CrÃ©er des architectures distribuÃ©es** adaptÃ©es Ã  chaque besoin mÃ©tier
4. **Respecter les contraintes rÃ©glementaires** (RGPD, localisation des donnÃ©es)
5. **Optimiser les coÃ»ts** en ne rÃ©pliquant que l'essentiel

Les cas d'usage prÃ©sentÃ©s montrent que la rÃ©plication logique n'est pas qu'un outil de haute disponibilitÃ© : c'est une **brique fondamentale** des architectures modernes, permettant de concilier performance, flexibilitÃ© et conformitÃ©.

### Points ClÃ©s Ã  Retenir

- ğŸ“Œ **Migrations Zero-Downtime** = La rÃ©plication logique permet des migrations avec seulement quelques secondes d'interruption
- ğŸ“Œ **SÃ©lectivitÃ© Fine** = Filtrage par table, colonne, ligne (WHERE), opÃ©ration
- ğŸ“Œ **CompatibilitÃ© Multi-Versions** = Possible entre PostgreSQL 13 et 18
- ğŸ“Œ **Planification Essentielle** = Une migration rÃ©ussie repose sur une prÃ©paration minutieuse
- ğŸ“Œ **Monitoring Continu** = Surveiller le lag, les slots, les performances
- ğŸ“Œ **Rollback PrÃ©parÃ©** = Toujours avoir un plan B documentÃ©

---


â­ï¸ [Limitations et considÃ©rations](/17-haute-disponibilite-et-replication/03.3-limitations-considerations.md)
