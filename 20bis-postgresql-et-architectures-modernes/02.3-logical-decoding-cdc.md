üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20bis.2.3 ‚Äî Logical Decoding et Change Data Capture (CDC)

## Introduction

Dans les chapitres pr√©c√©dents, nous avons explor√© deux m√©canismes pour propager les changements de donn√©es :

- **Event Store** : Stocker explicitement les √©v√©nements m√©tier
- **NOTIFY/LISTEN** : Notifications temps r√©el via triggers

Mais que faire si vous souhaitez capturer **tous les changements** d'une base existante, sans modifier les applications qui y √©crivent ? Comment synchroniser une base PostgreSQL avec Elasticsearch, Kafka, ou un data warehouse, de mani√®re fiable et en temps r√©el ?

C'est l√† qu'interviennent le **Logical Decoding** et le **Change Data Capture (CDC)**. Ces technologies permettent de "lire" le journal de transactions de PostgreSQL et de transformer chaque modification en √©v√©nement exploitable.

Ce chapitre vous apprendra √† capturer les changements de votre base PostgreSQL et √† les diffuser vers d'autres syst√®mes.

---

## Qu'est-ce que le Change Data Capture ?

### D√©finition

Le **Change Data Capture (CDC)** est une technique qui consiste √† identifier et capturer les modifications apport√©es aux donn√©es d'une base de donn√©es, puis √† livrer ces changements √† un syst√®me cible en temps r√©el.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CHANGE DATA CAPTURE (CDC)                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Application  ‚îÇ          ‚îÇ              ‚îÇ          ‚îÇ   Syst√®mes   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Source     ‚îÇ          ‚îÇ     CDC      ‚îÇ          ‚îÇ    Cibles    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ   Pipeline   ‚îÇ          ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  INSERT ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ          ‚îÇ              ‚îÇ          ‚îÇ Elasticsearch‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  UPDATE ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Capture ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Kafka        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  DELETE ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ          ‚îÇ  Transform   ‚îÇ          ‚îÇ Data Lake    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ  Deliver     ‚îÇ          ‚îÇ Analytics    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ        Source                   CDC                      Sink           ‚îÇ
‚îÇ       (PostgreSQL)           (Debezium)              (Consumers)        ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Les Approches Traditionnelles et Leurs Limites

Avant le CDC, plusieurs approches √©taient utilis√©es pour synchroniser les donn√©es :

| Approche | Principe | Limites |
|----------|----------|---------|
| **Polling** | Requ√™ter p√©riodiquement les changements | Latence, charge sur la base, colonnes updated_at requises |
| **Triggers applicatifs** | √âcrire dans une table d'audit via triggers | Overhead sur chaque √©criture, couplage |
| **Dual Write** | L'application √©crit dans deux syst√®mes | Risque d'incoh√©rence, complexit√© applicative |
| **ETL batch** | Export/import p√©riodique complet | Tr√®s haute latence (heures), co√ªteux en ressources |

### L'Avantage du CDC Bas√© sur les Logs

Le CDC moderne lit directement le **journal de transactions** (WAL) de la base de donn√©es :

| Avantage | Description |
|----------|-------------|
| **Non intrusif** | Aucune modification de l'application source |
| **Temps r√©el** | Latence de l'ordre de la seconde |
| **Complet** | Capture TOUTES les modifications (INSERT, UPDATE, DELETE) |
| **Faible impact** | Lecture du WAL, pas de requ√™tes suppl√©mentaires |
| **Fiable** | Bas√© sur le journal de transactions, rien n'est perdu |
| **Ordonn√©** | L'ordre des op√©rations est pr√©serv√© |

---

## Le WAL : Le C≈ìur du Syst√®me

### Qu'est-ce que le WAL ?

Le **Write-Ahead Log (WAL)** est le journal de transactions de PostgreSQL. Chaque modification de donn√©es est d'abord √©crite dans le WAL avant d'√™tre appliqu√©e aux fichiers de donn√©es.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          PostgreSQL                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ   Transaction                                                           ‚îÇ
‚îÇ       ‚îÇ                                                                 ‚îÇ
‚îÇ       ‚ñº                                                                 ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ   ‚îÇ                      WAL (Write-Ahead Log)                    ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ                                                               ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ LSN ‚îÇ ‚îÇ LSN ‚îÇ ‚îÇ LSN ‚îÇ ‚îÇ LSN ‚îÇ ‚îÇ LSN ‚îÇ ‚îÇ LSN ‚îÇ ‚îÇ LSN ‚îÇ      ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ  1  ‚îÇ ‚îÇ  2  ‚îÇ ‚îÇ  3  ‚îÇ ‚îÇ  4  ‚îÇ ‚îÇ  5  ‚îÇ ‚îÇ  6  ‚îÇ ‚îÇ  7  ‚îÇ      ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ     ‚îÇ       ‚îÇ       ‚îÇ       ‚îÇ       ‚îÇ       ‚îÇ       ‚îÇ         ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ  INSERT  UPDATE  DELETE  INSERT  UPDATE  COMMIT  INSERT       ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ  user    order   item    order   user            product      ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ                                                               ‚îÇ     ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                              ‚îÇ                                          ‚îÇ
‚îÇ                              ‚ñº                                          ‚îÇ
‚îÇ                    Fichiers de donn√©es                                  ‚îÇ
‚îÇ                    (tables, index)                                      ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

LSN = Log Sequence Number (position dans le WAL)
```

### Pourquoi le WAL est Id√©al pour le CDC

| Caract√©ristique | B√©n√©fice pour le CDC |
|-----------------|---------------------|
| **S√©quentiel** | Ordre des √©v√©nements garanti |
| **Durable** | Aucune perte de donn√©es apr√®s commit |
| **Complet** | Contient toutes les modifications |
| **Performant** | Lecture s√©quentielle efficace |
| **Ind√©pendant** | Pas d'impact sur les requ√™tes applicatives |

---

## Logical Decoding : Transformer le WAL en √âv√©nements

### Principe

Le **Logical Decoding** est la fonctionnalit√© PostgreSQL qui permet de d√©coder le contenu du WAL en changements logiques compr√©hensibles (lignes ins√©r√©es, mises √† jour, supprim√©es).

```
WAL Physique                    Logical Decoding                √âv√©nements
(bytes bruts)                   (d√©codage)                      (lisibles)

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 0x1A2B3C...    ‚îÇ              ‚îÇ                ‚îÇ              ‚îÇ INSERT INTO    ‚îÇ
‚îÇ page 42        ‚îÇ     ‚îÄ‚îÄ‚îÄ‚ñ∫     ‚îÇ   Plugin de    ‚îÇ     ‚îÄ‚îÄ‚îÄ‚ñ∫     ‚îÇ users (id, name‚îÇ
‚îÇ offset 128     ‚îÇ              ‚îÇ   d√©codage     ‚îÇ              ‚îÇ VALUES (1,     ‚îÇ
‚îÇ tuple data...  ‚îÇ              ‚îÇ   (wal2json,   ‚îÇ              ‚îÇ 'Alice')       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ   pgoutput)    ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Les Composants Cl√©s

#### 1. Slots de R√©plication

Un **slot de r√©plication** est un pointeur qui suit la position de lecture dans le WAL. Il garantit que PostgreSQL conserve les segments WAL tant qu'ils n'ont pas √©t√© consomm√©s.

```sql
-- Cr√©er un slot de r√©plication logique
SELECT pg_create_logical_replication_slot(
    'my_slot',      -- Nom du slot
    'pgoutput'      -- Plugin de d√©codage
);

-- Lister les slots existants
SELECT slot_name, plugin, slot_type, active, restart_lsn
FROM pg_replication_slots;

-- Supprimer un slot
SELECT pg_drop_replication_slot('my_slot');
```

#### 2. Plugins de D√©codage

Les **output plugins** transforment les donn√©es WAL en format lisible :

| Plugin | Format | Usage |
|--------|--------|-------|
| **pgoutput** | Protocole binaire PostgreSQL | R√©plication logique native, Debezium |
| **wal2json** | JSON | Int√©gration simple, debugging |
| **test_decoding** | Texte simple | Tests et d√©monstrations |
| **decoderbufs** | Protocol Buffers | Haute performance |

#### 3. Publications

Les **publications** d√©finissent quelles tables sont incluses dans la r√©plication logique :

```sql
-- Publication pour toutes les tables
CREATE PUBLICATION my_publication FOR ALL TABLES;

-- Publication pour des tables sp√©cifiques
CREATE PUBLICATION orders_pub FOR TABLE orders, order_items;

-- Publication avec filtrage des op√©rations
CREATE PUBLICATION inserts_only FOR TABLE audit_log
    WITH (publish = 'insert');  -- Seulement les INSERT
```

---

## Configuration de PostgreSQL pour le CDC

### √âtape 1 : Param√®tres postgresql.conf

```ini
# Activer la r√©plication logique
wal_level = logical

# Nombre maximum de slots de r√©plication
max_replication_slots = 10

# Nombre maximum de processus WAL sender
max_wal_senders = 10

# Conserver le WAL pour le d√©codage (optionnel mais recommand√©)
wal_keep_size = 1GB
```

Apr√®s modification, red√©marrez PostgreSQL :

```bash
sudo systemctl restart postgresql
```

### √âtape 2 : V√©rifier la Configuration

```sql
-- V√©rifier wal_level
SHOW wal_level;
-- Doit retourner 'logical'

-- V√©rifier les slots disponibles
SHOW max_replication_slots;

-- V√©rifier les WAL senders
SHOW max_wal_senders;
```

### √âtape 3 : Configurer les Permissions

```sql
-- Cr√©er un utilisateur d√©di√© √† la r√©plication
CREATE USER cdc_user WITH REPLICATION LOGIN PASSWORD 'secure_password';

-- Donner les droits de lecture sur les tables
GRANT SELECT ON ALL TABLES IN SCHEMA public TO cdc_user;

-- Donner les droits sur le sch√©ma
GRANT USAGE ON SCHEMA public TO cdc_user;
```

Dans `pg_hba.conf`, autoriser la connexion de r√©plication :

```
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    replication     cdc_user        10.0.0.0/8              scram-sha-256
host    mydb            cdc_user        10.0.0.0/8              scram-sha-256
```

---

## Utilisation du Logical Decoding

### Test avec test_decoding

Le plugin `test_decoding` est parfait pour comprendre le fonctionnement :

```sql
-- Cr√©er un slot avec test_decoding
SELECT pg_create_logical_replication_slot('test_slot', 'test_decoding');

-- Cr√©er une table de test
CREATE TABLE customers (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255)
);

-- Ins√©rer des donn√©es
INSERT INTO customers (name, email) VALUES ('Alice', 'alice@example.com');
INSERT INTO customers (name, email) VALUES ('Bob', 'bob@example.com');
UPDATE customers SET email = 'alice.new@example.com' WHERE id = 1;
DELETE FROM customers WHERE id = 2;

-- Lire les changements du slot
SELECT * FROM pg_logical_slot_get_changes(
    'test_slot',    -- Nom du slot
    NULL,           -- LSN de d√©part (NULL = depuis le d√©but)
    NULL            -- Nombre max de changements (NULL = tous)
);
```

R√©sultat :

```
    lsn     |   xid   |                          data
------------+---------+---------------------------------------------------------
 0/16B5D80  |     734 | BEGIN 734
 0/16B5D80  |     734 | table public.customers: INSERT: id[integer]:1 name[...
 0/16B5E48  |     734 | COMMIT 734
 0/16B5E80  |     735 | BEGIN 735
 0/16B5E80  |     735 | table public.customers: INSERT: id[integer]:2 name[...
 0/16B5F18  |     735 | COMMIT 735
 0/16B5F50  |     736 | BEGIN 736
 0/16B5F50  |     736 | table public.customers: UPDATE: id[integer]:1 name[...
 0/16B6018  |     736 | COMMIT 736
 0/16B6050  |     737 | BEGIN 737
 0/16B6050  |     737 | table public.customers: DELETE: id[integer]:2
 0/16B60B8  |     737 | COMMIT 737
```

### Diff√©rence entre get_changes et peek_changes

```sql
-- peek_changes : Lit sans consommer (le pointeur ne bouge pas)
SELECT * FROM pg_logical_slot_peek_changes('test_slot', NULL, NULL);
-- Appeler plusieurs fois retourne les m√™mes donn√©es

-- get_changes : Lit ET consomme (le pointeur avance)
SELECT * FROM pg_logical_slot_get_changes('test_slot', NULL, NULL);
-- Appeler √† nouveau retourne les NOUVEAUX changements uniquement
```

---

## wal2json : Format JSON pour le CDC

### Installation

```bash
# Debian/Ubuntu
sudo apt-get install postgresql-16-wal2json

# RHEL/CentOS
sudo yum install wal2json_16

# Ou compilation depuis les sources
git clone https://github.com/eulerto/wal2json.git
cd wal2json
make
sudo make install
```

### Utilisation

```sql
-- Cr√©er un slot avec wal2json
SELECT pg_create_logical_replication_slot('json_slot', 'wal2json');

-- Ins√©rer des donn√©es
INSERT INTO customers (name, email) VALUES ('Charlie', 'charlie@example.com');
UPDATE customers SET name = 'Charles' WHERE id = 3;

-- Lire les changements en JSON
SELECT * FROM pg_logical_slot_get_changes(
    'json_slot',
    NULL,
    NULL,
    'include-timestamp', 'true',
    'include-lsn', 'true'
);
```

R√©sultat JSON :

```json
{
  "change": [
    {
      "kind": "insert",
      "schema": "public",
      "table": "customers",
      "columnnames": ["id", "name", "email"],
      "columntypes": ["integer", "character varying(100)", "character varying(255)"],
      "columnvalues": [3, "Charlie", "charlie@example.com"],
      "timestamp": "2025-01-15 10:30:00.123456+00",
      "lsn": "0/16B6150"
    }
  ]
}
```

### Options de Configuration wal2json

```sql
SELECT * FROM pg_logical_slot_get_changes(
    'json_slot',
    NULL,
    NULL,
    -- Options disponibles
    'include-timestamp', 'true',      -- Inclure le timestamp
    'include-lsn', 'true',            -- Inclure le LSN
    'include-xids', 'true',           -- Inclure l'ID de transaction
    'include-schemas', 'true',        -- Inclure le sch√©ma
    'include-types', 'true',          -- Inclure les types de colonnes
    'include-type-oids', 'false',     -- Inclure les OIDs des types
    'include-not-null', 'true',       -- Inclure l'info NOT NULL
    'pretty-print', 'true',           -- JSON format√©
    'write-in-chunks', 'false',       -- √âcriture par morceaux
    'filter-tables', 'public.logs',   -- Exclure certaines tables
    'add-tables', 'public.customers'  -- Inclure seulement certaines tables
);
```

---

## Debezium : CDC pour la Production

### Qu'est-ce que Debezium ?

**Debezium** est une plateforme CDC open-source qui capture les changements de bases de donn√©es et les diffuse vers Apache Kafka. C'est la solution de r√©f√©rence pour le CDC en production.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Architecture Debezium                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ     ‚îÇ              ‚îÇ     ‚îÇ                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Debezium   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ      Apache Kafka        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ     ‚îÇ  Connector   ‚îÇ     ‚îÇ                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Source)    ‚îÇ     ‚îÇ              ‚îÇ     ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ Topic: dbserver.    ‚îÇ ‚îÇ ‚îÇ
‚îÇ        ‚îÇ                     ‚îÇ             ‚îÇ  ‚îÇ public.customers    ‚îÇ ‚îÇ ‚îÇ
‚îÇ        ‚îÇ                     ‚îÇ             ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ     WAL / Logical            ‚îÇ             ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ     Replication              ‚îÇ             ‚îÇ  ‚îÇ Topic: dbserver.    ‚îÇ ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îÇ  ‚îÇ public.orders       ‚îÇ ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                              ‚îÇ                         ‚îÇ                ‚îÇ
‚îÇ                              ‚îÇ                         ‚ñº                ‚îÇ
‚îÇ                              ‚îÇ             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ                              ‚îÇ             ‚îÇ      Consumers           ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îÇ  - Elasticsearch         ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îÇ  - Data Warehouse        ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îÇ  - Microservices         ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îÇ  - Analytics             ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Format des Messages Debezium

Debezium produit des messages avec une structure riche :

```json
{
  "schema": { ... },
  "payload": {
    "before": null,
    "after": {
      "id": 1,
      "name": "Alice",
      "email": "alice@example.com"
    },
    "source": {
      "version": "2.4.0.Final",
      "connector": "postgresql",
      "name": "dbserver1",
      "ts_ms": 1705312200123,
      "snapshot": "false",
      "db": "mydb",
      "schema": "public",
      "table": "customers",
      "txId": 734,
      "lsn": 23456789,
      "xmin": null
    },
    "op": "c",
    "ts_ms": 1705312200456,
    "transaction": null
  }
}
```

| Champ | Description |
|-------|-------------|
| `before` | √âtat de la ligne AVANT la modification (null pour INSERT) |
| `after` | √âtat de la ligne APR√àS la modification (null pour DELETE) |
| `op` | Type d'op√©ration : `c` (create), `u` (update), `d` (delete), `r` (read/snapshot) |
| `source` | M√©tadonn√©es : base, table, LSN, timestamp, etc. |
| `ts_ms` | Timestamp de capture par Debezium |

### Configuration Debezium pour PostgreSQL

#### docker-compose.yml

```yaml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  connect:
    image: debezium/connect:2.4
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
```

#### Enregistrer le Connecteur PostgreSQL

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "postgres-connector",
    "config": {
      "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
      "database.hostname": "postgres",
      "database.port": "5432",
      "database.user": "cdc_user",
      "database.password": "secure_password",
      "database.dbname": "mydb",
      "topic.prefix": "dbserver1",
      "plugin.name": "pgoutput",
      "slot.name": "debezium_slot",
      "publication.name": "dbz_publication",
      "table.include.list": "public.customers,public.orders",
      "column.exclude.list": "public.customers.password_hash",
      "decimal.handling.mode": "string",
      "time.precision.mode": "adaptive_time_microseconds"
    }
  }'
```

### Options de Configuration Importantes

| Option | Description |
|--------|-------------|
| `topic.prefix` | Pr√©fixe des topics Kafka (ex: `dbserver1.public.customers`) |
| `plugin.name` | Plugin de d√©codage (`pgoutput` recommand√©) |
| `slot.name` | Nom du slot de r√©plication |
| `table.include.list` | Tables √† capturer (regex support√©) |
| `table.exclude.list` | Tables √† exclure |
| `column.exclude.list` | Colonnes sensibles √† exclure |
| `snapshot.mode` | Mode de snapshot initial (`initial`, `never`, `always`) |
| `tombstones.on.delete` | G√©n√©rer des tombstones Kafka pour les DELETE |

---

## Consommer les √âv√©nements CDC

### Python avec kafka-python

```python
from kafka import KafkaConsumer
import json

def consume_cdc_events():
    consumer = KafkaConsumer(
        'dbserver1.public.customers',
        bootstrap_servers=['localhost:9092'],
        auto_offset_reset='earliest',
        enable_auto_commit=True,
        group_id='cdc-consumer-group',
        value_deserializer=lambda m: json.loads(m.decode('utf-8'))
    )

    print("En √©coute des changements...")

    for message in consumer:
        payload = message.value['payload']

        op = payload['op']
        table = payload['source']['table']

        if op == 'c':  # CREATE (INSERT)
            print(f"[INSERT] {table}: {payload['after']}")
            handle_insert(table, payload['after'])

        elif op == 'u':  # UPDATE
            print(f"[UPDATE] {table}:")
            print(f"  Before: {payload['before']}")
            print(f"  After:  {payload['after']}")
            handle_update(table, payload['before'], payload['after'])

        elif op == 'd':  # DELETE
            print(f"[DELETE] {table}: {payload['before']}")
            handle_delete(table, payload['before'])

        elif op == 'r':  # READ (snapshot)
            print(f"[SNAPSHOT] {table}: {payload['after']}")
            handle_snapshot(table, payload['after'])

def handle_insert(table, data):
    # Indexer dans Elasticsearch
    # Mettre √† jour un cache
    # Notifier un service
    pass

def handle_update(table, before, after):
    # Comparer les changements
    changes = {k: (before.get(k), v) for k, v in after.items() if before.get(k) != v}
    print(f"  Changes: {changes}")

def handle_delete(table, data):
    # Supprimer de l'index
    # Invalider le cache
    pass

def handle_snapshot(table, data):
    # Chargement initial
    pass

if __name__ == "__main__":
    consume_cdc_events()
```

### Synchronisation avec Elasticsearch

```python
from kafka import KafkaConsumer
from elasticsearch import Elasticsearch
import json

es = Elasticsearch(['http://localhost:9200'])

def sync_to_elasticsearch():
    consumer = KafkaConsumer(
        'dbserver1.public.products',
        bootstrap_servers=['localhost:9092'],
        group_id='es-sync-group',
        value_deserializer=lambda m: json.loads(m.decode('utf-8'))
    )

    for message in consumer:
        payload = message.value['payload']
        op = payload['op']

        if op in ('c', 'u', 'r'):  # INSERT, UPDATE, SNAPSHOT
            doc = payload['after']
            doc_id = doc['id']

            es.index(
                index='products',
                id=doc_id,
                document=doc
            )
            print(f"Indexed product {doc_id}")

        elif op == 'd':  # DELETE
            doc_id = payload['before']['id']

            es.delete(
                index='products',
                id=doc_id,
                ignore=[404]
            )
            print(f"Deleted product {doc_id}")

if __name__ == "__main__":
    sync_to_elasticsearch()
```

---

## Cas d'Usage du CDC

### 1. Synchronisation de Cache

```
PostgreSQL ‚îÄ‚îÄ‚ñ∫ Debezium ‚îÄ‚îÄ‚ñ∫ Kafka ‚îÄ‚îÄ‚ñ∫ Consumer ‚îÄ‚îÄ‚ñ∫ Redis Cache

Quand une donn√©e change dans PostgreSQL,
le cache Redis est automatiquement invalid√© ou mis √† jour.
```

### 2. Recherche Full-Text

```
PostgreSQL ‚îÄ‚îÄ‚ñ∫ Debezium ‚îÄ‚îÄ‚ñ∫ Kafka ‚îÄ‚îÄ‚ñ∫ Consumer ‚îÄ‚îÄ‚ñ∫ Elasticsearch

Les produits modifi√©s sont automatiquement r√©index√©s
pour la recherche.
```

### 3. Data Warehouse / Analytics

```
PostgreSQL ‚îÄ‚îÄ‚ñ∫ Debezium ‚îÄ‚îÄ‚ñ∫ Kafka ‚îÄ‚îÄ‚ñ∫ Consumer ‚îÄ‚îÄ‚ñ∫ BigQuery/Snowflake

Les donn√©es op√©rationnelles sont r√©pliqu√©es en temps r√©el
vers le data warehouse pour l'analytics.
```

### 4. Microservices : Propagation d'√âv√©nements

```
Service A (PostgreSQL) ‚îÄ‚îÄ‚ñ∫ Debezium ‚îÄ‚îÄ‚ñ∫ Kafka ‚îÄ‚îÄ‚ñ∫ Service B, C, D

Les changements dans un service sont propag√©s aux autres
sans couplage direct.
```

### 5. Audit et Compliance

```
PostgreSQL ‚îÄ‚îÄ‚ñ∫ Debezium ‚îÄ‚îÄ‚ñ∫ Kafka ‚îÄ‚îÄ‚ñ∫ Consumer ‚îÄ‚îÄ‚ñ∫ Audit Store

Chaque modification est captur√©e et archiv√©e
pour la conformit√© r√©glementaire.
```

---

## Comparaison : NOTIFY/LISTEN vs CDC

| Crit√®re | NOTIFY/LISTEN | CDC (Debezium) |
|---------|---------------|----------------|
| **Infrastructure** | PostgreSQL seul | Kafka + Connect + PostgreSQL |
| **Complexit√©** | Simple | Plus complexe |
| **Persistance** | ‚ùå Non (fire-and-forget) | ‚úÖ Oui (Kafka) |
| **Replay** | ‚ùå Non | ‚úÖ Oui |
| **Garantie de livraison** | ‚ùå At-most-once | ‚úÖ At-least-once |
| **Payload** | 8000 caract√®res max | Illimit√© |
| **Performance** | Tr√®s rapide | Quelques secondes de latence |
| **Modification du code** | Triggers requis | Aucune modification |
| **Multi-consommateurs** | Oui (m√™me connexion) | Oui (groupes Kafka) |
| **Historique des donn√©es** | ‚ùå Non | ‚úÖ Before/After |

### Quand Utiliser Quoi ?

| Sc√©nario | Recommandation |
|----------|----------------|
| Dashboard temps r√©el interne | NOTIFY/LISTEN |
| Invalidation de cache local | NOTIFY/LISTEN |
| Synchronisation vers syst√®mes externes | CDC |
| √âv√©nements critiques ne devant pas √™tre perdus | CDC |
| Audit complet avec historique | CDC |
| Infrastructure simple, pas de Kafka | NOTIFY/LISTEN |
| Replay des √©v√©nements n√©cessaire | CDC |

---

## Gestion des Slots de R√©plication

### Surveillance des Slots

```sql
-- √âtat des slots de r√©plication
SELECT
    slot_name,
    plugin,
    slot_type,
    active,
    restart_lsn,
    confirmed_flush_lsn,
    pg_size_pretty(
        pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)
    ) AS replication_lag
FROM pg_replication_slots;
```

### Attention : Slots Non Consomm√©s

Un slot qui n'est plus consomm√© emp√™che PostgreSQL de recycler le WAL, ce qui peut remplir le disque !

```sql
-- Trouver les slots probl√©matiques (lag > 1GB)
SELECT
    slot_name,
    active,
    pg_size_pretty(
        pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)
    ) AS lag
FROM pg_replication_slots
WHERE pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) > 1073741824;

-- Supprimer un slot abandonn√© (ATTENTION : perte de donn√©es CDC)
SELECT pg_drop_replication_slot('abandoned_slot');
```

### Configuration de S√©curit√©

```sql
-- Limiter la r√©tention WAL par slot (PostgreSQL 13+)
ALTER SYSTEM SET max_slot_wal_keep_size = '10GB';
SELECT pg_reload_conf();
```

---

## CDC Sans Kafka : Alternatives L√©g√®res

Si Kafka est trop lourd pour votre contexte, des alternatives existent :

### 1. pg_recvlogical (CLI PostgreSQL)

```bash
# √âcouter les changements en continu
pg_recvlogical -d mydb \
    --slot=my_slot \
    --plugin=wal2json \
    --start \
    -f - \
    -o include-timestamp=true
```

### 2. Script Python Direct

```python
import psycopg
import json

def consume_logical_changes():
    conn = psycopg.connect(
        "host=localhost dbname=mydb user=cdc_user password=secret"
    )
    conn.autocommit = True

    # Cr√©er le slot si n√©cessaire
    with conn.cursor() as cur:
        cur.execute("""
            SELECT pg_create_logical_replication_slot(
                'python_slot', 'wal2json'
            )
        """)

    print("√âcoute des changements...")

    while True:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT * FROM pg_logical_slot_get_changes(
                    'python_slot', NULL, NULL,
                    'include-timestamp', 'true'
                )
            """)

            for row in cur.fetchall():
                lsn, xid, data = row
                changes = json.loads(data)

                for change in changes.get('change', []):
                    print(f"[{change['kind'].upper()}] "
                          f"{change['schema']}.{change['table']}")
                    print(f"  Data: {change.get('columnvalues', change.get('oldkeys'))}")

        # Pause entre les polls
        time.sleep(1)

if __name__ == "__main__":
    consume_logical_changes()
```

### 3. Solutions Manag√©es

| Solution | Description |
|----------|-------------|
| **AWS DMS** | Service manag√© AWS pour CDC |
| **Fivetran** | SaaS pour synchronisation de donn√©es |
| **Airbyte** | Open-source, alternative √† Fivetran |
| **Striim** | Plateforme CDC entreprise |

---

## Bonnes Pratiques

### 1. Toujours Configurer REPLICA IDENTITY

Pour capturer les valeurs BEFORE lors des UPDATE/DELETE :

```sql
-- FULL : Toutes les colonnes dans before (recommand√© pour CDC)
ALTER TABLE customers REPLICA IDENTITY FULL;

-- DEFAULT : Seulement la cl√© primaire dans before
ALTER TABLE orders REPLICA IDENTITY DEFAULT;

-- USING INDEX : Utiliser un index unique
ALTER TABLE products REPLICA IDENTITY USING INDEX products_sku_key;
```

### 2. Exclure les Colonnes Sensibles

```json
{
  "column.exclude.list": "public.users.password_hash,public.users.ssn"
}
```

### 3. Monitorer les Slots

```sql
-- Alerte si lag > 500MB
SELECT slot_name
FROM pg_replication_slots
WHERE pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) > 524288000;
```

### 4. G√©rer les Sch√©mas √âvolutifs

Debezium g√®re les changements de sch√©ma, mais :

- Testez les migrations en staging
- √âvitez de renommer des colonnes (pr√©f√©rez ajouter/supprimer)
- Utilisez le Schema Registry pour la compatibilit√©

### 5. Idempotence des Consommateurs

Les messages peuvent √™tre d√©livr√©s plusieurs fois (at-least-once) :

```python
def handle_event(event):
    event_id = f"{event['source']['lsn']}_{event['source']['txId']}"

    # V√©rifier si d√©j√† trait√©
    if is_processed(event_id):
        return

    # Traiter l'√©v√©nement
    process(event)

    # Marquer comme trait√©
    mark_processed(event_id)
```

---

## Conclusion

Le **Logical Decoding** et le **Change Data Capture** transforment PostgreSQL en une source d'√©v√©nements puissante. Sans modifier vos applications, vous pouvez :

- Capturer chaque INSERT, UPDATE, DELETE en temps r√©el
- Synchroniser des syst√®mes externes (Elasticsearch, caches, data warehouses)
- Construire des architectures √©v√©nementielles d√©coupl√©es
- Garantir un audit complet de toutes les modifications

**Debezium** avec **Kafka** est la solution de production la plus robuste, offrant persistance, replay, et scalabilit√©. Pour des besoins plus simples, `wal2json` avec un script de consommation peut suffire.

Le CDC est le pont entre le monde transactionnel de PostgreSQL et le monde √©v√©nementiel des architectures modernes.

---

## Points Cl√©s √† Retenir

- **CDC** : Capture des changements de donn√©es depuis le journal de transactions
- **WAL** : Source de v√©rit√© pour toutes les modifications PostgreSQL
- **Logical Decoding** : Transformation du WAL binaire en √©v√©nements lisibles
- **Slots de r√©plication** : Pointeurs qui garantissent la r√©tention du WAL
- **Plugins** : `pgoutput` (natif), `wal2json` (JSON), `test_decoding` (test)
- **Debezium** : Plateforme CDC de r√©f√©rence pour Kafka
- **REPLICA IDENTITY FULL** : N√©cessaire pour capturer l'√©tat "before"
- **Surveillance** : Monitorer les slots pour √©viter de remplir le disque
- **Idempotence** : Les consommateurs doivent g√©rer les doublons

---


‚è≠Ô∏è [Debezium pour streaming d'√©v√©nements](/20bis-postgresql-et-architectures-modernes/02.4-debezium.md)
