ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 19.5.3. GÃ©o-rÃ©plication et Multi-Region

## Introduction

Imaginez cette situation : vous gÃ©rez une application e-commerce internationale. Vos clients sont aux Ã‰tats-Unis, en Europe et en Asie. Ã€ 3h du matin, heure de Paris, un incendie dÃ©truit votre datacenter principal situÃ© en France.

**Sans gÃ©o-rÃ©plication :**
- âŒ Votre site est totalement hors ligne
- âŒ Vous perdez potentiellement des heures ou jours de donnÃ©es
- âŒ Vos clients du monde entier ne peuvent plus commander
- âŒ Votre rÃ©putation est ruinÃ©e
- âŒ Les pertes financiÃ¨res sont catastrophiques

**Avec gÃ©o-rÃ©plication :**
- âœ… Un datacenter aux Ã‰tats-Unis prend automatiquement le relais
- âœ… Vos clients europÃ©ens subissent une lÃ©gÃ¨re hausse de latence (300ms au lieu de 50ms)
- âœ… Aucune donnÃ©e n'est perdue
- âœ… Le service continue de fonctionner
- âœ… Vous avez le temps de reconstruire votre infrastructure europÃ©enne

La **gÃ©o-rÃ©plication** et l'architecture **multi-rÃ©gion** sont des stratÃ©gies qui protÃ¨gent votre base de donnÃ©es PostgreSQL contre les catastrophes rÃ©gionales et amÃ©liorent simultanÃ©ment les performances pour vos utilisateurs dispersÃ©s gÃ©ographiquement.

Ce chapitre vous explique pourquoi, quand et comment mettre en place une architecture PostgreSQL distribuÃ©e gÃ©ographiquement.

---

## Qu'est-ce que la GÃ©o-rÃ©plication ?

### DÃ©finition

La **gÃ©o-rÃ©plication** est la technique consistant Ã  maintenir des copies de votre base de donnÃ©es PostgreSQL dans plusieurs datacenters situÃ©s dans diffÃ©rentes **rÃ©gions gÃ©ographiques** (pays, continents).

C'est une extension du concept de rÃ©plication que nous avons vu prÃ©cÃ©demment, mais Ã  l'Ã©chelle planÃ©taire.

### RÃ©plication locale vs GÃ©o-rÃ©plication

```
RÃ‰PLICATION LOCALE (mÃªme datacenter ou ville)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Datacenter Paris (France)       â”‚
â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚ Primary â”‚â”€â”€â”€â†’â”‚ Standby â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                     â”‚
â”‚   Latence: <1ms                     â”‚
â”‚   Distance: quelques km             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

GÃ‰O-RÃ‰PLICATION (multi-rÃ©gions)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Datacenter Paris  â”‚        â”‚ Datacenter Virginieâ”‚
â”‚     (Europe)       â”‚        â”‚    (US-East)       â”‚
â”‚                    â”‚        â”‚                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Primary â”‚â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â†’â”‚ Standby â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                    â”‚        â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Latence: 80-150ms
    Distance: ~6000 km
```

**DiffÃ©rences clÃ©s :**

| Aspect | RÃ©plication locale | GÃ©o-rÃ©plication |
|--------|-------------------|-----------------|
| **Latence** | <1ms | 50-300ms |
| **Bande passante** | TrÃ¨s Ã©levÃ©e (10+ Gbps) | LimitÃ©e (100 Mbps - 1 Gbps) |
| **Protection contre** | Pannes matÃ©rielles | Catastrophes rÃ©gionales |
| **CoÃ»t** | ModÃ©rÃ© | Ã‰levÃ© |
| **ComplexitÃ©** | Moyenne | Ã‰levÃ©e |

---

## Pourquoi mettre en place une GÃ©o-rÃ©plication ?

### 1. Protection contre les catastrophes rÃ©gionales (Disaster Recovery)

**Risques rÃ©gionaux auxquels vous Ãªtes exposÃ©s :**

- ğŸ”¥ **Incendies** : OVH Strasbourg (2021), 3,6 millions de sites affectÃ©s
- ğŸŒŠ **Inondations** : Datacenter de Bangkok (2011)
- âš¡ **Pannes Ã©lectriques massives** : Texas (2021), plusieurs jours sans Ã©lectricitÃ©
- ğŸŒªï¸ **Catastrophes naturelles** : Tremblements de terre, ouragans, tornades
- ğŸ’£ **Ã‰vÃ©nements gÃ©opolitiques** : Guerre, terrorisme, cyberattaque d'Ã‰tat
- ğŸ›ï¸ **ProblÃ¨mes lÃ©gaux** : Saisie de serveurs, fermeture administrative

**Exemple concret :**

En mars 2021, l'incendie du datacenter OVH Ã  Strasbourg a dÃ©truit complÃ¨tement plusieurs bÃ¢timents. Des milliers d'entreprises qui n'avaient qu'un seul site ont **tout perdu** :
- Sites web hors ligne pendant des semaines
- DonnÃ©es perdues dÃ©finitivement pour certaines
- Entreprises en difficultÃ© financiÃ¨re, certaines ont fermÃ©

Avec une gÃ©o-rÃ©plication, ces entreprises auraient pu basculer instantanÃ©ment sur un datacenter aux Pays-Bas ou en Allemagne.

### 2. RÃ©duction de la latence pour les utilisateurs globaux

**Le problÃ¨me de la latence intercontinentale :**

```
Temps de latence depuis Paris :
- Paris â†’ Paris        :   1 ms
- Paris â†’ Londres      :  15 ms
- Paris â†’ New York     :  80 ms
- Paris â†’ Tokyo        : 250 ms
- Paris â†’ Sydney       : 350 ms
```

Pour un utilisateur Ã  Sydney, chaque requÃªte SQL prend au minimum 700ms (350ms aller + 350ms retour), ce qui rend l'application **trÃ¨s lente**.

**Solution avec gÃ©o-rÃ©plication :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Ã       â”‚                    â”‚ User Ã       â”‚
â”‚ Paris       â”‚                    â”‚ Sydney      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1ms                              â”‚ 1ms
       â†“                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚â†â”€â”€â”€â”€ Sync â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ PostgreSQL  â”‚
â”‚ Paris       â”‚     250ms          â”‚ Sydney      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Chaque utilisateur accÃ¨de Ã  un serveur proche gÃ©ographiquement, rÃ©duisant la latence de 350ms Ã  1-10ms.

### 3. ConformitÃ© rÃ©glementaire (Data Residency)

Certaines lÃ©gislations imposent que les donnÃ©es des citoyens restent dans leur pays ou rÃ©gion :

- **RGPD (Europe)** : DonnÃ©es des citoyens europÃ©ens
- **LGPD (BrÃ©sil)** : DonnÃ©es des citoyens brÃ©siliens
- **FedRAMP (USA)** : DonnÃ©es gouvernementales amÃ©ricaines
- **PDPA (Singapour)** : DonnÃ©es Ã  Singapour

**Exemple :**

Une banque europÃ©enne doit stocker les donnÃ©es de ses clients europÃ©ens en Europe, mais peut servir des clients asiatiques depuis des serveurs en Asie.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Europe (RGPD)  â”‚          â”‚   Asie (PDPA)     â”‚
â”‚                  â”‚          â”‚                   â”‚
â”‚ Clients: ğŸ‡«ğŸ‡·ğŸ‡©ğŸ‡ªğŸ‡®ğŸ‡¹  â”‚          â”‚ Clients: ğŸ‡¯ğŸ‡µğŸ‡¸ğŸ‡¬ğŸ‡°ğŸ‡·   â”‚
â”‚                  â”‚          â”‚                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ PostgreSQL   â”‚ â”‚          â”‚ â”‚ PostgreSQL    â”‚ â”‚
â”‚ â”‚ (donnÃ©es EU) â”‚ â”‚          â”‚ â”‚ (donnÃ©es Asia)â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚          â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†‘                             â†‘
    â””â”€ RÃ©plication sÃ©lective â”€â”€â”€â”€â”˜
       (uniquement mÃ©tadonnÃ©es globales)
```

### 4. Haute disponibilitÃ© Ã  l'Ã©chelle planÃ©taire

**Objectif :** Atteindre une disponibilitÃ© de **99,99%** ou plus (moins de 53 minutes d'indisponibilitÃ© par an).

Avec plusieurs rÃ©gions :
- Si une rÃ©gion tombe, les autres prennent le relais
- Maintenance sans interruption (rolling updates)
- Pas de single point of failure gÃ©ographique

---

## Architectures de GÃ©o-rÃ©plication

### Architecture 1 : Primary-Standby Multi-rÃ©gions (Active-Passive)

C'est l'architecture la plus simple pour dÃ©buter.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WRITES                         â”‚
â”‚                      â†“                           â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚            â”‚   PRIMARY        â”‚                  â”‚
â”‚            â”‚   Paris (EU)     â”‚                  â”‚
â”‚            â”‚   Read + Write   â”‚                  â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                     â”‚                            â”‚
â”‚          Streaming Replication                   â”‚
â”‚          (Asynchronous)                          â”‚
â”‚                     â”‚                            â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚        â†“                         â†“               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  STANDBY     â”‚         â”‚  STANDBY     â”‚       â”‚
â”‚  â”‚  Virginia    â”‚         â”‚  Tokyo       â”‚       â”‚
â”‚  â”‚  (US-East)   â”‚         â”‚  (Asia)      â”‚       â”‚
â”‚  â”‚  Read-only   â”‚         â”‚  Read-only   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                  â”‚
â”‚  READS: Primary + Standbys (load balancing)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques :**

- âœ… **Simple Ã  mettre en place**
- âœ… **Une seule source de vÃ©ritÃ©** (pas de conflit)
- âœ… **Standbys peuvent servir les lectures** (lecture locale rapide)
- âŒ **Ã‰critures centralisÃ©es** (latence pour utilisateurs lointains)
- âŒ **Failover manuel** en cas de panne du primary

**Configuration PostgreSQL :**

```sql
-- Sur le Primary (Paris)
-- postgresql.conf
wal_level = replica
max_wal_senders = 10
wal_keep_size = 1GB
archive_mode = on
archive_command = 'aws s3 cp %p s3://pg-wal-archive/%f'

-- Sur les Standbys (Virginia, Tokyo)
-- postgresql.conf
hot_standby = on
primary_conninfo = 'host=paris-primary.example.com port=5432 user=replicator'
restore_command = 'aws s3 cp s3://pg-wal-archive/%f %p'
```

**Cas d'usage :**
- Application dont les Ã©critures proviennent principalement d'une rÃ©gion
- Budget limitÃ©
- Ã‰quipe technique de taille moyenne

### Architecture 2 : Multi-Primary avec RÃ©partition GÃ©ographique

Chaque rÃ©gion a son propre serveur primary qui gÃ¨re ses donnÃ©es locales.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRIMARY Europe    â”‚     â”‚  PRIMARY US        â”‚     â”‚  PRIMARY Asia      â”‚
â”‚  Paris             â”‚     â”‚  Virginia          â”‚     â”‚  Tokyo             â”‚
â”‚                    â”‚     â”‚                    â”‚     â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ customers_eu â”‚  â”‚     â”‚  â”‚ customers_us â”‚  â”‚     â”‚  â”‚customers_asiaâ”‚  â”‚
â”‚  â”‚ orders_eu    â”‚  â”‚     â”‚  â”‚ orders_us    â”‚  â”‚     â”‚  â”‚ orders_asia  â”‚  â”‚
â”‚  â”‚ products (R) â”‚â†â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”‚ products (W) â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â†’ â”‚ products (R) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                    â”‚     â”‚                    â”‚     â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                          â†‘                          â†‘
         â””â”€â”€â”€â”€â”€â”€â”€â”€ Logical â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€ Replication â”€â”€â”€â”€â”€â”˜
                   (Selective tables)
```

**Principe :**
- Chaque rÃ©gion gÃ¨re ses **propres donnÃ©es clients**
- Certaines tables (produits, configuration) sont rÃ©pliquÃ©es partout
- Ã‰vite les conflits en partitionnant les donnÃ©es gÃ©ographiquement

**Configuration avec Logical Replication :**

```sql
-- Sur le serveur US (primary pour customers_us)
CREATE PUBLICATION pub_products FOR TABLE products;

-- Sur le serveur EU (subscribe aux products US)
CREATE SUBSCRIPTION sub_products_from_us
CONNECTION 'host=us-primary.example.com dbname=mydb user=replicator'
PUBLICATION pub_products;

-- Sur le serveur Asia (subscribe aux products US)
CREATE SUBSCRIPTION sub_products_from_us
CONNECTION 'host=us-primary.example.com dbname=mydb user=replicator'
PUBLICATION pub_products;
```

**Avantages :**

- âœ… **Ã‰critures locales rapides** (faible latence)
- âœ… **RÃ©silience Ã©levÃ©e** (chaque rÃ©gion autonome)
- âœ… **ConformitÃ© rÃ©glementaire** (donnÃ©es localisÃ©es)

**InconvÃ©nients :**

- âŒ **ComplexitÃ© Ã©levÃ©e** de la logique applicative
- âŒ **Gestion des conflits** si donnÃ©es partagÃ©es
- âŒ **CoÃ»t important** (3+ serveurs primaries)

**Cas d'usage :**
- Application SaaS multi-tenant avec clients par rÃ©gion
- ConformitÃ© stricte (RGPD, etc.)
- Budget consÃ©quent

### Architecture 3 : Multi-Primary avec RÃ©solution de Conflits (Active-Active)

**Attention : Non supportÃ© nativement par PostgreSQL !**

PostgreSQL ne supporte pas nativement le multi-primary avec Ã©critures concurrentes sur les mÃªmes donnÃ©es. Vous aurez besoin d'extensions tierces.

**Solutions externes :**

1. **Patroni + Citus** : Sharding distribuÃ©
2. **BDR (Bi-Directional Replication)** : Solution commerciale de EDB
3. **Bucardo** : RÃ©plication asynchrone avec rÃ©solution de conflits
4. **Pglogical** : Base pour BDR, open-source

**SchÃ©ma avec BDR :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node Europe       â”‚          â”‚  Node US           â”‚
â”‚  (Primary)         â”‚          â”‚  (Primary)         â”‚
â”‚                    â”‚          â”‚                    â”‚
â”‚  Write: users      â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  Write: users      â”‚
â”‚  Write: orders     â”‚   BDR    â”‚  Write: orders     â”‚
â”‚                    â”‚          â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                               â†‘
         â”‚                               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
            Conflict Resolution:
            - Last Write Wins (LWW)
            - Custom Rules
            - Application Logic
```

**Gestion des conflits :**

```sql
-- Exemple de conflit
-- Ã€ Paris (11:00:00 UTC): UPDATE users SET email='alice@paris.com' WHERE id=1;
-- Ã€ New York (11:00:00 UTC): UPDATE users SET email='alice@ny.com' WHERE id=1;

-- StratÃ©gies de rÃ©solution:
-- 1. Last Write Wins (plus rÃ©cent gagne)
-- 2. First Write Wins (premier gagne)
-- 3. Merge (fusion des changements)
-- 4. Custom logic (rÃ¨gle mÃ©tier)
```

**âš ï¸ ComplexitÃ© trÃ¨s Ã©levÃ©e - Ã€ Ã©viter sauf besoin absolument critique**

---

## Les dÃ©fis de la GÃ©o-rÃ©plication

### 1. Le thÃ©orÃ¨me CAP

Vous ne pouvez avoir que **2 des 3 propriÃ©tÃ©s** suivantes dans un systÃ¨me distribuÃ© :

```
       Consistency (CohÃ©rence)
              /\
             /  \
            /    \
           /      \
          /        \
         /          \
        /   Choose   \
       /      2       \
      /________________\
Availability        Partition
(DisponibilitÃ©)     Tolerance
                    (TolÃ©rance aux
                     pannes rÃ©seau)
```

**En pratique pour PostgreSQL gÃ©o-rÃ©pliquÃ© :**

| Mode | C | A | P | Description |
|------|---|---|---|-------------|
| **RÃ©plication synchrone** | âœ… | âŒ | âœ… | CohÃ©rence forte, mais indisponibilitÃ© si liaison rÃ©seau coupÃ©e |
| **RÃ©plication asynchrone** | âŒ | âœ… | âœ… | Haute disponibilitÃ©, mais perte de donnÃ©es possible (RPO > 0) |

**Vous devez choisir votre compromis selon votre contexte mÃ©tier.**

### 2. Latence rÃ©seau et bande passante

**Latences typiques inter-rÃ©gions (ping) :**

| Route | Latence moyenne | Latence 95th percentile |
|-------|----------------|------------------------|
| Paris â†’ Londres | 15 ms | 25 ms |
| Paris â†’ Francfort | 20 ms | 30 ms |
| Paris â†’ New York | 80 ms | 120 ms |
| Paris â†’ SÃ£o Paulo | 200 ms | 300 ms |
| Paris â†’ Tokyo | 250 ms | 350 ms |
| Paris â†’ Sydney | 350 ms | 450 ms |

**Impact sur la rÃ©plication synchrone :**

```sql
-- Chaque COMMIT doit attendre la confirmation du standby
BEGIN;
INSERT INTO orders VALUES (...);
COMMIT;  -- Attend 80ms (Paris â†’ New York) avant de confirmer

-- Impact sur le dÃ©bit:
-- Avec 80ms de latence, max thÃ©orique = 1000/80 = 12,5 transactions/seconde
-- (si transactions sÃ©quentielles)
```

**Pour les charges importantes, la rÃ©plication asynchrone est souvent nÃ©cessaire.**

### 3. CoÃ»ts

**Exemple de coÃ»ts mensuels (AWS) :**

```
Architecture Single-Region (Paris uniquement):
- 1Ã— RDS PostgreSQL db.r6g.2xlarge : 550â‚¬/mois
- 500 GB stockage SSD               : 70â‚¬/mois
- 1 TB backup S3                    : 25â‚¬/mois
TOTAL: ~645â‚¬/mois

Architecture Multi-Region (Paris + Virginia + Tokyo):
- 3Ã— RDS PostgreSQL db.r6g.2xlarge  : 1650â‚¬/mois
- 3Ã— 500 GB stockage SSD            : 210â‚¬/mois
- 3Ã— 1 TB backup S3                 : 75â‚¬/mois
- Data transfer inter-rÃ©gions (~500GB/mois) : 400â‚¬/mois
TOTAL: ~2335â‚¬/mois

SurcoÃ»t: +262% (Ã—3,6)
```

Le coÃ»t augmente considÃ©rablement, surtout Ã  cause des **transferts de donnÃ©es inter-rÃ©gions**.

### 4. ComplexitÃ© opÃ©rationnelle

**TÃ¢ches additionnelles :**

- Monitoring de la latence de rÃ©plication sur chaque rÃ©gion
- Gestion des failovers multi-rÃ©gions
- Tests DR sur plusieurs rÃ©gions
- Coordination des dÃ©ploiements (migrations de schÃ©ma)
- Gestion des fuseaux horaires
- ConformitÃ© multi-juridictions

**Taille d'Ã©quipe recommandÃ©e :**

- Single-region : 1-2 personnes
- Multi-region : 3-5 personnes (Ã©quipe DevOps/SRE dÃ©diÃ©e)

---

## Mise en place d'une GÃ©o-rÃ©plication PostgreSQL

### Ã‰tape 1 : Planification et Design

#### Questions Ã  vous poser

**Technique :**
- Quelle latence acceptable pour les Ã©critures ?
- Quel RPO est acceptable (0, 1 seconde, 1 minute) ?
- Quel volume de donnÃ©es Ã  rÃ©pliquer ?
- Quelle bande passante disponible entre rÃ©gions ?

**MÃ©tier :**
- Quelles rÃ©gions gÃ©ographiques cibler ?
- Quels utilisateurs dans quelle rÃ©gion ?
- Quelles donnÃ©es doivent rester localisÃ©es (RGPD) ?
- Quel budget disponible ?

**Organisationnel :**
- Avez-vous l'expertise technique ?
- Qui sera on-call pour les incidents multi-rÃ©gions ?
- Avez-vous les outils de monitoring adaptÃ©s ?

#### Dimensionnement

**Calculer le volume de rÃ©plication :**

```sql
-- Calculer le taux de gÃ©nÃ©ration de WAL (Write-Ahead Log)
SELECT
    pg_size_pretty(
        pg_wal_lsn_diff(pg_current_wal_lsn(), '0/0')
    ) as wal_generated;
-- ExÃ©cuter Ã  T0, puis Ã  T0+1h

-- Exemple de rÃ©sultat: 2.5 GB en 1 heure
-- = 60 GB/jour de WAL Ã  transfÃ©rer entre rÃ©gions
```

**Calculer la bande passante nÃ©cessaire :**

```
Volume WAL: 60 GB/jour = 2.5 GB/heure
Converti en Mbps: (2.5 Ã— 8 Ã— 1024) / 3600 = 5.7 Mbps minimum
Marge de sÃ©curitÃ© Ã—3 = 17 Mbps recommandÃ©
```

### Ã‰tape 2 : Configuration de la RÃ©plication Physique GÃ©o-distribuÃ©e

**ScÃ©nario :** Primary Ã  Paris, Standby Ã  New York

#### Sur le Primary (Paris)

```bash
# 1. Ã‰diter postgresql.conf
cat >> /etc/postgresql/18/main/postgresql.conf << EOF

# RÃ©plication
wal_level = replica
max_wal_senders = 5
max_replication_slots = 5
wal_keep_size = 2GB

# Archive des WAL (vers S3 pour DR)
archive_mode = on
archive_command = 'aws s3 cp %p s3://pg-wal-paris/%f --region eu-west-1'

# RÃ©plication synchrone (optionnel - impact performance)
# synchronous_commit = remote_apply
# synchronous_standby_names = 'newyork_standby'

EOF

# 2. CrÃ©er un utilisateur de rÃ©plication
sudo -u postgres psql << EOF
CREATE ROLE replicator WITH REPLICATION LOGIN PASSWORD 'SecureP@ssw0rd!';
EOF

# 3. Configurer pg_hba.conf
cat >> /etc/postgresql/18/main/pg_hba.conf << EOF
# Autoriser rÃ©plication depuis New York
host    replication    replicator    54.123.45.67/32    scram-sha-256
EOF

# 4. RedÃ©marrer PostgreSQL
sudo systemctl restart postgresql

# 5. CrÃ©er un slot de rÃ©plication
sudo -u postgres psql << EOF
SELECT pg_create_physical_replication_slot('newyork_slot');
EOF
```

#### Sur le Standby (New York)

```bash
# 1. Faire une sauvegarde de base depuis Paris
sudo -u postgres pg_basebackup \
    -h paris-primary.example.com \
    -D /var/lib/postgresql/18/main \
    -U replicator \
    -v \
    -P \
    -W \
    -R \
    --slot=newyork_slot

# L'option -R crÃ©e automatiquement standby.signal et configure
# primary_conninfo dans postgresql.auto.conf

# 2. VÃ©rifier la configuration auto-gÃ©nÃ©rÃ©e
cat /var/lib/postgresql/18/main/postgresql.auto.conf
# primary_conninfo = 'host=paris-primary.example.com port=5432 user=replicator password=...'
# primary_slot_name = 'newyork_slot'

# 3. Configurer le restore_command (optionnel, pour PITR)
cat >> /var/lib/postgresql/18/main/postgresql.conf << EOF
restore_command = 'aws s3 cp s3://pg-wal-paris/%f %p --region eu-west-1'
EOF

# 4. DÃ©marrer PostgreSQL
sudo systemctl start postgresql
```

### Ã‰tape 3 : VÃ©rification de la RÃ©plication

```sql
-- Sur le Primary (Paris)
-- VÃ©rifier les connexions de rÃ©plication
SELECT
    client_addr,
    application_name,
    state,
    sync_state,
    pg_wal_lsn_diff(pg_current_wal_lsn(), sent_lsn) as sending_lag_bytes,
    pg_wal_lsn_diff(pg_current_wal_lsn(), write_lsn) as write_lag_bytes,
    replay_lag
FROM pg_stat_replication;

-- RÃ©sultat attendu:
--  client_addr   | application_name | state     | sync_state | sending_lag_bytes | replay_lag
-- ---------------+------------------+-----------+------------+-------------------+------------
--  54.123.45.67  | newyork_standby  | streaming | async      |              0    | 00:00:00.5

-- Sur le Standby (New York)
-- VÃ©rifier qu'on est bien en mode standby
SELECT pg_is_in_recovery();
-- RÃ©sultat: t (true)

-- VÃ©rifier le lag de rÃ©plication
SELECT
    NOW() - pg_last_xact_replay_timestamp() AS replication_lag;
-- RÃ©sultat: 00:00:00.247 (247 millisecondes de retard)
```

### Ã‰tape 4 : Monitoring spÃ©cifique GÃ©o-rÃ©plication

**MÃ©triques critiques Ã  surveiller :**

1. **Replication Lag (Retard de rÃ©plication)**

```sql
-- Query Ã  exÃ©cuter sur le Primary
SELECT
    application_name,
    client_addr,
    pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) / 1024 / 1024 as lag_mb,
    EXTRACT(EPOCH FROM replay_lag) as replay_lag_seconds
FROM pg_stat_replication
ORDER BY replay_lag DESC;
```

**Seuils d'alerte recommandÃ©s :**
- âš ï¸ Warning : Lag > 100 MB ou > 10 secondes
- ğŸš¨ Critical : Lag > 1 GB ou > 60 secondes

2. **Slot de rÃ©plication non consommÃ©**

```sql
-- Sur le Primary
SELECT
    slot_name,
    pg_size_pretty(
        pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)
    ) as retained_wal,
    active
FROM pg_replication_slots;
```

**Alerte si :**
- Slot inactif pendant > 30 minutes
- WAL retenus > 10 GB (risque de remplissage disque)

3. **Bande passante rÃ©seau**

```bash
# Monitoring de la bande passante utilisÃ©e
# Exemple avec iftop
sudo iftop -i eth0 -f "dst port 5432"

# Ou avec nethogs
sudo nethogs eth0
```

### Ã‰tape 5 : Configuration du Failover

Pour automatiser le basculement en cas de panne du primary, utilisez **Patroni**.

**Architecture avec Patroni :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 etcd Cluster                     â”‚
â”‚          (Consensus distribuÃ©)                   â”‚
â”‚                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚etcd Parisâ”‚    â”‚etcd NY   â”‚    â”‚etcd Tokyoâ”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚               â”‚
        â†“              â†“               â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Patroni  â”‚   â”‚ Patroni  â”‚   â”‚ Patroni  â”‚
  â”‚  Paris   â”‚   â”‚  NY      â”‚   â”‚  Tokyo   â”‚
  â”‚ (Leader) â”‚   â”‚(Replica) â”‚   â”‚(Replica) â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â†“              â†“              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   PG     â”‚   â”‚   PG     â”‚   â”‚   PG     â”‚
  â”‚ Primary  â”‚â”€â”€â†’â”‚ Standby  â”‚   â”‚ Standby  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Installation de Patroni (simplifiÃ©e) :**

```yaml
# /etc/patroni/patroni.yml (Paris)
scope: postgres-cluster
namespace: /service/
name: paris-node

restapi:
  listen: 0.0.0.0:8008
  connect_address: paris.example.com:8008

etcd:
  hosts:
    - paris-etcd.example.com:2379
    - ny-etcd.example.com:2379
    - tokyo-etcd.example.com:2379

bootstrap:
  dcs:
    ttl: 30
    loop_wait: 10
    retry_timeout: 10
    maximum_lag_on_failover: 1048576  # 1 MB

  initdb:
    - encoding: UTF8
    - data-checksums

postgresql:
  listen: 0.0.0.0:5432
  connect_address: paris.example.com:5432
  data_dir: /var/lib/postgresql/18/main
  pgpass: /tmp/pgpass
  authentication:
    replication:
      username: replicator
      password: SecureP@ssw0rd!
    superuser:
      username: postgres
      password: SuperSecureP@ss!

  parameters:
    wal_level: replica
    hot_standby: on
    max_wal_senders: 10
    max_replication_slots: 10
    wal_keep_size: 2GB
```

**DÃ©marrage :**

```bash
# Sur chaque nÅ“ud (Paris, NY, Tokyo)
sudo systemctl start patroni
sudo systemctl enable patroni

# VÃ©rifier le cluster
patronictl -c /etc/patroni/patroni.yml list

# RÃ©sultat:
# + Cluster: postgres-cluster ----+--------+---------+----+-----------+
# | Member      | Host            | Role    | State   | TL | Lag in MB |
# +-------------+-----------------+---------+---------+----+-----------+
# | paris-node  | 10.0.1.10:5432  | Leader  | running | 1  |           |
# | ny-node     | 10.0.2.10:5432  | Replica | running | 1  |      0    |
# | tokyo-node  | 10.0.3.10:5432  | Replica | running | 1  |      0    |
# +-------------+-----------------+---------+---------+----+-----------+
```

**Test de failover :**

```bash
# Simuler une panne du leader (Paris)
sudo systemctl stop postgresql

# Patroni dÃ©tecte automatiquement et Ã©lit un nouveau leader
# (typiquement NY si c'est le plus Ã  jour)

# AprÃ¨s ~30 secondes:
patronictl -c /etc/patroni/patroni.yml list

# RÃ©sultat:
# + Cluster: postgres-cluster ----+--------+---------+----+-----------+
# | Member      | Host            | Role    | State   | TL | Lag in MB |
# +-------------+-----------------+---------+---------+----+-----------+
# | paris-node  | 10.0.1.10:5432  | Replica | stopped | 1  |           |
# | ny-node     | 10.0.2.10:5432  | Leader  | running | 2  |           |
# | tokyo-node  | 10.0.3.10:5432  | Replica | running | 2  |      0    |
# +-------------+-----------------+---------+---------+----+-----------+
```

---

## StratÃ©gies de Routage des RequÃªtes

### 1. DNS-based Routing

Utiliser des enregistrements DNS avec dÃ©tection gÃ©ographique.

```
# Configuration AWS Route 53 (exemple)

postgres-primary.example.com
â”œâ”€ Geolocation: Europe â†’ paris-pg.example.com (2.3.4.5)
â”œâ”€ Geolocation: Americas â†’ ny-pg.example.com (54.123.45.67)
â””â”€ Geolocation: Asia â†’ tokyo-pg.example.com (13.234.56.78)

postgres-read.example.com (load balanced)
â”œâ”€ Geolocation: Europe â†’ paris-read.example.com
â”œâ”€ Geolocation: Americas â†’ ny-read.example.com
â””â”€ Geolocation: Asia â†’ tokyo-read.example.com
```

**Dans l'application :**

```python
# Python avec psycopg2
import psycopg2

# Connexion pour Ã©critures (toujours vers le primary actuel)
write_conn = psycopg2.connect(
    host="postgres-primary.example.com",  # RÃ©solu gÃ©ographiquement
    database="mydb",
    user="app_user",
    password="secret"
)

# Connexion pour lectures (vers replica le plus proche)
read_conn = psycopg2.connect(
    host="postgres-read.example.com",  # RÃ©solu vers replica local
    database="mydb",
    user="app_user",
    password="secret"
)
```

### 2. Proxy-based Routing avec HAProxy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               HAProxy (Load Balancer)            â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Port 5432      â”‚      â”‚  Port 5433      â”‚    â”‚
â”‚  â”‚  (Write)        â”‚      â”‚  (Read)         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                        â”‚
            â†“                        â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Primary  â”‚          â”‚ Round-robin:    â”‚
     â”‚ (Master) â”‚          â”‚ - Primary       â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ - Standby 1     â”‚
                           â”‚ - Standby 2     â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration HAProxy :**

```
# /etc/haproxy/haproxy.cfg

global
    maxconn 10000

defaults
    mode tcp
    timeout connect 5s
    timeout client 1h
    timeout server 1h

# Backend pour Ã©critures (vers primary uniquement)
backend postgres_write
    option pgsql-check user haproxy
    server paris-primary 10.0.1.10:5432 check
    server ny-standby 10.0.2.10:5432 check backup
    server tokyo-standby 10.0.3.10:5432 check backup

# Backend pour lectures (load balancing sur tous)
backend postgres_read
    balance roundrobin
    option pgsql-check user haproxy
    server paris-primary 10.0.1.10:5432 check weight 30
    server ny-standby 10.0.2.10:5432 check weight 35
    server tokyo-standby 10.0.3.10:5432 check weight 35

# Frontend
frontend postgres_write_frontend
    bind *:5432
    default_backend postgres_write

frontend postgres_read_frontend
    bind *:5433
    default_backend postgres_read
```

### 3. Application-level Routing

L'application dÃ©cide elle-mÃªme oÃ¹ router les requÃªtes.

```javascript
// Node.js avec pg (node-postgres)
const { Pool } = require('pg');

// Pools sÃ©parÃ©s par rÃ©gion
const pools = {
  paris: new Pool({
    host: 'paris-pg.example.com',
    database: 'mydb',
    max: 20
  }),
  ny: new Pool({
    host: 'ny-pg.example.com',
    database: 'mydb',
    max: 20
  }),
  tokyo: new Pool({
    host: 'tokyo-pg.example.com',
    database: 'mydb',
    max: 20
  })
};

// Fonction de routing gÃ©ographique
function getPoolForUser(userRegion) {
  switch(userRegion) {
    case 'EU': return pools.paris;
    case 'US': return pools.ny;
    case 'ASIA': return pools.tokyo;
    default: return pools.paris; // fallback
  }
}

// Utilisation
async function getUser(userId, userRegion) {
  const pool = getPoolForUser(userRegion);
  const result = await pool.query(
    'SELECT * FROM users WHERE id = $1',
    [userId]
  );
  return result.rows[0];
}
```

---

## Bonnes Pratiques

### 1. Tester rÃ©guliÃ¨rement les failovers

**Calendrier suggÃ©rÃ© :**
- Failover manuel : Trimestriel
- Chaos engineering (panne simulÃ©e) : Annuel
- Review des runbooks : AprÃ¨s chaque incident

**Script de test de failover :**

```bash
#!/bin/bash
# test_failover.sh
# Test de failover contrÃ´lÃ© avec Patroni

echo "=== TEST DE FAILOVER GÃ‰OGRAPHIQUE ==="
echo "Date: $(date)"

# 1. Identifier le leader actuel
CURRENT_LEADER=$(patronictl -c /etc/patroni/patroni.yml list --format=json | \
  jq -r '.[] | select(.Role == "Leader") | .Member')

echo "Leader actuel: $CURRENT_LEADER"

# 2. Effectuer un switchover contrÃ´lÃ© vers un autre nÅ“ud
TARGET_NODE="ny-node"  # Choisir le nÅ“ud cible

echo "DÃ©clenchement du switchover vers $TARGET_NODE..."
patronictl -c /etc/patroni/patroni.yml switchover \
  --master $CURRENT_LEADER \
  --candidate $TARGET_NODE \
  --force

# 3. Attendre la stabilisation
echo "Attente de stabilisation (30s)..."
sleep 30

# 4. VÃ©rifier le nouveau leader
NEW_LEADER=$(patronictl -c /etc/patroni/patroni.yml list --format=json | \
  jq -r '.[] | select(.Role == "Leader") | .Member')

echo "Nouveau leader: $NEW_LEADER"

# 5. Test de connectivitÃ©
echo "Test de connectivitÃ©..."
psql -h postgres-primary.example.com -U app_user -d mydb -c "SELECT NOW();"

if [ $? -eq 0 ]; then
    echo "âœ… Failover rÃ©ussi"
else
    echo "âŒ Failover Ã©chouÃ©"
    exit 1
fi

# 6. Mesurer le downtime
echo "Downtime mesurÃ©: ~5 secondes"  # Ã€ mesurer rÃ©ellement avec monitoring
```

### 2. Monitorer les mÃ©triques critiques

**Dashboard Grafana recommandÃ© :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL Geo-Replication Dashboard                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Replication Lag by Region                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Paris: 0 MB / 0.1s                     â”‚            â”‚
â”‚  â”‚  NY: 2 MB / 0.3s                        â”‚            â”‚
â”‚  â”‚  Tokyo: 5 MB / 0.8s                     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                         â”‚
â”‚  Network Throughput (Replication)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Parisâ†’NY: 15 Mbps                      â”‚            â”‚
â”‚  â”‚  Parisâ†’Tokyo: 12 Mbps                   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                         â”‚
â”‚  WAL Generated vs Replicated                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Generated: 60 GB/day                   â”‚            â”‚
â”‚  â”‚  Replicated: 58 GB/day (96%)            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                         â”‚
â”‚  Alerts (Last 24h)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  ğŸš¨ Tokyo lag > 10s (3 occurrences)     â”‚            â”‚
â”‚  â”‚  âš ï¸  Slot NY retention > 5GB (1x)       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Queries Prometheus :**

```promql
# Replication lag en secondes
pg_replication_lag_seconds{job="postgres"}

# Taille du lag en bytes
pg_replication_lag_bytes{job="postgres"}

# Slots non actifs
pg_replication_slots_active{job="postgres"} == 0
```

### 3. Optimiser les transferts inter-rÃ©gions

**Techniques de rÃ©duction des coÃ»ts :**

1. **Compression WAL**

```sql
-- Dans postgresql.conf
wal_compression = on
```

RÃ©duction typique : 30-50% du volume WAL.

2. **RÃ©plication sÃ©lective (Logical Replication)**

Ne rÃ©pliquer que les tables nÃ©cessaires.

```sql
-- Sur le primary
CREATE PUBLICATION pub_critical_tables
FOR TABLE orders, customers, products;

-- Sur le standby
CREATE SUBSCRIPTION sub_critical
CONNECTION 'host=primary.example.com dbname=mydb'
PUBLICATION pub_critical_tables;
```

3. **Tuning de la rÃ©plication**

```sql
-- Augmenter la taille des WAL segments pour rÃ©duire la frÃ©quence
-- postgresql.conf
max_wal_size = 2GB
min_wal_size = 1GB

-- Tuning des paramÃ¨tres rÃ©seau
tcp_keepalives_idle = 60
tcp_keepalives_interval = 10
tcp_keepalives_count = 6
```

### 4. Documenter les procÃ©dures d'urgence

**Runbook : Panne rÃ©gion complÃ¨te**

```markdown
# RUNBOOK: Panne Datacenter RÃ©gion Europe

## DÃ©tection
- Monitoring dÃ©tecte: paris-primary.example.com DOWN
- Alertes: PagerDuty, Slack #incidents

## Actions immÃ©diates (5 premiÃ¨res minutes)

1. VÃ©rifier que c'est bien une panne rÃ©gionale (ping, traceroute)
2. DÃ©clarer l'incident (war room Zoom)
3. VÃ©rifier les standbys: ny-node et tokyo-node UP?

## Failover vers NY (minutes 5-10)

```bash
# 1. VÃ©rifier lag avant promotion
patronictl -c /etc/patroni/patroni.yml list

# 2. Promouvoir NY comme nouveau primary
patronictl -c /etc/patroni/patroni.yml failover \
  --candidate ny-node --force

# 3. Mettre Ã  jour DNS (TTL: 60s)
# Pointer postgres-primary.example.com vers ny-node
aws route53 change-resource-record-sets ...

# 4. VÃ©rifier l'application
curl https://app.example.com/health
```

## Communication (minutes 10-15)

- Status page: "Service dÃ©gradÃ© - Latence augmentÃ©e Europe"
- Email clients critiques
- Tweet @CompanyStatus

## Stabilisation (minutes 15-60)

- Monitoring intensif des mÃ©triques
- VÃ©rifier les queues applicatives
- Investiguer la cause racine

## Post-incident (J+1)

- Post-mortem
- AmÃ©lioration runbook
- Test de restauration rÃ©gion Europe
```

### 5. GÃ©rer les migrations de schÃ©ma

**ProcÃ©dure de migration zero-downtime multi-rÃ©gions :**

```sql
-- PHASE 1: Ajouter une colonne (compatible backwards)
-- DÃ©ployer sur toutes les rÃ©gions simultanÃ©ment
ALTER TABLE users ADD COLUMN phone VARCHAR(20);

-- PHASE 2: DÃ©ployer le code applicatif qui utilise la colonne
-- DÃ©ploiement progressif par rÃ©gion (Paris â†’ NY â†’ Tokyo)

-- PHASE 3: Backfill des donnÃ©es (optionnel)
UPDATE users SET phone = '...' WHERE phone IS NULL;

-- PHASE 4: Ajouter contrainte NOT NULL (une fois backfill terminÃ©)
ALTER TABLE users ALTER COLUMN phone SET NOT NULL;
```

**Outils recommandÃ©s :**
- **Flyway** : Migrations versionnÃ©es
- **Liquibase** : Migrations avec rollback
- **Alembic** (Python) : Migrations SQLAlchemy

---

## Alternatives et Solutions ManagÃ©es

### Solutions Cloud Natives

Si gÃ©rer la gÃ©o-rÃ©plication vous semble trop complexe, considÃ©rez des solutions managÃ©es :

#### 1. **AWS Aurora Global Database**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Primary Region      â”‚          â”‚  Secondary Region    â”‚
â”‚  (us-east-1)         â”‚          â”‚  (eu-west-1)         â”‚
â”‚                      â”‚          â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Aurora Primary â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’â”‚ Aurora Read    â”‚  â”‚
â”‚  â”‚   (Write)      â”‚  â”‚ Async    â”‚  â”‚   Replica      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ <1s lag  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚          â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Features:
âœ… RÃ©plication < 1 seconde
âœ… Failover global automatique
âœ… Compatible PostgreSQL
âŒ CoÃ»t Ã©levÃ© (~3Ã— RDS standard)
âŒ Vendor lock-in AWS
```

#### 2. **Google Cloud Spanner** (pas PostgreSQL natif)

Solution distribuÃ©e globalement, fortement cohÃ©rente.

```
âœ… CohÃ©rence forte (ACID)
âœ… Distribution automatique
âœ… ScalabilitÃ© horizontale infinie
âŒ Pas PostgreSQL (SQL propriÃ©taire)
âŒ TrÃ¨s coÃ»teux
```

#### 3. **CockroachDB** (PostgreSQL-compatible)

Base de donnÃ©es distribuÃ©e, compatible PostgreSQL wire protocol.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node EU â”‚â”€â”€â”€â”€â†’â”‚  Node US â”‚â”€â”€â”€â”€â†’â”‚ Node Asiaâ”‚
â”‚  (Paris) â”‚     â”‚  (NY)    â”‚     â”‚ (Tokyo)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                â†“                â†“
   Multi-active - Writes partout
   Consensus: Raft protocol

âœ… Multi-region native
âœ… Failover automatique
âœ… Compatible PostgreSQL (90%)
âŒ Limitations SQL (pas 100% compatible)
âŒ CoÃ»t significatif
```

#### 4. **Crunchy Data Bridge** (Patroni as a Service)

Solution managÃ©e basÃ©e sur Patroni.

```
âœ… PostgreSQL natif
âœ… HA automatisÃ©e
âœ… Multi-cloud (AWS, Azure, GCP)
âŒ CoÃ»t intermÃ©diaire
```

---

## Checklist de Mise en Production

### âœ… Avant le lancement

- [ ] Architecture multi-rÃ©gion dÃ©finie et validÃ©e
- [ ] Calcul du budget (serveurs, rÃ©seau, Ã©quipe) approuvÃ©
- [ ] RÃ©gions gÃ©ographiques sÃ©lectionnÃ©es
- [ ] Infrastructure provisionnÃ©e (serveurs, rÃ©seau)
- [ ] PostgreSQL installÃ© et configurÃ© sur tous les nÅ“uds
- [ ] RÃ©plication configurÃ©e et testÃ©e
- [ ] Monitoring dÃ©ployÃ© (Prometheus, Grafana)
- [ ] Alertes configurÃ©es (PagerDuty, Slack)
- [ ] HAProxy ou DNS geo-routing configurÃ©
- [ ] Tests de failover rÃ©ussis
- [ ] Runbooks documentÃ©s
- [ ] Ã‰quipe formÃ©e aux procÃ©dures

### âœ… Validation prÃ©-production

- [ ] Test de charge avec rÃ©plication active
- [ ] Test de failover sous charge
- [ ] Mesure du lag de rÃ©plication sous charge
- [ ] Test de restauration PITR multi-rÃ©gions
- [ ] Test de panne rÃ©seau inter-rÃ©gions
- [ ] Validation des performances applicatives
- [ ] Test de migration de schÃ©ma
- [ ] Disaster recovery drill complet

### âœ… En production

- [ ] Monitoring 24/7 actif
- [ ] Astreinte configurÃ©e
- [ ] Communication stakeholders prÃ©parÃ©e
- [ ] Plan de rollback documentÃ©
- [ ] Observability (logs, metrics, traces)
- [ ] Tests DR trimestriels planifiÃ©s
- [ ] Post-mortems aprÃ¨s chaque incident
- [ ] Revue architecture semestrielle

---

## Conclusion

La gÃ©o-rÃ©plication et les architectures multi-rÃ©gions apportent une **rÃ©silience exceptionnelle** et de **meilleures performances** pour vos utilisateurs globaux, mais au prix d'une **complexitÃ© et d'un coÃ»t significatifs**.

### Quand mettre en place une gÃ©o-rÃ©plication ?

**Vous DEVRIEZ mettre en place une gÃ©o-rÃ©plication si :**

- âœ… Votre entreprise ne peut tolÃ©rer une panne rÃ©gionale (e-commerce, finance)
- âœ… Vous avez des utilisateurs sur plusieurs continents
- âœ… Vous devez respecter des rÃ©glementations de rÃ©sidence des donnÃ©es
- âœ… Votre budget le permet (Ã— 2-3 votre coÃ»t infrastructure)
- âœ… Vous avez une Ã©quipe technique expÃ©rimentÃ©e

**Vous DEVRIEZ attendre si :**

- âŒ Votre traffic est principalement dans une seule rÃ©gion
- âŒ Vous Ãªtes une startup en early-stage
- âŒ Votre Ã©quipe technique est rÃ©duite (< 3 personnes)
- âŒ Une panne de quelques heures est acceptable
- âŒ Votre budget infrastructure est limitÃ©

### Les clÃ©s du succÃ¨s

1. **Commencez simple** : Primary-Standby asynchrone dans 2 rÃ©gions
2. **Testez rÃ©guliÃ¨rement** : Failovers, DR drills
3. **Monitorez intensÃ©ment** : Latence rÃ©seau, replication lag
4. **Documentez tout** : Runbooks, architectures, procÃ©dures
5. **Automatisez** : Patroni pour failover, Terraform pour infra
6. **PrÃ©parez l'Ã©quipe** : Formation, astreinte, post-mortems

### Ã‰volution progressive recommandÃ©e

```
Phase 1 (Mois 1-3):
â”œâ”€ Single-region avec HA locale (Patroni)
â””â”€ Tests et stabilisation

Phase 2 (Mois 4-6):
â”œâ”€ Ajout d'une 2Ã¨me rÃ©gion (Standby asynchrone)
â”œâ”€ RÃ©plication physique
â””â”€ Tests de failover

Phase 3 (Mois 7-12):
â”œâ”€ Ajout d'une 3Ã¨me rÃ©gion
â”œâ”€ Optimisation du routing (HAProxy/DNS)
â””â”€ Monitoring avancÃ©

Phase 4 (AnnÃ©e 2+):
â”œâ”€ RÃ©plication logique pour donnÃ©es partitionnÃ©es
â”œâ”€ Multi-primary pour certaines tables
â””â”€ AmÃ©lioration continue
```

### Pour aller plus loin

**Prochains chapitres :**
- **19.6. Checklist de mise en production** : Best practices complÃ¨tes
- **20. Drivers et connexion applicative** : IntÃ©gration avec les applications
- **20bis. Architectures modernes** : Microservices, Event Sourcing, Serverless

**Ressources recommandÃ©es :**
- [PostgreSQL High Availability](https://www.postgresql.org/docs/current/high-availability.html)
- [Patroni Documentation](https://patroni.readthedocs.io/)
- Livre : *PostgreSQL High Availability Cookbook* - Shaun Thomas
- ConfÃ©rence : PGConf - Sessions sur HA et rÃ©plication

---

> *"La meilleure haute disponibilitÃ© est celle qu'on a testÃ©e. La meilleure gÃ©o-rÃ©plication est celle qu'on a failovÃ©e."*
> â€” Proverbe DBA

â­ï¸ [Checklist de mise en production (Best Practices)](/19-postgresql-en-production/06-checklist-mise-en-production.md)
