üîù Retour au [Sommaire](/SOMMAIRE.md)

# 19.4.6. Connection storms et pooling

## Introduction : Quand les connexions deviennent un probl√®me

Imaginez un restaurant avec seulement 10 tables. Si 100 clients arrivent en m√™me temps, le chaos s'installe : certains attendent debout, les serveurs sont d√©bord√©s, la cuisine est satur√©e. C'est exactement ce qui se passe lors d'un **connection storm** (temp√™te de connexions) dans PostgreSQL.

Contrairement √† ce qu'on pourrait penser, PostgreSQL ne g√®re **pas** des milliers de connexions simultan√©es facilement. Chaque connexion consomme des ressources (m√©moire, CPU) et au-del√† d'un certain seuil, les performances s'effondrent.

**Dans ce chapitre, vous apprendrez** :
- Pourquoi trop de connexions posent probl√®me
- Comment d√©tecter un connection storm
- Le concept de connection pooling
- PgBouncer : la solution la plus populaire
- Les bonnes pratiques pour g√©rer les connexions

---

## Partie 1 : Comprendre le probl√®me des connexions

### Comment PostgreSQL g√®re les connexions

PostgreSQL utilise une architecture **process-per-connection** : chaque connexion client = un processus backend distinct.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Client 1  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Client 2  ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ  PostgreSQL      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  (Postmaster)    ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ         ‚îÇ
‚îÇ   Client 3  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Backend 1 (PID) ‚îÇ
                    ‚îÇ  Backend 2 (PID) ‚îÇ
                    ‚îÇ  Backend 3 (PID) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Cons√©quence** : Chaque connexion cr√©e un processus syst√®me complet avec :
- M√©moire propre (~10 MB par connexion)
- Ressources CPU pour la gestion
- Overhead de synchronisation entre processus

### Le co√ªt d'une connexion

```sql
-- Voir la m√©moire utilis√©e par connexion
SELECT
    pid,
    usename,
    application_name,
    pg_size_pretty(
        pg_backend_memory_contexts.total_bytes
    ) AS memory_used
FROM pg_stat_activity
JOIN pg_backend_memory_contexts ON pg_stat_activity.pid = pg_backend_memory_contexts.pid
ORDER BY pg_backend_memory_contexts.total_bytes DESC
LIMIT 10;
```

**Co√ªts typiques par connexion** :
- M√©moire de base : ~5-10 MB
- M√©moire work_mem (si utilis√©e) : 64 MB par d√©faut
- CPU : Context switching, gestion des verrous
- Connexion/d√©connexion : ~5-10 ms par cycle

### La limite th√©orique

```sql
-- Voir les connexions configur√©es
SHOW max_connections;
-- Valeur par d√©faut : 100

-- Voir les connexions actuellement utilis√©es
SELECT count(*) FROM pg_stat_activity;
```

**Calcul de m√©moire potentielle** :

```
Configuration :
- max_connections = 200
- work_mem = 64 MB

M√©moire potentielle = 200 √ó (10 MB base + 64 MB work_mem √ó 2-4 op√©rations)
                    = 200 √ó (10 + 128-256 MB)
                    = 27 GB - 53 GB de RAM !
```

‚ö†Ô∏è **Danger** : Avec seulement 32 GB de RAM, vous risquez un **Out Of Memory** (OOM) !

### Qu'est-ce qu'un connection storm ?

Un **connection storm** se produit quand un grand nombre de connexions sont cr√©√©es en tr√®s peu de temps.

**Sc√©narios typiques** :
1. **Application red√©marre** : Tous les workers se reconnectent en m√™me temps
2. **Traffic spike** : Pic soudain de trafic (Black Friday, annonce virale)
3. **Retry loops** : Application retry automatiquement apr√®s √©chec, cr√©ant une boucle
4. **Load balancer mal configur√©** : Ouvre trop de connexions
5. **Fonction serverless** : Chaque invocation = nouvelle connexion

### Sympt√¥mes d'un connection storm

#### 1. Erreurs de connexion

```
FATAL: sorry, too many clients already
FATAL: remaining connection slots are reserved for non-replication superuser connections
```

#### 2. Performances d√©grad√©es

```sql
-- Voir le nombre de connexions actives
SELECT
    count(*) FILTER (WHERE state = 'active') as active,
    count(*) FILTER (WHERE state = 'idle') as idle,
    count(*) FILTER (WHERE state = 'idle in transaction') as idle_in_transaction,
    count(*) as total
FROM pg_stat_activity;
```

**R√©sultat probl√©matique** :
```
 active | idle | idle_in_transaction | total
--------+------+---------------------+-------
    450 |  200 |                  50 |   700
```

Si `total` approche `max_connections` (ex: 800 connexions pour max_connections=800), vous √™tes en saturation !

#### 3. Syst√®me surcharg√©

```bash
# CPU √©lev√© pour gestion des processus
top
# Charge : load average > nombre de c≈ìurs √ó 3

# Beaucoup de processus PostgreSQL
ps aux | grep postgres | wc -l
# R√©sultat : 700+ processus
```

---

## Partie 2 : D√©tecter et diagnostiquer

### Monitoring des connexions

#### Vue d'ensemble des connexions

```sql
SELECT
    datname,
    count(*) as connections,
    max(now() - backend_start) as oldest_connection
FROM pg_stat_activity
WHERE pid != pg_backend_pid()
GROUP BY datname
ORDER BY connections DESC;
```

**Exemple de r√©sultat** :
```
  datname  | connections | oldest_connection
-----------+-------------+-------------------
 mydb      |         650 | 02:34:56.789012
 postgres  |          10 | 01:23:45.678901
```

#### Connexions par utilisateur et application

```sql
SELECT
    usename,
    application_name,
    count(*) as connection_count,
    count(*) FILTER (WHERE state = 'active') as active,
    count(*) FILTER (WHERE state = 'idle') as idle
FROM pg_stat_activity
GROUP BY usename, application_name
ORDER BY connection_count DESC;
```

**R√©sultat typique d'un probl√®me** :
```
  usename  | application_name | connection_count | active | idle
-----------+------------------+------------------+--------+------
 app_user  | MyWebApp         |              580 |     45 |  535
 app_user  | BackgroundJob    |               80 |     12 |   68
```

**Analyse** : 580 connexions pour une application web = **PROBL√àME** !
- Pourquoi autant de connexions idle ?
- L'application ouvre-t-elle trop de connexions ?
- Y a-t-il des connection leaks ?

#### Identifier les connexions probl√©matiques

```sql
-- Connexions idle depuis longtemps
SELECT
    pid,
    usename,
    application_name,
    client_addr,
    backend_start,
    state,
    state_change,
    now() - state_change as idle_duration
FROM pg_stat_activity
WHERE state = 'idle'
  AND now() - state_change > interval '10 minutes'
ORDER BY state_change;
```

**Connexions "idle in transaction"** (tr√®s probl√©matiques) :

```sql
SELECT
    pid,
    usename,
    application_name,
    now() - xact_start as transaction_duration,
    query
FROM pg_stat_activity
WHERE state = 'idle in transaction'
  AND now() - xact_start > interval '5 minutes';
```

‚ö†Ô∏è Ces connexions **bloquent** VACUUM et peuvent causer des probl√®mes de performance !

### Visualisation graphique

```sql
-- Connexions par √©tat (pour graphique)
SELECT
    state,
    count(*) as count
FROM pg_stat_activity
GROUP BY state;
```

**R√©sultat √† exporter vers Grafana** :
```
        state         | count
----------------------+-------
 active               |    45
 idle                 |   520
 idle in transaction  |    15
 disabled             |     0
```

### Alertes proactives

```sql
-- Cr√©er une fonction d'alerte
CREATE OR REPLACE FUNCTION check_connection_saturation()
RETURNS TABLE(
    max_conn int,
    current_conn bigint,
    percent_used numeric,
    status text
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        current_setting('max_connections')::int as max_conn,
        count(*)::bigint as current_conn,
        round(100.0 * count(*) / current_setting('max_connections')::numeric, 2) as percent_used,
        CASE
            WHEN count(*) > current_setting('max_connections')::numeric * 0.9 THEN 'CRITICAL'
            WHEN count(*) > current_setting('max_connections')::numeric * 0.75 THEN 'WARNING'
            ELSE 'OK'
        END as status
    FROM pg_stat_activity;
END;
$$ LANGUAGE plpgsql;

-- Utiliser
SELECT * FROM check_connection_saturation();
```

---

## Partie 3 : Connection Pooling - La solution

### Qu'est-ce que le connection pooling ?

Le **connection pooling** est comme un syst√®me de location de voitures :
- Au lieu que chaque personne ach√®te sa propre voiture (connexion d√©di√©e)
- On partage un parc de voitures (pool de connexions)
- Quand vous avez besoin, vous louez une voiture
- Quand vous avez fini, vous la rendez au pool

```
SANS POOLING :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client1 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Conn1   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  SGBD   ‚îÇ
‚îÇ Client2 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Conn2   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ (500    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  conn)  ‚îÇ
‚îÇ Client3 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Conn3   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ...           ...
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client500‚îÄ‚îÄ‚îÄ ‚îÇ Conn500 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Probl√®me : 500 connexions = Saturation !


AVEC POOLING :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client1 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client2 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚ñ∂‚îÇ  Connection  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ Conn1   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚îÇ     Pool     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ Conn2   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ SGBD
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  ‚îÇ  (PgBouncer) ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ Conn3   ‚îÇ   (3 conn)
‚îÇ Client3 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ...    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ Conn20  ‚îÇ
     ...                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client500
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Solution : 500 clients ‚Üí 20 connexions r√©elles !
```

### Avantages du pooling

| Aspect | Sans Pooling | Avec Pooling |
|--------|--------------|--------------|
| Connexions SGBD | 1 par client | Partag√©es |
| M√©moire PostgreSQL | 500 √ó 10MB = 5GB | 20 √ó 10MB = 200MB |
| Overhead connexion | 5-10ms par requ√™te | 0.1ms (r√©utilisation) |
| Scalabilit√© | Limit√©e (max_connections) | Illimit√©e c√¥t√© app |
| Performances | D√©grad√©es > 200 conn | Stables |

### Types de pooling

#### 1. Session Pooling (par session)

```
Client connect ‚Üí Get connection ‚Üí Keep connection ‚Üí Client disconnect
                                   (toute la session)
```

**Caract√©ristiques** :
- Une connexion = une session client compl√®te
- TOUTES les fonctionnalit√©s PostgreSQL disponibles
- Prepared statements, temporary tables, cursors : OK
- Moins d'√©conomie de connexions

**Cas d'usage** : Applications avec sessions longues, utilisant features avanc√©es.

#### 2. Transaction Pooling (par transaction)

```
Client ‚Üí BEGIN ‚Üí Get connection ‚Üí COMMIT ‚Üí Release connection
```

**Caract√©ristiques** :
- Connexion rendue apr√®s chaque transaction
- Maximum d'√©conomie de connexions
- Limitations : Pas de prepared statements entre transactions
- Pas de session state (SET commands limit√©s)

**Cas d'usage** : APIs web, microservices (recommand√©).

#### 3. Statement Pooling (par requ√™te)

```
Client ‚Üí Query ‚Üí Get connection ‚Üí Execute ‚Üí Release connection
```

**Caract√©ristiques** :
- Connexion rendue apr√®s **chaque requ√™te**
- √âconomie maximale mais limitations majeures
- Pas de transactions multi-requ√™tes
- Rarement utilis√©

**Cas d'usage** : Tr√®s rare, seulement pour read-only queries simples.

---

## Partie 4 : PgBouncer - Le pooler de r√©f√©rence

### Qu'est-ce que PgBouncer ?

**PgBouncer** est un connection pooler l√©ger et ultra-performant pour PostgreSQL. C'est la solution la plus utilis√©e en production.

**Avantages** :
- ‚úÖ Tr√®s l√©ger (< 10 MB RAM)
- ‚úÖ Tr√®s rapide (~2 MB/s overhead)
- ‚úÖ Facile √† configurer
- ‚úÖ Support transaction et session pooling
- ‚úÖ Peut g√©rer 10,000+ connexions clients

### Installation de PgBouncer

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install pgbouncer

# CentOS/RHEL
sudo yum install pgbouncer

# macOS
brew install pgbouncer

# V√©rifier l'installation
pgbouncer --version
```

### Configuration de base

#### Fichier pgbouncer.ini

```ini
[databases]
mydb = host=localhost port=5432 dbname=mydb

[pgbouncer]
# Mode de pooling (RECOMMAND√â pour web apps)
pool_mode = transaction

# Connexions
listen_addr = 0.0.0.0
listen_port = 6432
auth_type = scram-sha-256
auth_file = /etc/pgbouncer/userlist.txt

# Limites connexions
max_client_conn = 10000          # Connexions clients max
default_pool_size = 25           # Connexions PostgreSQL par base
min_pool_size = 5                # Connexions minimum gard√©es
reserve_pool_size = 5            # Connexions de r√©serve
reserve_pool_timeout = 3         # Timeout pour obtenir connexion (secondes)

# Logs
log_connections = 1
log_disconnections = 1
log_pooler_errors = 1

# Performance
max_db_connections = 100         # Limite totale connexions PostgreSQL
ignore_startup_parameters = extra_float_digits

# S√©curit√©
admin_users = postgres
stats_users = postgres, monitoring_user
```

**Explication des param√®tres cl√©s** :

| Param√®tre | Description | Valeur recommand√©e |
|-----------|-------------|--------------------|
| `pool_mode` | transaction\|session\|statement | `transaction` |
| `max_client_conn` | Connexions clients max | 10000 |
| `default_pool_size` | Connexions PostgreSQL par DB | 25 |
| `reserve_pool_size` | Connexions r√©serve | 5 |

#### Fichier userlist.txt (authentification)

```bash
# Format : "username" "password" (hashed avec SCRAM-SHA-256)
# Obtenir le hash :
echo -n "passwordMD5$(echo -n 'passwordusername' | md5sum | awk '{print $1}')" | md5sum

# Ou utiliser le format SCRAM (PostgreSQL 10+)
"app_user" "SCRAM-SHA-256$4096:salt:hash:serverkey"

# Pour d√©veloppement (INSECURE) :
"app_user" "plain_password"
```

**M√©thode recommand√©e** : Copier depuis PostgreSQL

```sql
-- Dans PostgreSQL, voir le hash du mot de passe
SELECT rolname, rolpassword
FROM pg_authid
WHERE rolname = 'app_user';

-- Copier ce hash dans userlist.txt
```

### D√©marrer PgBouncer

```bash
# D√©marrer
sudo systemctl start pgbouncer

# Activer au d√©marrage
sudo systemctl enable pgbouncer

# V√©rifier le statut
sudo systemctl status pgbouncer

# Voir les logs
sudo tail -f /var/log/postgresql/pgbouncer.log
```

### Se connecter via PgBouncer

```bash
# Connexion client ‚Üí PgBouncer (port 6432)
psql -h localhost -p 6432 -U app_user -d mydb

# PgBouncer ‚Üí PostgreSQL (port 5432)
# (g√©r√© automatiquement par PgBouncer)
```

### Console d'administration PgBouncer

```bash
# Se connecter √† la console d'admin
psql -h localhost -p 6432 -U postgres pgbouncer

# Commandes disponibles :
pgbouncer=# SHOW HELP;
```

**Commandes utiles** :

```sql
-- Voir les statistiques
SHOW STATS;

-- Voir les pools de connexions
SHOW POOLS;

-- Voir les clients connect√©s
SHOW CLIENTS;

-- Voir les connexions PostgreSQL
SHOW SERVERS;

-- Voir la configuration
SHOW CONFIG;

-- Recharger la configuration (sans red√©marrage)
RELOAD;

-- Suspendre les connexions (maintenance)
PAUSE;

-- Reprendre
RESUME;

-- Tuer une connexion client
KILL client_addr;
```

#### SHOW POOLS (exemple de r√©sultat)

```
 database  |   user   | cl_active | cl_waiting | sv_active | sv_idle | sv_used | sv_tested | sv_login | maxwait | pool_mode
-----------+----------+-----------+------------+-----------+---------+---------+-----------+----------+---------+-----------
 mydb      | app_user |        12 |          0 |        12 |      13 |       0 |         0 |        0 |       0 | transaction
```

**Interpr√©tation** :
- `cl_active` : 12 clients actifs
- `cl_waiting` : 0 clients en attente (bon signe !)
- `sv_active` : 12 connexions PostgreSQL actives
- `sv_idle` : 13 connexions PostgreSQL idle (disponibles)
- **25 connexions PostgreSQL** au total (12 + 13) = `default_pool_size`

#### SHOW STATS (exemple de r√©sultat)

```
 database  | total_xact_count | total_query_count | total_received | total_sent | total_xact_time | total_query_time | total_wait_time | avg_xact_count | avg_query_count | avg_recv | avg_sent | avg_xact_time | avg_query_time | avg_wait_time
-----------+------------------+-------------------+----------------+------------+-----------------+------------------+-----------------+----------------+-----------------+----------+----------+---------------+----------------+---------------
 mydb      |          1234567 |           2345678 |      123456789 |   98765432 |       123456789 |        234567890 |            1234 |            123 |             234 |    12345 |     9876 |           123 |            234 |             1
```

**M√©triques importantes** :
- `total_xact_count` : Nombre de transactions trait√©es
- `avg_wait_time` : Temps d'attente moyen (doit √™tre < 1ms)
- `total_query_time` / `total_query_count` : Latence moyenne

---

## Partie 5 : Configuration optimale

### Dimensionner le pool

**Formule de base** :

```
default_pool_size = Nombre de c≈ìurs CPU √ó 2 √† 4
```

**Exemples** :

| Serveur | C≈ìurs CPU | default_pool_size | Justification |
|---------|-----------|-------------------|---------------|
| Petit (dev) | 2 | 8-10 | 2 √ó 4 |
| Moyen (prod) | 8 | 20-30 | 8 √ó 3 |
| Grand (prod) | 32 | 80-100 | 32 √ó 3 |

**R√®gle importante** : Plus n'est pas toujours mieux !
- Trop de connexions PostgreSQL = contention, context switching
- Optimal : Garder CPU √† 70-80% d'utilisation

### Configuration par base de donn√©es

```ini
[databases]
# Base principale (beaucoup de traffic)
mydb = host=localhost port=5432 dbname=mydb pool_size=50

# Base analytics (requ√™tes lourdes, peu de concurrence)
analytics = host=localhost port=5432 dbname=analytics pool_size=10 pool_mode=session

# Base de reporting (read-only)
reports = host=replica.example.com port=5432 dbname=mydb pool_size=20
```

### Transaction pooling : Limitations et solutions

#### Probl√®me : Prepared Statements

```python
# ‚ùå NE FONCTIONNE PAS avec transaction pooling
conn = psycopg2.connect("host=pgbouncer port=6432 dbname=mydb")
cursor = conn.cursor()
cursor.execute("PREPARE myplan AS SELECT * FROM users WHERE id = $1")
cursor.execute("EXECUTE myplan (123)")  # ERREUR : prepared statement n'existe pas
```

**Solution** : Ne pas utiliser PREPARE/EXECUTE explicites. Les drivers modernes g√®rent √ßa automatiquement avec le protocole Extended Query.

```python
# ‚úÖ FONCTIONNE : Utilise le protocole Extended Query
cursor.execute("SELECT * FROM users WHERE id = %s", (123,))
```

#### Probl√®me : Temporary Tables

```sql
-- ‚ùå NE FONCTIONNE PAS : table perdue apr√®s transaction
BEGIN;
CREATE TEMP TABLE temp_data (id int);
INSERT INTO temp_data VALUES (1), (2);
COMMIT;

-- Nouvelle transaction = nouvelle connexion = table perdue !
SELECT * FROM temp_data;  -- ERROR: relation does not exist
```

**Solution 1** : Tout faire dans une transaction
```sql
BEGIN;
CREATE TEMP TABLE temp_data (id int);
INSERT INTO temp_data VALUES (1), (2);
-- Utiliser la table
SELECT * FROM temp_data;
-- Nettoyage automatique
COMMIT;
```

**Solution 2** : Utiliser CTE au lieu de TEMP TABLE
```sql
WITH temp_data AS (
    SELECT generate_series(1, 100) as id
)
SELECT * FROM temp_data WHERE id < 10;
```

#### Probl√®me : Session variables

```sql
-- ‚ùå PEUT NE PAS FONCTIONNER
SET work_mem = '256MB';  -- Perdu apr√®s transaction

-- ‚úÖ FONCTIONNE : SET LOCAL dans transaction
BEGIN;
SET LOCAL work_mem = '256MB';
-- Requ√™te lourde ici
COMMIT;
```

**Configuration PgBouncer** pour autoriser certains SET :

```ini
[pgbouncer]
# Ignorer ces param√®tres (ne pas les r√©initialiser)
ignore_startup_parameters = extra_float_digits,options

# Autoriser ces commandes SET
server_reset_query = DISCARD ALL
server_reset_query_always = 0
```

### Monitoring PgBouncer

#### M√©triques √† surveiller

```sql
-- Dans la console PgBouncer
SHOW POOLS;

-- M√©triques cl√©s :
-- cl_waiting > 0 : Clients en attente ‚Üí Augmenter pool_size
-- sv_active ‚âà pool_size : Pool satur√© ‚Üí Augmenter pool_size
-- avg_wait_time > 1ms : Latence √©lev√©e ‚Üí Probl√®me de sizing
```

#### Exporter vers Prometheus

```bash
# Installer pgbouncer_exporter
wget https://github.com/prometheus-community/pgbouncer_exporter/releases/download/v0.7.0/pgbouncer_exporter-0.7.0.linux-amd64.tar.gz
tar xvfz pgbouncer_exporter-0.7.0.linux-amd64.tar.gz
cd pgbouncer_exporter-0.7.0.linux-amd64

# Lancer l'exporter
./pgbouncer_exporter \
  --pgBouncer.connectionString="postgres://stats_user:password@localhost:6432/pgbouncer?sslmode=disable"
```

**Dashboards Grafana** recommand√©s :
- PgBouncer Dashboard (ID: 12421)

---

## Partie 6 : Alternatives et solutions compl√©mentaires

### 1. pgpool-II

**Caract√©ristiques** :
- Plus de fonctionnalit√©s que PgBouncer (load balancing, replication)
- Plus complexe √† configurer
- Plus de overhead

**Cas d'usage** : Quand vous avez besoin de load balancing automatique + pooling.

```bash
# Installation
sudo apt install pgpool2

# Configuration de base
/etc/pgpool2/pgpool.conf
```

### 2. Connection Pooling int√©gr√© aux applications

#### Python (psycopg2)

```python
from psycopg2 import pool

# Cr√©er un pool de connexions
connection_pool = pool.SimpleConnectionPool(
    minconn=5,      # Minimum 5 connexions
    maxconn=20,     # Maximum 20 connexions
    host="localhost",
    database="mydb",
    user="app_user",
    password="secret"
)

# Utiliser une connexion
conn = connection_pool.getconn()
try:
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM users")
    results = cursor.fetchall()
finally:
    # IMPORTANT : Rendre la connexion au pool
    connection_pool.putconn(conn)
```

#### Node.js (node-postgres)

```javascript
const { Pool } = require('pg');

const pool = new Pool({
  host: 'localhost',
  database: 'mydb',
  user: 'app_user',
  password: 'secret',
  max: 20,                  // Maximum 20 connexions
  idleTimeoutMillis: 30000, // Timeout connexion idle
  connectionTimeoutMillis: 2000,
});

// Utiliser le pool
pool.query('SELECT * FROM users', (err, result) => {
  console.log(result.rows);
});
```

#### Java (HikariCP)

```java
HikariConfig config = new HikariConfig();
config.setJdbcUrl("jdbc:postgresql://localhost:5432/mydb");
config.setUsername("app_user");
config.setPassword("secret");
config.setMaximumPoolSize(20);
config.setMinimumIdle(5);

HikariDataSource ds = new HikariDataSource(config);

// Utiliser
Connection conn = ds.getConnection();
try {
    Statement stmt = conn.createStatement();
    ResultSet rs = stmt.executeQuery("SELECT * FROM users");
    // ...
} finally {
    conn.close(); // Rend au pool
}
```

**Avantage** : Pas de composant externe.
**Inconv√©nient** : Chaque instance d'application a son propre pool.

### 3. AWS RDS Proxy (Cloud)

Pour PostgreSQL sur AWS RDS :

```
Application ‚Üí RDS Proxy ‚Üí RDS PostgreSQL
   (10000)      (100)       (100 connexions)
```

**Avantages** :
- G√©r√© par AWS (pas de maintenance)
- Connection pooling automatique
- Failover automatique
- Int√©gration IAM

**Configuration** :
```bash
# Via AWS CLI
aws rds create-db-proxy \
  --db-proxy-name mydb-proxy \
  --engine-family POSTGRESQL \
  --auth {...} \
  --role-arn {...} \
  --vpc-subnet-ids subnet-xxx subnet-yyy
```

### 4. Azure Database for PostgreSQL - Connection Pooling

Azure propose √©galement un pooling int√©gr√©.

### 5. Supabase / Neon (Serverless PostgreSQL)

Ces services cloud incluent du connection pooling natif optimis√© pour serverless.

---

## Partie 7 : Bonnes pratiques

### 1. Fermer les connexions correctement

```python
# ‚ùå MAUVAIS : Connection leak
def get_users():
    conn = psycopg2.connect(...)
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM users")
    return cursor.fetchall()
    # Connexion jamais ferm√©e !

# ‚úÖ BON : Utiliser context manager
def get_users():
    with psycopg2.connect(...) as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM users")
            return cursor.fetchall()
    # Connexion ferm√©e automatiquement
```

### 2. Configurer les timeouts

```python
# Application
conn = psycopg2.connect(
    host="localhost",
    database="mydb",
    connect_timeout=5,      # Timeout connexion
    options="-c statement_timeout=30000"  # Timeout requ√™te (30s)
)
```

```sql
-- PostgreSQL
-- Dans postgresql.conf
idle_in_transaction_session_timeout = 60000  # 60 secondes
statement_timeout = 30000  # 30 secondes
```

```ini
# PgBouncer
[pgbouncer]
query_timeout = 30
query_wait_timeout = 5
idle_transaction_timeout = 60
```

### 3. √âviter les connexions long-lived

```python
# ‚ùå MAUVAIS : Connexion gard√©e toute la dur√©e de vie de l'app
class MyApp:
    def __init__(self):
        self.conn = psycopg2.connect(...)  # Garde la connexion

    def do_something(self):
        cursor = self.conn.cursor()
        # ...

# ‚úÖ BON : Connexion par requ√™te (avec pool)
class MyApp:
    def __init__(self):
        self.pool = create_pool(...)

    def do_something(self):
        with self.pool.get_connection() as conn:
            cursor = conn.cursor()
            # ...
        # Connexion rendue au pool
```

### 4. Dimensionner en fonction de la charge

```
R√®gle empirique :

Connexions PostgreSQL = Nombre de c≈ìurs CPU √ó 2 √† 4

Exemples :
- Serveur 4 c≈ìurs : 10-15 connexions
- Serveur 8 c≈ìurs : 20-30 connexions
- Serveur 16 c≈ìurs : 40-60 connexions
```

**Validation** : Surveiller CPU et load average
- Si CPU < 70% : Peut augmenter connexions
- Si CPU > 90% : Trop de connexions, r√©duire

### 5. S√©parer les workloads

```ini
# PgBouncer : Diff√©rents pools pour diff√©rents usages

[databases]
# API web : Transaction pooling, petit pool
api_db = host=localhost dbname=mydb pool_size=25 pool_mode=transaction

# Background jobs : Session pooling, pool moyen
jobs_db = host=localhost dbname=mydb pool_size=15 pool_mode=session

# Analytics : Session pooling, grand pool
analytics_db = host=replica dbname=mydb pool_size=50 pool_mode=session
```

### 6. Tester sous charge

```bash
# Utiliser pgbench pour simuler charge
pgbench -h localhost -p 6432 -U app_user -c 100 -j 4 -T 300 mydb

# -c 100 : 100 clients simultan√©s
# -j 4 : 4 threads
# -T 300 : Test de 5 minutes
```

---

## Partie 8 : Troubleshooting

### Probl√®me 1 : "too many clients already"

**Sympt√¥me** :
```
FATAL: sorry, too many clients already
```

**Diagnostic** :

```sql
-- Voir les connexions actuelles
SELECT count(*), state
FROM pg_stat_activity
GROUP BY state;

SHOW max_connections;
```

**Solutions** :

1. **Imm√©diat** : Tuer les connexions idle
```sql
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE state = 'idle'
  AND now() - state_change > interval '10 minutes';
```

2. **Court terme** : Augmenter max_connections
```sql
-- Dans postgresql.conf
max_connections = 200  # Au lieu de 100

-- Red√©marrer
sudo systemctl restart postgresql
```

3. **Long terme** : Impl√©menter PgBouncer
```ini
# Permet 10000 clients avec seulement 25 connexions PostgreSQL
max_client_conn = 10000
default_pool_size = 25
```

### Probl√®me 2 : Clients en attente (cl_waiting > 0)

**Sympt√¥me dans PgBouncer** :
```
SHOW POOLS;
# cl_waiting > 0 constamment
```

**Causes** :
- Pool trop petit
- Requ√™tes lentes monopolisent connexions
- Transactions non ferm√©es

**Diagnostic** :

```sql
-- Voir les requ√™tes actives longues
SELECT pid, now() - query_start as duration, query
FROM pg_stat_activity
WHERE state = 'active'
ORDER BY duration DESC
LIMIT 10;
```

**Solutions** :

1. Augmenter pool_size
```ini
default_pool_size = 50  # Au lieu de 25
```

2. Optimiser les requ√™tes lentes (voir chapitre Query Tuning)

3. Configurer timeouts
```ini
query_timeout = 30
query_wait_timeout = 5
```

### Probl√®me 3 : Connection leaks

**Sympt√¥me** : Nombre de connexions augmente continuellement.

**Diagnostic** :

```python
# Script de test pour d√©tecter leaks
import psycopg2
import time

for i in range(100):
    conn = psycopg2.connect(...)
    # Oublier de fermer : conn.close()
    time.sleep(1)

# R√©sultat : 100 connexions ouvertes !
```

**Solution** : Toujours utiliser context managers ou try/finally

```python
# ‚úÖ BON
try:
    conn = psycopg2.connect(...)
    # Utiliser conn
finally:
    conn.close()

# Ou mieux : context manager
with psycopg2.connect(...) as conn:
    # Utiliser conn
    pass
# Fermeture automatique
```

### Probl√®me 4 : PgBouncer ne d√©marre pas

**Erreurs communes** :

```bash
# Erreur : permission denied
# Solution : V√©rifier les permissions
sudo chown pgbouncer:pgbouncer /etc/pgbouncer/*
sudo chmod 600 /etc/pgbouncer/userlist.txt

# Erreur : could not connect to server
# Solution : V√©rifier pg_hba.conf
# Ajouter dans PostgreSQL /etc/postgresql/*/main/pg_hba.conf :
host    all    all    127.0.0.1/32    scram-sha-256

# Recharger PostgreSQL
sudo systemctl reload postgresql
```

---

## Partie 9 : Monitoring et alertes

### M√©triques critiques √† surveiller

#### 1. Nombre de connexions

```sql
-- Alerte si > 80% de max_connections
SELECT
    current_setting('max_connections')::int as max,
    count(*) as current,
    round(100.0 * count(*) / current_setting('max_connections')::int, 2) as percent
FROM pg_stat_activity;
```

**Seuil d'alerte** : > 80%

#### 2. Connexions idle in transaction

```sql
-- Alerte si > 10 connexions idle in transaction
SELECT count(*)
FROM pg_stat_activity
WHERE state = 'idle in transaction';
```

**Seuil d'alerte** : > 10 connexions

#### 3. PgBouncer : Clients en attente

```sql
-- Dans console PgBouncer
SHOW POOLS;

-- Alerte si cl_waiting > 0 pendant > 1 minute
```

### Dashboard Grafana

**Requ√™tes Prometheus** :

```yaml
# Nombre de connexions PostgreSQL
pg_stat_activity_count

# Connexions par √©tat
pg_stat_activity_count{state="active"}
pg_stat_activity_count{state="idle"}
pg_stat_activity_count{state="idle in transaction"}

# PgBouncer : Clients en attente
pgbouncer_pools_cl_waiting

# PgBouncer : Connexions serveur
pgbouncer_pools_sv_active
pgbouncer_pools_sv_idle
```

### Alertes Prometheus

```yaml
groups:
  - name: postgresql_connections
    rules:
      - alert: PostgreSQLTooManyConnections
        expr: pg_stat_activity_count / pg_settings_max_connections > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQL connections above 80%"

      - alert: PostgreSQLIdleInTransaction
        expr: pg_stat_activity_count{state="idle in transaction"} > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Too many idle in transaction connections"

      - alert: PgBouncerClientsWaiting
        expr: pgbouncer_pools_cl_waiting > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PgBouncer has clients waiting for connections"
```

---

## Partie 10 : Checklist de d√©ploiement

### Avant la mise en production

- [ ] PgBouncer install√© et configur√©
- [ ] `pool_mode = transaction` (sauf besoin sp√©cifique)
- [ ] `default_pool_size` dimensionn√© (CPU √ó 2-4)
- [ ] `max_client_conn` suffisant pour charge attendue
- [ ] Authentification configur√©e (scram-sha-256)
- [ ] Application modifi√©e pour se connecter via PgBouncer
- [ ] Tests de charge effectu√©s (pgbench)
- [ ] Monitoring configur√© (Prometheus + Grafana)
- [ ] Alertes configur√©es
- [ ] Documentation des runbooks

### Apr√®s la mise en production

- [ ] Surveiller m√©triques pendant 48h
- [ ] V√©rifier absence de cl_waiting
- [ ] V√©rifier latence acceptable
- [ ] Ajuster pool_size si n√©cessaire
- [ ] V√©rifier absence de connection leaks
- [ ] Documenter toute anomalie

---

## Configuration de r√©f√©rence

### PostgreSQL (postgresql.conf)

```ini
# CONNEXIONS
max_connections = 100           # R√©duit (PgBouncer g√®re)
superuser_reserved_connections = 5

# TIMEOUTS
idle_in_transaction_session_timeout = 60000  # 60 secondes
statement_timeout = 30000                    # 30 secondes

# Pas besoin de plus avec PgBouncer
```

### PgBouncer (pgbouncer.ini)

```ini
[databases]
mydb = host=localhost port=5432 dbname=mydb

[pgbouncer]
# Connection pooling
listen_addr = 0.0.0.0
listen_port = 6432
pool_mode = transaction
auth_type = scram-sha-256
auth_file = /etc/pgbouncer/userlist.txt

# Pool sizing (adapter selon CPU)
max_client_conn = 10000
default_pool_size = 25      # Pour serveur 8 c≈ìurs
min_pool_size = 5
reserve_pool_size = 5
reserve_pool_timeout = 3

# Timeouts
query_timeout = 30
query_wait_timeout = 5
client_idle_timeout = 600   # 10 minutes
server_idle_timeout = 600
idle_transaction_timeout = 60

# Performance
max_db_connections = 100
server_check_delay = 30
server_check_query = SELECT 1

# Logging
log_connections = 1
log_disconnections = 1
log_pooler_errors = 1
admin_users = postgres
stats_users = postgres, monitoring
```

### Application (Python exemple)

```python
# config.py
DATABASE_CONFIG = {
    'host': 'localhost',
    'port': 6432,  # PgBouncer, pas PostgreSQL direct !
    'database': 'mydb',
    'user': 'app_user',
    'password': 'secret',
    'connect_timeout': 5,
    'options': '-c statement_timeout=30000'
}

# app.py
from psycopg2 import pool

# Cr√©er un pool applicatif (optionnel avec PgBouncer)
app_pool = pool.SimpleConnectionPool(5, 20, **DATABASE_CONFIG)

def get_users():
    conn = app_pool.getconn()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM users")
            return cur.fetchall()
    finally:
        app_pool.putconn(conn)
```

---

## R√©sum√© des points cl√©s

‚úÖ **Connection storms** : Saturation par trop de connexions simultan√©es

‚úÖ **PostgreSQL = process-per-connection** : Chaque connexion co√ªte ~10 MB RAM + CPU

‚úÖ **Limite pratique** : ~200-300 connexions sans pooling

‚úÖ **Connection pooling** : Partage intelligent des connexions

‚úÖ **PgBouncer** : Solution de r√©f√©rence, l√©ger et performant

‚úÖ **Transaction pooling** : Mode recommand√© pour web apps (quelques limitations)

‚úÖ **Dimensionnement** : pool_size = CPU √ó 2 √† 4

‚úÖ **Monitoring** : Surveiller cl_waiting, connections count, idle in transaction

‚úÖ **Timeouts** : Configuration critique pour √©viter connexions zombies

‚úÖ **Tests de charge** : Valider avant production avec pgbench

---

## Conclusion

Le connection pooling est **essentiel** pour toute application PostgreSQL en production. Sans pooling :
- Vous √™tes limit√© √† ~200-300 utilisateurs simultan√©s
- Chaque connexion consomme des ressources pr√©cieuses
- Les connection storms peuvent faire tomber votre base

Avec PgBouncer :
- Vous pouvez g√©rer **10,000+ utilisateurs** avec 25 connexions PostgreSQL
- Overhead minimal (~0.1ms de latence)
- Configuration simple et maintenance facile
- R√©silience accrue face aux pics de charge

**L'investissement temps** pour configurer PgBouncer (1-2 heures) est largement compens√© par :
- √âconomies de ressources (RAM, CPU)
- Meilleure scalabilit√©
- Stabilit√© accrue en production
- Co√ªts d'infrastructure r√©duits

PgBouncer n'est pas une optimisation optionnelle : c'est un **composant standard** de toute infrastructure PostgreSQL professionnelle.

---

**Fin du chapitre 19.4 - Troubleshooting et Crises**

---


‚è≠Ô∏è [Disaster Recovery (DR)](/19-postgresql-en-production/05-disaster-recovery.md)
