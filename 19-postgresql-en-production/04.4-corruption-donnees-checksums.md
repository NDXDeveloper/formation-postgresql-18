ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 19.4.4. Corruption de donnÃ©es et Checksums

## Introduction : Le cauchemar silencieux

La **corruption de donnÃ©es** est le pire scÃ©nario qui puisse arriver Ã  une base de donnÃ©es. Contrairement aux autres problÃ¨mes (verrous, saturation de ressources, wraparound), la corruption peut entraÃ®ner une **perte dÃ©finitive de donnÃ©es**.

Imaginez que votre disque dur est comme un livre gigantesque. La corruption, c'est comme si des pages de ce livre devenaient illisibles, des mots disparaissaient, ou pire, changeaient sans raison. Vous pourriez lire "Solde : 1000â‚¬" alors que la valeur rÃ©elle a Ã©tÃ© corrompue en "Solde : #@$%".

**La bonne nouvelle** :
- âœ… La corruption est **rare** avec du matÃ©riel de qualitÃ©
- âœ… PostgreSQL 18 active les **checksums par dÃ©faut** pour dÃ©tecter la corruption
- âœ… Des stratÃ©gies de prÃ©vention et rÃ©cupÃ©ration existent
- âœ… La majoritÃ© des corruptions sont dÃ©tectables avant de causer des dÃ©gÃ¢ts

Ce chapitre va vous expliquer ce qu'est la corruption, comment la dÃ©tecter, et surtout comment vous en **protÃ©ger**.

---

## Qu'est-ce que la corruption de donnÃ©es ?

### DÃ©finition simple

La corruption de donnÃ©es se produit quand le **contenu physique** d'une base de donnÃ©es ne correspond plus Ã  ce qui a Ã©tÃ© Ã©crit initialement. Les bits stockÃ©s sur le disque sont modifiÃ©s, perdus ou mÃ©langÃ©s.

### Types de corruption

#### 1. Corruption matÃ©rielle (la plus frÃ©quente)

CausÃ©e par des dÃ©faillances physiques :

- **Disque dur dÃ©faillant** : Secteurs dÃ©fectueux qui retournent des donnÃ©es erronÃ©es
- **RAM dÃ©fectueuse** : Erreurs lors du traitement en mÃ©moire (bit flips)
- **CÃ¢bles SATA/SAS dÃ©fectueux** : DonnÃ©es corrompues pendant le transfert
- **ContrÃ´leur RAID buguÃ©** : Erreurs dans la logique de redondance
- **Coupure de courant** : Ã‰criture partielle sur disque

**Analogie** : C'est comme un stylo qui bave sur un document important, rendant certains mots illisibles.

#### 2. Corruption logicielle (rare)

CausÃ©e par des bugs logiciels :

- **Bug dans PostgreSQL** (extrÃªmement rare, mais possible)
- **Bug dans le systÃ¨me de fichiers** (ext4, XFS, ZFS)
- **Bug dans les drivers de stockage**
- **Crash pendant une Ã©criture critique**

#### 3. Corruption induite par l'opÃ©rateur (humaine)

- **ArrÃªt brutal du serveur** (`kill -9` sur postgres)
- **Modification manuelle des fichiers de donnÃ©es** (JAMAIS faire Ã§a !)
- **Clonage de disque pendant que PostgreSQL tourne**
- **Restauration partielle ou incorrecte de sauvegarde**

---

## Les symptÃ´mes de la corruption

### SymptÃ´mes immÃ©diats (erreurs)

```sql
-- Exemples d'erreurs typiques de corruption

ERROR:  invalid page in block 12345 of relation base/16384/16385
ERROR:  could not read block 67890 in file "base/16384/16385": read only 0 of 8192 bytes
ERROR:  invalid page header in block 456 of relation "users"
ERROR:  checksum failure on block 789 in file "base/16384/16385"
WARNING:  page verification failed, calculated checksum 12345 but expected 67890
PANIC:  corrupted page pointers
```

### SymptÃ´mes silencieux (plus dangereux)

- **DonnÃ©es incohÃ©rentes** : Totaux qui ne correspondent pas
- **Lignes qui disparaissent** : SELECT retourne moins de rÃ©sultats qu'attendu
- **Valeurs bizarres** : Nombres nÃ©gatifs impossibles, dates dans le futur
- **Crashes alÃ©atoires** : PostgreSQL redÃ©marre sans raison apparente

### VÃ©rifier les logs PostgreSQL

```bash
# Rechercher des erreurs de corruption dans les logs
sudo tail -f /var/log/postgresql/postgresql-*.log | grep -i "invalid\|corrupt\|checksum\|verification failed"

# Ou consulter les logs complets
sudo grep -i "invalid page\|corrupt\|checksum" /var/log/postgresql/postgresql-*.log
```

---

## Les Checksums : Votre premiÃ¨re ligne de dÃ©fense

### Qu'est-ce qu'un checksum ?

Un **checksum** (ou somme de contrÃ´le) est comme une **empreinte digitale** pour chaque bloc de donnÃ©es. PostgreSQL calcule cette empreinte quand il Ã©crit des donnÃ©es, et la vÃ©rifie quand il les relit.

**Analogie** : Imaginez que vous mettez un cadenas numÃ©rique sur chaque page d'un livre. Si quelqu'un modifie la page, le code du cadenas ne correspondra plus, et vous saurez immÃ©diatement que la page a Ã©tÃ© altÃ©rÃ©e.

### Comment fonctionne un checksum ?

```
1. Ã‰CRITURE de donnÃ©es
   â”œâ”€ PostgreSQL Ã©crit un bloc de 8192 bytes
   â”œâ”€ Calcule un checksum (hash) de ce bloc
   â””â”€ Stocke le checksum dans l'en-tÃªte du bloc

2. LECTURE de donnÃ©es
   â”œâ”€ PostgreSQL lit le bloc depuis le disque
   â”œâ”€ Recalcule le checksum Ã  partir des donnÃ©es lues
   â”œâ”€ Compare avec le checksum stockÃ©
   â””â”€ Si diffÃ©rent â†’ CORRUPTION DÃ‰TECTÃ‰E !
```

### Exemple visuel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BLOC DE DONNÃ‰ES (8192 bytes)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ En-tÃªte (header)                    â”‚
â”‚ â”œâ”€ Checksum: 0xABCD1234 âœ…           â”‚
â”‚ â””â”€ MÃ©tadonnÃ©es diverses             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DonnÃ©es rÃ©elles (lignes de table)   â”‚
â”‚ Row 1: id=1, name="Alice"           â”‚
â”‚ Row 2: id=2, name="Bob"             â”‚
â”‚ ...                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã€ la lecture :
1. Lire le bloc entier
2. Recalculer checksum â†’ 0xABCD1234
3. Comparer avec stockÃ© (0xABCD1234)
4. âœ… Match â†’ DonnÃ©es intÃ¨gres

Si corruption :
1. Lire le bloc (donnÃ©es corrompues)
2. Recalculer checksum â†’ 0x9876FEDC
3. Comparer avec stockÃ© (0xABCD1234)
4. âŒ Mismatch â†’ CORRUPTION DÃ‰TECTÃ‰E !
```

---

## NouveautÃ© PostgreSQL 18 : Checksums activÃ©s par dÃ©faut

### Historique

- **PostgreSQL â‰¤ 17** : Checksums **dÃ©sactivÃ©s** par dÃ©faut (pour compatibilitÃ© et lÃ©gÃ¨re performance)
- **PostgreSQL 18** : Checksums **activÃ©s** par dÃ©faut ! ğŸ‰

### Pourquoi ce changement ?

1. **MatÃ©riel moderne** : Le coÃ»t CPU des checksums est nÃ©gligeable sur processeurs rÃ©cents
2. **Protection essentielle** : DÃ©tection prÃ©coce vaut mieux que perte de donnÃ©es
3. **Meilleures pratiques** : La majoritÃ© des DBAs les activaient manuellement

### Impact sur les performances

**Overhead typique** :
- Ã‰criture : +1-3% de CPU
- Lecture : +0.5-2% de CPU

Sur matÃ©riel moderne (2020+), cet overhead est **imperceptible** et largement compensÃ© par la sÃ©curitÃ© apportÃ©e.

### VÃ©rifier si les checksums sont activÃ©s

```sql
-- MÃ©thode 1 : Via SQL
SHOW data_checksums;
-- RÃ©sultat : on (PG 18) ou off (versions antÃ©rieures)

-- MÃ©thode 2 : Via pg_controldata
pg_controldata /var/lib/postgresql/data | grep checksum
-- RÃ©sultat : Data page checksum version:           1
```

### Activer les checksums sur une instance existante

Si vous migrez depuis une version antÃ©rieure oÃ¹ checksums Ã©tait dÃ©sactivÃ© :

```bash
# âš ï¸ ATTENTION : NÃ©cessite arrÃªt de la base et peut prendre des heures !

# 1. ArrÃªter PostgreSQL
sudo systemctl stop postgresql

# 2. Activer les checksums (scan complet de la base)
sudo -u postgres pg_checksums --enable -D /var/lib/postgresql/data

# Exemple de sortie :
# Checksum operation completed
# Files scanned:  1234567
# Blocks scanned: 98765432
# pg_checksums: syncing data directory
# pg_checksums: checksums enabled in cluster

# 3. RedÃ©marrer PostgreSQL
sudo systemctl start postgresql
```

**DurÃ©e estimÃ©e** :
- 100 GB : ~10-30 minutes (SSD)
- 1 TB : ~1-3 heures (SSD)
- 10 TB : ~10-30 heures (SSD)

**Planifier pendant une fenÃªtre de maintenance !**

### DÃ©sactiver les checksums (non recommandÃ©)

```bash
# Lors de l'initialisation d'une nouvelle instance
initdb --no-data-checksums -D /var/lib/postgresql/data

# Ou pour dÃ©sactiver sur instance existante
sudo systemctl stop postgresql
sudo -u postgres pg_checksums --disable -D /var/lib/postgresql/data
sudo systemctl start postgresql
```

âš ï¸ **Ã€ Ã©viter** : Sauf raison trÃ¨s spÃ©cifique (hardware extrÃªmement limitÃ©), gardez les checksums activÃ©s.

---

## DÃ©tecter la corruption

### MÃ©thode 1 : Attendre une erreur (rÃ©actif)

La mÃ©thode la plus simple mais la moins souhaitable : attendre qu'une requÃªte Ã©choue.

```sql
-- Si corruption, vous verrez :
SELECT * FROM users WHERE id = 12345;

ERROR:  invalid page in block 789 of relation base/16384/16385
HINT:  This error can be caused by corrupt data or hardware failure.
```

### MÃ©thode 2 : VÃ©rification proactive avec pg_verifybackup

```bash
# VÃ©rifier une sauvegarde avec pg_basebackup
pg_verifybackup /path/to/backup

# RÃ©sultat si OK :
# backup successfully verified
# 0 files verified, 0 checksums verified

# Si corruption dÃ©tectÃ©e :
# error: checksum mismatch in file "base/16384/16385"
```

### MÃ©thode 3 : Extension amcheck (vÃ©rification d'index)

```sql
-- Installer l'extension
CREATE EXTENSION amcheck;

-- VÃ©rifier l'intÃ©gritÃ© d'un index
SELECT bt_index_check('users_pkey');
-- RÃ©sultat si OK : (pas de rÃ©sultat, c'est bon)

-- VÃ©rification plus approfondie (plus lente)
SELECT bt_index_parent_check('users_pkey');

-- VÃ©rifier tous les index d'une table
SELECT
    indexrelid::regclass AS index_name,
    bt_index_check(indexrelid)
FROM pg_index
WHERE indrelid = 'users'::regclass;
```

Si corruption dÃ©tectÃ©e :
```
ERROR:  heap tuple (0,52) from table "users" lacks matching index tuple within index "users_pkey"
```

### MÃ©thode 4 : Extension pg_verify_checksums (versions < 18)

Pour PostgreSQL < 18 sans checksums natifs :

```bash
# Installer l'extension
CREATE EXTENSION pg_verify_checksums;

# VÃ©rifier toute la base
SELECT pg_verify_checksums();
```

### MÃ©thode 5 : VÃ©rification manuelle des fichiers

```bash
# Utiliser l'outil pg_checksums en lecture seule
sudo -u postgres pg_checksums --check -D /var/lib/postgresql/data

# RÃ©sultat si OK :
# Checksum operation completed
# Files scanned:  12345
# Blocks scanned: 9876543
# Bad checksums:  0

# Si corruption :
# pg_checksums: error: checksum verification failed in file "base/16384/16385", block 789
# Blocks scanned:  9876543
# Bad checksums:  3
```

---

## Diagnostic : Identifier l'Ã©tendue de la corruption

### Ã‰tape 1 : Identifier les fichiers corrompus

```sql
-- Noter le numÃ©ro de fichier dans l'erreur
-- ERROR:  checksum failure on block 789 in file "base/16384/16385"
--                                                    ^^^^^^^^^^^^^^

-- Identifier la table correspondante
SELECT
    c.relname AS table_name,
    n.nspname AS schema_name,
    c.relfilenode,
    pg_relation_filepath(c.oid) AS file_path
FROM pg_class c
JOIN pg_namespace n ON n.oid = c.relnamespace
WHERE c.relfilenode = 16385;  -- NumÃ©ro du fichier
```

### Ã‰tape 2 : Tenter de lire autour de la corruption

```sql
-- Si la table est connue, essayer de lire les donnÃ©es valides
-- en Ã©vitant les blocs corrompus

-- Utiliser LIMIT pour Ã©viter de scanner toute la table
SELECT * FROM users LIMIT 100;

-- Si Ã§a Ã©choue, essayer par portions
SELECT * FROM users WHERE id < 1000;
SELECT * FROM users WHERE id >= 1000 AND id < 2000;
-- Continue jusqu'Ã  trouver le bloc problÃ©matique
```

### Ã‰tape 3 : Utiliser l'extension pageinspect

```sql
-- Installer l'extension
CREATE EXTENSION pageinspect;

-- Examiner un bloc spÃ©cifique
SELECT * FROM page_header(get_raw_page('users', 0));

-- RÃ©sultat normal :
--  lsn        | checksum | flags | lower | upper | special | pagesize | version | prune_xid
-- ------------+----------+-------+-------+-------+---------+----------+---------+-----------
--  0/12345678 |    12345 |     0 |    48 |  8064 |    8192 |     8192 |       4 |         0

-- Si corruption, get_raw_page Ã©chouera :
-- ERROR:  invalid page in block 789
```

### Ã‰tape 4 : CrÃ©er un rapport de corruption

```sql
-- Script pour documenter la corruption
DO $$
DECLARE
    corrupted_table TEXT;
    corrupted_block INTEGER;
BEGIN
    -- Capturer les informations
    corrupted_table := 'users';
    corrupted_block := 789;

    RAISE NOTICE 'CORRUPTION REPORT';
    RAISE NOTICE '==================';
    RAISE NOTICE 'Date: %', now();
    RAISE NOTICE 'Table: %', corrupted_table;
    RAISE NOTICE 'Block: %', corrupted_block;
    RAISE NOTICE 'File: %', pg_relation_filepath(corrupted_table::regclass);
END $$;
```

---

## RÃ©cupÃ©ration : Que faire face Ã  une corruption ?

### StratÃ©gie de rÃ©cupÃ©ration par niveau de gravitÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NIVEAU 1 : Corruption mineure (quelques blocs)     â”‚
â”‚  â†’ Restaurer depuis sauvegarde                      â”‚
â”‚  â†’ Ou reconstruire les index                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NIVEAU 2 : Corruption modÃ©rÃ©e (table entiÃ¨re)      â”‚
â”‚  â†’ Restaurer la table depuis sauvegarde             â”‚
â”‚  â†’ Ou reconstruire depuis rÃ©plica                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NIVEAU 3 : Corruption majeure (plusieurs tables)   â”‚
â”‚  â†’ Restauration complÃ¨te depuis sauvegarde          â”‚
â”‚  â†’ Point-In-Time Recovery (PITR)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NIVEAU 4 : Corruption catastrophique               â”‚
â”‚  â†’ DerniÃ¨re chance : zero_damaged_pages             â”‚
â”‚  â†’ Accepter la perte de donnÃ©es                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Niveau 1 : Corruption d'index

Si seuls les index sont corrompus (le plus courant et le moins grave) :

```sql
-- 1. Identifier l'index corrompu
SELECT indexrelid::regclass, indrelid::regclass
FROM pg_index
WHERE indexrelid = 'users_pkey'::regclass;

-- 2. Supprimer l'index corrompu
DROP INDEX CONCURRENTLY users_pkey;

-- 3. RecrÃ©er l'index
CREATE UNIQUE INDEX CONCURRENTLY users_pkey ON users(id);

-- 4. RÃ©affecter comme clÃ© primaire si nÃ©cessaire
ALTER TABLE users ADD PRIMARY KEY USING INDEX users_pkey;
```

**Avantage** : Pas de perte de donnÃ©es, opÃ©ration possible en production avec CONCURRENTLY.

### Niveau 2 : Corruption de table - Option A (avec sauvegarde)

```bash
# 1. Identifier la table corrompue
# ERROR in table "users"

# 2. CrÃ©er une nouvelle table temporaire
psql -d mydb -c "CREATE TABLE users_backup (LIKE users INCLUDING ALL);"

# 3. Restaurer depuis pg_dump (sauvegarde logique)
pg_restore -d mydb -t users --data-only backup.dump -a users_backup

# 4. VÃ©rifier les donnÃ©es restaurÃ©es
psql -d mydb -c "SELECT count(*) FROM users_backup;"

# 5. Remplacer la table (ATTENTION : Perte des donnÃ©es depuis la sauvegarde)
psql -d mydb <<EOF
BEGIN;
DROP TABLE users CASCADE;
ALTER TABLE users_backup RENAME TO users;
COMMIT;
EOF

# 6. RecrÃ©er les index, contraintes, etc.
```

### Niveau 2 : Corruption de table - Option B (extraction partielle)

Si vous devez sauver ce qui peut l'Ãªtre :

```sql
-- 1. CrÃ©er une nouvelle table
CREATE TABLE users_recovered (LIKE users);

-- 2. Copier les lignes lisibles (ignorer les blocs corrompus)
-- Utiliser zero_damaged_pages (DANGER : Perte de donnÃ©es)

-- Activer temporairement (Ã  vos risques !)
SET zero_damaged_pages = on;

-- Copier les donnÃ©es valides
INSERT INTO users_recovered
SELECT * FROM users;  -- Ignore silencieusement les blocs corrompus

-- DÃ©sactiver immÃ©diatement
SET zero_damaged_pages = off;

-- 3. VÃ©rifier ce qui a Ã©tÃ© sauvÃ©
SELECT count(*) FROM users;          -- Avant (avec corruption)
SELECT count(*) FROM users_recovered; -- AprÃ¨s (donnÃ©es valides)

-- 4. Remplacer la table
BEGIN;
DROP TABLE users CASCADE;
ALTER TABLE users_recovered RENAME TO users;
COMMIT;
```

âš ï¸ **DANGER** : `zero_damaged_pages` **supprime silencieusement les donnÃ©es corrompues**. Ã€ utiliser uniquement en dernier recours.

### Niveau 3 : Restauration complÃ¨te depuis sauvegarde

#### Option A : Sauvegarde logique (pg_dump)

```bash
# 1. ArrÃªter l'application (Ã©viter nouvelles transactions)
# ...

# 2. CrÃ©er une nouvelle base
createdb mydb_restored

# 3. Restaurer depuis pg_dump
pg_restore -d mydb_restored -v backup.dump

# Ou si format SQL :
psql -d mydb_restored -f backup.sql

# 4. VÃ©rifier l'intÃ©gritÃ©
psql -d mydb_restored -c "SELECT count(*) FROM users;"

# 5. Basculer l'application vers la nouvelle base
# Modifier la configuration de connexion
```

#### Option B : Sauvegarde physique (pg_basebackup + PITR)

```bash
# 1. ArrÃªter PostgreSQL
sudo systemctl stop postgresql

# 2. Sauvegarder l'instance corrompue (au cas oÃ¹)
sudo mv /var/lib/postgresql/data /var/lib/postgresql/data.corrupted

# 3. Restaurer depuis pg_basebackup
sudo -u postgres cp -a /path/to/backup/base /var/lib/postgresql/data

# 4. Configurer la rÃ©cupÃ©ration (recovery.signal)
sudo -u postgres touch /var/lib/postgresql/data/recovery.signal

# Ã‰diter postgresql.conf
restore_command = 'cp /path/to/wal_archive/%f %p'
recovery_target_time = '2024-11-23 10:30:00'  # Point avant corruption

# 5. DÃ©marrer PostgreSQL (mode recovery)
sudo systemctl start postgresql

# 6. VÃ©rifier dans les logs que recovery s'est bien passÃ©
sudo tail -f /var/log/postgresql/postgresql-*.log

# 7. Promouvoir si OK
psql -c "SELECT pg_wal_replay_resume();"
```

### Niveau 4 : Dernier recours - Accepter la perte partielle

Si aucune sauvegarde n'existe (ğŸ˜±) :

```sql
-- Configuration globale (TRÃˆS DANGEREUX)
-- Dans postgresql.conf
zero_damaged_pages = on
ignore_checksum_failure = on  -- Ignore les erreurs de checksum

-- RedÃ©marrer PostgreSQL
-- sudo systemctl restart postgresql

-- Extraire ce qui peut l'Ãªtre
CREATE TABLE rescued_data AS
SELECT * FROM corrupted_table;  -- Ignore les blocs illisibles

-- Restaurer les paramÃ¨tres normaux immÃ©diatement
-- zero_damaged_pages = off
-- ignore_checksum_failure = off
```

âš ï¸ **NE JAMAIS laisser ces paramÃ¨tres activÃ©s en production !**

---

## PrÃ©vention : Ã‰viter la corruption

### 1. Hardware de qualitÃ©

#### Disques

- âœ… **SSD d'entreprise** avec protection contre les coupures de courant (PLP - Power Loss Protection)
- âœ… **RAID 10 ou RAID 6** pour redondance
- âŒ **Ã‰viter** : Disques grand public, USB, NFS non redondant

#### RAM

- âœ… **RAM ECC** (Error Correcting Code) : DÃ©tecte et corrige les erreurs mÃ©moire
- âŒ **Ã‰viter** : RAM standard pour serveurs de production

```bash
# VÃ©rifier si vous avez RAM ECC
sudo dmidecode -t memory | grep -i ecc

# RÃ©sultat souhaitÃ© :
# Error Correction Type: Multi-bit ECC
```

#### Alimentation

- âœ… **UPS (onduleur)** : Protection contre coupures de courant
- âœ… **Double alimentation** : Redondance alimentation

### 2. SystÃ¨me de fichiers appropriÃ©

```bash
# XFS ou ext4 sont recommandÃ©s
# VÃ©rifier le systÃ¨me de fichiers actuel
df -T /var/lib/postgresql/data

# RÃ©sultat exemple :
# Filesystem     Type  Size  Used Avail Use% Mounted on
# /dev/sda1      ext4  100G   45G   50G  48% /var/lib/postgresql/data
```

**Recommandations** :
- âœ… **ext4** : Solide, Ã©prouvÃ©, bonne performance
- âœ… **XFS** : Excellent pour trÃ¨s grands volumes
- âœ… **ZFS** : Protection intÃ©grÃ©e contre corruption (checksums natifs)
- âš ï¸ **Btrfs** : Prometteur mais moins mature
- âŒ **NFS** : Ã‰viter pour data, OK pour archives

### 3. Configuration PostgreSQL anti-corruption

```sql
-- Dans postgresql.conf

# Activer checksums (dÃ©faut PG 18)
data_checksums = on

# Synchronisation stricte (Ã©vite corruption en cas de crash)
fsync = on                          # JAMAIS dÃ©sactiver
synchronous_commit = on             # Pour transactions critiques
full_page_writes = on               # Protection aprÃ¨s checkpoint
wal_sync_method = fdatasync         # MÃ©thode la plus sÃ»re (Linux)

# Journalisation
wal_level = replica                 # Minimum pour PITR
archive_mode = on                   # Archiver les WAL
archive_command = 'cp %p /path/to/wal_archive/%f'

# Logging des corruptions
log_checkpoints = on
log_autovacuum_min_duration = 0
```

### 4. Sauvegardes rÃ©guliÃ¨res et testÃ©es

```bash
# Script de sauvegarde quotidienne
#!/bin/bash
# backup_daily.sh

DATE=$(date +%Y%m%d)
BACKUP_DIR="/backup/postgresql"
PGDATABASE="mydb"

# Sauvegarde logique
pg_dump -Fc $PGDATABASE > $BACKUP_DIR/mydb_$DATE.dump

# Sauvegarde physique (base backup)
pg_basebackup -D $BACKUP_DIR/basebackup_$DATE -Ft -z -P

# VÃ©rifier l'intÃ©gritÃ© de la sauvegarde
pg_verifybackup $BACKUP_DIR/basebackup_$DATE

# Rotation (garder 7 jours)
find $BACKUP_DIR -name "*.dump" -mtime +7 -delete
find $BACKUP_DIR -name "basebackup_*" -mtime +7 -exec rm -rf {} \;

echo "Backup completed: $DATE"
```

**Planifier avec cron** :

```bash
# Tous les jours Ã  2h du matin
0 2 * * * /usr/local/bin/backup_daily.sh >> /var/log/postgresql_backup.log 2>&1
```

**CRITIQUE** : Testez vos sauvegardes rÃ©guliÃ¨rement !

```bash
# Test de restauration mensuel
#!/bin/bash
# test_restore.sh

BACKUP="/backup/postgresql/mydb_latest.dump"
TESTDB="mydb_test"

# CrÃ©er DB de test
dropdb --if-exists $TESTDB
createdb $TESTDB

# Restaurer
pg_restore -d $TESTDB $BACKUP

# VÃ©rifier
psql -d $TESTDB -c "SELECT count(*) FROM users;"

# Nettoyer
dropdb $TESTDB

echo "Restore test successful!"
```

### 5. Monitoring de l'intÃ©gritÃ©

#### Surveillance automatisÃ©e avec pg_cron

```sql
-- Installer pg_cron
CREATE EXTENSION pg_cron;

-- VÃ©rifier les index chaque dimanche Ã  3h
SELECT cron.schedule(
    'check-indexes',
    '0 3 * * 0',
    $$SELECT bt_index_check(indexrelid::regclass)
      FROM pg_index
      WHERE indrelid IN (
        SELECT oid FROM pg_class
        WHERE relname IN ('users', 'orders', 'products')
      )$$
);

-- Notifier si problÃ¨me
CREATE OR REPLACE FUNCTION check_critical_indexes()
RETURNS void AS $$
DECLARE
    v_error TEXT;
BEGIN
    -- VÃ©rifier chaque index critique
    PERFORM bt_index_check('users_pkey');
    PERFORM bt_index_check('orders_pkey');
EXCEPTION WHEN OTHERS THEN
    -- Logger l'erreur
    INSERT INTO corruption_alerts (detected_at, error_message)
    VALUES (now(), SQLERRM);

    -- Notifier (via pg_notify ou autre)
    PERFORM pg_notify('corruption_alert', SQLERRM);
END;
$$ LANGUAGE plpgsql;
```

#### Script de surveillance externe

```bash
#!/bin/bash
# check_corruption.sh

LOGFILE="/var/log/corruption_check.log"
DATE=$(date +"%Y-%m-%d %H:%M:%S")

# VÃ©rifier les checksums
RESULT=$(sudo -u postgres pg_checksums --check -D /var/lib/postgresql/data 2>&1)

if echo "$RESULT" | grep -q "Bad checksums: 0"; then
    echo "[$DATE] OK - No corruption detected" >> $LOGFILE
    exit 0
else
    echo "[$DATE] ERROR - Corruption detected!" >> $LOGFILE
    echo "$RESULT" >> $LOGFILE

    # Alerter (email, Slack, PagerDuty, etc.)
    echo "CORRUPTION DETECTED: $RESULT" | mail -s "PostgreSQL Corruption Alert" admin@example.com

    exit 1
fi
```

**Planifier avec cron** :

```bash
# Tous les jours Ã  4h
0 4 * * * /usr/local/bin/check_corruption.sh
```

### 6. Tests de hardware

```bash
# Tester la RAM
sudo memtester 1G 5  # Tester 1GB, 5 passes

# Tester le disque
sudo smartctl -t long /dev/sda  # Test SMART long
sudo smartctl -a /dev/sda        # Voir les rÃ©sultats

# Surveiller les erreurs disque
sudo smartctl -H /dev/sda
# RÃ©sultat souhaitÃ© : "PASSED"
```

---

## Outils de diagnostic avancÃ©s

### 1. pg_filedump (analyse bas niveau)

```bash
# Installer pg_filedump
git clone https://github.com/df7cb/pg_filedump
cd pg_filedump
make
sudo make install

# Analyser un fichier de donnÃ©es
pg_filedump /var/lib/postgresql/data/base/16384/16385

# RÃ©sultat normal :
# Block    0 ********************************************************
# <Header> -----
#  Block Offset: 0x00000000         Offsets: Lower      48 (0x0030)
#  Block: Size 8192  Version    4            Upper    8064 (0x1f80)
#  LSN:  logid      0 recoff 0x01234567      Special  8192 (0x2000)
#  Items:   52                      Free Space: 8016
#  Checksum: 0xABCD  Prune XID: 0x00000000  Flags: 0x0000 ()
```

### 2. pageinspect (inspection depuis SQL)

```sql
-- Examiner l'en-tÃªte d'une page
SELECT * FROM page_header(get_raw_page('users', 0));

-- Voir les items dans une page
SELECT * FROM heap_page_items(get_raw_page('users', 0));

-- Examiner un index B-Tree
SELECT * FROM bt_page_stats('users_pkey', 1);
SELECT * FROM bt_page_items('users_pkey', 1);
```

### 3. Monitoring SMART des disques

```bash
# Installer smartmontools
sudo apt install smartmontools

# Activer monitoring
sudo systemctl enable smartd
sudo systemctl start smartd

# Configuration dans /etc/smartd.conf
/dev/sda -a -o on -S on -s (S/../.././02|L/../../6/03) -m admin@example.com

# Explication :
# -a : Surveiller tous les attributs
# -o on : Activer offline tests automatiques
# -S on : Activer autosave des attributs
# -s : Schedule des tests (Short: quotidien 2h, Long: samedi 3h)
# -m : Email en cas de problÃ¨me
```

---

## Cas d'Ã©tude : RÃ©cupÃ©ration rÃ©elle

### ScÃ©nario : Corruption dÃ©tectÃ©e en production

**Contexte** :
- Production, 500 utilisateurs simultanÃ©s
- Erreur dÃ©tectÃ©e : `checksum failure on block 789 in file base/16384/16385`
- Table identifiÃ©e : `orders` (critique)

**Plan d'action** :

#### Phase 1 : Ã‰valuation (5 minutes)

```sql
-- 1. Identifier la table
SELECT relname, relfilenode
FROM pg_class
WHERE relfilenode = 16385;
-- RÃ©sultat : orders

-- 2. Ã‰valuer l'impact
SELECT count(*) FROM orders;
-- Si erreur â†’ corruption majeure
-- Si rÃ©ussi â†’ corruption mineure (quelques blocs)

-- 3. VÃ©rifier l'Ã¢ge de la derniÃ¨re sauvegarde
SELECT pg_size_pretty(pg_database_size('mydb')),
       now() - (SELECT modification FROM pg_stat_file('base/16384/16385'));
```

#### Phase 2 : Isolement (10 minutes)

```sql
-- 1. Basculer application en mode lecture seule
-- (dans l'application, bloquer les INSERT/UPDATE/DELETE sur orders)

-- 2. CrÃ©er une table temporaire avec les donnÃ©es valides
CREATE TABLE orders_safe AS
SELECT * FROM orders WHERE order_id < 10000;  -- Avant le bloc corrompu

-- 3. VÃ©rifier les donnÃ©es sauvÃ©es
SELECT count(*) FROM orders_safe;
```

#### Phase 3 : RÃ©cupÃ©ration (30 minutes)

```sql
-- Option A : Restauration depuis sauvegarde
-- 1. Restaurer dans nouvelle table
CREATE TABLE orders_restored (LIKE orders INCLUDING ALL);

-- 2. Importer depuis backup (commande externe)
-- pg_restore -d mydb -t orders --data-only backup.dump -a orders_restored

-- 3. Comparer
SELECT count(*) FROM orders_safe;     -- DonnÃ©es depuis production
SELECT count(*) FROM orders_restored; -- DonnÃ©es depuis backup

-- 4. Merger les deux sources
BEGIN;
-- Supprimer la table corrompue
DROP TABLE orders CASCADE;
-- Restaurer depuis backup
ALTER TABLE orders_restored RENAME TO orders;
-- Ajouter les commandes rÃ©centes depuis orders_safe si nÃ©cessaire
COMMIT;
```

#### Phase 4 : VÃ©rification (15 minutes)

```sql
-- 1. VÃ©rifier l'intÃ©gritÃ© de la nouvelle table
SELECT bt_index_check('orders_pkey');

-- 2. VÃ©rifier la cohÃ©rence des donnÃ©es
SELECT count(*), min(order_date), max(order_date)
FROM orders;

-- 3. Tester quelques requÃªtes critiques
SELECT * FROM orders WHERE user_id = 12345 LIMIT 10;
SELECT sum(amount) FROM orders WHERE order_date = current_date;
```

#### Phase 5 : Reprise (5 minutes)

```sql
-- 1. Remettre application en mode lecture-Ã©criture
-- (configuration applicative)

-- 2. Surveiller les logs
-- sudo tail -f /var/log/postgresql/postgresql-*.log

-- 3. Monitorer les performances
SELECT * FROM pg_stat_activity WHERE state = 'active';
```

#### Phase 6 : Post-mortem (dÃ¨s que possible)

```bash
# 1. Identifier la cause racine
sudo smartctl -a /dev/sda  # VÃ©rifier la santÃ© du disque

# 2. Consulter les logs systÃ¨me
sudo dmesg | grep -i "error\|fail"
sudo journalctl -u postgresql --since "2 hours ago"

# 3. Documenter l'incident
# - Timestamp
# - SymptÃ´mes
# - Actions prises
# - DurÃ©e d'interruption
# - DonnÃ©es perdues (si applicable)
# - Cause identifiÃ©e
# - Actions prÃ©ventives

# 4. AmÃ©liorer la prÃ©vention
# - Remplacer matÃ©riel dÃ©faillant
# - AmÃ©liorer monitoring
# - Tester backups plus frÃ©quemment
```

---

## Checklist anti-corruption

### Avant mise en production

- [ ] Checksums activÃ©s (`data_checksums = on`)
- [ ] RAM ECC installÃ©e
- [ ] SSD/HDD avec SMART monitoring
- [ ] RAID configurÃ© correctement
- [ ] UPS (onduleur) en place
- [ ] `fsync = on` (JAMAIS dÃ©sactiver)
- [ ] `full_page_writes = on`
- [ ] Sauvegardes automatiques configurÃ©es
- [ ] Test de restauration effectuÃ©

### Hebdomadaire

- [ ] VÃ©rifier les logs pour erreurs de checksum
- [ ] VÃ©rifier SMART status des disques
- [ ] VÃ©rifier que sauvegardes s'exÃ©cutent
- [ ] VÃ©rifier l'espace disque disponible

### Mensuel

- [ ] Test de restauration complet
- [ ] VÃ©rification des index (`amcheck`)
- [ ] Analyse des mÃ©triques de corruption
- [ ] Revue des alertes systÃ¨me

### Annuel

- [ ] Test de disaster recovery complet
- [ ] Remplacement matÃ©riel planifiÃ© (disques > 5 ans)
- [ ] Audit de la configuration
- [ ] Formation Ã©quipe sur procÃ©dures de rÃ©cupÃ©ration

---

## Configuration de rÃ©fÃ©rence anti-corruption

```ini
# postgresql.conf - Configuration optimale pour intÃ©gritÃ©

# CHECKSUMS (PG 18 : par dÃ©faut)
data_checksums = on

# DURABILITÃ‰
fsync = on                          # CRITIQUE - Ne JAMAIS dÃ©sactiver
synchronous_commit = on             # Pour transactions critiques
full_page_writes = on               # Protection aprÃ¨s checkpoint
wal_sync_method = fdatasync         # Le plus sÃ»r (Linux)
wal_compression = on                # RÃ©duit I/O sans compromettre intÃ©gritÃ©

# WAL ET SAUVEGARDE
wal_level = replica                 # Permet PITR et rÃ©plication
archive_mode = on
archive_command = 'test ! -f /wal_archive/%f && cp %p /wal_archive/%f'
archive_timeout = 3600              # Forcer archive toutes les heures

# LOGGING
logging_collector = on
log_directory = '/var/log/postgresql'
log_filename = 'postgresql-%Y-%m-%d.log'
log_rotation_age = 1d
log_rotation_size = 100MB

# Logs de diagnostic corruption
log_checkpoints = on
log_connections = on
log_disconnections = on
log_duration = off
log_line_prefix = '%t [%p]: user=%u,db=%d,app=%a,client=%h '
log_min_error_statement = error
log_min_messages = warning

# CHECKSUMS ERRORS
ignore_checksum_failure = off       # Ne JAMAIS ignorer (dÃ©faut)
zero_damaged_pages = off            # Ne JAMAIS activer (dÃ©faut)

# MONITORING
track_io_timing = on
track_functions = all
```

---

## Mythes et idÃ©es reÃ§ues

### âŒ Mythe 1 : "Les checksums ralentissent trop la base"

**RÃ©alitÃ©** : Impact nÃ©gligeable sur matÃ©riel moderne (+1-3% CPU). Le coÃ»t d'une corruption non dÃ©tectÃ©e est infiniment plus Ã©levÃ©.

### âŒ Mythe 2 : "Si j'ai du RAID, je n'ai pas besoin de checksums"

**RÃ©alitÃ©** : RAID protÃ¨ge contre dÃ©faillance matÃ©rielle, pas contre corruption silencieuse (silent data corruption). Les deux sont complÃ©mentaires.

### âŒ Mythe 3 : "La corruption est extrÃªmement rare"

**RÃ©alitÃ©** : Une Ã©tude de Google (2016) a montrÃ© que 2-4% des disques subissent au moins une corruption silencieuse par an. Sur un datacenter de 10,000 disques, c'est 200-400 corruptions/an !

### âŒ Mythe 4 : "Les sauvegardes suffisent"

**RÃ©alitÃ©** : Les checksums dÃ©tectent **immÃ©diatement** la corruption. Les sauvegardes vous sauvent **aprÃ¨s coup**, mais vous perdez potentiellement des heures/jours de donnÃ©es.

### âŒ Mythe 5 : "fsync = off c'est OK pour plus de performance"

**RÃ©alitÃ©** : **JAMAIS**. `fsync = off` est une recette pour la corruption en cas de crash. Les gains de performance ne valent jamais la perte de donnÃ©es.

---

## Ressources complÃ©mentaires

- **Documentation PostgreSQL** : [Data Page Checksums](https://www.postgresql.org/docs/current/app-initdb.html#APP-INITDB-DATA-CHECKSUMS)
- **Extension amcheck** : [amcheck Documentation](https://www.postgresql.org/docs/current/amcheck.html)
- **Blog Percona** : "PostgreSQL Data Corruption"
- **Paper Google** : "An Analysis of Data Corruption in the Storage Stack" (2016)
- **Tool pg_filedump** : [GitHub Repository](https://github.com/df7cb/pg_filedump)

---

## RÃ©sumÃ© des points clÃ©s

âœ… **Corruption** : Modification involontaire des donnÃ©es sur disque, potentiellement catastrophique

âœ… **Checksums** : Empreintes digitales pour chaque bloc, dÃ©tectent corruption immÃ©diatement

âœ… **PostgreSQL 18** : Checksums activÃ©s par dÃ©faut (enfin !)

âœ… **RAM ECC** : Protection contre erreurs mÃ©moire (bit flips)

âœ… **MatÃ©riel de qualitÃ©** : SSD entreprise, RAID, UPS indispensables en production

âœ… **Configuration** : `fsync = on`, `full_page_writes = on`, `synchronous_commit = on`

âœ… **Sauvegardes** : RÃ©guliÃ¨res (quotidiennes), testÃ©es (mensuelles), vÃ©rifiÃ©es (pg_verifybackup)

âœ… **Monitoring** : Checksums automatiques, SMART disks, logs PostgreSQL

âœ… **RÃ©cupÃ©ration** : Index â†’ Restauration partielle â†’ Restauration complÃ¨te â†’ Dernier recours (zero_damaged_pages)

âœ… **PrÃ©vention** : 95% du problÃ¨me. Investir dans hardware et monitoring

---

## Conclusion

La corruption de donnÃ©es est le scÃ©nario le plus effrayant pour tout administrateur de base de donnÃ©es. Contrairement aux autres problÃ¨mes qui peuvent ralentir votre systÃ¨me, la corruption peut entraÃ®ner une **perte dÃ©finitive de donnÃ©es**.

**La bonne approche** :

1. **PrÃ©vention** : Hardware de qualitÃ©, checksums activÃ©s, configuration appropriÃ©e
2. **DÃ©tection** : Monitoring automatisÃ©, vÃ©rifications rÃ©guliÃ¨res
3. **RÃ©action** : Sauvegardes testÃ©es, procÃ©dures de rÃ©cupÃ©ration documentÃ©es

Avec PostgreSQL 18 activant les checksums par dÃ©faut, la communautÃ© PostgreSQL fait un pas majeur vers la protection de vos donnÃ©es. Mais les checksums ne sont qu'une partie de la solution : matÃ©riel de qualitÃ©, sauvegardes rÃ©guliÃ¨res et tests de restauration sont tout aussi critiques.

**Rappelez-vous** :
- Checksums activÃ©s = dÃ©tection prÃ©coce âœ…
- Sauvegardes rÃ©guliÃ¨res = filet de sÃ©curitÃ© âœ…
- Tests de restauration = assurance que le filet fonctionne âœ…
- Hardware de qualitÃ© = rÃ©duction drastique du risque âœ…

La corruption est rare avec des pratiques appropriÃ©es, mais quand elle survient, Ãªtre prÃ©parÃ© fait toute la diffÃ©rence entre une interruption mineure et une catastrophe.

---

**Prochaine Ã©tape** : 19.4.5 - Slow queries et Query tuning

---


â­ï¸ [Slow queries et Query tuning](/19-postgresql-en-production/04.5-slow-queries-tuning.md)
