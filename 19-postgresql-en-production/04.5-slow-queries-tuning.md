üîù Retour au [Sommaire](/SOMMAIRE.md)

# 19.4.5. Slow queries et Query tuning

## Introduction : La qu√™te de la performance

Une **requ√™te lente** (slow query) est comme un embouteillage sur l'autoroute de vos donn√©es : elle bloque tout le trafic derri√®re elle, frustre vos utilisateurs et peut mettre √† genoux votre application enti√®re.

Imaginez que vous cherchez un livre dans une biblioth√®que :
- **Requ√™te rapide** : Vous utilisez le catalogue informatis√©, allez directement √† la bonne √©tag√®re ‚Üí 30 secondes
- **Requ√™te lente** : Vous parcourez chaque √©tag√®re, chaque livre, une par une ‚Üí 3 heures

Le **Query tuning** (optimisation de requ√™tes) est l'art de transformer ces 3 heures en 30 secondes. C'est souvent le moyen le plus **efficace** et le moins **co√ªteux** d'am√©liorer drastiquement les performances d'une application.

**Dans ce chapitre, vous apprendrez** :
- Comment identifier les requ√™tes qui ralentissent votre base
- Comment lire et comprendre un plan d'ex√©cution (EXPLAIN)
- Les techniques pour optimiser vos requ√™tes
- Comment cr√©er les bons index
- Les pi√®ges courants et comment les √©viter

---

## Partie 1 : Identifier les requ√™tes lentes

### Qu'est-ce qu'une "requ√™te lente" ?

Il n'y a pas de d√©finition absolue, mais voici des rep√®res :

| Type de requ√™te | Acceptable | Lent | Tr√®s lent |
|-----------------|------------|------|-----------|
| SELECT simple (avec index) | < 10ms | 50-100ms | > 500ms |
| SELECT avec JOIN (petites tables) | < 50ms | 100-500ms | > 1s |
| SELECT avec JOIN (grandes tables) | < 200ms | 500ms-2s | > 5s |
| INSERT/UPDATE/DELETE | < 20ms | 50-100ms | > 500ms |
| Agr√©gations complexes | < 500ms | 1-5s | > 10s |

**Contexte important** : Une requ√™te "lente" d√©pend aussi de :
- Fr√©quence d'ex√©cution (1000√ó/seconde vs 1√ó/jour)
- Attentes utilisateur (batch nocturne vs API temps r√©el)
- Volume de donn√©es trait√©

### M√©thode 1 : Via pg_stat_statements (recommand√©)

C'est l'extension **indispensable** pour tout DBA PostgreSQL.

#### Installation et configuration

```sql
-- 1. Activer l'extension
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- 2. Configurer dans postgresql.conf
-- shared_preload_libraries = 'pg_stat_statements'
-- pg_stat_statements.track = all
-- pg_stat_statements.max = 10000

-- Puis red√©marrer PostgreSQL
-- sudo systemctl restart postgresql

-- 3. V√©rifier que √ßa fonctionne
SELECT count(*) FROM pg_stat_statements;
```

#### Trouver les requ√™tes les plus lentes (temps total)

```sql
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time,
    stddev_exec_time,
    rows
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 10;
```

**Colonnes importantes** :
- `total_exec_time` : Temps cumul√© total (ms) - **Impact global**
- `mean_exec_time` : Temps moyen par ex√©cution (ms)
- `calls` : Nombre d'ex√©cutions
- `max_exec_time` : Pire cas observ√©

**Interpr√©ter les r√©sultats** :

```
 query                                      | calls  | total_exec_time | mean_exec_time | max_exec_time
--------------------------------------------+--------+-----------------+----------------+---------------
 SELECT * FROM orders WHERE user_id = $1   | 500000 | 250000.00       | 0.50           | 150.00
 SELECT * FROM logs WHERE created_at > $1  | 100    | 180000.00       | 1800.00        | 3500.00
```

**Analyse** :
- **Requ√™te 1** : Tr√®s fr√©quente (500k appels), rapide individuellement (0.5ms), mais impact global √©norme (250s cumul√©s)
  ‚Üí **Optimiser pour r√©duire les appels** ou am√©liorer la vitesse

- **Requ√™te 2** : Peu fr√©quente (100 appels), mais tr√®s lente (1.8s en moyenne)
  ‚Üí **Optimiser la requ√™te elle-m√™me**

#### Trouver les requ√™tes les plus lentes (temps moyen)

```sql
SELECT
    query,
    calls,
    mean_exec_time,
    max_exec_time,
    total_exec_time,
    rows
FROM pg_stat_statements
WHERE calls > 10  -- Ignorer les one-off queries
ORDER BY mean_exec_time DESC
LIMIT 10;
```

#### Requ√™tes avec variance √©lev√©e (comportement erratique)

```sql
SELECT
    query,
    calls,
    mean_exec_time,
    stddev_exec_time,
    max_exec_time,
    min_exec_time,
    -- Coefficient de variation
    CASE
        WHEN mean_exec_time > 0
        THEN round((stddev_exec_time / mean_exec_time * 100)::numeric, 2)
        ELSE 0
    END AS cv_percent
FROM pg_stat_statements
WHERE calls > 100
ORDER BY stddev_exec_time DESC
LIMIT 10;
```

**Interpr√©tation** : `cv_percent` > 100% indique un comportement tr√®s variable (parfois rapide, parfois tr√®s lent).

### M√©thode 2 : Via les logs PostgreSQL

#### Configuration du logging

```sql
-- Dans postgresql.conf

# Logger toutes les requ√™tes > 1 seconde
log_min_duration_statement = 1000  # en millisecondes

# Ajouter le temps d'ex√©cution dans les logs
log_duration = off  # D√©j√† inclus avec log_min_duration_statement
log_line_prefix = '%t [%p]: user=%u,db=%d,app=%a '

# Activer auto_explain pour voir le plan des requ√™tes lentes
shared_preload_libraries = 'pg_stat_statements,auto_explain'
auto_explain.log_min_duration = 1000  # Log EXPLAIN pour requ√™tes > 1s
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.log_timing = on
```

#### Consulter les logs

```bash
# Voir les requ√™tes lentes en temps r√©el
sudo tail -f /var/log/postgresql/postgresql-*.log | grep "duration:"

# Exemple de ligne de log :
# 2024-11-23 10:30:15.123 [12345]: user=app_user,db=mydb,app=MyApp LOG: duration: 2341.567 ms  statement: SELECT * FROM orders WHERE status = 'pending';

# Extraire les requ√™tes > 5 secondes
sudo grep "duration: [5-9][0-9][0-9][0-9]" /var/log/postgresql/postgresql-*.log
```

#### Analyser avec pgBadger

```bash
# Installer pgBadger
sudo apt install pgbadger

# Analyser les logs
pgbadger /var/log/postgresql/postgresql-*.log -o /tmp/report.html

# Ouvrir le rapport
firefox /tmp/report.html
```

**pgBadger vous montre** :
- Top requ√™tes par temps cumul√©
- Top requ√™tes par temps moyen
- Graphiques temporels
- R√©partition par type de requ√™te

### M√©thode 3 : Monitoring en temps r√©el

```sql
-- Voir les requ√™tes actuellement actives et lentes
SELECT
    pid,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    now() - query_start AS duration,
    wait_event_type,
    wait_event,
    query
FROM pg_stat_activity
WHERE state = 'active'
  AND query NOT LIKE '%pg_stat_activity%'
  AND now() - query_start > interval '5 seconds'
ORDER BY duration DESC;
```

**Colonnes importantes** :
- `duration` : Depuis combien de temps la requ√™te tourne
- `wait_event_type` / `wait_event` : Ce qui bloque la requ√™te
  - `IO` : Attente disque
  - `Lock` : Attente d'un verrou
  - `Client` : Attente du client (r√©seau)

---

## Partie 2 : EXPLAIN - Comprendre le plan d'ex√©cution

### Qu'est-ce qu'un plan d'ex√©cution ?

Quand vous donnez une requ√™te SQL √† PostgreSQL, il doit d√©cider **comment** r√©cup√©rer les donn√©es. Le **plan d'ex√©cution** est la strat√©gie choisie par le planificateur (query planner).

**Analogie GPS** : Vous demandez un itin√©raire de Paris √† Lyon. Le GPS (planificateur) peut choisir :
- Autoroute A6 (rapide mais p√©ages) ‚Üí Index Scan
- Routes nationales (plus lent mais gratuit) ‚Üí Sequential Scan
- Combinaison des deux ‚Üí Mix de strat√©gies

### EXPLAIN de base

```sql
EXPLAIN
SELECT * FROM users WHERE email = 'alice@example.com';
```

**R√©sultat** :
```
                                QUERY PLAN
--------------------------------------------------------------------------
 Index Scan using users_email_idx on users  (cost=0.42..8.44 rows=1 width=100)
   Index Cond: (email = 'alice@example.com'::text)
```

**Lecture du plan** :
- `Index Scan` : Type d'op√©ration (bon signe, utilise un index)
- `users_email_idx` : Nom de l'index utilis√©
- `cost=0.42..8.44` : Co√ªt estim√© (unit√©s arbitraires PostgreSQL)
  - `0.42` : Co√ªt pour obtenir la premi√®re ligne
  - `8.44` : Co√ªt total estim√©
- `rows=1` : Nombre de lignes estim√©
- `width=100` : Taille moyenne d'une ligne (bytes)

### EXPLAIN ANALYZE (avec ex√©cution r√©elle)

```sql
EXPLAIN ANALYZE
SELECT * FROM users WHERE email = 'alice@example.com';
```

**R√©sultat** :
```
                                QUERY PLAN
--------------------------------------------------------------------------
 Index Scan using users_email_idx on users  (cost=0.42..8.44 rows=1 width=100)
   (actual time=0.023..0.024 rows=1 loops=1)
   Index Cond: (email = 'alice@example.com'::text)
 Planning Time: 0.156 ms
 Execution Time: 0.045 ms
```

**Nouvelles informations** :
- `actual time=0.023..0.024` : Temps r√©el (ms) pour premi√®re ligne..derni√®re ligne
- `rows=1` (r√©el) vs `rows=1` (estim√©) : Ici, estimation parfaite
- `loops=1` : Nombre de fois que ce n≈ìud a √©t√© ex√©cut√©
- `Planning Time` : Temps pour cr√©er le plan
- `Execution Time` : Temps d'ex√©cution r√©el

### EXPLAIN options compl√®tes

```sql
EXPLAIN (ANALYZE, BUFFERS, VERBOSE, FORMAT JSON)
SELECT * FROM users WHERE email = 'alice@example.com';
```

**Options importantes** :

| Option | Description |
|--------|-------------|
| `ANALYZE` | Ex√©cute r√©ellement la requ√™te et montre les temps r√©els |
| `BUFFERS` | Montre l'utilisation du cache (shared buffers) |
| `VERBOSE` | Affiche plus de d√©tails sur chaque n≈ìud |
| `COSTS` | Affiche les co√ªts estim√©s (activ√© par d√©faut) |
| `TIMING` | Mesure le temps de chaque n≈ìud (activ√© par d√©faut avec ANALYZE) |
| `FORMAT TEXT\|JSON\|XML\|YAML` | Format de sortie |

**Exemple avec BUFFERS** :
```
Index Scan using users_email_idx on users (actual time=0.023..0.024 rows=1 loops=1)
  Index Cond: (email = 'alice@example.com'::text)
  Buffers: shared hit=4
Planning Time: 0.156 ms
Execution Time: 0.045 ms
```

**Interpr√©tation BUFFERS** :
- `shared hit=4` : 4 blocs lus depuis le cache (pas de disque) ‚úÖ
- `shared read=4` : 4 blocs lus depuis le disque ‚ö†Ô∏è
- Plus de `hit` que de `read` = bon signe !

---

## Partie 3 : Les types de Scan

### 1. Sequential Scan (Scan s√©quentiel)

**Description** : PostgreSQL lit **toute la table** de bout en bout.

```sql
EXPLAIN ANALYZE
SELECT * FROM orders WHERE status = 'pending';

Seq Scan on orders  (cost=0.00..18457.34 rows=123456 width=200)
  (actual time=0.012..145.234 rows=123456 loops=1)
  Filter: (status = 'pending'::text)
  Rows Removed by Filter: 876544
```

**Quand est-ce utilis√© ?**
- Pas d'index disponible
- Petite table (< 10,000 lignes)
- Requ√™te renvoie > 5-10% des lignes

**Bon ou mauvais ?**
- ‚úÖ **Bon** si petite table ou beaucoup de lignes √† retourner
- ‚ùå **Mauvais** si grande table et peu de lignes √† retourner

**Optimisation** :
```sql
-- Cr√©er un index
CREATE INDEX idx_orders_status ON orders(status);
```

### 2. Index Scan (Scan d'index)

**Description** : PostgreSQL utilise un index pour trouver les lignes.

```sql
EXPLAIN ANALYZE
SELECT * FROM orders WHERE order_id = 12345;

Index Scan using orders_pkey on orders  (cost=0.42..8.44 rows=1 width=200)
  (actual time=0.023..0.024 rows=1 loops=1)
  Index Cond: (order_id = 12345)
```

**Avantages** :
- Tr√®s rapide pour retrouver peu de lignes
- √âvite de lire toute la table

**Inconv√©nient** :
- Si beaucoup de lignes √† retourner, peut √™tre plus lent que Seq Scan

### 3. Index Only Scan (Scan d'index seul)

**Description** : Les donn√©es sont enti√®rement dans l'index, pas besoin d'aller √† la table.

```sql
-- Cr√©er un index couvrant
CREATE INDEX idx_orders_user_status ON orders(user_id, status);

EXPLAIN ANALYZE
SELECT user_id, status FROM orders WHERE user_id = 123;

Index Only Scan using idx_orders_user_status on orders
  (cost=0.42..4.44 rows=5 width=8) (actual time=0.015..0.017 rows=5 loops=1)
  Index Cond: (user_id = 123)
  Heap Fetches: 0  -- ‚úÖ Excellent ! Aucun acc√®s √† la table
```

**Avantage √©norme** : Jusqu'√† **10√ó plus rapide** qu'Index Scan normal.

**Comment l'obtenir ?**
- L'index contient **toutes** les colonnes du SELECT
- Utiliser `INCLUDE` pour ajouter des colonnes √† l'index

```sql
-- Index avec colonnes suppl√©mentaires
CREATE INDEX idx_orders_user_include
ON orders(user_id) INCLUDE (status, amount, created_at);

-- Maintenant cette requ√™te utilise Index Only Scan
SELECT user_id, status, amount, created_at
FROM orders
WHERE user_id = 123;
```

### 4. Bitmap Scan

**Description** : Utilis√© quand plusieurs index peuvent √™tre combin√©s.

```sql
EXPLAIN ANALYZE
SELECT * FROM orders
WHERE user_id = 123
  AND status = 'pending'
  AND amount > 100;

Bitmap Heap Scan on orders  (cost=12.34..56.78 rows=10 width=200)
  Recheck Cond: ((user_id = 123) AND (status = 'pending') AND (amount > 100))
  ->  BitmapAnd
        ->  Bitmap Index Scan on idx_orders_user
              Index Cond: (user_id = 123)
        ->  Bitmap Index Scan on idx_orders_status
              Index Cond: (status = 'pending')
        ->  Bitmap Index Scan on idx_orders_amount
              Index Cond: (amount > 100)
```

**Fonctionnement** :
1. Scan chaque index pour cr√©er une bitmap (carte de bits) des lignes
2. Combiner les bitmaps (AND/OR)
3. Lire les lignes identifi√©es

**Avantage** : Peut utiliser plusieurs index ensemble.

---

## Partie 4 : Les types de JOIN

### 1. Nested Loop (Boucle imbriqu√©e)

**Description** : Pour chaque ligne de la table externe, scan la table interne.

```sql
EXPLAIN ANALYZE
SELECT * FROM users u
JOIN orders o ON o.user_id = u.id
WHERE u.id = 123;

Nested Loop  (cost=0.85..24.31 rows=5 width=400)
  ->  Index Scan using users_pkey on users u  (cost=0.42..8.44 rows=1)
        Index Cond: (id = 123)
  ->  Index Scan using orders_user_id_idx on orders o  (cost=0.42..15.82 rows=5)
        Index Cond: (user_id = 123)
```

**Analogie** : Deux boucles for imbriqu√©es.

**Quand est-ce utilis√© ?**
- Petite table externe (peu de lignes)
- Index disponible sur la jointure

**Performance** :
- ‚úÖ **Excellent** pour petits datasets (< 100 lignes)
- ‚ùå **Mauvais** pour grandes jointures (complexit√© O(n√óm))

### 2. Hash Join

**Description** : Cr√©e une table de hachage en m√©moire, puis la sonde.

```sql
EXPLAIN ANALYZE
SELECT * FROM users u
JOIN orders o ON o.user_id = u.id;

Hash Join  (cost=1234.56..5678.90 rows=50000 width=400)
  Hash Cond: (o.user_id = u.id)
  ->  Seq Scan on orders o  (cost=0.00..3456.78 rows=100000)
  ->  Hash  (cost=890.12..890.12 rows=10000 width=200)
        ->  Seq Scan on users u  (cost=0.00..890.12 rows=10000)
```

**Fonctionnement** :
1. Scan la table la plus petite (users)
2. Cr√©er une table de hachage en m√©moire
3. Scan la table la plus grande (orders)
4. Sonder la table de hachage pour chaque ligne

**Performance** :
- ‚úÖ **Tr√®s bon** pour grandes jointures (complexit√© O(n+m))
- ‚ö†Ô∏è N√©cessite assez de m√©moire (`work_mem`)

### 3. Merge Join

**Description** : Trie les deux tables, puis les fusionne.

```sql
EXPLAIN ANALYZE
SELECT * FROM users u
JOIN orders o ON o.user_id = u.id
ORDER BY u.id;

Merge Join  (cost=123.45..678.90 rows=50000 width=400)
  Merge Cond: (u.id = o.user_id)
  ->  Index Scan using users_pkey on users u
  ->  Index Scan using orders_user_id_idx on orders o
```

**Fonctionnement** :
1. Trier les deux tables (ou utiliser index d√©j√† tri√©)
2. Fusionner les deux flux tri√©s

**Performance** :
- ‚úÖ **Optimal** si les deux c√¥t√©s sont d√©j√† tri√©s (par index)
- ‚ö†Ô∏è Lent si besoin de trier (co√ªteux en m√©moire)

---

## Partie 5 : Optimisation des requ√™tes

### Technique 1 : Ajouter un index appropri√©

#### Exemple de probl√®me

```sql
-- Requ√™te lente (Seq Scan)
EXPLAIN ANALYZE
SELECT * FROM users WHERE email = 'alice@example.com';

Seq Scan on users  (cost=0.00..18457.34 rows=1 width=100)
  (actual time=52.341..145.678 rows=1 loops=1)
  Filter: (email = 'alice@example.com'::text)
  Rows Removed by Filter: 999999
Execution Time: 145.723 ms
```

**Probl√®me** : Scan de 1 million de lignes pour en retourner 1 seule !

#### Solution : Index

```sql
-- Cr√©er l'index
CREATE INDEX idx_users_email ON users(email);

-- M√™me requ√™te apr√®s index
EXPLAIN ANALYZE
SELECT * FROM users WHERE email = 'alice@example.com';

Index Scan using idx_users_email on users  (cost=0.42..8.44 rows=1 width=100)
  (actual time=0.023..0.024 rows=1 loops=1)
Execution Time: 0.045 ms
```

**Am√©lioration** : 145ms ‚Üí 0.045ms = **3200√ó plus rapide !** üöÄ

### Technique 2 : Index multi-colonnes

#### Exemple

```sql
-- Requ√™te avec deux filtres
SELECT * FROM orders
WHERE user_id = 123
  AND status = 'pending';
```

#### Mauvaise approche : Un index par colonne

```sql
CREATE INDEX idx_orders_user ON orders(user_id);
CREATE INDEX idx_orders_status ON orders(status);

-- PostgreSQL utilisera Bitmap Scan (pas optimal)
```

#### Bonne approche : Index multi-colonnes

```sql
-- Index compos√© (ordre important !)
CREATE INDEX idx_orders_user_status ON orders(user_id, status);

-- Maintenant : Index Scan direct
EXPLAIN ANALYZE
SELECT * FROM orders WHERE user_id = 123 AND status = 'pending';

Index Scan using idx_orders_user_status on orders
  Index Cond: ((user_id = 123) AND (status = 'pending'))
```

**R√®gle d'ordre** : Colonne avec **√©galit√©** d'abord, puis **range/inequality**.

```sql
-- ‚úÖ BON
CREATE INDEX idx_orders_user_date ON orders(user_id, created_at);
SELECT * FROM orders WHERE user_id = 123 AND created_at > '2024-01-01';

-- ‚ùå MOINS BON (order invers√©)
CREATE INDEX idx_orders_date_user ON orders(created_at, user_id);
-- Ne peut pas utiliser l'index efficacement pour user_id = 123
```

### Technique 3 : Index partiels

Pour indexer seulement un sous-ensemble de lignes.

```sql
-- Index uniquement les commandes non pay√©es
CREATE INDEX idx_orders_pending ON orders(user_id)
WHERE status = 'pending';

-- Cette requ√™te utilise l'index partiel (plus petit, plus rapide)
SELECT * FROM orders
WHERE user_id = 123
  AND status = 'pending';
```

**Avantages** :
- Index plus petit (moins d'espace disque)
- Plus rapide √† maintenir (moins de mises √† jour)
- Cache plus efficace

### Technique 4 : R√©√©crire la requ√™te

#### Exemple : NOT IN vs NOT EXISTS

```sql
-- ‚ùå LENT : NOT IN avec sous-requ√™te
SELECT * FROM users
WHERE id NOT IN (
    SELECT user_id FROM orders WHERE amount > 1000
);

-- ‚úÖ RAPIDE : NOT EXISTS (mieux optimis√©)
SELECT * FROM users u
WHERE NOT EXISTS (
    SELECT 1 FROM orders o
    WHERE o.user_id = u.id
      AND o.amount > 1000
);
```

**Raison** : `NOT EXISTS` peut s'arr√™ter d√®s qu'il trouve une correspondance. `NOT IN` doit √©valuer toute la sous-requ√™te.

#### Exemple : OR vs UNION

```sql
-- ‚ùå LENT : OR peut emp√™cher l'utilisation d'index
SELECT * FROM orders
WHERE user_id = 123 OR customer_email = 'alice@example.com';

-- ‚úÖ RAPIDE : UNION ALL avec deux index
SELECT * FROM orders WHERE user_id = 123
UNION ALL
SELECT * FROM orders WHERE customer_email = 'alice@example.com'
  AND user_id != 123;  -- √âviter les doublons
```

**Nouveaut√© PG 18** : PostgreSQL 18 optimise automatiquement certaines OR-clauses en ANY, donc cette optimisation est moins n√©cessaire qu'avant !

### Technique 5 : √âviter SELECT *

```sql
-- ‚ùå LENT : R√©cup√®re toutes les colonnes
SELECT * FROM users WHERE id = 123;

-- ‚úÖ RAPIDE : Seulement les colonnes n√©cessaires
SELECT id, username, email FROM users WHERE id = 123;
```

**Pourquoi ?**
- Moins de donn√©es √† transf√©rer
- Peut utiliser Index Only Scan si les colonnes sont dans l'index
- Moins de bande passante r√©seau

### Technique 6 : LIMIT avec ORDER BY

```sql
-- ‚ùå LENT : Trie tout puis limite
SELECT * FROM orders
ORDER BY created_at DESC
LIMIT 10;

-- Si pas d'index sur created_at : Sort de toute la table !
```

**Solution** :

```sql
-- Cr√©er un index sur la colonne de tri
CREATE INDEX idx_orders_created_desc ON orders(created_at DESC);

-- Maintenant : Index Scan avec Limit (tr√®s rapide)
EXPLAIN ANALYZE
SELECT * FROM orders ORDER BY created_at DESC LIMIT 10;

Limit  (cost=0.42..1.23 rows=10 width=200)
  ->  Index Scan Backward using idx_orders_created_desc on orders
        (cost=0.42..8457.34 rows=100000 width=200)
```

**Am√©lioration** : PostgreSQL s'arr√™te apr√®s avoir lu 10 lignes, pas besoin de trier !

### Technique 7 : Utiliser les CTE judicieusement

```sql
-- ‚ùå POTENTIELLEMENT LENT : CTE non mat√©rialis√©e
WITH recent_orders AS (
    SELECT * FROM orders WHERE created_at > now() - interval '7 days'
)
SELECT u.username, count(o.*)
FROM users u
JOIN recent_orders o ON o.user_id = u.id
GROUP BY u.username;

-- CTE peut √™tre recalcul√© plusieurs fois ou emp√™cher optimisations
```

**Solutions** :

```sql
-- Option 1 : Forcer la mat√©rialisation (cache le r√©sultat)
WITH recent_orders AS MATERIALIZED (
    SELECT * FROM orders WHERE created_at > now() - interval '7 days'
)
SELECT u.username, count(o.*)
FROM users u
JOIN recent_orders o ON o.user_id = u.id
GROUP BY u.username;

-- Option 2 : R√©√©crire sans CTE (peut √™tre mieux optimis√©)
SELECT u.username, count(o.*)
FROM users u
JOIN orders o ON o.user_id = u.id
WHERE o.created_at > now() - interval '7 days'
GROUP BY u.username;
```

**Astuce** : Testez les deux versions avec EXPLAIN ANALYZE !

---

## Partie 6 : Optimisations avanc√©es

### Nouveaut√© PostgreSQL 18 : Skip Scan

PostgreSQL 18 peut maintenant utiliser des index multi-colonnes m√™me si la premi√®re colonne n'est pas dans la clause WHERE.

```sql
-- Index multi-colonnes
CREATE INDEX idx_orders_status_date ON orders(status, created_at);

-- Avant PG 18 : Seq Scan (ne pouvait pas utiliser l'index)
-- PG 18 : Skip Scan (utilise l'index !)
SELECT * FROM orders WHERE created_at > '2024-01-01';

Index Scan using idx_orders_status_date on orders
  Filter: (created_at > '2024-01-01')
```

**Avantage** : Moins d'index n√©cessaires, meilleure utilisation des index existants.

### Nouveaut√© PostgreSQL 18 : Auto-√©limination des self-joins

```sql
-- Avant PG 18 : Join inutile non d√©tect√©
SELECT DISTINCT o1.id
FROM orders o1
JOIN orders o2 ON o1.id = o2.id;

-- PG 18 d√©tecte et √©limine le self-join
-- Transform√© en :
SELECT DISTINCT id FROM orders;
```

### Nouveaut√© PostgreSQL 18 : Optimisation IN (VALUES ...)

```sql
-- Avant : Lent
SELECT * FROM users WHERE id IN (1, 2, 3, 4, 5);

-- PG 18 optimise automatiquement en :
SELECT * FROM users WHERE id = ANY(ARRAY[1, 2, 3, 4, 5]);
```

### Partitioning pour performances

```sql
-- Partitionner une grande table par date
CREATE TABLE logs (
    id BIGSERIAL,
    message TEXT,
    created_at TIMESTAMP
) PARTITION BY RANGE (created_at);

-- Cr√©er des partitions mensuelles
CREATE TABLE logs_2024_01 PARTITION OF logs
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE logs_2024_02 PARTITION OF logs
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- Requ√™te ne scanne que la partition pertinente
SELECT * FROM logs WHERE created_at >= '2024-01-15' AND created_at < '2024-01-20';

-- EXPLAIN montre : Partition Pruning
-- Scan uniquement logs_2024_01
```

**Avantages** :
- Scan de moins de donn√©es
- Maintenance par partition (VACUUM, index)
- Suppression rapide (DROP PARTITION)

---

## Partie 7 : Configuration PostgreSQL pour performances

### Param√®tres critiques

```sql
-- work_mem : M√©moire pour tris, hash tables
-- Par d√©faut : 4MB (souvent trop faible)
-- Recommand√© : 64MB - 256MB
SET work_mem = '128MB';

-- Effet visible dans EXPLAIN
EXPLAIN ANALYZE
SELECT * FROM orders ORDER BY created_at;

-- Avant (work_mem = 4MB) :
-- Sort Method: external merge  Disk: 123456kB  -- ‚ùå Trie sur disque !

-- Apr√®s (work_mem = 128MB) :
-- Sort Method: quicksort  Memory: 45678kB      -- ‚úÖ Trie en m√©moire !
```

**Attention** : `work_mem` peut √™tre utilis√© **plusieurs fois** par requ√™te. Formule :

```
M√©moire max = work_mem √ó max_connections √ó 2 √† 4
```

### effective_cache_size

Indique au planificateur combien de RAM le syst√®me a pour cacher les donn√©es.

```sql
-- Valeur recommand√©e : 50-75% de la RAM totale
-- Serveur avec 32GB RAM :
effective_cache_size = '24GB'
```

**Impact** : Influence les d√©cisions du planificateur (Index Scan vs Seq Scan).

### random_page_cost

Co√ªt relatif d'une lecture al√©atoire vs s√©quentielle.

```sql
-- HDD traditionnel (d√©faut)
random_page_cost = 4.0

-- SSD (recommand√©)
random_page_cost = 1.1

-- NVMe (tr√®s rapide)
random_page_cost = 1.0
```

**Impact** : Valeur plus basse favorise l'utilisation d'index.

### Configuration optimale pour performances

```sql
-- Dans postgresql.conf

# M√âMOIRE
shared_buffers = 8GB                # 25% de RAM
work_mem = 128MB                    # Pour tris, hash
maintenance_work_mem = 2GB          # Pour VACUUM, CREATE INDEX
effective_cache_size = 24GB         # 75% de RAM

# QUERY PLANNER
random_page_cost = 1.1              # Pour SSD
effective_io_concurrency = 200      # Op√©rations I/O parall√®les (SSD)
default_statistics_target = 100     # Statistiques plus pr√©cises

# PARALL√âLISATION
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_worker_processes = 8

# LOGGING (pour debugging)
log_min_duration_statement = 1000   # Log requ√™tes > 1s
log_line_prefix = '%t [%p]: '
shared_preload_libraries = 'pg_stat_statements'
```

---

## Partie 8 : Maintenance pour performances

### ANALYZE : Mettre √† jour les statistiques

Le planificateur se base sur des **statistiques** pour choisir le meilleur plan.

```sql
-- Statistiques obsol√®tes ‚Üí Mauvais plans
-- Exemple : Table a 1M lignes, mais stats disent 1000 lignes
-- Planificateur choisit Nested Loop ‚Üí Tr√®s lent !

-- Mettre √† jour les statistiques
ANALYZE users;
ANALYZE orders;

-- Ou toute la base
ANALYZE;
```

**Quand faire ANALYZE ?**
- Apr√®s gros import de donn√©es
- Apr√®s DELETE/UPDATE massif
- P√©riodiquement (autovacuum le fait automatiquement)

### VACUUM : Nettoyer les lignes mortes

Les UPDATE/DELETE laissent des "lignes mortes" qui ralentissent les scans.

```sql
-- Voir les lignes mortes
SELECT
    schemaname,
    tablename,
    n_live_tup,    -- Lignes vivantes
    n_dead_tup,    -- Lignes mortes
    last_vacuum,
    last_autovacuum
FROM pg_stat_user_tables
ORDER BY n_dead_tup DESC;

-- Si n_dead_tup √©lev√© :
VACUUM ANALYZE users;
```

### REINDEX : Reconstruire les index

Les index peuvent devenir "gonfl√©s" (bloat) avec le temps.

```sql
-- V√©rifier la taille des index
SELECT
    indexrelname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS size
FROM pg_stat_user_indexes
ORDER BY pg_relation_size(indexrelid) DESC;

-- Reconstruire un index gonfl√©
REINDEX INDEX CONCURRENTLY users_email_idx;

-- Ou toute une table
REINDEX TABLE CONCURRENTLY users;
```

**Note** : `CONCURRENTLY` permet de faire l'op√©ration sans bloquer les lectures/√©critures.

---

## Partie 9 : Outils et monitoring

### 1. pg_stat_statements (d√©j√† vu)

```sql
-- Reset les statistiques (pour commencer fresh)
SELECT pg_stat_statements_reset();

-- Apr√®s quelques heures, analyser
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 10;
```

### 2. explain.depesz.com

Service web pour visualiser et analyser les plans EXPLAIN.

```sql
-- Copier le r√©sultat de :
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)
SELECT * FROM orders WHERE user_id = 123;

-- Coller sur : https://explain.depesz.com/
```

**Avantages** :
- Visualisation graphique
- Coloration selon les co√ªts
- Recommandations d'optimisation

### 3. pgBadger (d√©j√† vu)

Analyse des logs pour identifier les requ√™tes probl√©matiques.

```bash
pgbadger /var/log/postgresql/*.log -o report.html
```

### 4. Extension pg_stat_kcache

```sql
-- Installer
CREATE EXTENSION pg_stat_kcache;

-- Voir les statistiques CPU et I/O par requ√™te
SELECT
    pss.query,
    pss.calls,
    pss.total_exec_time,
    psk.user_time,     -- CPU user time
    psk.system_time,   -- CPU system time
    psk.reads,         -- I/O reads
    psk.writes         -- I/O writes
FROM pg_stat_statements pss
JOIN pg_stat_kcache psk USING (userid, dbid, queryid)
ORDER BY pss.total_exec_time DESC
LIMIT 10;
```

### 5. Extension HypoPG (index hypoth√©tiques)

Tester des index **sans les cr√©er** !

```sql
-- Installer
CREATE EXTENSION hypopg;

-- Cr√©er un index hypoth√©tique
SELECT hypopg_create_index('CREATE INDEX ON orders(user_id, status)');

-- Voir son effet dans EXPLAIN
EXPLAIN SELECT * FROM orders WHERE user_id = 123 AND status = 'pending';
-- Le plan utilisera l'index hypoth√©tique si b√©n√©fique

-- Supprimer tous les index hypoth√©tiques
SELECT hypopg_reset();
```

**Usage** : Tester plusieurs strat√©gies d'indexation avant de cr√©er r√©ellement.

---

## Partie 10 : Anti-patterns et pi√®ges courants

### Pi√®ge 1 : N+1 queries

**Probl√®me** :

```python
# ‚ùå MAUVAIS : 1 requ√™te pour users + N requ√™tes pour orders
users = db.query("SELECT * FROM users LIMIT 100")
for user in users:
    orders = db.query("SELECT * FROM orders WHERE user_id = %s", user.id)
    print(f"{user.name} has {len(orders)} orders")

# Total : 101 requ√™tes !
```

**Solution** :

```python
# ‚úÖ BON : 2 requ√™tes seulement
users = db.query("SELECT * FROM users LIMIT 100")
user_ids = [u.id for u in users]
orders = db.query("""
    SELECT user_id, count(*) as order_count
    FROM orders
    WHERE user_id = ANY(%s)
    GROUP BY user_id
""", user_ids)

# Cr√©er un dict pour lookup rapide
order_counts = {o.user_id: o.order_count for o in orders}
for user in users:
    print(f"{user.name} has {order_counts.get(user.id, 0)} orders")
```

### Pi√®ge 2 : Fonctions dans WHERE emp√™chent index

```sql
-- ‚ùå MAUVAIS : Fonction emp√™che l'utilisation d'index
SELECT * FROM users WHERE LOWER(email) = 'alice@example.com';

-- ‚úÖ BON : Index fonctionnel
CREATE INDEX idx_users_email_lower ON users(LOWER(email));

-- Ou mieux : normaliser les donn√©es en amont
UPDATE users SET email = LOWER(email);
CREATE INDEX idx_users_email ON users(email);
```

### Pi√®ge 3 : Type mismatch

```sql
-- ‚ùå MAUVAIS : user_id est INTEGER, mais '123' est TEXT
-- PostgreSQL ne peut pas utiliser l'index !
SELECT * FROM orders WHERE user_id = '123';

-- ‚úÖ BON : M√™me type
SELECT * FROM orders WHERE user_id = 123;
```

### Pi√®ge 4 : OFFSET √©lev√©

```sql
-- ‚ùå MAUVAIS : Pour page 1000 (OFFSET 10000)
-- PostgreSQL doit scanner 10000 lignes puis les ignorer !
SELECT * FROM orders ORDER BY created_at OFFSET 10000 LIMIT 10;

-- ‚úÖ BON : Pagination par curseur
SELECT * FROM orders
WHERE created_at < '2024-01-01 10:30:00'  -- Last cr√©√© de page pr√©c√©dente
ORDER BY created_at DESC
LIMIT 10;
```

### Pi√®ge 5 : LIKE avec wildcard au d√©but

```sql
-- ‚ùå MAUVAIS : Ne peut pas utiliser l'index B-Tree
SELECT * FROM users WHERE email LIKE '%@example.com';

-- ‚úÖ Solutions :
-- 1. Cr√©er un index GIN avec trigram
CREATE EXTENSION pg_trgm;
CREATE INDEX idx_users_email_trgm ON users USING gin(email gin_trgm_ops);

-- 2. Ou utiliser full-text search
CREATE INDEX idx_users_email_fts ON users USING gin(to_tsvector('english', email));
SELECT * FROM users WHERE to_tsvector('english', email) @@ to_tsquery('example.com');

-- 3. Ou ajouter une colonne domain
ALTER TABLE users ADD COLUMN email_domain TEXT;
UPDATE users SET email_domain = split_part(email, '@', 2);
CREATE INDEX idx_users_email_domain ON users(email_domain);
SELECT * FROM users WHERE email_domain = 'example.com';
```

---

## Partie 11 : Checklist d'optimisation

### Niveau 1 : Diagnostic (15 minutes)

- [ ] Activer `pg_stat_statements`
- [ ] Identifier top 10 requ√™tes lentes (temps total)
- [ ] Identifier top 10 requ√™tes lentes (temps moyen)
- [ ] V√©rifier les logs pour requ√™tes > 1s

### Niveau 2 : Analyse (30 minutes)

Pour chaque requ√™te lente :

- [ ] Ex√©cuter `EXPLAIN ANALYZE`
- [ ] Identifier le n≈ìud le plus co√ªteux
- [ ] V√©rifier si index manquant
- [ ] V√©rifier si Seq Scan sur grande table
- [ ] V√©rifier les estimations vs r√©alit√© (rows)

### Niveau 3 : Action (temps variable)

- [ ] Cr√©er index manquants
- [ ] R√©√©crire requ√™tes probl√©matiques
- [ ] Ajouter `INCLUDE` aux index pour Index Only Scan
- [ ] Consid√©rer index partiels
- [ ] Consid√©rer partitioning pour tr√®s grandes tables

### Niveau 4 : Validation (15 minutes)

- [ ] Re-tester avec `EXPLAIN ANALYZE`
- [ ] V√©rifier am√©lioration des temps
- [ ] Surveiller impact sur autres requ√™tes
- [ ] Documenter changements

### Niveau 5 : Maintenance continue

- [ ] `ANALYZE` apr√®s gros changements
- [ ] `VACUUM` r√©gulier (autovacuum)
- [ ] Surveiller pg_stat_statements
- [ ] Review trimestriel des index

---

## Cas d'√©tude : Optimisation r√©elle

### Probl√®me : Dashboard lent

**Contexte** :
- Dashboard affiche statistiques utilisateur
- Temps de chargement : 8-12 secondes
- Requ√™te principale identifi√©e via pg_stat_statements

### √âtape 1 : Requ√™te originale

```sql
SELECT
    u.id,
    u.username,
    u.email,
    COUNT(DISTINCT o.id) as order_count,
    SUM(o.amount) as total_spent,
    MAX(o.created_at) as last_order_date,
    (
        SELECT COUNT(*) FROM reviews r
        WHERE r.user_id = u.id
    ) as review_count
FROM users u
LEFT JOIN orders o ON o.user_id = u.id
WHERE u.created_at > now() - interval '30 days'
GROUP BY u.id
ORDER BY total_spent DESC
LIMIT 20;
```

### √âtape 2 : EXPLAIN ANALYZE (avant)

```
Hash Join  (cost=45678.90..123456.78 rows=1000 width=200)
  (actual time=4567.123..11234.567 rows=20 loops=1)
  ->  Seq Scan on users u  (cost=0.00..12345.67 rows=5000 width=100)
        Filter: (created_at > (now() - '30 days'))
        Rows Removed by Filter: 995000
  ->  Hash  (cost=23456.78..23456.78 rows=100000 width=50)
        ->  Seq Scan on orders o  (cost=0.00..23456.78 rows=1000000 width=50)
  SubPlan 1
    ->  Aggregate  (cost=45.67..45.68 rows=1 width=8)
          ->  Seq Scan on reviews r  (cost=0.00..45.67 rows=5 width=0)
                Filter: (user_id = u.id)

Planning Time: 12.345 ms
Execution Time: 11234.567 ms
```

**Probl√®mes identifi√©s** :
1. Seq Scan sur `users` avec filtre (995k lignes supprim√©es)
2. Seq Scan sur `orders` (1M lignes)
3. Sous-requ√™te corr√©l√©e ex√©cut√©e pour chaque ligne
4. Pas d'index sur `users.created_at`

### √âtape 3 : Optimisations appliqu√©es

```sql
-- 1. Index sur created_at pour filtrer rapidement
CREATE INDEX idx_users_created ON users(created_at);

-- 2. Index pour les jointures
CREATE INDEX idx_orders_user_amount ON orders(user_id, amount, created_at);

-- 3. Index pour les reviews
CREATE INDEX idx_reviews_user ON reviews(user_id);

-- 4. R√©√©crire la requ√™te sans sous-requ√™te corr√©l√©e
SELECT
    u.id,
    u.username,
    u.email,
    COUNT(DISTINCT o.id) as order_count,
    SUM(o.amount) as total_spent,
    MAX(o.created_at) as last_order_date,
    COALESCE(r.review_count, 0) as review_count
FROM users u
LEFT JOIN orders o ON o.user_id = u.id
LEFT JOIN (
    SELECT user_id, COUNT(*) as review_count
    FROM reviews
    GROUP BY user_id
) r ON r.user_id = u.id
WHERE u.created_at > now() - interval '30 days'
GROUP BY u.id, r.review_count
ORDER BY total_spent DESC NULLS LAST
LIMIT 20;
```

### √âtape 4 : EXPLAIN ANALYZE (apr√®s)

```
Limit  (cost=234.56..345.67 rows=20 width=200)
  (actual time=5.123..12.456 rows=20 loops=1)
  ->  Sort  (cost=234.56..245.67 rows=1000 width=200)
        Sort Key: (sum(o.amount)) DESC NULLS LAST
        ->  Hash Left Join  (cost=123.45..234.56 rows=1000 width=200)
              ->  Index Scan using idx_users_created on users u
                    (cost=0.42..45.67 rows=5000 width=100)
                    Index Cond: (created_at > (now() - '30 days'))
              ->  Hash  (cost=100.00..100.00 rows=1000 width=50)
                    ->  Index Scan using idx_orders_user_amount on orders o
                          (cost=0.42..100.00 rows=50000 width=50)
              ->  Hash  (cost=23.45..23.45 rows=500 width=16)
                    ->  HashAggregate  (cost=20.00..23.45 rows=500 width=16)
                          ->  Index Only Scan using idx_reviews_user on reviews
                                (cost=0.42..15.00 rows=5000 width=8)

Planning Time: 2.345 ms
Execution Time: 12.567 ms
```

### R√©sultat

| M√©trique | Avant | Apr√®s | Am√©lioration |
|----------|-------|-------|--------------|
| Execution Time | 11,234 ms | 12.5 ms | **898√ó plus rapide** |
| Planning Time | 12.3 ms | 2.3 ms | 5√ó plus rapide |
| Rows Scanned | ~2,000,000 | ~10,000 | 200√ó moins |

**Actions** :
- 3 index cr√©√©s
- Requ√™te r√©√©crite (sans sous-requ√™te corr√©l√©e)
- Temps de chargement dashboard : **12 secondes ‚Üí 0.01 seconde**

---

## R√©sum√© des points cl√©s

‚úÖ **pg_stat_statements** : Extension indispensable pour identifier les slow queries

‚úÖ **EXPLAIN ANALYZE** : Outil principal pour comprendre pourquoi une requ√™te est lente

‚úÖ **Index appropri√©s** : Peuvent am√©liorer les performances de 100√ó √† 10,000√ó

‚úÖ **Index multi-colonnes** : Ordre important (√©galit√© avant range)

‚úÖ **Index Only Scan** : Le plus rapide, utiliser `INCLUDE` pour l'obtenir

‚úÖ **R√©√©criture de requ√™tes** : NOT EXISTS > NOT IN, UNION peut √™tre meilleur que OR

‚úÖ **Configuration** : work_mem, effective_cache_size, random_page_cost pour SSD

‚úÖ **Maintenance** : ANALYZE pour statistiques, VACUUM pour performance

‚úÖ **Anti-patterns** : √âviter N+1, fonctions dans WHERE, OFFSET √©lev√©

‚úÖ **Nouveaut√©s PG 18** : Skip Scan, auto-√©limination self-joins, optimisations OR/IN

---

## Conclusion

L'optimisation des requ√™tes est un **processus it√©ratif** :

1. **Mesurer** : Identifier les requ√™tes lentes avec pg_stat_statements
2. **Analyser** : Comprendre le plan avec EXPLAIN ANALYZE
3. **Optimiser** : Ajouter index, r√©√©crire requ√™tes, ajuster configuration
4. **Valider** : V√©rifier l'am√©lioration
5. **Surveiller** : Monitoring continu pour nouveaux probl√®mes

**R√®gles d'or** :
- Un bon index peut √™tre 1000√ó plus efficace qu'une requ√™te complexe
- EXPLAIN ANALYZE est votre meilleur ami
- Mesurez toujours avant et apr√®s l'optimisation
- Optimisez d'abord les requ√™tes √† fort impact (fr√©quentes OU tr√®s lentes)

Avec les techniques de ce chapitre, vous pouvez transformer une base de donn√©es lente en une machine de course performante. La majorit√© des probl√®mes de performance proviennent de **requ√™tes mal optimis√©es** plut√¥t que de limitations mat√©rielles. Investir du temps dans le query tuning est donc **toujours** rentable.

---

**Prochaine √©tape** : 19.4.6 - Connection storms et pooling

---


‚è≠Ô∏è [Connection storms et pooling](/19-postgresql-en-production/04.6-connection-storms-pooling.md)
