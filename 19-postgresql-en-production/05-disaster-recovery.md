ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 19.5. Disaster Recovery (DR) : Introduction

## Qu'est-ce que le Disaster Recovery ?

Imaginez-vous un lundi matin. Vous arrivez au bureau avec votre cafÃ©, prÃªt Ã  attaquer la semaine. Vous allumez votre ordinateur et dÃ©couvrez que votre serveur PostgreSQL de production est **complÃ¨tement inaccessible**.

- Le datacenter a pris feu pendant la nuit ğŸ”¥
- Un ransomware a chiffrÃ© toutes vos donnÃ©es ğŸ”’
- Une erreur humaine a supprimÃ© la base de donnÃ©es principale ğŸ—‘ï¸
- Une inondation a noyÃ© la salle serveur ğŸŒŠ

**Qu'allez-vous faire ?** Comment allez-vous rÃ©cupÃ©rer vos donnÃ©es ? Combien de temps faudra-t-il pour remettre le service en ligne ? Combien de donnÃ©es allez-vous perdre ?

C'est exactement Ã  ces questions que rÃ©pond le **Disaster Recovery** (rÃ©cupÃ©ration aprÃ¨s sinistre en franÃ§ais, abrÃ©gÃ© **DR**).

### DÃ©finition

Le **Disaster Recovery** est l'ensemble des **politiques, procÃ©dures, outils et processus** qui permettent de rÃ©cupÃ©rer et de protÃ©ger votre infrastructure informatique (ici, votre base de donnÃ©es PostgreSQL) en cas de **catastrophe majeure**.

En d'autres termes : c'est votre **plan de survie** pour votre base de donnÃ©es.

---

## Pourquoi le Disaster Recovery est-il critique ?

### Les chiffres qui font rÃ©flÃ©chir

Voici quelques statistiques qui montrent l'importance cruciale du DR :

| Statistique | Impact |
|------------|---------|
| **93% des entreprises** qui perdent leurs donnÃ©es pendant plus de 10 jours font faillite dans l'annÃ©e | Source : National Archives & Records Administration |
| **60% des PME** ferment dans les 6 mois suivant une perte de donnÃ©es majeure | Source : University of Texas |
| **CoÃ»t moyen d'un downtime** : 5 600â‚¬ par minute pour une grande entreprise | Source : Gartner 2024 |
| **81% des cyberattaques** ciblent les bases de donnÃ©es | Source : Verizon DBIR 2024 |
| **40% des entreprises** n'ont pas de plan DR formalisÃ© | Source : IDC Research |

**Conclusion :** Ne pas avoir de plan DR, c'est jouer Ã  la roulette russe avec votre entreprise.

### Les types de "dÃ©sastres"

Un dÃ©sastre n'est pas forcÃ©ment un Ã©vÃ©nement catastrophique comme un incendie. Voici les principaux types de dÃ©sastres que vous devez anticiper :

#### 1. DÃ©sastres naturels ğŸŒªï¸

- **Incendies** : Exemple cÃ©lÃ¨bre - OVH Strasbourg (mars 2021), 3,6 millions de sites affectÃ©s
- **Inondations** : Datacenters en sous-sol particuliÃ¨rement vulnÃ©rables
- **Tremblements de terre** : Risque dans certaines rÃ©gions (Japon, Californie, Italie)
- **Ouragans, tornades** : Dommages aux infrastructures Ã©lectriques et rÃ©seau
- **Pannes Ã©lectriques prolongÃ©es** : Texas (fÃ©vrier 2021), plusieurs jours sans Ã©lectricitÃ©

**Impact typique :** Perte totale du datacenter, indisponibilitÃ© de plusieurs jours Ã  semaines.

#### 2. Erreurs humaines ğŸ‘¤

- **Suppression accidentelle** : `DROP DATABASE production;` au lieu de `DROP DATABASE test;`
- **Mauvaise migration** : Script SQL qui corrompt les donnÃ©es
- **Mauvaise configuration** : Modification de postgresql.conf qui empÃªche le dÃ©marrage
- **Oubli de backup** : Les sauvegardes n'ont pas Ã©tÃ© vÃ©rifiÃ©es depuis des mois

**Statistique :** 30-40% des incidents de production sont dus Ã  l'erreur humaine (source : ITIC).

**Exemple rÃ©el :**
```sql
-- ScÃ©nario : Un dÃ©veloppeur se trompe de console
-- Il pense Ãªtre sur la base de test...
psql -h production-db.example.com -U admin

-- ... mais il est en rÃ©alitÃ© sur la production
DELETE FROM orders WHERE created_at < '2024-01-01';
-- Catastrophe : 500 000 commandes supprimÃ©es !

-- Sans backup rÃ©cent = perte dÃ©finitive
```

#### 3. Pannes matÃ©rielles ğŸ–¥ï¸

- **DÃ©faillance disque** : SSD/HDD qui lÃ¢chent sans prÃ©avis
- **Corruption mÃ©moire** : RAM dÃ©fectueuse qui corrompt les donnÃ©es
- **Panne alimentation** : Sans onduleur, corruption des donnÃ©es en cours d'Ã©criture
- **Surchauffe** : Climatisation dÃ©faillante â†’ arrÃªt d'urgence des serveurs
- **DÃ©faillance contrÃ´leur RAID** : Perte de plusieurs disques simultanÃ©ment

**DurÃ©e de vie moyenne :**
- Disque SSD : 5-7 ans
- Disque HDD : 3-5 ans
- Serveur : 5-7 ans

**Vous ALLEZ avoir une panne matÃ©rielle. Ce n'est qu'une question de temps.**

#### 4. Cyberattaques ğŸ¦¹

- **Ransomware** : Chiffrement de toutes vos donnÃ©es avec demande de ranÃ§on
- **Attaque DDoS** : Saturation du serveur, impossibilitÃ© d'accÃ¨s
- **Injection SQL** : Destruction ou vol de donnÃ©es
- **AccÃ¨s non autorisÃ©** : Ancien employÃ© mÃ©content qui supprime des donnÃ©es
- **Crypto-mining** : Serveur compromis utilisÃ© pour miner de la crypto

**Exemple de ransomware :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”’ YOUR DATABASE HAS BEEN ENCRYPTED           â”‚
â”‚                                                â”‚
â”‚  All your PostgreSQL data is locked.           â”‚
â”‚  Pay 50 BTC to recover your files.             â”‚
â”‚                                                â”‚
â”‚  Bitcoin Address: 1A1zP1eP5QGefi2DM...         â”‚
â”‚  Time remaining: 48 hours                      â”‚
â”‚                                                â”‚
â”‚  After 48h, data will be deleted forever.      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ne payez JAMAIS la ranÃ§on.** Avec un bon plan DR, vous pouvez restaurer sans payer.

#### 5. DÃ©sastres logiciels ğŸ›

- **Bug dans PostgreSQL** : Rare mais possible (corruption de donnÃ©es)
- **Bug dans l'application** : Boucle infinie qui corrompt les donnÃ©es
- **Migration ratÃ©e** : Upgrade de PostgreSQL 17 â†’ 18 qui Ã©choue
- **IncompatibilitÃ©** : Extension qui cause des crashs rÃ©pÃ©tÃ©s

#### 6. DÃ©sastres juridiques et politiques âš–ï¸

- **Saisie de serveurs** : Dans le cadre d'une enquÃªte
- **Fermeture administrative** : Non-conformitÃ© RGPD
- **Ã‰vÃ©nements gÃ©opolitiques** : Guerre, instabilitÃ© politique dans le pays hÃ©bergeur
- **Faillite de l'hÃ©bergeur** : Datacenter fermÃ© du jour au lendemain

---

## Les composantes d'un plan Disaster Recovery

Un plan DR complet pour PostgreSQL comprend plusieurs Ã©lÃ©ments interconnectÃ©s :

### 1. StratÃ©gie de Sauvegarde (Backup Strategy)

**Question clÃ© :** Comment et Ã  quelle frÃ©quence sauvegardez-vous vos donnÃ©es ?

```
Types de backup PostgreSQL :

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Sauvegardes Logiques (pg_dump)                   â”‚
â”‚    âœ… Flexible, portable                            â”‚
â”‚    âŒ Lent pour grandes bases                       â”‚
â”‚    FrÃ©quence : Quotidienne pour bases < 100 GB      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Sauvegardes Physiques (pg_basebackup)            â”‚
â”‚    âœ… Rapide, idÃ©al pour grandes bases              â”‚
â”‚    âŒ DÃ©pendant de la version PostgreSQL            â”‚
â”‚    FrÃ©quence : Quotidienne ou hebdomadaire          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Archivage WAL (Write-Ahead Logs)                 â”‚
â”‚    âœ… Point-in-Time Recovery (PITR)                 â”‚
â”‚    âœ… RPO minimal (< 1 minute possible)             â”‚
â”‚    FrÃ©quence : Continu (temps rÃ©el)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Snapshots (Cloud ou SAN)                         â”‚
â”‚    âœ… TrÃ¨s rapide (secondes)                        â”‚
â”‚    âŒ DÃ©pendant de l'infrastructure                 â”‚
â”‚    FrÃ©quence : Horaire ou plus                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. RÃ©plication

**Question clÃ© :** Avez-vous des copies en temps rÃ©el de vos donnÃ©es ?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PRIMARY SERVER                     â”‚
â”‚         (Paris - Production)                  â”‚
â”‚                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ PostgreSQL 18                   â”‚          â”‚
â”‚  â”‚ Read + Write                    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                 â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ Streaming Replication
                  â”‚ (WAL shipping)
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STANDBY #1    â”‚   â”‚ STANDBY #2    â”‚
â”‚ (Paris)       â”‚   â”‚ (Londres)     â”‚
â”‚ Read-only     â”‚   â”‚ Read-only     â”‚
â”‚               â”‚   â”‚               â”‚
â”‚ Hot Standby   â”‚   â”‚ Warm Standby  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Types de rÃ©plication :**
- **Streaming Replication** : RÃ©plication en temps quasi-rÃ©el (< 1 seconde)
- **Logical Replication** : RÃ©plication sÃ©lective (certaines tables)
- **Physical Replication** : Copie bit Ã  bit du serveur

### 3. Monitoring et Alerting

**Question clÃ© :** Savez-vous immÃ©diatement quand quelque chose ne va pas ?

```
MÃ©triques critiques Ã  surveiller :

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”´ CRITICAL ALERTS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ PostgreSQL down                                   â”‚
â”‚ â€¢ Replication lag > 60 secondes                     â”‚
â”‚ â€¢ Disk usage > 90%                                  â”‚
â”‚ â€¢ Backup failed                                     â”‚
â”‚ â€¢ Corruption dÃ©tectÃ©e (checksums)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸  WARNING ALERTS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Replication lag > 10 secondes                     â”‚
â”‚ â€¢ Disk usage > 80%                                  â”‚
â”‚ â€¢ Connections > 80% max_connections                 â”‚
â”‚ â€¢ Backup duration > 2Ã— normal                       â”‚
â”‚ â€¢ WAL archiving delayed                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. ProcÃ©dures de Restauration

**Question clÃ© :** Savez-vous exactement comment restaurer vos donnÃ©es ?

Un bon plan DR inclut des **runbooks** (procÃ©dures documentÃ©es) dÃ©taillÃ©s pour chaque scÃ©nario :

```markdown
RUNBOOK : Restauration complÃ¨te aprÃ¨s sinistre

ScÃ©nario : Serveur PostgreSQL production dÃ©truit
RTO cible : 2 heures
RPO cible : 15 minutes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ã‰TAPE 1 : Ã‰VALUATION (0-5 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ ] Confirmer que le serveur est vraiment down
[ ] Identifier la cause (hardware, rÃ©seau, logiciel)
[ ] DÃ©cider : rÃ©parer ou restaurer ?
[ ] DÃ©clarer l'incident (war room)

Ã‰TAPE 2 : PRÃ‰PARATION (5-15 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ ] Provisionner nouveau serveur (ou utiliser standby)
[ ] VÃ©rifier accÃ¨s rÃ©seau et DNS
[ ] PrÃ©parer environnement PostgreSQL

Ã‰TAPE 3 : RESTAURATION (15-90 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ ] TÃ©lÃ©charger dernier backup base
[ ] Extraire le backup
[ ] Restaurer les WAL archives (PITR)
[ ] Configurer PostgreSQL
[ ] DÃ©marrer PostgreSQL

Ã‰TAPE 4 : VALIDATION (90-110 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ ] VÃ©rifier intÃ©gritÃ© des donnÃ©es
[ ] Tester requÃªtes critiques
[ ] Valider avec Ã©quipe mÃ©tier
[ ] VÃ©rifier performances

Ã‰TAPE 5 : BASCULE (110-120 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ ] Rediriger le trafic (DNS/Load balancer)
[ ] Surveiller les mÃ©triques
[ ] Communiquer aux utilisateurs

CONTACTS URGENCE :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ DBA Lead : +33 6 12 34 56 78
â€¢ DevOps : +33 6 98 76 54 32
â€¢ CTO : +33 6 11 22 33 44
```

### 5. Tests RÃ©guliers

**Question clÃ© :** Avez-vous testÃ© votre plan DR rÃ©cemment ?

> **RÃ¨gle d'or :** Une procÃ©dure DR non testÃ©e n'est pas une procÃ©dure DR, c'est une thÃ©orie.

**FrÃ©quence recommandÃ©e des tests :**
- **Tests de backup** : Hebdomadaire (automatisÃ©)
- **Tests de restauration** : Mensuel ou trimestriel
- **Disaster Recovery Drill complet** : Semestriel ou annuel

### 6. Documentation et Formation

**Question clÃ© :** Toute l'Ã©quipe sait-elle quoi faire en cas de crise ?

**Ã‰lÃ©ments essentiels :**
- Diagrammes d'architecture Ã  jour
- Runbooks dÃ©taillÃ©s pour chaque scÃ©nario
- Contacts d'urgence (on-call rotation)
- AccÃ¨s d'urgence (credentials, VPN, serveurs)
- Formation rÃ©guliÃ¨re de l'Ã©quipe
- Post-mortems aprÃ¨s chaque incident

---

## La rÃ¨gle 3-2-1 des sauvegardes

C'est une rÃ¨gle fondamentale en Disaster Recovery :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RÃˆGLE 3-2-1                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  3ï¸âƒ£  Gardez AU MOINS 3 COPIES de vos donnÃ©es        â”‚
â”‚       (1 originale + 2 backups)                     â”‚
â”‚                                                     â”‚
â”‚  2ï¸âƒ£  Sur AU MOINS 2 TYPES de supports diffÃ©rents    â”‚
â”‚       (disque local + cloud S3, ou NAS + tape)      â”‚
â”‚                                                     â”‚
â”‚  1ï¸âƒ£  Dont AU MOINS 1 COPIE hors site (off-site)     â”‚
â”‚       (datacenter diffÃ©rent, rÃ©gion gÃ©ographique)   â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple d'application pour PostgreSQL :**

```
COPIE 1 : Production Database (Primary)
â””â”€ Serveur : Paris Datacenter
â””â”€ Support : SSD local

COPIE 2 : Backup quotidien
â””â”€ Serveur : NAS dans le mÃªme datacenter
â””â”€ Support : Disques durs (RAID 6)

COPIE 3 : Backup cloud
â””â”€ Serveur : AWS S3 (rÃ©gion eu-west-1)
â””â”€ Support : Object storage

COPIE BONUS : RÃ©plication
â””â”€ Serveur : Standby Ã  Londres (autre datacenter)
â””â”€ Support : SSD local
```

**Pourquoi cette rÃ¨gle est importante :**

| ScÃ©nario de dÃ©sastre | Protection |
|---------------------|-----------|
| ğŸ”¥ Incendie datacenter Paris | âœ… Copie #3 (S3) + Copie Bonus (Londres) OK |
| ğŸ’¾ DÃ©faillance disque local | âœ… Copies #2 et #3 OK |
| ğŸ¦¹ Ransomware qui chiffre tout | âœ… Copie #3 (S3 avec versioning) OK |
| ğŸ‘¤ Suppression accidentelle | âœ… Toutes les copies peuvent restaurer |
| ğŸŒŠ Inondation datacenter | âœ… Copie #3 (autre rÃ©gion) OK |

---

## Le coÃ»t du Disaster Recovery

### Combien coÃ»te un bon plan DR ?

**Benchmark par taille d'entreprise (estimation mensuelle) :**

#### Petite structure (1-10 personnes)

```
Base de donnÃ©es : < 100 GB
RTO acceptable : 4-8 heures
RPO acceptable : 1-4 heures

COÃ›TS :
â€¢ Backup S3 (100 GB) : 3â‚¬/mois
â€¢ Serveur standby (petit) : 50â‚¬/mois
â€¢ Temps Ã©quipe (setup + maintenance) : 200â‚¬/mois
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL : ~250â‚¬/mois (~3000â‚¬/an)
```

#### Entreprise moyenne (50-200 personnes)

```
Base de donnÃ©es : 500 GB - 2 TB
RTO acceptable : 1-2 heures
RPO acceptable : 15 minutes

COÃ›TS :
â€¢ Backup S3 (2 TB + archives) : 80â‚¬/mois
â€¢ Serveur standby (Ã©quivalent prod) : 600â‚¬/mois
â€¢ Monitoring (Datadog, New Relic) : 150â‚¬/mois
â€¢ Outils DR (pgBackRest, Patroni) : 0â‚¬ (open-source)
â€¢ Temps Ã©quipe (1 DevOps 20%) : 1000â‚¬/mois
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL : ~1830â‚¬/mois (~22 000â‚¬/an)
```

#### Grande entreprise (500+ personnes)

```
Base de donnÃ©es : 5+ TB
RTO acceptable : 15-30 minutes
RPO acceptable : 0-5 minutes

COÃ›TS :
â€¢ Backup multi-rÃ©gion (10 TB) : 400â‚¬/mois
â€¢ 2Ã— Serveurs standby (multi-rÃ©gion) : 2500â‚¬/mois
â€¢ Monitoring enterprise : 800â‚¬/mois
â€¢ Data transfer inter-rÃ©gions : 600â‚¬/mois
â€¢ Ã‰quipe DR dÃ©diÃ©e (2 personnes) : 12 000â‚¬/mois
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL : ~16 300â‚¬/mois (~195 000â‚¬/an)
```

### Et combien coÃ»te de NE PAS avoir de plan DR ?

**Exemple concret : E-commerce de taille moyenne**

```
ScÃ©nario : Panne totale pendant 24 heures

PERTES DIRECTES :
â€¢ Chiffre d'affaires perdu : 50 000â‚¬/jour
â€¢ Clients perdus dÃ©finitivement (10%) : 15 000â‚¬
â€¢ Frais de rÃ©cupÃ©ration d'urgence : 20 000â‚¬
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sous-total : 85 000â‚¬

PERTES INDIRECTES :
â€¢ Atteinte Ã  la rÃ©putation : 50 000â‚¬
â€¢ Temps Ã©quipe (crise + rÃ©cupÃ©ration) : 10 000â‚¬
â€¢ PÃ©nalitÃ©s contractuelles (SLA) : 25 000â‚¬
â€¢ Audit de sÃ©curitÃ© post-incident : 15 000â‚¬
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sous-total : 100 000â‚¬

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOTAL DES PERTES : 185 000â‚¬
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CoÃ»t annuel d'un bon plan DR : 22 000â‚¬
ROI : RentabilisÃ© dÃ¨s la premiÃ¨re panne Ã©vitÃ©e
```

**Conclusion :** Ne PAS investir dans le DR coÃ»te **beaucoup plus cher** que d'investir dedans.

---

## Les piÃ¨ges courants Ã  Ã©viter

### âŒ PiÃ¨ge #1 : "Nous avons des backups, Ã§a suffit"

**Erreur :** Penser que faire des backups = avoir un plan DR.

**RÃ©alitÃ© :** Les backups ne sont qu'**un Ã©lÃ©ment** du DR. Vous avez aussi besoin de :
- ProcÃ©dures de restauration testÃ©es
- Monitoring
- Infrastructure de secours
- Ã‰quipe formÃ©e
- Documentation Ã  jour

**Vrai DR = Backups + ProcÃ©dures + Tests + Formation**

### âŒ PiÃ¨ge #2 : "Nous avons testÃ© la restauration il y a 2 ans"

**Erreur :** Tester une seule fois et penser que c'est suffisant.

**RÃ©alitÃ© :**
- Votre infrastructure Ã©volue constamment
- PostgreSQL est upgradÃ©
- L'Ã©quipe change
- Les procÃ©dures deviennent obsolÃ¨tes

**Solution :** Tests rÃ©guliers (au moins trimestriels).

### âŒ PiÃ¨ge #3 : "Notre hÃ©bergeur s'occupe des backups"

**Erreur :** DÃ©lÃ©guer entiÃ¨rement la responsabilitÃ© DR Ã  un tiers.

**RÃ©alitÃ© :**
- Leur backup peut Ã©chouer
- Leurs procÃ©dures de restauration peuvent Ãªtre lentes
- Vous n'avez pas le contrÃ´le
- DÃ©pendance critique Ã  un fournisseur

**Solution :** Toujours avoir **vos propres backups** en plus, mÃªme si l'hÃ©bergeur en fait.

### âŒ PiÃ¨ge #4 : "Le DR, c'est pour les grandes entreprises"

**Erreur :** Penser que seules les grosses structures ont besoin de DR.

**RÃ©alitÃ© :** Les PME sont **plus vulnÃ©rables** :
- Moins de ressources pour rÃ©cupÃ©rer
- Impact proportionnellement plus important
- Moins de rÃ©silience financiÃ¨re

**Les PME sont celles qui ont le PLUS besoin de DR.**

### âŒ PiÃ¨ge #5 : "Nous sommes sur le cloud, nous sommes protÃ©gÃ©s"

**Erreur :** Croire que le cloud vous protÃ¨ge automatiquement.

**RÃ©alitÃ© :**
- Le cloud protÃ¨ge contre les pannes matÃ©rielles
- Mais PAS contre : erreurs humaines, bugs logiciels, cyberattaques
- ResponsabilitÃ© partagÃ©e : l'hÃ©bergeur gÃ¨re l'infra, vous gÃ©rez vos donnÃ©es

**Le cloud facilite le DR, mais ne le remplace pas.**

---

## Matrice de risques et stratÃ©gies DR

Voici comment adapter votre stratÃ©gie DR selon votre contexte :

| Type d'application | CriticitÃ© | RTO suggÃ©rÃ© | RPO suggÃ©rÃ© | StratÃ©gie DR |
|-------------------|-----------|-------------|-------------|--------------|
| **Blog personnel** | Faible | 7 jours | 7 jours | Backup hebdomadaire S3 |
| **Site vitrine PME** | Moyenne | 24-48h | 24h | Backup quotidien + monitoring |
| **Application SaaS B2B** | Ã‰levÃ©e | 2-4h | 1h | Backup + WAL archiving + standby |
| **E-commerce** | Critique | 30min-2h | 15min | RÃ©plication synchrone + multi-AZ |
| **Banque, Finance** | Critique+ | 5-15min | 0-1min | Multi-rÃ©gion + HA automatisÃ©e |
| **SystÃ¨mes mÃ©dicaux** | Critique+ | <5min | 0 | RÃ©plication synchrone multi-site |

---

## Le Disaster Recovery, c'est un Ã©tat d'esprit

Le DR n'est pas qu'une question technique, c'est une **culture** :

### Principes fondamentaux

1. **Assumer que tout peut Ã©chouer**
   - Murphy's Law : "Tout ce qui peut mal tourner, va mal tourner"
   - Ne jamais dire "Ã§a ne peut pas arriver chez nous"

2. **Tester, tester, tester**
   - Un plan non testÃ© est un plan qui ne fonctionne pas
   - Les tests rÃ©vÃ¨lent les faiblesses avant qu'il ne soit trop tard

3. **Documenter tout**
   - Les procÃ©dures doivent Ãªtre claires pour n'importe qui
   - Les runbooks doivent Ãªtre Ã  jour

4. **Former l'Ã©quipe**
   - Tout le monde doit savoir quoi faire
   - Exercices rÃ©guliers (fire drills)

5. **AmÃ©liorer continuellement**
   - Chaque incident est une opportunitÃ© d'apprentissage
   - Post-mortems blameless (sans blÃ¢mer les personnes)

6. **Accepter le coÃ»t**
   - Le DR a un coÃ»t, c'est une assurance
   - Mieux vaut payer pour ne pas l'utiliser que de ne pas l'avoir quand on en a besoin

---

## Structure de cette section du tutoriel

Cette introduction au Disaster Recovery vous a prÃ©sentÃ© les concepts fondamentaux. Les sections suivantes vont approfondir chaque aspect :

### ğŸ“‹ Ce que vous allez apprendre

```
19.5. Disaster Recovery (DR) â† Vous Ãªtes ici
â”‚
â”œâ”€ 19.5.1. RTO et RPO : DÃ©finir les objectifs
â”‚   â””â”€ Comment dÃ©terminer vos objectifs de rÃ©cupÃ©ration
â”‚
â”œâ”€ 19.5.2. Tests de restauration rÃ©guliers
â”‚   â””â”€ Pourquoi, quand et comment tester vos procÃ©dures
â”‚
â””â”€ 19.5.3. GÃ©o-rÃ©plication et Multi-Region
    â””â”€ ProtÃ©ger contre les catastrophes rÃ©gionales
```

### Progression pÃ©dagogique

Chaque section s'appuie sur la prÃ©cÃ©dente :

1. **D'abord**, vous dÃ©finissez vos objectifs (RTO/RPO)
2. **Ensuite**, vous mettez en place les procÃ©dures
3. **Puis**, vous testez rÃ©guliÃ¨rement
4. **Enfin**, vous Ã©tendez gÃ©ographiquement si nÃ©cessaire

---

## Checklist : Avez-vous un plan DR ?

Ã‰valuez votre situation actuelle :

### âœ… Backups

- [ ] Vous avez des backups automatisÃ©s
- [ ] Les backups sont testÃ©s rÃ©guliÃ¨rement (au moins trimestriellement)
- [ ] Vous appliquez la rÃ¨gle 3-2-1
- [ ] Les backups sont stockÃ©s hors site (diffÃ©rent datacenter)
- [ ] Vous archivez les WAL pour Point-in-Time Recovery
- [ ] Vous savez combien de temps prend une restauration
- [ ] Vous avez documentÃ© la procÃ©dure de restauration

### âœ… RÃ©plication

- [ ] Vous avez au moins 1 serveur standby
- [ ] La rÃ©plication est monitorÃ©e
- [ ] Le lag de rÃ©plication est < 10 secondes
- [ ] Vous avez testÃ© un failover manuel
- [ ] Vous connaissez le temps nÃ©cessaire pour un failover

### âœ… Monitoring et Alertes

- [ ] Vous Ãªtes alertÃ© si PostgreSQL tombe
- [ ] Vous Ãªtes alertÃ© si les backups Ã©chouent
- [ ] Vous Ãªtes alertÃ© si la rÃ©plication prend du retard
- [ ] Vous avez un systÃ¨me d'astreinte (on-call)
- [ ] Les alertes sont envoyÃ©es sur plusieurs canaux

### âœ… Documentation et ProcÃ©dures

- [ ] Vous avez des runbooks Ã©crits pour chaque scÃ©nario
- [ ] Les runbooks sont Ã  jour (< 6 mois)
- [ ] Toute l'Ã©quipe sait oÃ¹ trouver les runbooks
- [ ] Les contacts d'urgence sont documentÃ©s
- [ ] Les accÃ¨s d'urgence sont documentÃ©s et testÃ©s

### âœ… Tests et Formation

- [ ] Vous testez les restaurations au moins trimestriellement
- [ ] Toute l'Ã©quipe technique a Ã©tÃ© formÃ©e aux procÃ©dures DR
- [ ] Vous faites des post-mortems aprÃ¨s chaque incident
- [ ] Vous avez fait au moins 1 disaster recovery drill complet

### âœ… Objectifs et ConformitÃ©

- [ ] Vous avez dÃ©fini votre RTO (Recovery Time Objective)
- [ ] Vous avez dÃ©fini votre RPO (Recovery Point Objective)
- [ ] Vos objectifs sont validÃ©s par la direction
- [ ] Vous respectez vos objectifs (mesurÃ© lors des tests)
- [ ] Vous Ãªtes conforme aux obligations lÃ©gales (RGPD, etc.)

### Scoring

- **12-15 âœ…** : Excellent ! Vous avez un bon plan DR
- **8-11 âœ…** : Bien, mais des amÃ©liorations sont nÃ©cessaires
- **4-7 âœ…** : Attention ! Votre organisation est Ã  risque
- **0-3 âœ…** : ğŸš¨ Critique ! Vous Ãªtes en danger, agissez immÃ©diatement

---

## Conclusion de l'introduction

Le Disaster Recovery n'est pas une option, c'est une **nÃ©cessitÃ© absolue** pour toute organisation qui dÃ©pend de ses donnÃ©es (donc, toutes les organisations).

**Les questions que vous devez vous poser :**

1. **Si notre base de donnÃ©es disparaÃ®t ce soir, que se passe-t-il demain matin ?**
2. **Combien de donnÃ©es pouvons-nous nous permettre de perdre ?**
3. **Combien de temps pouvons-nous rester hors ligne ?**
4. **Notre Ã©quipe sait-elle exactement quoi faire en cas de crise ?**

Si vous n'avez pas de rÃ©ponses claires et rassurantes Ã  ces questions, **c'est maintenant qu'il faut agir**.

### Les 3 actions immÃ©diates

Si vous n'avez pas encore de plan DR, commencez par ces 3 actions dÃ¨s aujourd'hui :

1. **ğŸ“¦ Mettez en place des backups automatisÃ©s**
   - Au minimum : backup quotidien vers S3 ou Ã©quivalent
   - Testez une restauration cette semaine

2. **ğŸ“ Documentez vos procÃ©dures**
   - CrÃ©ez un runbook simple avec les Ã©tapes de restauration
   - Notez les contacts d'urgence

3. **â° Planifiez votre premier test**
   - Dans 2 semaines maximum
   - Bloquez 2 heures dans votre calendrier
   - Testez une restauration complÃ¨te

**Ne reportez pas.** Le meilleur moment pour mettre en place un plan DR Ã©tait il y a 1 an. Le deuxiÃ¨me meilleur moment, c'est **maintenant**.

---

### Prochaine Ã©tape

Maintenant que vous comprenez l'importance du Disaster Recovery et ses composantes principales, la premiÃ¨re Ã©tape concrÃ¨te consiste Ã  **dÃ©finir vos objectifs de rÃ©cupÃ©ration**.

C'est exactement ce que nous allons voir dans la section suivante : **19.5.1. RTO et RPO : DÃ©finir les objectifs**.

Vous y dÃ©couvrirez comment calculer :
- Le temps d'indisponibilitÃ© maximum acceptable (RTO)
- La quantitÃ© de donnÃ©es que vous pouvez perdre (RPO)
- Comment ces objectifs influencent votre architecture technique

**Passons Ã  la suite ! â†’**

---

> **Citation pour finir :**
> *"Hope is not a strategy."* â€” Proverbe DevOps
> (L'espoir n'est pas une stratÃ©gie. Ayez un vrai plan DR.)

â­ï¸ [RTO et RPO : DÃ©finir les objectifs](/19-postgresql-en-production/05.1-rto-rpo-objectifs.md)
