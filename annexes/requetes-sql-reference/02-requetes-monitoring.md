üîù Retour au [Sommaire](/SOMMAIRE.md)

# Requ√™tes de Monitoring PostgreSQL
## Cache Hit Ratio et Slow Queries

---

## Table des Mati√®res

1. [Introduction au Monitoring PostgreSQL](#1-introduction-au-monitoring-postgresql)
2. [Cache Hit Ratio : Comprendre et Optimiser](#2-cache-hit-ratio--comprendre-et-optimiser)
3. [Slow Queries : Identifier et Corriger](#3-slow-queries--identifier-et-corriger)
4. [M√©triques Compl√©mentaires Essentielles](#4-m%C3%A9triques-compl%C3%A9mentaires-essentielles)
5. [Mise en Pratique : Diagnostic de Performance](#5-mise-en-pratique--diagnostic-de-performance)
6. [Automatisation et Alerting](#6-automatisation-et-alerting)
7. [Bonnes Pratiques de Monitoring](#7-bonnes-pratiques-de-monitoring)

---

## 1. Introduction au Monitoring PostgreSQL

### 1.1. Pourquoi Monitorer Votre Base de Donn√©es ?

Le monitoring (surveillance) de PostgreSQL est **essentiel** pour :

1. **D√©tecter les probl√®mes avant qu'ils ne deviennent critiques**
   - Une requ√™te lente aujourd'hui = une panne demain
   - Un cache inefficace = des co√ªts serveur multipli√©s

2. **Optimiser les performances**
   - Identifier les goulots d'√©tranglement
   - Valider l'impact des optimisations

3. **Planifier la capacit√©**
   - Savoir quand ajouter de la RAM, du CPU, du stockage
   - √âviter les surprises lors des pics de charge

4. **Garantir la disponibilit√©**
   - Respecter les SLA (Service Level Agreement)
   - Maintenir une exp√©rience utilisateur fluide

### 1.2. Les Deux Piliers du Monitoring PostgreSQL

Ce tutoriel se concentre sur les deux m√©triques les plus importantes :

#### Cache Hit Ratio (Taux de succ√®s du cache)

**Qu'est-ce que c'est ?**
Le pourcentage de fois o√π PostgreSQL trouve les donn√©es dans la **m√©moire RAM** plut√¥t que de devoir les lire sur le **disque**.

**Pourquoi c'est important ?**
- Lire en RAM : **~100 nanosecondes**
- Lire sur disque SSD : **~100 microsecondes** (1000√ó plus lent)
- Lire sur disque HDD : **~10 millisecondes** (100 000√ó plus lent)

**Objectif** : Viser un cache hit ratio **> 95%**

#### Slow Queries (Requ√™tes lentes)

**Qu'est-ce que c'est ?**
Les requ√™tes SQL qui prennent **trop de temps** √† s'ex√©cuter.

**Pourquoi c'est important ?**
- 1 requ√™te lente peut bloquer des centaines d'utilisateurs
- Consomme des ressources (CPU, RAM, I/O)
- D√©grade l'exp√©rience utilisateur

**Objectif** : Identifier et optimiser toute requ√™te > 100-200ms

### 1.3. Les Vues Syst√®me PostgreSQL pour le Monitoring

PostgreSQL expose des **vues syst√®me** qui collectent automatiquement des statistiques :

| Vue | Usage |
|-----|-------|
| `pg_stat_database` | Statistiques globales par base de donn√©es |
| `pg_stat_user_tables` | Statistiques par table (scans, tuples) |
| `pg_stat_user_indexes` | Statistiques par index (scans, tuples) |
| `pg_statio_user_tables` | Statistiques I/O par table |
| `pg_statio_user_indexes` | Statistiques I/O par index |
| `pg_stat_statements` | **Extension** : Toutes les requ√™tes ex√©cut√©es |
| `pg_stat_activity` | Activit√© en temps r√©el (connexions, requ√™tes) |

### 1.4. Configuration Pr√©alable : pg_stat_statements

L'extension **pg_stat_statements** est **indispensable** pour monitorer les slow queries. Elle doit √™tre activ√©e manuellement.

#### Installation (une seule fois par base de donn√©es)

```sql
-- Se connecter √† votre base de donn√©es
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
```

#### Configuration dans postgresql.conf

```conf
# Ajouter dans postgresql.conf
shared_preload_libraries = 'pg_stat_statements'

# Configuration recommand√©e
pg_stat_statements.max = 10000          # Nombre de requ√™tes track√©es
pg_stat_statements.track = all          # Tracker toutes les requ√™tes
pg_stat_statements.track_utility = on   # Inclure DDL (CREATE, ALTER, etc.)
```

**Red√©marrage requis** apr√®s modification de `shared_preload_libraries`.

#### V√©rifier que l'extension est active

```sql
SELECT * FROM pg_stat_statements LIMIT 5;
```

Si la requ√™te retourne des r√©sultats, c'est bon ! Sinon, v√©rifiez la configuration.

---

## 2. Cache Hit Ratio : Comprendre et Optimiser

### 2.1. Qu'est-ce que le Buffer Cache ?

PostgreSQL utilise une zone de m√©moire RAM appel√©e **Shared Buffers** pour mettre en cache les pages de donn√©es lues depuis le disque.

#### Fonctionnement en D√©tail

1. **Premi√®re lecture** : Donn√©es lues depuis le disque ‚Üí Copi√©es dans le buffer cache
2. **Lectures suivantes** : Si les donn√©es sont encore en cache ‚Üí Lecture instantan√©e
3. **Cache plein** : Algorithme LRU (Least Recently Used) √©vince les donn√©es anciennes

**Configuration** : Le param√®tre `shared_buffers` dans `postgresql.conf`

```conf
# Recommandation g√©n√©rale : 25% de la RAM
# Serveur avec 16 GB RAM ‚Üí shared_buffers = 4 GB
shared_buffers = 4GB
```

### 2.2. Cache Hit Ratio : Formule et Interpr√©tation

Le cache hit ratio se calcule ainsi :

```
Cache Hit Ratio = (blks_hit / (blks_hit + blks_read)) √ó 100
```

O√π :
- **blks_hit** : Nombre de blocs lus depuis le cache (RAM)
- **blks_read** : Nombre de blocs lus depuis le disque

**Interpr√©tation** :

| Ratio | √âtat | Action |
|-------|------|--------|
| > 99% | **Excellent** | Continuez ainsi |
| 95-99% | **Bon** | Acceptable pour la plupart des cas |
| 90-95% | **Moyen** | Envisagez d'augmenter shared_buffers |
| < 90% | **Mauvais** | Action urgente requise |

### 2.3. Requ√™te : Cache Hit Ratio Global (Base de Donn√©es)

Cette requ√™te mesure le cache hit ratio pour toute la base de donn√©es :

```sql
SELECT
    datname AS database_name,
    blks_hit AS cache_hits,
    blks_read AS disk_reads,
    blks_hit + blks_read AS total_reads,
    round(
        100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0),
        2
    ) AS cache_hit_ratio_pct
FROM
    pg_stat_database
WHERE
    datname IS NOT NULL
    AND (blks_hit + blks_read) > 0
ORDER BY
    cache_hit_ratio_pct ASC;
```

**Ce que vous cherchez** :
- Votre base de donn√©es doit avoir un ratio > 95%
- Si < 95%, c'est un signal d'alerte

**Exemple de r√©sultat** :

```
database_name | cache_hits | disk_reads | total_reads | cache_hit_ratio_pct
--------------+------------+------------+-------------+--------------------
production    | 15234567   | 456789     | 15691356    | 97.09
```

### 2.4. Requ√™te : Cache Hit Ratio par Table

Pour identifier quelles tables causent des lectures disque excessives :

```sql
SELECT
    schemaname,
    relname AS table_name,
    heap_blks_hit AS cache_hits,
    heap_blks_read AS disk_reads,
    heap_blks_hit + heap_blks_read AS total_reads,
    round(
        100.0 * heap_blks_hit / NULLIF(heap_blks_hit + heap_blks_read, 0),
        2
    ) AS cache_hit_ratio_pct,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||relname)) AS total_size
FROM
    pg_statio_user_tables
WHERE
    (heap_blks_hit + heap_blks_read) > 100  -- Ignorer les tables peu utilis√©es
ORDER BY
    cache_hit_ratio_pct ASC
LIMIT 20;
```

**Analyse** :

- **Table avec ratio < 90%** : Candidate √† l'optimisation ou au partitionnement
- **Grosse table avec ratio < 90%** : Critique, action imm√©diate
- **Petite table avec ratio < 90%** : Moins grave mais √† surveiller

**Exemple de r√©sultat** :

```
table_name | cache_hits | disk_reads | cache_hit_ratio_pct | total_size
-----------+------------+------------+---------------------+-----------
orders     | 1234       | 5678       | 17.85               | 45 GB
products   | 89012      | 123        | 99.86               | 2 GB
```

‚Üí La table `orders` a un ratio catastrophique : **17.85%**. Il faut agir.

### 2.5. Requ√™te : Cache Hit Ratio par Index

Les index aussi b√©n√©ficient du cache :

```sql
SELECT
    schemaname,
    relname AS table_name,
    indexrelname AS index_name,
    idx_blks_hit AS cache_hits,
    idx_blks_read AS disk_reads,
    idx_blks_hit + idx_blks_read AS total_reads,
    round(
        100.0 * idx_blks_hit / NULLIF(idx_blks_hit + idx_blks_read, 0),
        2
    ) AS cache_hit_ratio_pct,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM
    pg_statio_user_indexes
WHERE
    (idx_blks_hit + idx_blks_read) > 100
ORDER BY
    cache_hit_ratio_pct ASC
LIMIT 20;
```

**Analyse** :

- Un index avec un mauvais ratio consomme beaucoup d'I/O
- Si l'index est peu utilis√© (`idx_scan` faible) : Envisagez de le supprimer
- Si l'index est tr√®s utilis√© : C'est normal qu'il soit souvent lu depuis le disque

### 2.6. Diagnostiquer un Mauvais Cache Hit Ratio

Si votre cache hit ratio est < 95%, plusieurs causes possibles :

#### Cause 1 : shared_buffers Trop Petit

**Solution** : Augmenter `shared_buffers` dans `postgresql.conf`

```conf
# Avant
shared_buffers = 128MB

# Apr√®s (pour serveur avec 16 GB RAM)
shared_buffers = 4GB
```

**Attention** : N√©cessite un red√©marrage de PostgreSQL.

#### Cause 2 : Workload "Cold" (D√©marrage R√©cent)

Juste apr√®s un red√©marrage, le cache est vide. C'est normal d'avoir un ratio bas temporairement.

**Solution** : Attendre quelques heures que le cache se "r√©chauffe".

#### Cause 3 : Donn√©es Plus Grosses que la RAM

Si votre base de donn√©es fait 500 GB et que vous avez 16 GB de RAM, vous ne pourrez **jamais** tout mettre en cache.

**Solutions** :
1. Ajouter plus de RAM
2. Partitionner les tables pour r√©duire la surface de scan
3. Archiver les donn√©es anciennes
4. Utiliser un r√©plica en lecture seule pour r√©partir la charge

#### Cause 4 : Requ√™tes Inefficaces (Scan S√©quentiels)

Des requ√™tes qui font des scans s√©quentiels sur de grosses tables vont syst√©matiquement lire depuis le disque.

**Solution** : Cr√©er des index appropri√©s (voir section 3).

### 2.7. Requ√™te : Taille de la Base vs Shared Buffers

Pour √©valuer si votre cache est dimensionn√© correctement :

```sql
SELECT
    pg_size_pretty(pg_database_size(current_database())) AS database_size,
    current_setting('shared_buffers') AS shared_buffers_setting,
    pg_size_pretty(
        pg_size_bytes(current_setting('shared_buffers'))
    ) AS shared_buffers_size,
    round(
        100.0 * pg_size_bytes(current_setting('shared_buffers')) /
        pg_database_size(current_database()),
        2
    ) AS cache_coverage_pct;
```

**Interpr√©tation** :

- **cache_coverage_pct > 50%** : Excellent, une grande partie de la DB peut tenir en cache
- **cache_coverage_pct < 10%** : Tr√®s peu de donn√©es en cache, augmentez shared_buffers si possible

### 2.8. Nouveaut√© PostgreSQL 18 : Statistiques I/O par Backend

PostgreSQL 18 ajoute des statistiques I/O d√©taill√©es par processus backend :

```sql
-- Requ√™te pour voir les I/O par session active
SELECT
    pid,
    usename,
    application_name,
    query,
    backend_type,
    -- Statistiques I/O (PostgreSQL 18)
    CASE
        WHEN backend_type = 'client backend' THEN 'Active Connection'
        ELSE backend_type
    END AS connection_type
FROM
    pg_stat_activity
WHERE
    state = 'active'
    AND pid != pg_backend_pid()  -- Exclure cette requ√™te
ORDER BY
    query_start DESC;
```

**Note** : Les colonnes I/O d√©taill√©es sont disponibles dans les vues `pg_stat_io` (PostgreSQL 18).

---

## 3. Slow Queries : Identifier et Corriger

### 3.1. Qu'est-ce qu'une Slow Query ?

Une **slow query (requ√™te lente)** est une requ√™te SQL qui prend plus de temps que souhait√© √† s'ex√©cuter.

**Seuils typiques** :

| Type d'application | Seuil "lent" | Seuil "critique" |
|-------------------|--------------|------------------|
| API Web temps r√©el | > 100ms | > 500ms |
| Dashboard analytics | > 1s | > 10s |
| Batch processing | > 10s | > 60s |

**Impact** :

- **Utilisateur** : Timeouts, frustration
- **Serveur** : Consommation CPU/RAM excessive
- **Base de donn√©es** : Verrous prolong√©s, congestion

### 3.2. Installation et Configuration de pg_stat_statements

**Rappel** : pg_stat_statements est l'outil indispensable pour tracker les slow queries.

Si ce n'est pas d√©j√† fait, suivez les √©tapes de la section 1.4.

### 3.3. Requ√™te : Top 20 des Requ√™tes les Plus Lentes (Temps Total)

Cette requ√™te identifie les requ√™tes qui ont consomm√© le **plus de temps cumul√©** :

```sql
SELECT
    round(total_exec_time::numeric, 2) AS total_time_ms,
    calls,
    round(mean_exec_time::numeric, 2) AS avg_time_ms,
    round(max_exec_time::numeric, 2) AS max_time_ms,
    round(min_exec_time::numeric, 2) AS min_time_ms,
    round((100 * total_exec_time / sum(total_exec_time) OVER ())::numeric, 2) AS pct_total_time,
    query
FROM
    pg_stat_statements
WHERE
    query NOT LIKE '%pg_stat_statements%'  -- Exclure les requ√™tes de monitoring
ORDER BY
    total_exec_time DESC
LIMIT 20;
```

**Colonnes importantes** :

- **total_time_ms** : Temps cumul√© total (si une requ√™te s'ex√©cute 1000√ó pendant 10ms = 10 000ms)
- **calls** : Nombre d'ex√©cutions
- **avg_time_ms** : Temps moyen par ex√©cution
- **max_time_ms** : Temps maximum enregistr√© (pic)
- **pct_total_time** : Pourcentage du temps total de toutes les requ√™tes

**Analyse** :

- **Requ√™te avec total_time √©lev√© + avg_time faible** : Requ√™te fr√©quente, optimiser r√©duira beaucoup la charge
- **Requ√™te avec avg_time tr√®s √©lev√©** : Requ√™te lente, m√™me si rare

**Exemple de r√©sultat** :

```
total_time_ms | calls | avg_time_ms | pct_total_time | query
--------------+-------+-------------+----------------+-------
125678.45     | 50000 | 2.51        | 45.23          | SELECT * FROM orders WHERE user_id = $1
23456.78      | 100   | 234.57      | 8.44           | SELECT COUNT(*) FROM logs WHERE date > $1
```

‚Üí La premi√®re requ√™te repr√©sente **45% du temps total** : **priorit√© absolue**.

### 3.4. Requ√™te : Top 20 des Requ√™tes les Plus Lentes (Temps Moyen)

Pour identifier les requ√™tes individuellement lentes :

```sql
SELECT
    round(mean_exec_time::numeric, 2) AS avg_time_ms,
    round(max_exec_time::numeric, 2) AS max_time_ms,
    calls,
    round(total_exec_time::numeric, 2) AS total_time_ms,
    round(stddev_exec_time::numeric, 2) AS stddev_time_ms,
    query
FROM
    pg_stat_statements
WHERE
    calls > 10  -- Ignorer les requ√™tes ex√©cut√©es trop rarement
    AND query NOT LIKE '%pg_stat_statements%'
ORDER BY
    mean_exec_time DESC
LIMIT 20;
```

**Analyse** :

- **avg_time_ms > 1000ms (1s)** : Tr√®s lent, optimisation urgente
- **stddev_time_ms √©lev√©** : Performance instable, peut indiquer des verrous ou de la contention

### 3.5. Requ√™te : Requ√™tes Avec le Plus de Lectures Disque

Les requ√™tes qui lisent beaucoup depuis le disque sont souvent lentes :

```sql
SELECT
    round(mean_exec_time::numeric, 2) AS avg_time_ms,
    calls,
    shared_blks_hit AS cache_hits,
    shared_blks_read AS disk_reads,
    round(
        100.0 * shared_blks_hit / NULLIF(shared_blks_hit + shared_blks_read, 0),
        2
    ) AS cache_hit_ratio_pct,
    query
FROM
    pg_stat_statements
WHERE
    (shared_blks_hit + shared_blks_read) > 1000  -- Au moins 1000 blocs lus
ORDER BY
    shared_blks_read DESC
LIMIT 20;
```

**Analyse** :

- **disk_reads √©lev√©** : La requ√™te lit beaucoup depuis le disque
- **cache_hit_ratio_pct < 90%** : Mauvais taux de cache pour cette requ√™te

**Solution** : Ajouter un index ou augmenter shared_buffers.

### 3.6. Requ√™te : Requ√™tes en Cours d'Ex√©cution (Temps R√©el)

Pour voir les requ√™tes **actuellement en train de s'ex√©cuter** :

```sql
SELECT
    pid,
    usename AS user,
    application_name,
    client_addr,
    state,
    query_start,
    now() - query_start AS duration,
    wait_event_type,
    wait_event,
    query
FROM
    pg_stat_activity
WHERE
    state = 'active'
    AND pid != pg_backend_pid()  -- Exclure cette requ√™te
    AND query NOT LIKE '%pg_stat_activity%'
ORDER BY
    query_start ASC;  -- Les plus anciennes d'abord
```

**Colonnes importantes** :

- **duration** : Depuis combien de temps la requ√™te tourne
- **wait_event_type** / **wait_event** : Ce que la requ√™te attend (Lock, I/O, etc.)
- **query** : La requ√™te SQL en cours

**Si duration > 5 minutes** : Requ√™te probablement bloqu√©e ou tr√®s lente.

### 3.7. Analyser une Slow Query avec EXPLAIN ANALYZE

Une fois qu'une requ√™te lente est identifi√©e, il faut comprendre **pourquoi** elle est lente.

**Outil** : `EXPLAIN ANALYZE`

```sql
EXPLAIN ANALYZE
SELECT * FROM orders
WHERE user_id = 12345
AND created_at > '2024-01-01';
```

**R√©sultat typique** :

```
Seq Scan on orders  (cost=0.00..125678.45 rows=123 width=200)
                    (actual time=0.234..2345.678 rows=123 loops=1)
  Filter: (user_id = 12345 AND created_at > '2024-01-01'::date)
  Rows Removed by Filter: 4567890
Planning Time: 0.123 ms
Execution Time: 2345.789 ms
```

**Ce qu'il faut chercher** :

1. **Seq Scan (Scan S√©quentiel)** : PostgreSQL lit toute la table
   - **Solution** : Cr√©er un index

2. **Rows Removed by Filter √©lev√©** : Beaucoup de lignes lues pour rien
   - **Solution** : Index plus s√©lectif

3. **Nested Loop avec grosse table** : Jointure inefficace
   - **Solution** : Revoir la jointure ou ajouter un index

4. **Sort + High Memory** : Tri co√ªteux
   - **Solution** : Index sur la colonne de tri

### 3.8. Exemple Concret : Optimiser une Slow Query

**Requ√™te lente identifi√©e** :

```sql
SELECT * FROM orders
WHERE status = 'pending'
ORDER BY created_at DESC
LIMIT 20;
```

**EXPLAIN ANALYZE** montre :

```
Sort  (cost=5678.90..5679.15 rows=100 width=200) (actual time=1234.567..1234.890 rows=20 loops=1)
  Sort Key: created_at DESC
  Sort Method: quicksort  Memory: 25kB
  ->  Seq Scan on orders  (cost=0.00..5675.00 rows=100 width=200) (actual time=0.123..1234.000 rows=100 loops=1)
        Filter: (status = 'pending'::text)
        Rows Removed by Filter: 5000000
Planning Time: 0.234 ms
Execution Time: 1234.987 ms
```

**Probl√®me** : Scan s√©quentiel sur 5 millions de lignes.

**Solution** : Cr√©er un index :

```sql
CREATE INDEX idx_orders_status_created_at
ON orders(status, created_at DESC);
```

**Apr√®s cr√©ation de l'index** :

```
Index Scan using idx_orders_status_created_at on orders
  (cost=0.43..25.67 rows=20 width=200) (actual time=0.012..0.034 rows=20 loops=1)
  Index Cond: (status = 'pending'::text)
Planning Time: 0.123 ms
Execution Time: 0.045 ms
```

**R√©sultat** : De **1234ms √† 0.045ms** ‚Üí **27 000√ó plus rapide** ! üöÄ

### 3.9. Nouveaut√© PostgreSQL 18 : Optimisations du Planificateur

PostgreSQL 18 apporte plusieurs optimisations automatiques :

#### 1. Auto-√©limination des Self-Joins

**Avant PostgreSQL 18** :

```sql
SELECT o1.*
FROM orders o1
JOIN orders o2 ON o1.id = o2.id
WHERE o1.status = 'pending';
```

PostgreSQL devait ex√©cuter la jointure m√™me si redondante.

**Avec PostgreSQL 18** : Le planificateur d√©tecte et √©limine le self-join automatiquement.

#### 2. Optimisation OR ‚Üí ANY

**Avant** :

```sql
SELECT * FROM users
WHERE status = 'active' OR status = 'pending' OR status = 'trial';
```

**PostgreSQL 18** r√©√©crit automatiquement en :

```sql
SELECT * FROM users
WHERE status = ANY(ARRAY['active', 'pending', 'trial']);
```

Plus efficace pour l'utilisation d'index.

#### 3. Skip Scan pour Index Multi-Colonnes

Index sur `(a, b)` peut maintenant √™tre utilis√© efficacement pour `WHERE b = X` (sans condition sur `a`).

### 3.10. R√©initialiser les Statistiques pg_stat_statements

Apr√®s avoir optimis√© vos requ√™tes, vous pouvez r√©initialiser les statistiques :

```sql
-- R√©initialiser toutes les statistiques de requ√™tes
SELECT pg_stat_statements_reset();

-- R√©initialiser les statistiques d'une base sp√©cifique
SELECT pg_stat_reset();
```

**Quand le faire** :
- Apr√®s d√©ploiement d'optimisations majeures
- Pour mesurer l'impact d'un changement
- R√©guli√®rement (ex: mensuel) pour avoir des stats fra√Æches

**Attention** : Vous perdez l'historique !

---

## 4. M√©triques Compl√©mentaires Essentielles

### 4.1. Nombre de Connexions Actives

Trop de connexions = probl√®me de performance.

```sql
SELECT
    count(*) FILTER (WHERE state = 'active') AS active_connections,
    count(*) FILTER (WHERE state = 'idle') AS idle_connections,
    count(*) FILTER (WHERE state = 'idle in transaction') AS idle_in_transaction,
    count(*) AS total_connections,
    current_setting('max_connections')::int AS max_connections,
    round(100.0 * count(*) / current_setting('max_connections')::int, 2) AS usage_pct
FROM
    pg_stat_activity;
```

**Seuils d'alerte** :

- **usage_pct > 80%** : Proche de la saturation
- **idle_in_transaction √©lev√©** : Transactions ouvertes inutilement (fuites de connexions)

**Solution** : Utiliser un connection pooler (PgBouncer).

### 4.2. Taille des Tables et Index

Surveiller la croissance pour pr√©voir les besoins en stockage :

```sql
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
    pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) AS indexes_size,
    pg_total_relation_size(schemaname||'.'||tablename) AS bytes_total
FROM
    pg_tables
WHERE
    schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY
    bytes_total DESC
LIMIT 20;
```

**Analyse** :

- Si `indexes_size > table_size` : Vous avez peut-√™tre trop d'index
- Croissance rapide : Pr√©voir l'archivage ou le partitionnement

### 4.3. Checkpoint Frequency et WAL Generation

Les checkpoints fr√©quents indiquent une √©criture intensive :

```sql
SELECT
    checkpoints_timed,
    checkpoints_req,
    checkpoint_write_time,
    checkpoint_sync_time,
    buffers_checkpoint,
    buffers_clean,
    buffers_backend
FROM
    pg_stat_bgwriter;
```

**Analyse** :

- **checkpoints_req > checkpoints_timed** : Checkpoints forc√©s, augmentez `max_wal_size`
- **checkpoint_write_time √©lev√©** : Disque lent ou surcharge I/O

**Configuration recommand√©e** :

```conf
max_wal_size = 4GB  # Plus haut si √©criture intensive
checkpoint_timeout = 15min
checkpoint_completion_target = 0.9
```

### 4.4. Transaction ID (XID) Wraparound Risk

PostgreSQL utilise des identifiants de transaction (XID) sur 32 bits, qui peuvent "boucler". Si cela arrive sans VACUUM, c'est la **panne garantie**.

```sql
SELECT
    datname,
    age(datfrozenxid) AS xid_age,
    2^31 - 1000000 - age(datfrozenxid) AS xids_remaining,
    round(100.0 * age(datfrozenxid) / (2^31 - 1000000), 2) AS wraparound_risk_pct
FROM
    pg_database
ORDER BY
    age(datfrozenxid) DESC;
```

**Seuils critiques** :

- **xid_age > 1 000 000 000** : Surveiller
- **xid_age > 1 500 000 000** : Action recommand√©e (VACUUM FREEZE)
- **xid_age > 2 000 000 000** : **URGENT**, risque de wraparound

**Solution** :

```sql
VACUUM FREEZE VERBOSE ma_table;
```

### 4.5. R√©plication Lag (Si R√©plication Activ√©e)

Pour les setups avec r√©plication (primary/standby) :

```sql
-- Sur le PRIMARY
SELECT
    client_addr,
    state,
    sent_lsn,
    write_lsn,
    flush_lsn,
    replay_lsn,
    pg_wal_lsn_diff(sent_lsn, replay_lsn) / 1024 / 1024 AS replay_lag_mb
FROM
    pg_stat_replication;
```

**Seuils** :

- **replay_lag_mb < 100 MB** : Bon
- **replay_lag_mb > 1 GB** : Le standby est en retard, enqu√™ter

### 4.6. Nouveaut√© PostgreSQL 18 : Statistiques VACUUM et ANALYZE

PostgreSQL 18 enrichit les statistiques de maintenance :

```sql
SELECT
    schemaname,
    relname,
    last_vacuum,
    last_autovacuum,
    vacuum_count,
    autovacuum_count,
    last_analyze,
    last_autoanalyze,
    analyze_count,
    autoanalyze_count,
    n_dead_tup
FROM
    pg_stat_all_tables
WHERE
    schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY
    n_dead_tup DESC
LIMIT 20;
```

**Nouveaut√©** : Compteurs `vacuum_count` et `analyze_count` pour suivre la fr√©quence de maintenance.

---

## 5. Mise en Pratique : Diagnostic de Performance

### Sc√©nario 1 : L'Application Est Lente (Diagnostic G√©n√©ral)

**Sympt√¥mes** : Tous les utilisateurs se plaignent de lenteur.

**Checklist de diagnostic** :

#### √âtape 1 : V√©rifier les Connexions

```sql
SELECT count(*), state FROM pg_stat_activity GROUP BY state;
```

- Trop de connexions actives ? ‚Üí PgBouncer
- Beaucoup de `idle in transaction` ? ‚Üí Fuites de connexions applicatives

#### √âtape 2 : Identifier les Requ√™tes Lentes en Cours

```sql
SELECT pid, usename, query_start, now() - query_start AS duration, query
FROM pg_stat_activity
WHERE state = 'active' AND now() - query_start > interval '30 seconds'
ORDER BY duration DESC;
```

- Requ√™tes tournant depuis > 30s ? ‚Üí Analyser avec EXPLAIN ANALYZE

#### √âtape 3 : V√©rifier le Cache Hit Ratio

```sql
SELECT round(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) AS cache_hit_ratio
FROM pg_stat_database
WHERE datname = current_database();
```

- Ratio < 95% ? ‚Üí Augmenter shared_buffers ou optimiser requ√™tes

#### √âtape 4 : Identifier les Top Slow Queries

```sql
SELECT round(mean_exec_time::numeric, 2) AS avg_ms, calls, query
FROM pg_stat_statements
WHERE calls > 100
ORDER BY mean_exec_time DESC
LIMIT 10;
```

- Optimiser les requ√™tes identifi√©es

### Sc√©nario 2 : Un Endpoint API Pr√©cis Est Lent

**Sympt√¥mes** : `/api/users/orders` prend 5 secondes, le reste va bien.

**Diagnostic** :

#### √âtape 1 : Filtrer par Application Name

```sql
SELECT query, round(mean_exec_time::numeric, 2) AS avg_ms, calls
FROM pg_stat_statements
WHERE query ILIKE '%orders%'  -- Mots-cl√©s de votre endpoint
ORDER BY mean_exec_time DESC;
```

#### √âtape 2 : Analyser la Requ√™te avec EXPLAIN

```sql
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
[Coller la requ√™te lente ici];
```

#### √âtape 3 : Identifier le Goulot

- **Seq Scan** ‚Üí Cr√©er index
- **Nested Loop** co√ªteux ‚Üí Revoir jointure
- **Sort** co√ªteux ‚Üí Index sur colonne de tri

### Sc√©nario 3 : Disque Satur√© (I/O Wait √âlev√©)

**Sympt√¥mes** : Serveur lent, `iostat` montre 100% disk utilization.

**Diagnostic** :

#### √âtape 1 : Trouver les Requ√™tes Gourmandes en I/O

```sql
SELECT query, shared_blks_read, shared_blks_hit
FROM pg_stat_statements
ORDER BY shared_blks_read DESC
LIMIT 10;
```

#### √âtape 2 : V√©rifier le Cache Hit Ratio par Table

```sql
SELECT relname, heap_blks_read, heap_blks_hit,
       round(100.0 * heap_blks_hit / NULLIF(heap_blks_hit + heap_blks_read, 0), 2) AS ratio
FROM pg_statio_user_tables
WHERE (heap_blks_hit + heap_blks_read) > 0
ORDER BY heap_blks_read DESC
LIMIT 10;
```

**Solutions** :

1. Augmenter `shared_buffers`
2. Passer √† un SSD si HDD
3. Partitionner les grosses tables
4. Archiver les donn√©es anciennes

### Sc√©nario 4 : Pic de Charge Soudain

**Sympt√¥mes** : √áa marchait bien, puis soudainement tr√®s lent √† 14h.

**Diagnostic** :

#### √âtape 1 : Comparer les Statistiques Avant/Apr√®s

Si vous avez des snapshots r√©guliers de `pg_stat_statements` (via un outil de monitoring), comparez.

#### √âtape 2 : Identifier les Nouvelles Requ√™tes

```sql
SELECT query, calls, round(mean_exec_time::numeric, 2) AS avg_ms
FROM pg_stat_statements
WHERE calls > 1000  -- Requ√™tes fr√©quentes
ORDER BY calls DESC
LIMIT 20;
```

- Une nouvelle requ√™te avec beaucoup d'appels ? ‚Üí Optimiser en priorit√©

#### √âtape 3 : V√©rifier les Verrous

```sql
SELECT * FROM pg_stat_activity WHERE wait_event_type = 'Lock';
```

- Deadlock ou verrous prolong√©s ? ‚Üí Voir le tutoriel sur les locks

---

## 6. Automatisation et Alerting

### 6.1. Pourquoi Automatiser le Monitoring ?

Vous ne pouvez pas rester 24/7 devant votre terminal √† ex√©cuter ces requ√™tes. Il faut :

1. **Collecter automatiquement** les m√©triques
2. **Stocker l'historique** pour analyser les tendances
3. **Alerter** quand un seuil est d√©pass√©

### 6.2. Stack de Monitoring Recommand√©e

#### Option 1 : Prometheus + Grafana (Open Source)

**Architecture** :

```
PostgreSQL ‚Üí postgres_exporter ‚Üí Prometheus ‚Üí Grafana
                                      ‚Üì
                                  Alertmanager (alertes)
```

**Avantages** :
- Gratuit et open source
- Tr√®s populaire (nombreux dashboards communautaires)
- Hautement configurable

**Installation rapide** :

```bash
# 1. Installer postgres_exporter
docker run -d \
  --name postgres_exporter \
  -e DATA_SOURCE_NAME="postgresql://user:password@localhost:5432/dbname?sslmode=disable" \
  -p 9187:9187 \
  prometheuscommunity/postgres-exporter

# 2. Configurer Prometheus pour scraper les m√©triques
# 3. Importer un dashboard Grafana (ex: dashboard ID 9628)
```

#### Option 2 : pgBadger (Analyse de Logs)

**pgBadger** analyse les logs PostgreSQL et g√©n√®re des rapports HTML.

```bash
# G√©n√©rer un rapport
pgbadger /var/log/postgresql/postgresql.log -o report.html
```

**Avantages** :
- Rapports d√©taill√©s (slow queries, connexions, erreurs)
- Pas besoin d'agent suppl√©mentaire

**Inconv√©nient** : Pas de monitoring temps r√©el.

#### Option 3 : Solutions Cloud Natives

- **AWS RDS** : CloudWatch Metrics automatiques
- **Azure Database for PostgreSQL** : Azure Monitor
- **GCP Cloud SQL** : Cloud Monitoring

### 6.3. Configurer les Alertes

**M√©triques √† alerter** :

| M√©trique | Seuil Warning | Seuil Critical | Action |
|----------|---------------|----------------|--------|
| Cache Hit Ratio | < 95% | < 90% | Augmenter shared_buffers |
| Connexions actives | > 80% max | > 95% max | Ajouter PgBouncer |
| Requ√™te lente | > 1s | > 5s | Optimiser SQL |
| R√©plication lag | > 100 MB | > 1 GB | V√©rifier r√©seau/load |
| XID age | > 1B | > 1.5B | VACUUM FREEZE |
| Disk usage | > 80% | > 90% | Archiver/Nettoyer |

**Exemple de r√®gle Prometheus** :

```yaml
groups:
  - name: postgresql_alerts
    rules:
      - alert: PostgreSQLCacheHitRatioLow
        expr: pg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read) < 0.95
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Cache hit ratio is below 95%"
          description: "Database {{ $labels.datname }} has cache hit ratio of {{ $value }}"
```

### 6.4. Cr√©er des Vues pour Simplifier le Monitoring

Plut√¥t que de retaper les requ√™tes complexes, cr√©ez des vues :

```sql
-- Vue pour le cache hit ratio
CREATE VIEW monitoring.cache_hit_ratio AS
SELECT
    datname,
    round(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) AS ratio
FROM pg_stat_database;

-- Vue pour les slow queries
CREATE VIEW monitoring.slow_queries AS
SELECT
    round(mean_exec_time::numeric, 2) AS avg_ms,
    calls,
    query
FROM pg_stat_statements
WHERE mean_exec_time > 100
ORDER BY mean_exec_time DESC;
```

**Utilisation** :

```sql
-- Simple √† requ√™ter ensuite
SELECT * FROM monitoring.cache_hit_ratio;
SELECT * FROM monitoring.slow_queries;
```

---

## 7. Bonnes Pratiques de Monitoring

### 7.1. √âtablir une Baseline (Ligne de Base)

Avant d'optimiser, mesurez d'abord l'√©tat actuel :

1. **Prendre des snapshots r√©guliers** de `pg_stat_statements`
2. **Documenter les m√©triques normales** :
   - Cache hit ratio typique
   - Temps de r√©ponse moyen
   - Charge CPU/RAM/I/O

3. **Comparer apr√®s changements** pour valider l'am√©lioration

### 7.2. Monitoring R√©gulier vs Incident Response

**Monitoring R√©gulier** (quotidien/hebdomadaire) :
- V√©rifier les tendances (croissance des donn√©es)
- Identifier les d√©gradations progressives
- Optimisations proactives

**Incident Response** (alerte d√©clench√©e) :
- Diagnostic rapide avec requ√™tes temps r√©el
- Identifier la requ√™te/table/verrou probl√©matique
- Action corrective imm√©diate

### 7.3. Logging : Configuration Optimale

Dans `postgresql.conf` :

```conf
# Activer le logging des requ√™tes lentes
log_min_duration_statement = 200  # Log toute requ√™te > 200ms

# Format de log structur√©
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# Dur√©e des verrous
log_lock_waits = on
deadlock_timeout = 1s

# Checkpoints
log_checkpoints = on

# Connexions/D√©connexions (peut √™tre verbeux)
log_connections = off
log_disconnections = off

# Auto-explain pour les requ√™tes lentes (extension)
shared_preload_libraries = 'pg_stat_statements,auto_explain'
auto_explain.log_min_duration = 1000  # EXPLAIN si > 1s
auto_explain.log_analyze = on
auto_explain.log_buffers = on
```

### 7.4. Rotation et Archivage des Logs

Les logs PostgreSQL peuvent rapidement devenir volumineux.

**Configuration syst√®me (logrotate)** :

```conf
/var/log/postgresql/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0640 postgres postgres
}
```

### 7.5. Tests de Charge et Benchmarking

Avant un d√©ploiement majeur :

1. **Utiliser pgbench** pour simuler de la charge :

```bash
# Initialiser la base de test
pgbench -i -s 50 test_db

# Ex√©cuter un benchmark (10 clients, 1000 transactions chacun)
pgbench -c 10 -t 1000 test_db
```

2. **Comparer les m√©triques avant/apr√®s** :
   - Transactions par seconde (TPS)
   - Latence moyenne
   - Cache hit ratio

### 7.6. Documentation et Runbooks

**Cr√©ez des runbooks** pour les sc√©narios courants :

**Exemple : Runbook "Application Lente"**

```
1. V√©rifier cache hit ratio (requ√™te section 2.3)
   - Si < 90% : Augmenter shared_buffers
2. Identifier slow queries (requ√™te section 3.3)
   - Analyser avec EXPLAIN ANALYZE
   - Cr√©er index si n√©cessaire
3. V√©rifier connexions (section 4.1)
   - Si > 80% : Activer PgBouncer
4. V√©rifier verrous (tutoriel locks)
   - Tuer transaction bloquante si besoin
```

### 7.7. Revue de Performance P√©riodique

**Mensuel** :

- Audit des slow queries (top 50)
- Audit des index inutilis√©s
- Audit du bloat
- Revue des m√©triques de croissance

**Trimestriel** :

- Revue de l'architecture (partitionnement, r√©plication)
- Tests de DR (Disaster Recovery)
- Formation de l'√©quipe sur nouveaux outils

---

## R√©sum√© des Points Cl√©s

### Cache Hit Ratio

- ‚úÖ **Objectif** : > 95%
- ‚úÖ **Requ√™te principale** : Section 2.3 (cache hit ratio global)
- ‚úÖ **Action si < 95%** : Augmenter shared_buffers, optimiser requ√™tes
- ‚úÖ **PostgreSQL 18** : Nouvelles statistiques I/O par backend

### Slow Queries

- ‚úÖ **Outil indispensable** : pg_stat_statements
- ‚úÖ **Requ√™te principale** : Section 3.3 (top 20 slow queries)
- ‚úÖ **Diagnostic** : EXPLAIN ANALYZE
- ‚úÖ **Solution** : Index, r√©√©criture SQL, partitionnement
- ‚úÖ **PostgreSQL 18** : Optimisations automatiques (skip scan, OR ‚Üí ANY)

### M√©triques Compl√©mentaires

- ‚úÖ Connexions actives (section 4.1)
- ‚úÖ Taille des tables (section 4.2)
- ‚úÖ Checkpoints et WAL (section 4.3)
- ‚úÖ XID wraparound risk (section 4.4)
- ‚úÖ PostgreSQL 18 : Statistiques VACUUM/ANALYZE enrichies

### Automatisation

- ‚úÖ Prometheus + Grafana pour monitoring temps r√©el
- ‚úÖ Alertes sur seuils critiques
- ‚úÖ Vues personnalis√©es pour simplifier
- ‚úÖ Runbooks pour incident response

---

## Ressources Compl√©mentaires

### Documentation Officielle PostgreSQL

- [Monitoring Database Activity](https://www.postgresql.org/docs/18/monitoring.html)
- [pg_stat_statements](https://www.postgresql.org/docs/18/pgstatstatements.html)
- [EXPLAIN Documentation](https://www.postgresql.org/docs/18/sql-explain.html)

### Outils de Monitoring

- **pg_stat_statements** : Extension officielle
- **Prometheus + postgres_exporter** : Monitoring temps r√©el
- **Grafana** : Dashboards visuels (Dashboard ID 9628 recommand√©)
- **pgBadger** : Analyse de logs
- **pgAdmin 4** : Interface graphique avec monitoring int√©gr√©
- **Datadog, New Relic** : Solutions commerciales

### Articles et Guides

- [Explain Analyze Visualizer](https://explain.dalibo.com/) : Visualiser les plans d'ex√©cution
- [PostgreSQL Explain](https://www.postgresql.org/docs/current/using-explain.html)
- Blog Percona PostgreSQL : Articles d'experts
- 2ndQuadrant Blog : Astuces avanc√©es

### Communaut√©s

- Mailing list : pgsql-performance@postgresql.org
- Reddit : r/PostgreSQL
- Discord PostgreSQL (communaut√© francophone)
- Stack Overflow : Tag `postgresql-performance`

---


‚è≠Ô∏è [Requ√™tes d'analyse (statistiques, tables sizes)](/annexes/requetes-sql-reference/03-requetes-analyse.md)
