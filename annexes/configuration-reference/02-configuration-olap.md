üîù Retour au [Sommaire](/SOMMAIRE.md)

# Configuration PostgreSQL pour OLAP (Data Warehouse, Analytics)

## Introduction : Qu'est-ce que l'OLAP ?

### D√©finition

**OLAP** signifie **Online Analytical Processing** (Traitement Analytique en Ligne). C'est un type de charge de travail caract√©ris√© par :

- **Requ√™tes complexes et longues** : Analyses qui peuvent durer de quelques secondes √† plusieurs minutes
- **Agr√©gations massives** : Calculs sur des millions voire des milliards de lignes
- **Principalement des lectures** : Peu ou pas d'√©critures pendant les heures d'analyse
- **Faible concurrence** : Quelques analystes/rapports simultan√©s (vs milliers d'utilisateurs en OLTP)
- **Donn√©es historiques** : Conservation de plusieurs ann√©es de donn√©es pour analyse de tendances

### Exemples d'Applications OLAP

- **Business Intelligence (BI)** : Tableaux de bord, rapports de ventes, KPIs
- **Data Warehouse** : Entrep√¥t de donn√©es consolid√©es de plusieurs sources
- **Analytics avanc√©s** : Analyse de cohortes, segmentation clients, pr√©visions
- **Reporting financier** : Bilans, √©tats financiers, analyses de rentabilit√©
- **Big Data Analytics** : Analyse de logs, t√©l√©m√©trie, IoT

### OLAP vs OLTP : Tableau Comparatif

| Crit√®re | OLTP | OLAP |
|---------|------|------|
| **Objectif** | G√©rer les op√©rations quotidiennes | Analyser et prendre des d√©cisions |
| **Type d'op√©rations** | INSERT, UPDATE, DELETE fr√©quents | SELECT complexes avec GROUP BY, JOIN |
| **Volume par requ√™te** | 1-1000 lignes | Millions √† milliards de lignes |
| **Dur√©e des requ√™tes** | < 100ms | Secondes √† minutes |
| **Concurrence** | Tr√®s √©lev√©e (milliers) | Faible (quelques dizaines) |
| **Fra√Æcheur des donn√©es** | Temps r√©el | Batch quotidien/horaire acceptable |
| **Mod√®le de donn√©es** | Normalis√© (3NF) | D√©normalis√© (Star Schema, Snowflake) |
| **Index** | B-Tree sur cl√©s primaires/√©trang√®res | B-Tree + BRIN + vues mat√©rialis√©es |
| **Optimisation** | Latence et throughput | D√©bit (throughput) de donn√©es |

> **Pour les d√©butants** : OLTP c'est la caisse du supermarch√© (rapide, beaucoup de clients), OLAP c'est le bureau du directeur qui analyse les ventes de l'ann√©e (lent, calculs complexes, peu de personnes).

---

## Architecture Typique d'un Data Warehouse

### Sch√©ma en √âtoile (Star Schema)

Le mod√®le le plus courant en OLAP :

```
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ   DIM_TIME  ‚îÇ
                      ‚îÇ  (date_id)  ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                    ‚îÇ                   ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇDIM_PRODUCT ‚îÇ      ‚îÇ  FACT_SALES‚îÇ     ‚îÇDIM_CUSTOMER ‚îÇ
   ‚îÇ(product_id)‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ(measure)   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ(customer_id)‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇsum, avg,etc‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ DIM_STORE  ‚îÇ
                       ‚îÇ (store_id) ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Composants :**
- **Tables de faits (FACT)** : Mesures num√©riques (ventes, quantit√©s, revenus)
- **Tables de dimensions (DIM)** : Contexte (qui, quoi, o√π, quand)

**Exemple concret :**
```sql
-- Table de faits (des millions de lignes)
CREATE TABLE fact_sales (
    sale_id BIGINT PRIMARY KEY,
    date_id INT REFERENCES dim_time(date_id),
    product_id INT REFERENCES dim_product(product_id),
    customer_id INT REFERENCES dim_customer(customer_id),
    store_id INT REFERENCES dim_store(store_id),
    quantity INT,
    amount NUMERIC(10,2),
    cost NUMERIC(10,2)
);

-- Dimension Temps (quelques milliers de lignes)
CREATE TABLE dim_time (
    date_id INT PRIMARY KEY,
    date DATE,
    year INT,
    quarter INT,
    month INT,
    week INT,
    day_of_week INT,
    is_weekend BOOLEAN
);
```

---

## Objectifs de Configuration pour OLAP

Pour une charge de travail OLAP, nous cherchons √† optimiser PostgreSQL selon ces principes :

1. **Maximiser le d√©bit de donn√©es** (MB/s lus et trait√©s)
2. **Parall√©liser les requ√™tes** (utiliser tous les CPU)
3. **Optimiser les agr√©gations** (GROUP BY, SUM, AVG sur millions de lignes)
4. **Favoriser les scans s√©quentiels** (lire de grandes portions de tables)
5. **R√©duire l'importance de la latence** (OK si requ√™te prend 30s au lieu de 5s)
6. **Allouer beaucoup de m√©moire par requ√™te** (pour tris et hachages massifs)

---

## Param√®tres Cl√©s pour OLAP

### 1. Gestion de la M√©moire

#### **shared_buffers** : Cache Moins Critique qu'en OLTP

**Qu'est-ce que c'est ?**
M√©moire partag√©e pour le cache de pages. En OLAP, c'est moins critique car :
- Les requ√™tes scannent des millions de lignes (difficile de tout cacher)
- Le syst√®me d'exploitation (OS) g√®re bien le cache fichier pour les gros volumes

**Configuration recommand√©e pour OLAP :**
```ini
shared_buffers = 25% de la RAM (comme OLTP, mais moins critique)
```

**Exemples :**
- Serveur avec 64 GB RAM ‚Üí `shared_buffers = 16GB`
- Serveur avec 128 GB RAM ‚Üí `shared_buffers = 32GB`
- Serveur avec 256 GB RAM ‚Üí `shared_buffers = 64GB`

**Configuration dans postgresql.conf :**
```ini
shared_buffers = 32GB
```

---

#### **effective_cache_size** : Tr√®s Important !

**Configuration recommand√©e pour OLAP :**
```ini
effective_cache_size = 75-80% de la RAM totale
```

**Pourquoi important ?**
Le planificateur de requ√™tes utilise cette valeur pour d√©cider entre scan s√©quentiel et scan d'index. Avec beaucoup de cache, il peut mieux optimiser les plans complexes.

**Exemples :**
- Serveur avec 128 GB RAM ‚Üí `effective_cache_size = 96GB` (75%)
- Serveur avec 256 GB RAM ‚Üí `effective_cache_size = 200GB` (78%)

**Configuration dans postgresql.conf :**
```ini
effective_cache_size = 96GB
```

---

#### **work_mem** : LE Param√®tre Critique pour OLAP

**Qu'est-ce que c'est ?**
M√©moire allou√©e pour les op√©rations de tri, hachage, et construction de bitmaps. En OLAP, les requ√™tes font des tris massifs et des GROUP BY sur des millions de lignes.

**‚ö†Ô∏è Diff√©rence majeure avec OLTP :**
- OLTP : work_mem faible (16-32MB) car beaucoup de connexions
- OLAP : work_mem √©lev√© (256MB-2GB) car peu de connexions mais op√©rations massives

**Configuration recommand√©e pour OLAP :**
```ini
work_mem = 256MB √† 2GB (selon RAM et nombre de connexions)
```

**Calcul pratique pour OLAP :**
```
work_mem = (RAM totale √ó 50%) / max_connections / 2
```

**Pourquoi 50% et non 25% comme OLTP ?**
Parce qu'en OLAP vous avez beaucoup moins de connexions simultan√©es (10-50 vs 200-500 en OLTP).

**Exemples :**
- Serveur 128 GB, 20 connexions ‚Üí `work_mem = (128 √ó 0.5) / 20 / 2 = 1.6GB`
- Serveur 256 GB, 30 connexions ‚Üí `work_mem = (256 √ó 0.5) / 30 / 2 = 2GB`

**Configuration dans postgresql.conf :**
```ini
work_mem = 1GB
```

**üí° Impact direct :**
- `work_mem` trop faible ‚Üí PostgreSQL √©crit sur disque (TEMP FILES) ‚Üí requ√™te 10√ó plus lente
- `work_mem` suffisant ‚Üí Tout reste en RAM ‚Üí requ√™te rapide

**V√©rifier l'utilisation :**
```sql
-- Voir les requ√™tes qui utilisent des fichiers temporaires
SELECT
    query,
    temp_blks_written
FROM pg_stat_statements
WHERE temp_blks_written > 0
ORDER BY temp_blks_written DESC;
```

Si vous voyez beaucoup de `temp_blks_written`, augmentez `work_mem` !

---

#### **maintenance_work_mem** : Encore Plus Important qu'en OLTP

**Configuration recommand√©e pour OLAP :**
```ini
maintenance_work_mem = 2-8GB
```

**Pourquoi si √©lev√© ?**
- Tables de faits avec des milliards de lignes
- Index massifs √† construire ou reconstruire
- VACUUM sur tables √©normes

**Configuration dans postgresql.conf :**
```ini
maintenance_work_mem = 4GB
```

---

#### **hash_mem_multiplier** : Nouveau PostgreSQL 13+

**Qu'est-ce que c'est ?**
Multiplicateur de m√©moire pour les op√©rations de hachage (hash joins, hash aggregates).

**Configuration recommand√©e pour OLAP :**
```ini
hash_mem_multiplier = 2.0 √† 3.0
```

**Exemple :**
Avec `work_mem = 1GB` et `hash_mem_multiplier = 2.0` :
- Op√©rations de hachage peuvent utiliser jusqu'√† **2GB**
- Autres op√©rations (tri) restent √† 1GB

**Configuration dans postgresql.conf :**
```ini
hash_mem_multiplier = 2.0
```

---

### 2. Parall√©lisation : Utiliser Tous les CPU

En OLAP, une seule requ√™te doit pouvoir utiliser plusieurs CPU en parall√®le pour traiter des millions de lignes plus rapidement.

#### **max_worker_processes** : Nombre Total de Workers

**Configuration recommand√©e pour OLAP :**
```ini
max_worker_processes = Nombre de CPU (ou plus)
```

**Exemples :**
- Serveur 16 CPU ‚Üí `max_worker_processes = 16`
- Serveur 32 CPU ‚Üí `max_worker_processes = 32`

**Configuration dans postgresql.conf :**
```ini
max_worker_processes = 32
```

---

#### **max_parallel_workers_per_gather** : Workers par Requ√™te

**Qu'est-ce que c'est ?**
Nombre maximum de workers qu'une seule op√©ration parall√®le (Gather) peut utiliser.

**Configuration recommand√©e pour OLAP :**
```ini
max_parallel_workers_per_gather = 8 √† 16
```

**Exemple :**
Si vous scannez une table de 100 millions de lignes, PostgreSQL peut diviser le travail en 8 morceaux trait√©s en parall√®le.

**Configuration dans postgresql.conf :**
```ini
max_parallel_workers_per_gather = 8
```

---

#### **max_parallel_workers** : Pool Global de Workers

**Configuration recommand√©e pour OLAP :**
```ini
max_parallel_workers = max_worker_processes (utiliser tous les workers disponibles)
```

**Configuration dans postgresql.conf :**
```ini
max_parallel_workers = 32
```

---

#### **max_parallel_maintenance_workers** : Parall√©lisation de Maintenance

**Qu'est-ce que c'est ?**
Nombre de workers pour op√©rations de maintenance (CREATE INDEX, VACUUM).

**Configuration recommand√©e pour OLAP :**
```ini
max_parallel_maintenance_workers = 4 √† 8
```

**Impact :**
Cr√©ation d'index sur table de 1 milliard de lignes :
- Sans parall√©lisation : 2 heures
- Avec 8 workers : 20 minutes

**Configuration dans postgresql.conf :**
```ini
max_parallel_maintenance_workers = 8
```

---

#### **parallel_setup_cost** et **parallel_tuple_cost** : Seuils de Parall√©lisation

**Par d√©faut :**
- `parallel_setup_cost = 1000` (co√ªt d'initialisation du parall√©lisme)
- `parallel_tuple_cost = 0.1` (co√ªt par tuple en parall√®le)

**Configuration recommand√©e pour OLAP :**
```ini
parallel_setup_cost = 100  # R√©duire pour favoriser parall√©lisation
parallel_tuple_cost = 0.01  # R√©duire pour favoriser parall√©lisation
```

**Pourquoi ?**
En OLAP, les requ√™tes traitent des millions de lignes, donc le co√ªt d'initialisation est n√©gligeable. On veut parall√©liser le plus possible.

---

### 3. Optimisation des Scans

#### **seq_page_cost** : Co√ªt d'un Scan S√©quentiel

**Par d√©faut :** 1.0

**Configuration recommand√©e pour OLAP (SSD/NVMe) :**
```ini
seq_page_cost = 1.0  (garder par d√©faut)
```

---

#### **random_page_cost** : Co√ªt d'un Acc√®s Al√©atoire

**Configuration recommand√©e pour OLAP (SSD/NVMe) :**
```ini
random_page_cost = 1.0 √† 1.2
```

**Pourquoi proche de seq_page_cost ?**
Avec des SSD/NVMe, les acc√®s al√©atoires sont presque aussi rapides que les s√©quentiels. De plus, en OLAP, on scanne souvent de larges portions de tables, donc les scans s√©quentiels sont pr√©f√©rables.

**Configuration dans postgresql.conf :**
```ini
random_page_cost = 1.1
```

---

#### **effective_io_concurrency** : I/O Simultan√©s

**Configuration recommand√©e pour OLAP (SSD/NVMe) :**
```ini
effective_io_concurrency = 200-300 (SSD)
effective_io_concurrency = 300-500 (NVMe)
```

**Configuration dans postgresql.conf :**
```ini
effective_io_concurrency = 400
```

---

#### **Nouveaut√© PostgreSQL 18 : I/O Asynchrone**

PostgreSQL 18 introduit le sous-syst√®me I/O asynchrone qui peut am√©liorer significativement les performances des scans s√©quentiels massifs.

**Configuration dans postgresql.conf :**
```ini
io_method = 'async'  # N√©cessite Linux 5.1+ avec io_uring
```

**Impact typique :** Am√©lioration de 20-30% sur les requ√™tes avec gros scans s√©quentiels.

---

### 4. Gestion des Connexions

#### **max_connections** : Peu de Connexions en OLAP

**Configuration recommand√©e pour OLAP :**
```ini
max_connections = 20-100
```

**Pourquoi si peu ?**
- En OLAP, vous avez quelques analystes/rapports simultan√©s
- Chaque requ√™te consomme beaucoup de ressources (CPU, RAM)
- 10 requ√™tes parall√®les avec 8 workers chacune = 80 CPU utilis√©s !

**Configuration dans postgresql.conf :**
```ini
max_connections = 50
```

---

### 5. WAL et Checkpoints : Moins Critiques qu'en OLTP

#### **Configuration Recommand√©e**

En OLAP, vous avez peu d'√©critures (chargements batch quotidiens/horaires). Les param√®tres WAL sont donc moins critiques.

```ini
# WAL
wal_level = replica                     # Pour r√©plication si besoin
max_wal_size = 4GB                      # Suffisant pour OLAP
min_wal_size = 1GB
wal_compression = on                    # √âconomiser de l'espace

# Checkpoints (peut √™tre plus espac√©s qu'en OLTP)
checkpoint_timeout = 30min              # D√©faut 5min trop fr√©quent
checkpoint_completion_target = 0.9
```

---

### 6. Autovacuum : Configuration Diff√©rente

#### **Autovacuum en OLAP**

En OLAP :
- Peu de UPDATE/DELETE (donn√©es historiques, append-only souvent)
- Mais tables √©normes ‚Üí VACUUM prend du temps
- Besoin de statistiques √† jour pour bon planning

**Configuration recommand√©e pour OLAP :**

```ini
# Autovacuum moins agressif qu'en OLTP
autovacuum = on
autovacuum_max_workers = 4
autovacuum_naptime = 5min               # Moins fr√©quent qu'en OLTP (10s)

# Seuils plus √©lev√©s (tables plus grandes)
autovacuum_vacuum_threshold = 1000      # D√©faut 50
autovacuum_vacuum_scale_factor = 0.1    # D√©faut 0.2
autovacuum_analyze_threshold = 1000
autovacuum_analyze_scale_factor = 0.05  # Important : statistiques √† jour !

# Laisser autovacuum consommer plus de ressources (moins de concurrence)
autovacuum_vacuum_cost_delay = 0        # Pas de ralentissement artificiel
autovacuum_vacuum_cost_limit = -1       # Pas de limite
```

**‚ö†Ô∏è ANALYZE est plus important que VACUUM en OLAP**
Des statistiques obsol√®tes = mauvais plans de requ√™te = requ√™tes 100√ó plus lentes !

---

### 7. Statistiques pour le Planificateur

#### **default_statistics_target** : Tr√®s Important en OLAP

**Qu'est-ce que c'est ?**
Niveau de d√©tail des statistiques collect√©es par ANALYZE. Plus c'est √©lev√©, meilleur est le planning pour requ√™tes complexes.

**Valeur par d√©faut :** 100

**Configuration recommand√©e pour OLAP :**
```ini
default_statistics_target = 500 √† 1000
```

**Impact :**
- D√©faut (100) : Histogrammes avec 100 buckets
- OLAP (500) : Histogrammes avec 500 buckets ‚Üí meilleure estimation de cardinalit√©

**‚ö†Ô∏è Co√ªt :** ANALYZE prend plus de temps et consomme plus de m√©moire, mais c'est acceptable en OLAP.

**Configuration dans postgresql.conf :**
```ini
default_statistics_target = 500
```

**Configuration par colonne (pour colonnes critiques) :**
```sql
-- Pour colonnes utilis√©es dans WHERE/JOIN/GROUP BY
ALTER TABLE fact_sales
    ALTER COLUMN date_id SET STATISTICS 1000;
```

---

### 8. Param√®tres JIT (Just-In-Time Compilation)

PostgreSQL peut compiler les expressions SQL en code machine pour acc√©l√©rer l'ex√©cution.

#### **jit** : Activer le JIT

**Configuration recommand√©e pour OLAP :**
```ini
jit = on  # Activ√© par d√©faut dans PostgreSQL 11+
jit_above_cost = 100000  # Seuil d'activation (requ√™tes longues)
jit_inline_above_cost = 500000
jit_optimize_above_cost = 500000
```

**Impact :** Am√©lioration de 10-30% sur requ√™tes avec beaucoup d'expressions (calculs, CASE, etc.)

---

## Configuration Compl√®te pour OLAP

Voici une configuration **compl√®te** pour un serveur PostgreSQL 18 d√©di√© √† OLAP :

### Sc√©nario : Serveur 128 GB RAM, 32 CPU, SSD NVMe, 30 connexions max

```ini
# ===================================
# M√âMOIRE
# ===================================
shared_buffers = 32GB                   # 25% de 128GB
effective_cache_size = 96GB             # 75% de 128GB
work_mem = 1GB                          # (128 √ó 0.5) / 30 / 2
maintenance_work_mem = 4GB
hash_mem_multiplier = 2.0               # 2√ó work_mem pour hash operations

# ===================================
# PARALL√âLISATION (crucial pour OLAP)
# ===================================
max_worker_processes = 32               # Tous les CPU
max_parallel_workers_per_gather = 8     # Jusqu'√† 8 workers par op√©ration
max_parallel_workers = 32               # Pool global
max_parallel_maintenance_workers = 8

# Favoriser parall√©lisation (r√©duire seuils)
parallel_setup_cost = 100               # D√©faut 1000
parallel_tuple_cost = 0.01              # D√©faut 0.1
min_parallel_table_scan_size = 8MB      # D√©faut 8MB
min_parallel_index_scan_size = 512kB    # D√©faut 512kB

# Force parall√©lisation pour tests (d√©sactiver en prod)
# force_parallel_mode = on

# ===================================
# CONNEXIONS (peu en OLAP)
# ===================================
max_connections = 50
superuser_reserved_connections = 3

# ===================================
# WAL et CHECKPOINTS
# ===================================
wal_level = replica
max_wal_size = 4GB
min_wal_size = 1GB
checkpoint_timeout = 30min              # Plus espac√© qu'en OLTP
checkpoint_completion_target = 0.9
wal_compression = on
wal_buffers = 64MB

# Durabilit√©
synchronous_commit = on
fsync = on

# ===================================
# AUTOVACUUM (adapt√© OLAP)
# ===================================
autovacuum = on
autovacuum_max_workers = 4
autovacuum_naptime = 5min

# Seuils plus √©lev√©s (grandes tables)
autovacuum_vacuum_threshold = 1000
autovacuum_vacuum_scale_factor = 0.1
autovacuum_analyze_threshold = 1000
autovacuum_analyze_scale_factor = 0.05

# Pas de throttling (peu de concurrence)
autovacuum_vacuum_cost_delay = 0
autovacuum_vacuum_cost_limit = -1

# ===================================
# PLANIFICATEUR (optimis√© OLAP + SSD)
# ===================================
random_page_cost = 1.1                  # SSD/NVMe
seq_page_cost = 1.0
effective_io_concurrency = 400          # NVMe

# Statistiques d√©taill√©es (crucial OLAP)
default_statistics_target = 500

# JIT pour requ√™tes complexes
jit = on
jit_above_cost = 100000
jit_inline_above_cost = 500000
jit_optimize_above_cost = 500000

# PostgreSQL 18 : I/O asynchrone
io_method = 'async'

# ===================================
# LIMITES DE REQU√äTE
# ===================================
# Optionnel : limites pour √©viter requ√™tes infinies
# statement_timeout = 600000            # 10 minutes max
# idle_in_transaction_session_timeout = 300000  # 5 min

# ===================================
# LOGGING et MONITORING
# ===================================
logging_collector = on
log_destination = 'stderr'
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d.log'
log_rotation_age = 1d
log_rotation_size = 500MB               # Plus gros qu'en OLTP

log_line_prefix = '%t [%p]: user=%u,db=%d,app=%a,client=%h '
log_min_duration_statement = 5000       # Log requ√™tes > 5 secondes
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
log_temp_files = 0                      # Log tous fichiers temp (crucial OLAP)
log_autovacuum_min_duration = 0         # Log tous autovacuum

# Monitoring √©tendu
track_activities = on
track_counts = on
track_io_timing = on
track_functions = pl
compute_query_id = on                   # Pour pg_stat_statements

# Extensions monitoring
shared_preload_libraries = 'pg_stat_statements'

# ===================================
# S√âCURIT√â
# ===================================
ssl = on
ssl_prefer_server_ciphers = on
password_encryption = scram-sha-256

# ===================================
# TIMEZONE et LOCALE
# ===================================
timezone = 'UTC'
lc_messages = 'en_US.UTF-8'
lc_monetary = 'en_US.UTF-8'
lc_numeric = 'en_US.UTF-8'
lc_time = 'en_US.UTF-8'
default_text_search_config = 'pg_catalog.english'
```

---

## Optimisations Sp√©cifiques OLAP

### 1. Partitionnement : Indispensable pour Grandes Tables

#### **Pourquoi Partitionner en OLAP ?**

Tables de faits avec plusieurs ann√©es de donn√©es = milliards de lignes. Avantages du partitionnement :
- **Partition Pruning** : PostgreSQL ignore les partitions non concern√©es
- **Maintenance cibl√©e** : VACUUM/ANALYZE seulement les partitions r√©centes
- **Archivage facile** : D√©tacher partitions anciennes
- **Requ√™tes plus rapides** : Traiter 50M lignes au lieu de 2B

#### **Exemple : Partitionnement par Mois**

```sql
-- Table parent (partitionn√©e)
CREATE TABLE fact_sales (
    sale_id BIGINT,
    sale_date DATE NOT NULL,
    product_id INT,
    customer_id INT,
    amount NUMERIC(10,2),
    quantity INT
) PARTITION BY RANGE (sale_date);

-- Cr√©er des partitions pour chaque mois
CREATE TABLE fact_sales_2024_01 PARTITION OF fact_sales
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE fact_sales_2024_02 PARTITION OF fact_sales
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- ... et ainsi de suite
```

#### **Requ√™te avec Partition Pruning**

```sql
-- Analyse des ventes de janvier 2024
SELECT product_id, SUM(amount)
FROM fact_sales
WHERE sale_date >= '2024-01-01' AND sale_date < '2024-02-01'
GROUP BY product_id;

-- PostgreSQL scanne SEULEMENT fact_sales_2024_01
-- (50M lignes au lieu de 2B lignes)
```

#### **Automatiser avec pg_partman**

Extension pour g√©rer automatiquement les partitions :

```sql
CREATE EXTENSION pg_partman;

-- Cr√©er partitions automatiquement
SELECT partman.create_parent(
    p_parent_table => 'public.fact_sales',
    p_control => 'sale_date',
    p_type => 'native',
    p_interval => 'monthly',
    p_premake => 3  -- Cr√©er 3 mois √† l'avance
);

-- Job pour maintenir les partitions
SELECT partman.run_maintenance('public.fact_sales');
```

---

### 2. Index Adapt√©s √† OLAP

#### **BRIN : L'Index OLAP par Excellence**

**BRIN** (Block Range Index) est id√©al pour OLAP :
- **Tr√®s compact** : 1000√ó plus petit qu'un B-Tree
- **Donn√©es s√©quentielles** : Parfait pour tables partitionn√©es par date
- **Faible maintenance** : Peu d'espace disque

**Exemple :**

```sql
-- Table de 1 milliard de lignes tri√©es par date
-- B-Tree : 20 GB
-- BRIN : 20 MB

CREATE INDEX idx_sales_date_brin ON fact_sales
    USING BRIN (sale_date) WITH (pages_per_range = 128);
```

**Quand utiliser BRIN ?**
- Colonnes avec corr√©lation physique (date d'insertion ‚âà ordre sur disque)
- Tables en append-only (INSERT uniquement, pas de UPDATE)
- Requ√™tes avec pr√©dicats sur plages (WHERE date BETWEEN ... AND ...)

---

#### **B-Tree : Toujours Utile**

Pour les dimensions (petites tables) :

```sql
-- Dimensions : B-Tree classiques
CREATE INDEX idx_dim_product_id ON dim_product(product_id);
CREATE INDEX idx_dim_customer_id ON dim_customer(customer_id);
```

---

#### **GIN pour Colonnes JSONB**

Si vous stockez des donn√©es semi-structur√©es :

```sql
-- Colonne JSONB avec m√©tadonn√©es flexibles
ALTER TABLE fact_sales ADD COLUMN metadata JSONB;

CREATE INDEX idx_sales_metadata_gin ON fact_sales
    USING GIN (metadata jsonb_path_ops);

-- Requ√™te rapide sur JSONB
SELECT * FROM fact_sales
WHERE metadata @> '{"campaign": "summer2024"}';
```

---

### 3. Vues Mat√©rialis√©es : Pr√©-Calculer les Agr√©gations

#### **Concept**

Une vue mat√©rialis√©e stocke physiquement le r√©sultat d'une requ√™te complexe. C'est comme un "cache" de r√©sultats.

**Avantages :**
- Requ√™tes instantan√©es (d√©j√† calcul√©es)
- R√©duire charge sur tables de faits

**Inconv√©nients :**
- Donn√©es pas en temps r√©el (besoin de REFRESH)
- Consomme de l'espace disque

#### **Exemple : Ventes par Mois et Produit**

```sql
-- Calcul initial : 30 secondes sur 1 milliard de lignes
CREATE MATERIALIZED VIEW mv_sales_by_month_product AS
SELECT
    DATE_TRUNC('month', sale_date) AS month,
    product_id,
    SUM(amount) AS total_amount,
    SUM(quantity) AS total_quantity,
    COUNT(*) AS num_sales
FROM fact_sales
GROUP BY DATE_TRUNC('month', sale_date), product_id;

-- Index sur la vue mat√©rialis√©e
CREATE INDEX idx_mv_sales_month_product
    ON mv_sales_by_month_product(month, product_id);

-- Requ√™te sur vue : < 10ms (au lieu de 30 secondes)
SELECT * FROM mv_sales_by_month_product
WHERE month = '2024-01-01';
```

#### **Rafra√Æchir les Donn√©es**

```sql
-- Rafra√Æchissement complet (bloquant)
REFRESH MATERIALIZED VIEW mv_sales_by_month_product;

-- Rafra√Æchissement concurrent (non bloquant, n√©cessite UNIQUE index)
CREATE UNIQUE INDEX ON mv_sales_by_month_product(month, product_id);
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_sales_by_month_product;
```

#### **Automatiser avec pg_cron**

```sql
CREATE EXTENSION pg_cron;

-- Rafra√Æchir chaque jour √† 2h du matin
SELECT cron.schedule(
    'refresh-sales-mv',
    '0 2 * * *',
    'REFRESH MATERIALIZED VIEW CONCURRENTLY mv_sales_by_month_product'
);
```

---

### 4. Mod√®le D√©normalis√© (Star Schema)

#### **Principe : Joindre Moins, Filtrer Plus**

En OLAP, les jointures sur tables massives sont co√ªteuses. Strat√©gie : **d√©normaliser** en dupliquant certaines colonnes dans la table de faits.

**Avant (normalis√©) :**
```sql
-- Jointure √† chaque requ√™te (lent)
SELECT
    d.category,
    SUM(f.amount)
FROM fact_sales f
JOIN dim_product d ON f.product_id = d.product_id
WHERE d.category = 'Electronics'
GROUP BY d.category;
```

**Apr√®s (d√©normalis√©) :**
```sql
-- Ajouter category directement dans fact_sales
ALTER TABLE fact_sales ADD COLUMN product_category VARCHAR(50);

-- Maintenant : pas de jointure !
SELECT
    product_category,
    SUM(amount)
FROM fact_sales
WHERE product_category = 'Electronics'
GROUP BY product_category;
-- 10√ó plus rapide
```

**Compromis :**
- ‚úÖ Requ√™tes plus rapides
- ‚úÖ Moins de jointures
- ‚ùå Duplication de donn√©es (espace disque)
- ‚ùå Maintenance ETL plus complexe

---

### 5. Colonnes Compress√©es (TOAST et pg_column_compression)

PostgreSQL compresse automatiquement les grandes valeurs (TOAST), mais vous pouvez forcer la compression pour √©conomiser l'espace :

```sql
-- PostgreSQL 14+ : Compression par colonne
ALTER TABLE fact_sales
    ALTER COLUMN description SET COMPRESSION lz4;

-- Ou pour toute nouvelle donn√©e
SET default_toast_compression = 'lz4';
```

**Gain typique :** 50-70% d'√©conomie d'espace pour colonnes texte.

---

### 6. Nouveaut√© PostgreSQL 18 : Colonnes G√©n√©r√©es Virtuelles

**Concept :** Colonnes calcul√©es √† la vol√©e (non stock√©es physiquement), utiles pour simplifier les requ√™tes.

```sql
-- Avant PostgreSQL 18 : Calculer √† chaque requ√™te
SELECT
    amount * 1.20 AS amount_with_tax
FROM fact_sales;

-- PostgreSQL 18 : Colonne virtuelle
ALTER TABLE fact_sales
    ADD COLUMN amount_with_tax NUMERIC GENERATED ALWAYS AS (amount * 1.20) VIRTUAL;

-- Requ√™te simplifi√©e
SELECT amount_with_tax FROM fact_sales;
```

**Avantage :** Pas de stockage suppl√©mentaire, mais requ√™tes plus lisibles.

---

### 7. Requ√™tes Parall√®les : V√©rifier la Parall√©lisation

#### **EXPLAIN pour V√©rifier**

```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT product_id, SUM(amount)
FROM fact_sales
WHERE sale_date >= '2024-01-01'
GROUP BY product_id;
```

**Sortie attendue pour OLAP :**
```
Finalize GroupAggregate (actual time=1234.56..1234.78 rows=1000)
  -> Gather Merge (actual time=1000.12..1200.34 rows=8000)
        Workers Planned: 8
        Workers Launched: 8
        -> Partial GroupAggregate
              -> Parallel Seq Scan on fact_sales (actual time=...)
                    Filter: (sale_date >= '2024-01-01')
```

**Points cl√©s :**
- `Workers Planned: 8` ‚Üí Parall√©lisation activ√©e
- `Parallel Seq Scan` ‚Üí Scan s√©quentiel parall√®le
- `Gather Merge` ‚Üí Fusion des r√©sultats de chaque worker

**Si pas de parall√©lisation :**
- V√©rifier `max_parallel_workers_per_gather` (doit √™tre > 1)
- V√©rifier que la table est assez grande (`min_parallel_table_scan_size`)
- V√©rifier `parallel_setup_cost` (r√©duire si n√©cessaire)

---

## Monitoring Sp√©cifique OLAP

### 1. Requ√™tes Utilisant des Fichiers Temporaires

**Probl√®me :** Si `work_mem` est trop faible, PostgreSQL √©crit sur disque.

```sql
-- Trouver les requ√™tes avec beaucoup de fichiers temp
SELECT
    query,
    calls,
    mean_exec_time,
    temp_blks_written,
    temp_blks_written * 8192 / 1024 / 1024 AS temp_mb
FROM pg_stat_statements
WHERE temp_blks_written > 0
ORDER BY temp_blks_written DESC
LIMIT 10;
```

**Action :** Si vous voyez beaucoup de MB dans `temp_mb`, augmentez `work_mem`.

---

### 2. Efficacit√© de la Parall√©lisation

```sql
-- Voir les requ√™tes qui b√©n√©ficient de parall√©lisation
SELECT
    query,
    calls,
    total_exec_time / calls AS avg_time_ms,
    rows / calls AS avg_rows
FROM pg_stat_statements
WHERE query LIKE '%Parallel%'
ORDER BY total_exec_time DESC;
```

---

### 3. √âtat des Vues Mat√©rialis√©es

```sql
-- Trouver les vues mat√©rialis√©es
SELECT
    schemaname,
    matviewname,
    pg_size_pretty(pg_relation_size(schemaname||'.'||matviewname)) AS size
FROM pg_matviews;

-- Derni√®re date de refresh (n√©cessite tracking manuel ou pg_cron logs)
```

---

### 4. Taille des Tables et Index

```sql
-- Top 10 tables par taille
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) AS index_size
FROM pg_tables
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 10;
```

---

### 5. Statistiques ANALYZE

```sql
-- V√©rifier si les statistiques sont √† jour
SELECT
    schemaname,
    relname,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze,
    n_live_tup,
    n_dead_tup
FROM pg_stat_user_tables
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY last_analyze ASC NULLS FIRST;
```

**‚ö†Ô∏è Alerte :** Si `last_analyze` est NULL ou tr√®s ancien, lancez :
```sql
ANALYZE fact_sales;
```

---

## Checklist de V√©rification OLAP

Avant de mettre en production un data warehouse, v√©rifiez :

### M√©moire et CPU
- [ ] **shared_buffers** = 25% RAM
- [ ] **effective_cache_size** = 75% RAM
- [ ] **work_mem** = (RAM √ó 50%) / max_connections / 2 (au moins 256MB)
- [ ] **maintenance_work_mem** ‚â• 2GB
- [ ] **max_worker_processes** = Nombre de CPU
- [ ] **max_parallel_workers_per_gather** ‚â• 4
- [ ] **max_parallel_workers** = max_worker_processes

### Parall√©lisation
- [ ] **parallel_setup_cost** = 100 (r√©duit)
- [ ] **parallel_tuple_cost** = 0.01 (r√©duit)
- [ ] V√©rifier avec EXPLAIN que requ√™tes sont parall√©lis√©es

### Planificateur
- [ ] **default_statistics_target** ‚â• 500
- [ ] **random_page_cost** = 1.1 (SSD/NVMe)
- [ ] **jit** = on

### Stockage et I/O
- [ ] **PostgreSQL 18** : io_method = 'async' (si compatible)
- [ ] **effective_io_concurrency** ‚â• 200

### Autovacuum et Maintenance
- [ ] **autovacuum** = on
- [ ] **autovacuum_analyze_scale_factor** = 0.05
- [ ] **autovacuum_vacuum_cost_delay** = 0
- [ ] ANALYZE ex√©cut√© apr√®s chargements ETL

### Mod√©lisation
- [ ] Tables de faits partitionn√©es par date
- [ ] Index BRIN sur colonnes de date
- [ ] Index B-Tree sur dimensions
- [ ] Vues mat√©rialis√©es pour agr√©gations fr√©quentes
- [ ] D√©normalisation appliqu√©e o√π pertinent

### Monitoring
- [ ] pg_stat_statements activ√©
- [ ] Logs des requ√™tes > 5 secondes
- [ ] Logs des fichiers temporaires (log_temp_files = 0)
- [ ] Surveillance taille des tables/index
- [ ] Surveillance √©tat vues mat√©rialis√©es

---

## Erreurs Courantes √† √âviter

### ‚ùå Erreur 1 : work_mem Trop Faible
**Sympt√¥me :** Requ√™tes tr√®s lentes, logs montrent "temporary file"
**Solution :** Augmenter work_mem progressivement (256MB ‚Üí 512MB ‚Üí 1GB)

### ‚ùå Erreur 2 : Pas de Partitionnement sur Tables Massives
**Sympt√¥me :** Requ√™tes scannent toute la table (milliards de lignes)
**Solution :** Partitionner par date/r√©gion/autre crit√®re fr√©quent

### ‚ùå Erreur 3 : Statistiques Obsol√®tes
**Sympt√¥me :** Plans de requ√™te absurdes, estimations erron√©es
**Solution :** ANALYZE apr√®s chaque chargement ETL

### ‚ùå Erreur 4 : Index B-Tree sur Tout
**Sympt√¥me :** Maintenance lente, index √©normes, peu utilis√©s
**Solution :** Utiliser BRIN pour colonnes s√©quentielles

### ‚ùå Erreur 5 : Pas de Vues Mat√©rialis√©es
**Sympt√¥me :** M√™mes agr√©gations recalcul√©es √† chaque fois (lent)
**Solution :** Cr√©er vues mat√©rialis√©es pour KPIs fr√©quents

### ‚ùå Erreur 6 : Parall√©lisation D√©sactiv√©e
**Sympt√¥me :** Un seul CPU utilis√© malgr√© serveur 32 CPU
**Solution :** V√©rifier param√®tres `max_parallel_*`, r√©duire `parallel_setup_cost`

### ‚ùå Erreur 7 : Trop de Normalisation
**Sympt√¥me :** Jointures sur 5+ tables, requ√™tes extr√™mement lentes
**Solution :** D√©normaliser (dupliquer colonnes dans table de faits)

---

## ETL et Chargement de Donn√©es

### Strat√©gies de Chargement pour OLAP

#### **1. COPY : Le Plus Rapide**

```sql
-- Charger 10 millions de lignes en quelques secondes
COPY fact_sales FROM '/data/sales_2024_01.csv'
    WITH (FORMAT csv, HEADER true, DELIMITER ',');
```

**Optimisations :**
- D√©sactiver temporairement les triggers et contraintes
- Augmenter `maintenance_work_mem` pendant le chargement
- Cr√©er les index APR√àS le chargement

```sql
-- D√©sactiver contraintes
ALTER TABLE fact_sales DISABLE TRIGGER ALL;

-- Charger donn√©es
COPY fact_sales FROM ...;

-- R√©activer contraintes
ALTER TABLE fact_sales ENABLE TRIGGER ALL;

-- Cr√©er index en parall√®le
CREATE INDEX CONCURRENTLY idx_sales_date ON fact_sales(sale_date);
```

---

#### **2. Nouveaut√© PostgreSQL 18 : Am√©liorations COPY**

PostgreSQL 18 am√©liore significativement COPY :
- Gestion du marqueur de fin `\.` en CSV
- Performances am√©lior√©es (jusqu'√† 30% plus rapide)

---

#### **3. Chargement Incr√©mental**

```sql
-- Charger seulement les nouvelles donn√©es (delta)
INSERT INTO fact_sales
SELECT * FROM staging_sales
WHERE sale_date >= CURRENT_DATE - INTERVAL '1 day'
ON CONFLICT (sale_id) DO NOTHING;
```

---

#### **4. Partitions et ETL**

**Strat√©gie :** Charger dans partition temporaire, puis attacher.

```sql
-- 1. Cr√©er table temporaire
CREATE TABLE fact_sales_2024_01_temp (LIKE fact_sales INCLUDING ALL);

-- 2. Charger donn√©es
COPY fact_sales_2024_01_temp FROM '/data/sales_2024_01.csv' WITH CSV;

-- 3. Cr√©er index
CREATE INDEX ON fact_sales_2024_01_temp(sale_date);

-- 4. Attacher comme partition
ALTER TABLE fact_sales ATTACH PARTITION fact_sales_2024_01_temp
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

**Avantage :** Chargement et indexation en dehors de la table principale (pas de lock).

---

## Architectures Avanc√©es OLAP

### 1. Data Warehouse Distribu√©

Pour volumes extr√™mes (> 10 TB), consid√©rez des solutions distribu√©es :

- **Citus** : Extension PostgreSQL pour sharding automatique
- **Greenplum** : Fork PostgreSQL MPP (Massively Parallel Processing)
- **TimescaleDB** : Extension pour s√©ries temporelles

**Exemple Citus :**
```sql
CREATE EXTENSION citus;

-- Distribuer table de faits sur 4 n≈ìuds
SELECT create_distributed_table('fact_sales', 'customer_id');
```

---

### 2. Columnar Storage

PostgreSQL est orient√© lignes (row-based), mais pour analytics purs, le stockage colonnes est plus efficace.

**Options :**
- **Hydra Columnar** : Extension columnar pour PostgreSQL
- **pg_analytics** : Autre extension columnar

**Avantage :** Lire seulement les colonnes n√©cessaires (compression 10√ó, requ√™tes 5-10√ó plus rapides).

---

### 3. Int√©gration avec Outils BI

**Connexions typiques :**
- **Tableau** ‚Üí PostgreSQL (via driver natif)
- **Power BI** ‚Üí PostgreSQL (via ODBC/DirectQuery)
- **Metabase** ‚Üí PostgreSQL (open-source BI)
- **Apache Superset** ‚Üí PostgreSQL

**Bonnes pratiques :**
- Utiliser vues mat√©rialis√©es pour dashboards
- Limiter nombre de connexions (pooling)
- Pr√©-agr√©ger au maximum

---

## Ressources pour Aller Plus Loin

### Documentation Officielle
- [PostgreSQL Performance Optimization](https://www.postgresql.org/docs/18/performance-tips.html)
- [Partitioning](https://www.postgresql.org/docs/18/ddl-partitioning.html)
- [Parallel Query](https://www.postgresql.org/docs/18/parallel-query.html)

### Extensions Essentielles
- **pg_stat_statements** : Analyse de requ√™tes
- **pg_partman** : Gestion automatis√©e partitions
- **pg_cron** : Planification de t√¢ches (refresh MV, vacuum, etc.)
- **TimescaleDB** : S√©ries temporelles
- **Citus** : Distribution multi-n≈ìuds

### Outils
- **PGTune** : https://pgtune.leopard.in.ua/ (choisir "Data warehouse")
- **pgBadger** : Analyse de logs
- **Apache Hop / Airflow** : Orchestration ETL

### Lectures Recommand√©es
- *The Data Warehouse Toolkit* (Ralph Kimball) : Mod√©lisation dimensionnelle
- *PostgreSQL Query Optimization* : Techniques avanc√©es
- Blogs : Percona, Crunchy Data, 2ndQuadrant

---

## Conclusion

La configuration OLAP de PostgreSQL vise √† :

1. **Maximiser le d√©bit de donn√©es** (GB/s lus et trait√©s)
2. **Parall√©liser massivement** (utiliser tous les CPU)
3. **Optimiser pour agr√©gations** (work_mem √©lev√©, statistiques d√©taill√©es)
4. **Partitionner intelligemment** (Partition Pruning)
5. **Pr√©-calculer** (vues mat√©rialis√©es)
6. **Monitorer** (temp files, parall√©lisation, statistiques)

**Points cl√©s √† retenir :**

- ‚úÖ **work_mem √©lev√©** est LE param√®tre critique (256MB-2GB)
- ‚úÖ **Parall√©lisation** essentielle (max_parallel_workers_per_gather ‚â• 4)
- ‚úÖ **Partitionnement** obligatoire pour tables > 100M lignes
- ‚úÖ **BRIN** index id√©al pour colonnes s√©quentielles
- ‚úÖ **Vues mat√©rialis√©es** pour agr√©gations fr√©quentes
- ‚úÖ **Statistiques d√©taill√©es** (default_statistics_target ‚â• 500)
- ‚úÖ **ANALYZE** apr√®s chaque chargement ETL

**Diff√©rences cl√©s OLTP vs OLAP :**

| Param√®tre | OLTP | OLAP |
|-----------|------|------|
| work_mem | 16-32MB | 256MB-2GB |
| max_connections | 200-500 | 20-100 |
| max_parallel_workers_per_gather | 2-4 | 8-16 |
| default_statistics_target | 100 | 500-1000 |
| autovacuum_naptime | 10s | 5min |
| Partitionnement | Optionnel | Obligatoire |
| Vues mat√©rialis√©es | Rare | Fr√©quent |

PostgreSQL 18 apporte des am√©liorations significatives pour OLAP :
- I/O asynchrone (20-30% plus rapide)
- Colonnes virtuelles
- Optimisations du planificateur (skip scan, OR‚ÜíANY)
- Am√©liorations COPY

**Prochaines √âtapes :**

1. Appliquer configuration sur environnement dev/staging
2. Charger donn√©es repr√©sentatives
3. Tester requ√™tes typiques avec EXPLAIN ANALYZE
4. Ajuster work_mem et parall√©lisation selon r√©sultats
5. Cr√©er partitions et vues mat√©rialis√©es
6. Mettre en place monitoring (pg_stat_statements)
7. Automatiser ETL et refresh vues mat√©rialis√©es

Bonne chance avec votre Data Warehouse PostgreSQL ! üìäüöÄ

‚è≠Ô∏è [Mixed workload (√©quilibre OLTP/OLAP)](/annexes/configuration-reference/03-configuration-mixed-workload.md)
