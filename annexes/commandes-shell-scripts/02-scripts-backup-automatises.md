üîù Retour au [Sommaire](/SOMMAIRE.md)

# Scripts de Backup Automatis√©s pour PostgreSQL
## Annexe G.2 - Automatisation des Sauvegardes

---

## Table des Mati√®res

1. [Introduction aux Backups Automatis√©s](#1-introduction-aux-backups-automatis%C3%A9s)
2. [Strat√©gies de Backup](#2-strat%C3%A9gies-de-backup)
3. [Scripts de Base](#3-scripts-de-base)
4. [Scripts Avanc√©s pour Production](#4-scripts-avanc%C3%A9s-pour-production)
5. [Automatisation avec Cron](#5-automatisation-avec-cron)
6. [Rotation des Backups](#6-rotation-des-backups)
7. [Destinations de Sauvegarde](#7-destinations-de-sauvegarde)
8. [Monitoring et Alertes](#8-monitoring-et-alertes)
9. [Scripts de V√©rification](#9-scripts-de-v%C3%A9rification)
10. [Bonnes Pratiques](#10-bonnes-pratiques)

---

## 1. Introduction aux Backups Automatis√©s

### 1.1. Pourquoi Automatiser les Backups ?

**Les backups manuels sont risqu√©s :**
- ‚ùå Oublis fr√©quents
- ‚ùå Incoh√©rences dans le processus
- ‚ùå Erreurs humaines
- ‚ùå Pas d'historique fiable
- ‚ùå Impossible √† grande √©chelle

**Les backups automatis√©s offrent :**
- ‚úÖ Fiabilit√© : Ex√©cution r√©guli√®re garantie
- ‚úÖ Coh√©rence : Processus identique √† chaque fois
- ‚úÖ Tra√ßabilit√© : Logs et historique complets
- ‚úÖ S√©r√©nit√© : Dormez tranquille !
- ‚úÖ Conformit√© : Respect des politiques de sauvegarde

### 1.2. Qu'est-ce qu'un Script de Backup ?

Un **script de backup** est un programme (g√©n√©ralement en Bash) qui :
1. Se connecte √† PostgreSQL
2. Exporte les donn√©es (pg_dump)
3. Compresse le r√©sultat
4. Nomme le fichier avec un timestamp
5. Stocke le backup dans un emplacement s√ªr
6. Nettoie les anciens backups (rotation)
7. V√©rifie l'int√©grit√©
8. Envoie des alertes en cas de probl√®me

**Exemple de workflow automatis√© :**

```
[Cron] ‚Üí Tous les jours √† 2h du matin
    ‚Üì
[Script de backup]
    ‚Üì
1. V√©rifier que PostgreSQL est actif
2. Cr√©er le backup avec pg_dump
3. Compresser et nommer (db_20251121_020000.dump)
4. Copier vers NAS/Cloud
5. Supprimer backups > 30 jours
6. V√©rifier l'int√©grit√©
7. Envoyer email de confirmation
    ‚Üì
[Backup s√©curis√© et v√©rifi√©]
```

### 1.3. Composants d'un Syst√®me de Backup Complet

Un syst√®me de backup professionnel comprend :

1. **Script principal** : Effectue le backup
2. **Configuration** : Param√®tres centralis√©s
3. **Rotation** : Gestion de l'historique
4. **V√©rification** : Validation de l'int√©grit√©
5. **Stockage** : Multiple destinations (local, distant, cloud)
6. **Monitoring** : Surveillance et alertes
7. **Logs** : Tra√ßabilit√© compl√®te
8. **Restauration** : Tests r√©guliers

### 1.4. Pr√©requis

**Avant de commencer, assurez-vous d'avoir :**
- PostgreSQL 18 install√© et fonctionnel
- Acc√®s shell au serveur (SSH)
- Droits d'ex√©cution sur les scripts
- Espace disque suffisant pour les backups
- (Optionnel) Acc√®s √† un serveur distant ou cloud

**Connaissances requises :**
- Bases du shell Bash
- Utilisation de `pg_dump` (voir Annexe G.1)
- Notions de cron (sera expliqu√© ici)

---

## 2. Strat√©gies de Backup

### 2.1. Fr√©quences de Backup

**Quelle fr√©quence choisir ?** Cela d√©pend de votre tol√©rance √† la perte de donn√©es.

| Fr√©quence | RPO* | Cas d'usage | Co√ªt stockage |
|-----------|------|-------------|---------------|
| **Horaire** | 1 heure | Applications critiques (finance, sant√©) | Tr√®s √©lev√© |
| **4√ó par jour** | 6 heures | E-commerce, SaaS | √âlev√© |
| **Quotidienne** | 24 heures | Applications standard | Moyen |
| **Hebdomadaire** | 7 jours | D√©veloppement, archives | Faible |

**RPO = Recovery Point Objective : Perte de donn√©es maximale acceptable*

**üí° Recommandation standard :**
- **Production** : Backup quotidien + WAL archiving continu (RPO quasi-nul)
- **Staging** : Backup quotidien
- **D√©veloppement** : Backup hebdomadaire

### 2.2. Strat√©gie 3-2-1 (La R√®gle d'Or)

**Principe de la r√®gle 3-2-1 :**
- **3** copies de vos donn√©es (1 production + 2 backups)
- Sur **2** supports diff√©rents (disque local + NAS/cloud)
- **1** copie hors site (cloud, datacenter distant)

**Exemple concret :**

```
[Base Production]  ‚Üê Copie 1 (donn√©es actives)
        ‚Üì
[Backup Local]     ‚Üê Copie 2 (disque serveur)
        ‚Üì
[Backup NAS]       ‚Üê Copie 3 (r√©seau local, support diff√©rent)
        ‚Üì
[Backup Cloud/S3]  ‚Üê Copie 4 (hors site, protection maximale)
```

**Pourquoi c'est crucial ?**
- **Disque dur d√©faillant** ‚Üí Copie sur NAS disponible
- **Incendie datacenter** ‚Üí Copie cloud disponible
- **Ransomware** ‚Üí Copie hors site intacte
- **Erreur humaine** ‚Üí Plusieurs points de restauration

### 2.3. Strat√©gie de R√©tention (Combien de Temps Garder ?)

**Politique GFS (Grand-P√®re P√®re Fils) :**

```
[Quotidiens]     : 7 derniers jours   (Fils)
[Hebdomadaires]  : 4 derni√®res semaines  (P√®re)
[Mensuels]       : 12 derniers mois  (Grand-P√®re)
[Annuels]        : 5-7 derni√®res ann√©es (Archivage)
```

**Exemple de r√©partition :**
- Lundi-Dimanche : Backups quotidiens (7 fichiers)
- Dimanche uniquement : Backups hebdomadaires (4 fichiers)
- 1er du mois : Backups mensuels (12 fichiers)
- 1er janvier : Backup annuel (7 fichiers)

**Total : ~30 fichiers de backup** au lieu de 365 !

### 2.4. Types de Backups

#### 2.4.1. Backup Complet (Full)

**D√©finition :** Sauvegarde int√©grale de toute la base de donn√©es.

**Avantages :**
- ‚úÖ Restauration simple (1 seul fichier)
- ‚úÖ Autonome et ind√©pendant
- ‚úÖ Facile √† g√©rer

**Inconv√©nients :**
- ‚ùå Consomme beaucoup d'espace
- ‚ùå Temps de backup long
- ‚ùå Bande passante r√©seau importante

**Quand utiliser :**
- Bases de donn√©es < 500 GB
- Backup quotidien standard
- Obligation de conformit√©

#### 2.4.2. Backup Incr√©mental

**D√©finition :** Sauvegarde uniquement les modifications depuis le dernier backup.

**Avantages :**
- ‚úÖ Rapide √† ex√©cuter
- ‚úÖ Consomme peu d'espace
- ‚úÖ Peut √™tre ex√©cut√© fr√©quemment

**Inconv√©nients :**
- ‚ùå Restauration complexe (cha√Æne de backups)
- ‚ùå D√©pendance entre fichiers
- ‚ùå N√©cessite WAL archiving

**Quand utiliser :**
- Tr√®s grandes bases de donn√©es (> 1 TB)
- Backup continu (toutes les heures)
- Avec r√©plication physique

**üí° Note :** PostgreSQL g√®re l'incr√©mental via **WAL archiving** (Write-Ahead Logs). Nous nous concentrerons ici sur les backups complets logiques.

### 2.5. Checklist : D√©finir Votre Strat√©gie

**Avant de cr√©er vos scripts, r√©pondez √† ces questions :**

- [ ] Quelle perte de donn√©es maximale est acceptable ? (RPO)
- [ ] Combien de temps peut durer une restauration ? (RTO)
- [ ] Quelle est la taille de vos bases de donn√©es ?
- [ ] Combien d'espace disque avez-vous ?
- [ ] Avez-vous acc√®s √† un stockage distant/cloud ?
- [ ] Qui doit √™tre alert√© en cas de probl√®me ?
- [ ] Quelle est votre politique de r√©tention ?

**Exemple de strat√©gie d√©finie :**

```
Application E-commerce "MonShop"
- Base de donn√©es : 50 GB
- RPO : 24 heures (backup quotidien)
- RTO : 2 heures
- R√©tention : 7 jours (quotidien) + 4 semaines (hebdo) + 12 mois (mensuel)
- Stockage : Local + S3
- Alertes : admin@monshop.com
```

---

## 3. Scripts de Base

### 3.1. Script Minimaliste (Point de D√©part)

**Le script de backup le plus simple possible :**

```bash
#!/bin/bash
# backup_minimal.sh

DATABASE="mabase"
BACKUP_DIR="/var/backups/postgresql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Cr√©er le r√©pertoire si n√©cessaire
mkdir -p "$BACKUP_DIR"

# Effectuer le backup
pg_dump -F c "$DATABASE" -f "$BACKUP_DIR/${DATABASE}_${TIMESTAMP}.dump"

echo "Backup termin√© : $BACKUP_DIR/${DATABASE}_${TIMESTAMP}.dump"
```

**Ce que fait ce script :**
1. D√©finit la base √† sauvegarder (`mabase`)
2. D√©finit le r√©pertoire de destination
3. G√©n√®re un timestamp (ex: `20251121_143000`)
4. Cr√©e le r√©pertoire si besoin
5. Ex√©cute `pg_dump` en format custom compress√©
6. Affiche le chemin du backup cr√©√©

**Utilisation :**

```bash
# Rendre le script ex√©cutable
chmod +x backup_minimal.sh

# Ex√©cuter
./backup_minimal.sh
```

**R√©sultat :**

```
/var/backups/postgresql/mabase_20251121_143000.dump
```

### 3.2. Script Simple avec V√©rifications

**Am√©lioration : Ajouter des v√©rifications de base**

```bash
#!/bin/bash
# backup_simple.sh

# ========================================
# Configuration
# ========================================
DATABASE="mabase"
BACKUP_DIR="/var/backups/postgresql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/${DATABASE}_${TIMESTAMP}.dump"

# ========================================
# Fonctions
# ========================================

# Fonction de log simple
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Fonction de v√©rification de succ√®s
check_success() {
    if [ $? -eq 0 ]; then
        log "‚úÖ $1 : OK"
        return 0
    else
        log "‚ùå $1 : √âCHEC"
        return 1
    fi
}

# ========================================
# Script Principal
# ========================================

log "=== D√©but du backup de $DATABASE ==="

# √âtape 1 : Cr√©er le r√©pertoire
mkdir -p "$BACKUP_DIR"
check_success "Cr√©ation du r√©pertoire"

# √âtape 2 : V√©rifier que PostgreSQL est accessible
log "V√©rification de la connexion √† PostgreSQL..."
if ! pg_isready -d "$DATABASE" > /dev/null 2>&1; then
    log "‚ùå ERREUR : Impossible de se connecter √† PostgreSQL"
    exit 1
fi
log "‚úÖ Connexion PostgreSQL OK"

# √âtape 3 : Effectuer le backup
log "D√©but de l'export de $DATABASE..."
pg_dump -F c -Z 9 "$DATABASE" -f "$BACKUP_FILE"
check_success "Export de la base"

# √âtape 4 : V√©rifier que le fichier existe et n'est pas vide
if [ -f "$BACKUP_FILE" ] && [ -s "$BACKUP_FILE" ]; then
    SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
    log "‚úÖ Backup cr√©√© : $BACKUP_FILE ($SIZE)"
else
    log "‚ùå ERREUR : Le fichier de backup est vide ou inexistant"
    exit 1
fi

# √âtape 5 : V√©rifier l'int√©grit√© du backup
log "V√©rification de l'int√©grit√© du backup..."
if pg_restore --list "$BACKUP_FILE" > /dev/null 2>&1; then
    log "‚úÖ Backup valide"
else
    log "‚ùå ATTENTION : Le backup semble corrompu !"
    exit 1
fi

log "=== Backup termin√© avec succ√®s ==="
exit 0
```

**Am√©liorations apport√©es :**
- ‚úÖ Fonction `log()` pour horodater les messages
- ‚úÖ V√©rification de la connectivit√© PostgreSQL (`pg_isready`)
- ‚úÖ V√©rification de l'existence et taille du fichier
- ‚úÖ Validation de l'int√©grit√© (`pg_restore --list`)
- ‚úÖ Codes de retour appropri√©s (exit 0/1)
- ‚úÖ Messages clairs et informatifs

### 3.3. Script avec Rotation (Nettoyage Automatique)

**Ajout de la rotation pour √©viter de remplir le disque :**

```bash
#!/bin/bash
# backup_avec_rotation.sh

# ========================================
# Configuration
# ========================================
DATABASE="mabase"
BACKUP_DIR="/var/backups/postgresql"
RETENTION_DAYS=7  # Nombre de jours √† conserver
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/${DATABASE}_${TIMESTAMP}.dump"

# ========================================
# Fonctions
# ========================================

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# ========================================
# Script Principal
# ========================================

log "=== Backup de $DATABASE avec rotation ${RETENTION_DAYS} jours ==="

# Cr√©er le r√©pertoire
mkdir -p "$BACKUP_DIR"

# V√©rifier PostgreSQL
if ! pg_isready -d "$DATABASE" > /dev/null 2>&1; then
    log "‚ùå PostgreSQL non accessible"
    exit 1
fi

# Effectuer le backup
log "Cr√©ation du backup..."
pg_dump -F c -Z 9 "$DATABASE" -f "$BACKUP_FILE"

if [ $? -eq 0 ]; then
    SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
    log "‚úÖ Backup cr√©√© : $BACKUP_FILE ($SIZE)"

    # V√©rifier l'int√©grit√©
    if pg_restore --list "$BACKUP_FILE" > /dev/null 2>&1; then
        log "‚úÖ Backup valid√©"
    else
        log "‚ö†Ô∏è ATTENTION : Backup potentiellement corrompu"
    fi
else
    log "‚ùå √âchec du backup"
    exit 1
fi

# Rotation : Supprimer les backups plus anciens que RETENTION_DAYS
log "Nettoyage des anciens backups (> $RETENTION_DAYS jours)..."
BEFORE_COUNT=$(find "$BACKUP_DIR" -name "${DATABASE}_*.dump" | wc -l)

find "$BACKUP_DIR" -name "${DATABASE}_*.dump" -type f -mtime +$RETENTION_DAYS -delete

AFTER_COUNT=$(find "$BACKUP_DIR" -name "${DATABASE}_*.dump" | wc -l)
DELETED=$((BEFORE_COUNT - AFTER_COUNT))

log "üóëÔ∏è  $DELETED ancien(s) backup(s) supprim√©(s)"
log "üì¶ Backups restants : $AFTER_COUNT"

log "=== Backup termin√© ==="
exit 0
```

**Fonctionnement de la rotation :**

```bash
find "$BACKUP_DIR" -name "${DATABASE}_*.dump" -type f -mtime +$RETENTION_DAYS -delete
```

**Explication :**
- `find "$BACKUP_DIR"` : Cherche dans le r√©pertoire de backup
- `-name "${DATABASE}_*.dump"` : Fichiers correspondant au pattern (ex: `mabase_*.dump`)
- `-type f` : Uniquement les fichiers (pas les r√©pertoires)
- `-mtime +$RETENTION_DAYS` : Modifi√©s il y a plus de N jours
- `-delete` : Supprimer les fichiers trouv√©s

**Exemple avec RETENTION_DAYS=7 :**

```
Jour 1 : mabase_20251115.dump  ‚Üê Cr√©√©
Jour 2 : mabase_20251116.dump  ‚Üê Cr√©√©
...
Jour 7 : mabase_20251121.dump  ‚Üê Cr√©√©
Jour 8 : mabase_20251122.dump  ‚Üê Cr√©√©
         mabase_20251115.dump  ‚Üê Supprim√© (> 7 jours)
```

### 3.4. Script Multi-Bases

**Si vous avez plusieurs bases de donn√©es :**

```bash
#!/bin/bash
# backup_multi_bases.sh

# ========================================
# Configuration
# ========================================
BACKUP_DIR="/var/backups/postgresql"
RETENTION_DAYS=7
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Liste des bases √† sauvegarder
DATABASES=(
    "production"
    "staging"
    "analytics"
)

# ========================================
# Fonctions
# ========================================

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

backup_database() {
    local db="$1"
    local backup_file="$BACKUP_DIR/${db}_${TIMESTAMP}.dump"

    log "üì¶ Backup de $db..."

    if ! pg_isready -d "$db" > /dev/null 2>&1; then
        log "‚ùå $db non accessible"
        return 1
    fi

    pg_dump -F c -Z 9 "$db" -f "$backup_file"

    if [ $? -eq 0 ] && [ -s "$backup_file" ]; then
        local size=$(du -h "$backup_file" | cut -f1)
        log "‚úÖ $db : $backup_file ($size)"
        return 0
    else
        log "‚ùå $db : √âchec du backup"
        return 1
    fi
}

# ========================================
# Script Principal
# ========================================

log "=== Backup de ${#DATABASES[@]} base(s) de donn√©es ==="

mkdir -p "$BACKUP_DIR"

# Sauvegarder chaque base
SUCCESS_COUNT=0
FAIL_COUNT=0

for db in "${DATABASES[@]}"; do
    if backup_database "$db"; then
        ((SUCCESS_COUNT++))
    else
        ((FAIL_COUNT++))
    fi
done

log "üìä R√©sum√© : $SUCCESS_COUNT succ√®s, $FAIL_COUNT √©chec(s)"

# Rotation globale
log "Nettoyage des anciens backups..."
for db in "${DATABASES[@]}"; do
    deleted=$(find "$BACKUP_DIR" -name "${db}_*.dump" -type f -mtime +$RETENTION_DAYS -delete -print | wc -l)
    if [ $deleted -gt 0 ]; then
        log "üóëÔ∏è  $db : $deleted ancien(s) backup(s) supprim√©(s)"
    fi
done

log "=== Backup termin√© ==="

# Code de retour
if [ $FAIL_COUNT -eq 0 ]; then
    exit 0
else
    exit 1
fi
```

**Avantages :**
- ‚úÖ Sauvegarde plusieurs bases en une seule ex√©cution
- ‚úÖ Comptabilisation des succ√®s/√©checs
- ‚úÖ Rotation ind√©pendante par base
- ‚úÖ Facile √† √©tendre (ajouter des bases dans le tableau)

---

## 4. Scripts Avanc√©s pour Production

### 4.1. Script avec Fichier de Configuration

**S√©parer la configuration du code :**

**Fichier : `/etc/postgresql_backup.conf`**

```bash
# Configuration du syst√®me de backup PostgreSQL

# Bases de donn√©es √† sauvegarder (s√©par√©es par des espaces)
DATABASES="production staging analytics"

# R√©pertoire de backup local
BACKUP_DIR="/var/backups/postgresql"

# R√©pertoire des logs
LOG_DIR="/var/log/postgresql_backup"

# R√©tention (jours)
RETENTION_DAILY=7
RETENTION_WEEKLY=28
RETENTION_MONTHLY=365

# Compression (0-9)
COMPRESSION_LEVEL=9

# Parall√©lisme pour grandes bases
PARALLEL_JOBS=4

# Stockage distant
ENABLE_REMOTE_BACKUP=true
REMOTE_BACKUP_DIR="/mnt/nas/postgresql_backups"
S3_BUCKET="s3://my-company-backups/postgresql"

# Alertes
ENABLE_EMAIL_ALERTS=true
ALERT_EMAIL="admin@example.com"
SMTP_SERVER="smtp.example.com"

# Options avanc√©es
ENABLE_INTEGRITY_CHECK=true
ENABLE_SIZE_MONITORING=true
MAX_BACKUP_SIZE_GB=100
```

**Script : `backup_production.sh`**

```bash
#!/bin/bash
# backup_production.sh

# ========================================
# Chargement de la Configuration
# ========================================

CONFIG_FILE="/etc/postgresql_backup.conf"

if [ ! -f "$CONFIG_FILE" ]; then
    echo "‚ùå ERREUR : Fichier de configuration introuvable : $CONFIG_FILE"
    exit 1
fi

# Charger la configuration
source "$CONFIG_FILE"

# ========================================
# Variables Globales
# ========================================

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
DATE_SHORT=$(date +%Y%m%d)
LOG_FILE="$LOG_DIR/backup_${TIMESTAMP}.log"

# Cr√©er les r√©pertoires n√©cessaires
mkdir -p "$BACKUP_DIR" "$LOG_DIR"

# ========================================
# Fonctions
# ========================================

log() {
    local message="[$(date '+%Y-%m-%d %H:%M:%S')] $1"
    echo "$message" | tee -a "$LOG_FILE"
}

log_error() {
    local message="[$(date '+%Y-%m-%d %H:%M:%S')] ‚ùå ERREUR : $1"
    echo "$message" | tee -a "$LOG_FILE" >&2
}

send_alert() {
    if [ "$ENABLE_EMAIL_ALERTS" = true ]; then
        local subject="$1"
        local body="$2"

        echo "$body" | mail -s "$subject" -S smtp="$SMTP_SERVER" "$ALERT_EMAIL"
        log "üìß Alerte envoy√©e : $subject"
    fi
}

check_disk_space() {
    local min_space_gb=20
    local available_gb=$(df -BG "$BACKUP_DIR" | tail -1 | awk '{print $4}' | sed 's/G//')

    if [ "$available_gb" -lt "$min_space_gb" ]; then
        log_error "Espace disque insuffisant : ${available_gb}GB disponible (minimum: ${min_space_gb}GB)"
        send_alert "Backup PostgreSQL - Espace Disque Critique" \
                   "Espace disponible : ${available_gb}GB\nMinimum requis : ${min_space_gb}GB"
        return 1
    fi

    log "üíæ Espace disque : ${available_gb}GB disponible"
    return 0
}

backup_database() {
    local db="$1"
    local backup_file="$BACKUP_DIR/${db}_${TIMESTAMP}.dump"
    local start_time=$(date +%s)

    log "=========================================="
    log "üì¶ D√©but du backup : $db"
    log "=========================================="

    # V√©rifier la connectivit√©
    if ! pg_isready -d "$db" > /dev/null 2>&1; then
        log_error "Base $db non accessible"
        return 1
    fi

    # Taille de la base avant backup
    local db_size=$(psql -t -d "$db" -c "SELECT pg_size_pretty(pg_database_size('$db'))" | xargs)
    log "üìä Taille de la base : $db_size"

    # Effectuer le backup
    log "üîÑ Export en cours (compression: $COMPRESSION_LEVEL)..."

    if pg_dump -F c -Z "$COMPRESSION_LEVEL" "$db" -f "$backup_file" 2>> "$LOG_FILE"; then
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        local backup_size=$(du -h "$backup_file" | cut -f1)

        log "‚úÖ Backup r√©ussi en ${duration}s"
        log "üì¶ Fichier : $backup_file"
        log "üíæ Taille : $backup_size"

        # V√©rifier l'int√©grit√©
        if [ "$ENABLE_INTEGRITY_CHECK" = true ]; then
            log "üîç V√©rification de l'int√©grit√©..."
            if pg_restore --list "$backup_file" > /dev/null 2>&1; then
                log "‚úÖ Int√©grit√© valid√©e"
            else
                log_error "Backup corrompu : $backup_file"
                send_alert "Backup PostgreSQL - Backup Corrompu" \
                           "La base $db a un backup corrompu : $backup_file"
                return 1
            fi
        fi

        # Monitoring de taille
        if [ "$ENABLE_SIZE_MONITORING" = true ]; then
            local size_gb=$(du -BG "$backup_file" | cut -f1 | sed 's/G//')
            if [ "$size_gb" -gt "$MAX_BACKUP_SIZE_GB" ]; then
                log "‚ö†Ô∏è ATTENTION : Backup anormalement volumineux (${size_gb}GB)"
                send_alert "Backup PostgreSQL - Taille Anormale" \
                           "Le backup de $db fait ${size_gb}GB (max: ${MAX_BACKUP_SIZE_GB}GB)"
            fi
        fi

        return 0
    else
        log_error "√âchec du backup de $db"
        return 1
    fi
}

rotate_backups() {
    local db="$1"

    log "üóëÔ∏è  Rotation des backups pour $db..."

    # Quotidiens (garder RETENTION_DAILY jours)
    local deleted=$(find "$BACKUP_DIR" -name "${db}_*.dump" -type f -mtime +$RETENTION_DAILY -delete -print | wc -l)
    if [ $deleted -gt 0 ]; then
        log "  Quotidiens : $deleted supprim√©(s)"
    fi

    # Afficher les backups restants
    local remaining=$(find "$BACKUP_DIR" -name "${db}_*.dump" -type f | wc -l)
    log "  üì¶ Backups restants : $remaining"
}

backup_to_remote() {
    if [ "$ENABLE_REMOTE_BACKUP" != true ]; then
        return 0
    fi

    log "=========================================="
    log "‚òÅÔ∏è  Copie vers stockage distant"
    log "=========================================="

    # Copie vers NAS
    if [ -n "$REMOTE_BACKUP_DIR" ] && [ -d "$(dirname "$REMOTE_BACKUP_DIR")" ]; then
        log "üì° Copie vers NAS : $REMOTE_BACKUP_DIR"
        mkdir -p "$REMOTE_BACKUP_DIR"

        rsync -av --progress "$BACKUP_DIR/" "$REMOTE_BACKUP_DIR/" >> "$LOG_FILE" 2>&1

        if [ $? -eq 0 ]; then
            log "‚úÖ Copie NAS r√©ussie"
        else
            log_error "√âchec de la copie NAS"
        fi
    fi

    # Copie vers S3 (si aws-cli est install√©)
    if [ -n "$S3_BUCKET" ] && command -v aws > /dev/null 2>&1; then
        log "üì° Upload vers S3 : $S3_BUCKET"

        for dump_file in "$BACKUP_DIR"/*_${TIMESTAMP}.dump; do
            if [ -f "$dump_file" ]; then
                aws s3 cp "$dump_file" "$S3_BUCKET/$(basename "$dump_file")" >> "$LOG_FILE" 2>&1

                if [ $? -eq 0 ]; then
                    log "‚úÖ Upload S3 : $(basename "$dump_file")"
                else
                    log_error "√âchec upload S3 : $(basename "$dump_file")"
                fi
            fi
        done
    fi
}

# ========================================
# Script Principal
# ========================================

log "=========================================="
log "üöÄ D√©marrage du backup PostgreSQL"
log "=========================================="
log "Configuration : $CONFIG_FILE"
log "Timestamp : $TIMESTAMP"
log ""

# V√©rifier l'espace disque
if ! check_disk_space; then
    log_error "Backup annul√© : espace disque insuffisant"
    exit 1
fi

# Sauvegarder les objets globaux (r√¥les, tablespaces)
log "=========================================="
log "üë• Backup des objets globaux"
log "=========================================="

GLOBALS_FILE="$BACKUP_DIR/globals_${TIMESTAMP}.sql"
if pg_dumpall --globals-only > "$GLOBALS_FILE" 2>> "$LOG_FILE"; then
    log "‚úÖ Objets globaux sauvegard√©s : $GLOBALS_FILE"
else
    log_error "√âchec du backup des objets globaux"
fi

# Backup de chaque base
SUCCESS_COUNT=0
FAIL_COUNT=0

for db in $DATABASES; do
    if backup_database "$db"; then
        ((SUCCESS_COUNT++))
        rotate_backups "$db"
    else
        ((FAIL_COUNT++))
    fi
    echo "" >> "$LOG_FILE"
done

# Copie vers stockage distant
backup_to_remote

# ========================================
# R√©sum√© et Alertes
# ========================================

log "=========================================="
log "üìä R√âSUM√â"
log "=========================================="
log "Bases sauvegard√©es : $SUCCESS_COUNT"
log "√âchecs : $FAIL_COUNT"
log "Dur√©e totale : $SECONDS secondes"
log "Log complet : $LOG_FILE"

# Taille totale des backups
TOTAL_SIZE=$(du -sh "$BACKUP_DIR" | cut -f1)
log "üíæ Taille totale des backups : $TOTAL_SIZE"

# Envoyer une alerte si des √©checs
if [ $FAIL_COUNT -gt 0 ]; then
    send_alert "Backup PostgreSQL - √âchecs D√©tect√©s" \
               "$(cat "$LOG_FILE" | grep "ERREUR")"
    log "=========================================="
    exit 1
else
    log "‚úÖ Tous les backups r√©ussis"
    log "=========================================="
    exit 0
fi
```

**Avantages de cette approche :**
- ‚úÖ Configuration centralis√©e et facilement modifiable
- ‚úÖ Gestion compl√®te des erreurs
- ‚úÖ Monitoring et alertes
- ‚úÖ Logs d√©taill√©s
- ‚úÖ Copie vers stockage distant (NAS, S3)
- ‚úÖ V√©rification d'int√©grit√©
- ‚úÖ Monitoring de la taille des backups
- ‚úÖ Backup des objets globaux (r√¥les)
- ‚úÖ Pr√™t pour la production

### 4.2. Script avec Politique GFS (Grand-P√®re P√®re Fils)

**Rotation avanc√©e avec conservation hi√©rarchique :**

```bash
#!/bin/bash
# backup_gfs.sh

# ========================================
# Configuration
# ========================================

DATABASE="production"
BACKUP_DIR="/var/backups/postgresql"
DAILY_DIR="$BACKUP_DIR/daily"
WEEKLY_DIR="$BACKUP_DIR/weekly"
MONTHLY_DIR="$BACKUP_DIR/monthly"
YEARLY_DIR="$BACKUP_DIR/yearly"

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
DAY_OF_WEEK=$(date +%u)    # 1=Lundi, 7=Dimanche
DAY_OF_MONTH=$(date +%d)   # 01-31
DAY_OF_YEAR=$(date +%j)    # 001-365

# R√©tentions
RETENTION_DAILY=7      # 7 jours
RETENTION_WEEKLY=28    # 4 semaines
RETENTION_MONTHLY=365  # 12 mois
RETENTION_YEARLY=2555  # 7 ans

# ========================================
# Fonctions
# ========================================

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

create_backup() {
    local target_dir="$1"
    local backup_type="$2"

    mkdir -p "$target_dir"

    local backup_file="$target_dir/${DATABASE}_${backup_type}_${TIMESTAMP}.dump"

    log "üì¶ Cr√©ation backup $backup_type : $backup_file"

    if pg_dump -F c -Z 9 "$DATABASE" -f "$backup_file" 2>/dev/null; then
        local size=$(du -h "$backup_file" | cut -f1)
        log "‚úÖ Backup $backup_type cr√©√© : $size"
        return 0
    else
        log "‚ùå √âchec backup $backup_type"
        return 1
    fi
}

rotate_directory() {
    local dir="$1"
    local retention="$2"
    local type="$3"

    if [ ! -d "$dir" ]; then
        return 0
    fi

    local before=$(find "$dir" -name "*.dump" | wc -l)
    find "$dir" -name "*.dump" -type f -mtime +$retention -delete
    local after=$(find "$dir" -name "*.dump" | wc -l)
    local deleted=$((before - after))

    if [ $deleted -gt 0 ]; then
        log "üóëÔ∏è  $type : $deleted supprim√©(s), $after restant(s)"
    fi
}

# ========================================
# Script Principal
# ========================================

log "=========================================="
log "üîÑ Backup GFS de $DATABASE"
log "=========================================="
log "Date : $(date '+%Y-%m-%d %H:%M:%S')"
log "Jour de la semaine : $DAY_OF_WEEK"
log "Jour du mois : $DAY_OF_MONTH"
log ""

# D√©terminer le type de backup selon la date
BACKUP_CREATED=false

# Annuel (1er janvier)
if [ "$DAY_OF_YEAR" = "001" ]; then
    log "üìÖ Backup ANNUEL"
    create_backup "$YEARLY_DIR" "yearly"
    BACKUP_CREATED=true
fi

# Mensuel (1er du mois)
if [ "$DAY_OF_MONTH" = "01" ] && [ "$BACKUP_CREATED" = false ]; then
    log "üìÖ Backup MENSUEL"
    create_backup "$MONTHLY_DIR" "monthly"
    BACKUP_CREATED=true
fi

# Hebdomadaire (dimanche)
if [ "$DAY_OF_WEEK" = "7" ] && [ "$BACKUP_CREATED" = false ]; then
    log "üìÖ Backup HEBDOMADAIRE"
    create_backup "$WEEKLY_DIR" "weekly"
    BACKUP_CREATED=true
fi

# Quotidien (tous les jours)
if [ "$BACKUP_CREATED" = false ]; then
    log "üìÖ Backup QUOTIDIEN"
    create_backup "$DAILY_DIR" "daily"
fi

log ""
log "=========================================="
log "üóëÔ∏è  Rotation des anciens backups"
log "=========================================="

# Rotation de chaque niveau
rotate_directory "$DAILY_DIR" $RETENTION_DAILY "Quotidiens"
rotate_directory "$WEEKLY_DIR" $RETENTION_WEEKLY "Hebdomadaires"
rotate_directory "$MONTHLY_DIR" $RETENTION_MONTHLY "Mensuels"
rotate_directory "$YEARLY_DIR" $RETENTION_YEARLY "Annuels"

log ""
log "=========================================="
log "üìä R√©sum√© des backups"
log "=========================================="

# Compter les backups par cat√©gorie
DAILY_COUNT=$(find "$DAILY_DIR" -name "*.dump" 2>/dev/null | wc -l)
WEEKLY_COUNT=$(find "$WEEKLY_DIR" -name "*.dump" 2>/dev/null | wc -l)
MONTHLY_COUNT=$(find "$MONTHLY_DIR" -name "*.dump" 2>/dev/null | wc -l)
YEARLY_COUNT=$(find "$YEARLY_DIR" -name "*.dump" 2>/dev/null | wc -l)
TOTAL_COUNT=$((DAILY_COUNT + WEEKLY_COUNT + MONTHLY_COUNT + YEARLY_COUNT))

log "üì¶ Quotidiens : $DAILY_COUNT"
log "üì¶ Hebdomadaires : $WEEKLY_COUNT"
log "üì¶ Mensuels : $MONTHLY_COUNT"
log "üì¶ Annuels : $YEARLY_COUNT"
log "üì¶ TOTAL : $TOTAL_COUNT backups"

# Taille totale
TOTAL_SIZE=$(du -sh "$BACKUP_DIR" 2>/dev/null | cut -f1)
log "üíæ Espace utilis√© : $TOTAL_SIZE"

log "=========================================="
log "‚úÖ Backup GFS termin√©"
log "=========================================="
```

**Avantages de la strat√©gie GFS :**
- ‚úÖ Historique long sans exploser l'espace disque
- ‚úÖ Points de restauration fr√©quents (7 jours)
- ‚úÖ Archivage √† long terme (jusqu'√† 7 ans)
- ‚úÖ √âquilibre optimal co√ªt/protection

**Exemple de r√©partition sur un an :**

```
Janvier 1  : Backup annuel   ‚Üí yearly/
Janvier 7  : Backup hebdo    ‚Üí weekly/
Janvier 8  : Backup quotidien ‚Üí daily/
Janvier 9  : Backup quotidien ‚Üí daily/
...
F√©vrier 1  : Backup mensuel  ‚Üí monthly/
F√©vrier 7  : Backup hebdo    ‚Üí weekly/
...
```

**Apr√®s 1 an, vous aurez :**
- 7 backups quotidiens (derni√®re semaine)
- 4 backups hebdomadaires (dernier mois)
- 12 backups mensuels (derni√®re ann√©e)
- 1 backup annuel
- **Total : ~24 fichiers** au lieu de 365 !

---

## 5. Automatisation avec Cron

### 5.1. Introduction √† Cron

**Qu'est-ce que Cron ?**

Cron est un **planificateur de t√¢ches** sous Linux/Unix qui permet d'ex√©cuter des scripts √† intervalles r√©guliers (quotidien, hebdomadaire, mensuel, etc.).

**Analogie :** Cron est comme un assistant qui ex√©cute vos scripts automatiquement selon un planning que vous d√©finissez.

### 5.2. Syntaxe de Cron

Une ligne cron (crontab) suit ce format :

```
* * * * * commande_√†_ex√©cuter
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ Jour de la semaine (0-7, 0 et 7 = Dimanche)
‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Mois (1-12)
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Jour du mois (1-31)
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Heure (0-23)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Minute (0-59)
```

**Caract√®res sp√©ciaux :**
- `*` : Toutes les valeurs (chaque minute, chaque heure, etc.)
- `,` : Liste de valeurs (ex: `1,15,30` = 1er, 15e et 30e)
- `-` : Plage de valeurs (ex: `1-5` = de 1 √† 5)
- `/` : Intervalle (ex: `*/15` = toutes les 15 minutes)

### 5.3. Exemples de Syntaxe Cron

```bash
# Toutes les heures √† la minute 0
0 * * * * /chemin/script.sh

# Tous les jours √† 2h du matin
0 2 * * * /chemin/script.sh

# Tous les jours √† 2h30
30 2 * * * /chemin/script.sh

# Toutes les 6 heures
0 */6 * * * /chemin/script.sh

# Tous les lundis √† 3h
0 3 * * 1 /chemin/script.sh

# Tous les dimanches √† 4h
0 4 * * 0 /chemin/script.sh

# Le 1er de chaque mois √† 5h
0 5 1 * * /chemin/script.sh

# Du lundi au vendredi √† 8h
0 8 * * 1-5 /chemin/script.sh

# Toutes les 15 minutes
*/15 * * * * /chemin/script.sh

# √Ä 2h et 14h tous les jours
0 2,14 * * * /chemin/script.sh
```

### 5.4. Configurer Cron pour les Backups

#### 5.4.1. √âditer le Crontab

**Pour l'utilisateur postgres (recommand√©) :**

```bash
# Se connecter en tant que postgres
sudo su - postgres

# √âditer le crontab
crontab -e
```

**Ou en tant que root :**

```bash
sudo crontab -e
```

#### 5.4.2. Exemple de Configuration Compl√®te

**Ouvrir l'√©diteur crontab :**

```bash
crontab -e
```

**Ajouter ces lignes :**

```bash
# PostgreSQL Automated Backups
# ========================================

# Variables d'environnement
MAILTO=admin@example.com
PATH=/usr/local/bin:/usr/bin:/bin
PGDATA=/var/lib/postgresql/data

# Backup quotidien √† 2h du matin
0 2 * * * /usr/local/bin/backup_production.sh >> /var/log/postgresql_backup/cron.log 2>&1

# Backup hebdomadaire le dimanche √† 3h
0 3 * * 0 /usr/local/bin/backup_weekly.sh >> /var/log/postgresql_backup/cron.log 2>&1

# Backup mensuel le 1er √† 4h
0 4 1 * * /usr/local/bin/backup_monthly.sh >> /var/log/postgresql_backup/cron.log 2>&1

# V√©rification d'int√©grit√© tous les jours √† 6h
0 6 * * * /usr/local/bin/verify_backups.sh >> /var/log/postgresql_backup/verify.log 2>&1

# Nettoyage des logs tous les dimanches √† 23h
0 23 * * 0 find /var/log/postgresql_backup -name "*.log" -mtime +30 -delete
```

**Explication :**
- `MAILTO` : Envoie les erreurs par email
- `PATH` : Chemins pour trouver les commandes
- `>> fichier.log 2>&1` : Redirige sortie standard et erreurs vers un fichier log
- `-mtime +30` : Supprime les logs de plus de 30 jours

#### 5.4.3. V√©rifier les T√¢ches Cron

```bash
# Lister les t√¢ches cron de l'utilisateur actuel
crontab -l

# Lister les t√¢ches cron de postgres
sudo crontab -u postgres -l

# Lister toutes les t√¢ches cron syst√®me
cat /etc/crontab
ls -la /etc/cron.d/
```

#### 5.4.4. Logs de Cron

**V√©rifier que cron ex√©cute bien les t√¢ches :**

```bash
# Log syst√®me de cron (Ubuntu/Debian)
tail -f /var/log/syslog | grep CRON

# Ou (CentOS/RHEL)
tail -f /var/log/cron

# Voir les ex√©cutions r√©centes
grep CRON /var/log/syslog | tail -20
```

### 5.5. Exemple Complet : Automatisation d'un Backup Quotidien

**√âtape 1 : Cr√©er le script**

```bash
sudo nano /usr/local/bin/backup_daily.sh
```

**Contenu du script :**

```bash
#!/bin/bash
# backup_daily.sh - Backup quotidien automatis√©

DATABASE="production"
BACKUP_DIR="/var/backups/postgresql/daily"
LOG_FILE="/var/log/postgresql_backup/daily_$(date +%Y%m%d).log"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Cr√©er les r√©pertoires
mkdir -p "$BACKUP_DIR" "$(dirname "$LOG_FILE")"

# Rediriger toute la sortie vers le log
exec > >(tee -a "$LOG_FILE")
exec 2>&1

echo "=========================================="
echo "Backup quotidien de $DATABASE"
echo "Date : $(date)"
echo "=========================================="

# Backup
pg_dump -F c -Z 9 "$DATABASE" -f "$BACKUP_DIR/${DATABASE}_${TIMESTAMP}.dump"

if [ $? -eq 0 ]; then
    SIZE=$(du -h "$BACKUP_DIR/${DATABASE}_${TIMESTAMP}.dump" | cut -f1)
    echo "‚úÖ Backup r√©ussi : $SIZE"

    # Rotation (garder 7 jours)
    find "$BACKUP_DIR" -name "*.dump" -mtime +7 -delete
    echo "üóëÔ∏è Rotation effectu√©e"
else
    echo "‚ùå √âCHEC du backup"
    exit 1
fi

echo "=========================================="
echo "Backup termin√©"
echo "=========================================="
```

**√âtape 2 : Rendre le script ex√©cutable**

```bash
sudo chmod +x /usr/local/bin/backup_daily.sh
```

**√âtape 3 : Tester le script manuellement**

```bash
sudo /usr/local/bin/backup_daily.sh
```

**√âtape 4 : Ajouter au crontab**

```bash
sudo crontab -e
```

**Ajouter :**

```bash
# Backup quotidien √† 2h du matin
0 2 * * * /usr/local/bin/backup_daily.sh
```

**√âtape 5 : V√©rifier l'ex√©cution**

```bash
# Apr√®s le premier run (le lendemain √† 2h), v√©rifier :
ls -lh /var/backups/postgresql/daily/
cat /var/log/postgresql_backup/daily_*.log
```

### 5.6. Bonnes Pratiques pour Cron

#### ‚úÖ √Ä Faire

1. **Utiliser des chemins absolus**
   ```bash
   # ‚ùå Mauvais (chemin relatif)
   0 2 * * * backup.sh

   # ‚úÖ Bon (chemin absolu)
   0 2 * * * /usr/local/bin/backup.sh
   ```

2. **Rediriger les sorties vers des logs**
   ```bash
   0 2 * * * /usr/local/bin/backup.sh >> /var/log/backup.log 2>&1
   ```

3. **D√©finir les variables d'environnement**
   ```bash
   PATH=/usr/local/bin:/usr/bin:/bin
   PGDATA=/var/lib/postgresql/data
   ```

4. **Tester les scripts avant automation**
   ```bash
   # Toujours tester manuellement d'abord
   /usr/local/bin/backup.sh
   ```

5. **Configurer MAILTO pour les erreurs**
   ```bash
   MAILTO=admin@example.com
   ```

6. **Espacer les t√¢ches pour √©viter les conflits**
   ```bash
   # ‚úÖ Bon
   0 2 * * * backup_db1.sh
   0 3 * * * backup_db2.sh

   # ‚ùå Mauvais (risque de conflit)
   0 2 * * * backup_db1.sh
   0 2 * * * backup_db2.sh
   ```

7. **Utiliser un outil de g√©n√©ration de syntaxe**
   - https://crontab.guru/ (g√©n√©rateur en ligne)

#### ‚ùå √Ä √âviter

1. **Ne pas tester les scripts en environnement cron**
   - Variables d'environnement diff√©rentes
   - Peut fonctionner manuellement mais √©chouer en cron

2. **Oublier de g√©rer les erreurs**
   - Toujours v√©rifier les codes de retour
   - Logger les erreurs

3. **Planifier pendant les heures de pointe**
   - √âviter les backups pendant les p√©riodes d'activit√© maximale
   - Pr√©f√©rer la nuit ou t√¥t le matin

4. **Ne pas monitorer l'ex√©cution**
   - V√©rifier r√©guli√®rement les logs
   - Mettre en place des alertes

---

## 6. Rotation des Backups

### 6.1. Pourquoi la Rotation est Essentielle

**Sans rotation :**
- Disque satur√© en quelques semaines/mois
- Performance d√©grad√©e
- Co√ªts de stockage explosifs
- Backup interrompu (plus d'espace)

**Avec rotation :**
- Espace disque ma√Ætris√©
- Co√ªts pr√©visibles
- Historique adapt√© aux besoins
- Syst√®me p√©renne

### 6.2. Strat√©gies de Rotation

#### 6.2.1. Rotation Simple (Par √Çge)

**Principe :** Supprimer les backups plus vieux que N jours.

```bash
# Supprimer les backups de plus de 7 jours
find /var/backups/postgresql -name "*.dump" -mtime +7 -delete
```

**Avantages :**
- ‚úÖ Simple √† impl√©menter
- ‚úÖ Pr√©visible

**Inconv√©nients :**
- ‚ùå Tous les backups ont la m√™me importance
- ‚ùå Pas d'historique long terme

#### 6.2.2. Rotation par Nombre de Fichiers

**Principe :** Garder les N derniers backups, supprimer les plus anciens.

```bash
#!/bin/bash
# keep_last_n.sh

BACKUP_DIR="/var/backups/postgresql"
KEEP_COUNT=10

# Lister les fichiers par date (plus r√©cent en premier)
# Supprimer tout sauf les N premiers
ls -t "$BACKUP_DIR"/*.dump | tail -n +$((KEEP_COUNT + 1)) | xargs -r rm
```

**Avantages :**
- ‚úÖ Contr√¥le pr√©cis du nombre de fichiers
- ‚úÖ Pr√©visible en espace disque

**Inconv√©nients :**
- ‚ùå Pas adapt√© √† diff√©rentes fr√©quences

#### 6.2.3. Rotation GFS (Grand-P√®re P√®re Fils)

**D√©j√† vu en section 4.2 - R√©sum√© :**

```
Quotidiens   : 7 derniers jours
Hebdomadaires: 4 derni√®res semaines
Mensuels     : 12 derniers mois
Annuels      : 5-7 derni√®res ann√©es
```

**Avantages :**
- ‚úÖ Historique long sans exploser l'espace
- ‚úÖ Adapt√© aux besoins m√©tier
- ‚úÖ √âquilibre optimal

**Inconv√©nients :**
- ‚ùå Plus complexe √† mettre en place

#### 6.2.4. Rotation par Taille

**Principe :** Supprimer les anciens backups quand l'espace utilis√© d√©passe un seuil.

```bash
#!/bin/bash
# rotate_by_size.sh

BACKUP_DIR="/var/backups/postgresql"
MAX_SIZE_GB=100  # Taille maximale en GB

# Calculer la taille actuelle
CURRENT_SIZE_GB=$(du -s -BG "$BACKUP_DIR" | cut -f1 | sed 's/G//')

echo "Taille actuelle : ${CURRENT_SIZE_GB}GB / ${MAX_SIZE_GB}GB"

# Si d√©passement, supprimer les plus anciens fichiers
if [ "$CURRENT_SIZE_GB" -gt "$MAX_SIZE_GB" ]; then
    echo "‚ö†Ô∏è D√©passement de quota, nettoyage..."

    # Supprimer les plus anciens jusqu'√† revenir sous le seuil
    while [ "$CURRENT_SIZE_GB" -gt "$MAX_SIZE_GB" ]; do
        OLDEST_FILE=$(ls -t "$BACKUP_DIR"/*.dump | tail -1)

        if [ -f "$OLDEST_FILE" ]; then
            echo "Suppression : $OLDEST_FILE"
            rm "$OLDEST_FILE"
            CURRENT_SIZE_GB=$(du -s -BG "$BACKUP_DIR" | cut -f1 | sed 's/G//')
        else
            break
        fi
    done

    echo "‚úÖ Nettoyage termin√© : ${CURRENT_SIZE_GB}GB"
else
    echo "‚úÖ Espace suffisant"
fi
```

**Avantages :**
- ‚úÖ Garantit de ne jamais saturer le disque
- ‚úÖ S'adapte √† la croissance de la base

**Inconv√©nients :**
- ‚ùå Nombre de backups variable
- ‚ùå Peut supprimer beaucoup de backups d'un coup

### 6.3. Script de Rotation Avanc√©

**Combiner plusieurs strat√©gies :**

```bash
#!/bin/bash
# rotate_advanced.sh

BACKUP_DIR="/var/backups/postgresql"
LOG_FILE="/var/log/postgresql_backup/rotation.log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "=========================================="
log "üóëÔ∏è Rotation des backups PostgreSQL"
log "=========================================="

# Compter les backups avant rotation
BEFORE_COUNT=$(find "$BACKUP_DIR" -name "*.dump" | wc -l)
BEFORE_SIZE=$(du -sh "$BACKUP_DIR" | cut -f1)

log "üìä Avant rotation :"
log "  Fichiers : $BEFORE_COUNT"
log "  Taille : $BEFORE_SIZE"
log ""

# Strat√©gie 1 : Supprimer backups corrompus
log "üîç Recherche de backups corrompus..."
CORRUPTED_COUNT=0

for dump_file in "$BACKUP_DIR"/*.dump; do
    if [ -f "$dump_file" ]; then
        if ! pg_restore --list "$dump_file" > /dev/null 2>&1; then
            log "‚ö†Ô∏è Backup corrompu d√©tect√© : $(basename "$dump_file")"
            rm "$dump_file"
            ((CORRUPTED_COUNT++))
        fi
    fi
done

if [ $CORRUPTED_COUNT -gt 0 ]; then
    log "üóëÔ∏è $CORRUPTED_COUNT backup(s) corrompu(s) supprim√©(s)"
else
    log "‚úÖ Aucun backup corrompu"
fi
log ""

# Strat√©gie 2 : Rotation par √¢ge (quotidiens > 7 jours)
log "üìÖ Rotation des backups quotidiens (> 7 jours)..."
DAILY_DELETED=$(find "$BACKUP_DIR" -name "*daily*.dump" -mtime +7 -delete -print | wc -l)
log "üóëÔ∏è $DAILY_DELETED quotidien(s) supprim√©(s)"
log ""

# Strat√©gie 3 : Garder maximum 10 backups hebdomadaires
log "üìÖ Rotation des backups hebdomadaires (garder 10 max)..."
WEEKLY_COUNT=$(ls -t "$BACKUP_DIR"/*weekly*.dump 2>/dev/null | wc -l)

if [ "$WEEKLY_COUNT" -gt 10 ]; then
    WEEKLY_TO_DELETE=$((WEEKLY_COUNT - 10))
    ls -t "$BACKUP_DIR"/*weekly*.dump | tail -n "$WEEKLY_TO_DELETE" | xargs rm
    log "üóëÔ∏è $WEEKLY_TO_DELETE hebdomadaire(s) supprim√©(s)"
else
    log "‚úÖ Hebdomadaires OK ($WEEKLY_COUNT/10)"
fi
log ""

# Strat√©gie 4 : Rotation des mensuels (> 1 an)
log "üìÖ Rotation des backups mensuels (> 365 jours)..."
MONTHLY_DELETED=$(find "$BACKUP_DIR" -name "*monthly*.dump" -mtime +365 -delete -print | wc -l)
log "üóëÔ∏è $MONTHLY_DELETED mensuel(s) supprim√©(s)"
log ""

# Strat√©gie 5 : V√©rifier l'espace disque
log "üíæ V√©rification de l'espace disque..."
DISK_USAGE=$(df -h "$BACKUP_DIR" | tail -1 | awk '{print $5}' | sed 's/%//')

if [ "$DISK_USAGE" -gt 90 ]; then
    log "‚ö†Ô∏è ALERTE : Espace disque critique ($DISK_USAGE%)"
    log "Nettoyage d'urgence des backups les plus anciens..."

    # Supprimer les 5 plus anciens backups
    ls -t "$BACKUP_DIR"/*.dump | tail -5 | xargs rm
    log "üóëÔ∏è 5 backups supprim√©s en urgence"
else
    log "‚úÖ Espace disque OK ($DISK_USAGE%)"
fi
log ""

# R√©sum√© apr√®s rotation
AFTER_COUNT=$(find "$BACKUP_DIR" -name "*.dump" | wc -l)
AFTER_SIZE=$(du -sh "$BACKUP_DIR" | cut -f1)
DELETED=$((BEFORE_COUNT - AFTER_COUNT))

log "=========================================="
log "üìä Apr√®s rotation :"
log "  Fichiers : $AFTER_COUNT (- $DELETED)"
log "  Taille : $AFTER_SIZE"
log "=========================================="
log "‚úÖ Rotation termin√©e"
log ""
```

**Ce script :**
- ‚úÖ D√©tecte et supprime les backups corrompus
- ‚úÖ Applique diff√©rentes politiques de r√©tention
- ‚úÖ G√®re les alertes d'espace disque
- ‚úÖ Log toutes les actions
- ‚úÖ Affiche un r√©sum√© clair

### 6.4. Automatiser la Rotation avec Cron

**Ajouter dans le crontab :**

```bash
# Rotation quotidienne √† 23h
0 23 * * * /usr/local/bin/rotate_advanced.sh

# Ou apr√®s chaque backup
0 3 * * * /usr/local/bin/backup_daily.sh && /usr/local/bin/rotate_advanced.sh
```

---

## 7. Destinations de Sauvegarde

### 7.1. Stockage Local

**Avantages :**
- ‚úÖ Rapide (acc√®s disque)
- ‚úÖ Gratuit (pas de co√ªt cloud)
- ‚úÖ Contr√¥le total

**Inconv√©nients :**
- ‚ùå Vuln√©rable aux pannes mat√©rielles
- ‚ùå Pas de protection contre incendie/d√©sastre
- ‚ùå Limit√© en espace

**Configuration :**

```bash
BACKUP_DIR="/var/backups/postgresql"
```

### 7.2. Stockage NAS (Network Attached Storage)

**Principe :** Sauvegarder vers un serveur de fichiers r√©seau.

**Avantages :**
- ‚úÖ S√©paration physique du serveur de production
- ‚úÖ Capacit√© extensible
- ‚úÖ Redondance RAID
- ‚úÖ Accessible depuis plusieurs serveurs

**Inconv√©nients :**
- ‚ùå D√©pend du r√©seau local
- ‚ùå Co√ªt mat√©riel initial

**Script de copie vers NAS :**

```bash
#!/bin/bash
# backup_to_nas.sh

LOCAL_BACKUP_DIR="/var/backups/postgresql"
NAS_MOUNT_POINT="/mnt/nas"
NAS_BACKUP_DIR="$NAS_MOUNT_POINT/postgresql_backups"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

log "=========================================="
log "üì° Copie vers NAS"
log "=========================================="

# V√©rifier que le NAS est mont√©
if ! mountpoint -q "$NAS_MOUNT_POINT"; then
    log "‚ùå ERREUR : NAS non mont√© √† $NAS_MOUNT_POINT"

    # Tenter de monter
    log "Tentative de montage du NAS..."
    mount "$NAS_MOUNT_POINT"

    if [ $? -ne 0 ]; then
        log "‚ùå √âchec du montage du NAS"
        exit 1
    fi

    log "‚úÖ NAS mont√© avec succ√®s"
fi

# Cr√©er le r√©pertoire sur le NAS
mkdir -p "$NAS_BACKUP_DIR"

# Synchroniser avec rsync
log "Synchronisation en cours..."
rsync -av --progress \
    --exclude="*.log" \
    "$LOCAL_BACKUP_DIR/" \
    "$NAS_BACKUP_DIR/"

if [ $? -eq 0 ]; then
    # Statistiques
    LOCAL_SIZE=$(du -sh "$LOCAL_BACKUP_DIR" | cut -f1)
    NAS_SIZE=$(du -sh "$NAS_BACKUP_DIR" | cut -f1)

    log "‚úÖ Synchronisation r√©ussie"
    log "  Local : $LOCAL_SIZE"
    log "  NAS : $NAS_SIZE"
else
    log "‚ùå √âchec de la synchronisation"
    exit 1
fi

log "=========================================="
log "‚úÖ Copie NAS termin√©e"
log "=========================================="
```

**Montage NFS (exemple) :**

```bash
# /etc/fstab
nas.example.com:/volume1/backups /mnt/nas nfs defaults,_netdev 0 0

# Monter
mount /mnt/nas
```

**Montage CIFS/SMB (Windows share) :**

```bash
# /etc/fstab
//nas.example.com/backups /mnt/nas cifs credentials=/root/.nas_credentials,uid=postgres,gid=postgres 0 0

# Fichier .nas_credentials
# username=backup_user
# password=secure_password

# Monter
mount /mnt/nas
```

### 7.3. Stockage Cloud (AWS S3)

**Avantages :**
- ‚úÖ Stockage illimit√©
- ‚úÖ Haute disponibilit√© (99.999999999%)
- ‚úÖ Protection g√©ographique
- ‚úÖ Versioning int√©gr√©
- ‚úÖ Lifecycle policies automatiques

**Inconv√©nients :**
- ‚ùå Co√ªts r√©currents
- ‚ùå D√©pend d'Internet
- ‚ùå Transferts lents pour gros backups

**Pr√©requis : Installer AWS CLI**

```bash
# Ubuntu/Debian
sudo apt-get install awscli

# Configurer AWS CLI
aws configure
# AWS Access Key ID: <your-access-key>
# AWS Secret Access Key: <your-secret-key>
# Default region: eu-west-1
# Default output format: json
```

**Script de backup vers S3 :**

```bash
#!/bin/bash
# backup_to_s3.sh

LOCAL_BACKUP_DIR="/var/backups/postgresql"
S3_BUCKET="s3://my-company-backups/postgresql"
LOG_FILE="/var/log/postgresql_backup/s3_sync.log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "=========================================="
log "‚òÅÔ∏è Upload vers AWS S3"
log "=========================================="
log "Source : $LOCAL_BACKUP_DIR"
log "Destination : $S3_BUCKET"
log ""

# V√©rifier AWS CLI
if ! command -v aws > /dev/null 2>&1; then
    log "‚ùå ERREUR : AWS CLI non install√©"
    exit 1
fi

# V√©rifier les credentials
if ! aws sts get-caller-identity > /dev/null 2>&1; then
    log "‚ùå ERREUR : Credentials AWS invalides"
    exit 1
fi

log "‚úÖ Credentials AWS valides"
log ""

# Synchroniser vers S3
log "Upload en cours..."
START_TIME=$(date +%s)

aws s3 sync "$LOCAL_BACKUP_DIR" "$S3_BUCKET" \
    --storage-class STANDARD_IA \
    --exclude "*.log" \
    --exclude "*.tmp" \
    2>&1 | tee -a "$LOG_FILE"

if [ ${PIPESTATUS[0]} -eq 0 ]; then
    END_TIME=$(date +%s)
    DURATION=$((END_TIME - START_TIME))

    log ""
    log "‚úÖ Upload r√©ussi en ${DURATION}s"

    # Lister les fichiers sur S3
    FILE_COUNT=$(aws s3 ls "$S3_BUCKET" --recursive | wc -l)
    log "üì¶ Fichiers sur S3 : $FILE_COUNT"
else
    log "‚ùå √âchec de l'upload vers S3"
    exit 1
fi

log "=========================================="
log "‚úÖ Backup S3 termin√©"
log "=========================================="
```

**Classe de stockage S3 :**
- `STANDARD` : Acc√®s fr√©quent (cher)
- `STANDARD_IA` : Acc√®s peu fr√©quent (recommand√© pour backups)
- `GLACIER` : Archivage long terme (tr√®s peu cher, retrieval lent)

**Lifecycle Policy S3 (optionnel) :**

```json
{
  "Rules": [
    {
      "Id": "Move to Glacier after 30 days",
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "GLACIER"
        }
      ],
      "Expiration": {
        "Days": 2555
      }
    }
  ]
}
```

### 7.4. Stockage Multi-Destinations

**Combiner plusieurs destinations pour maximum de s√©curit√© :**

```bash
#!/bin/bash
# backup_multi_destinations.sh

DATABASE="production"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Destinations
LOCAL_DIR="/var/backups/postgresql"
NAS_DIR="/mnt/nas/postgresql_backups"
S3_BUCKET="s3://my-backups/postgresql"

BACKUP_FILE="$LOCAL_DIR/${DATABASE}_${TIMESTAMP}.dump"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

log "=========================================="
log "üåê Backup Multi-Destinations"
log "=========================================="

# √âtape 1 : Backup local
log "1Ô∏è‚É£ Cr√©ation du backup local..."
mkdir -p "$LOCAL_DIR"
pg_dump -F c -Z 9 "$DATABASE" -f "$BACKUP_FILE"

if [ $? -eq 0 ]; then
    SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
    log "‚úÖ Backup local cr√©√© : $SIZE"
else
    log "‚ùå √âchec du backup local"
    exit 1
fi

# √âtape 2 : Copie vers NAS
log ""
log "2Ô∏è‚É£ Copie vers NAS..."

if mountpoint -q "/mnt/nas"; then
    mkdir -p "$NAS_DIR"
    cp "$BACKUP_FILE" "$NAS_DIR/"

    if [ $? -eq 0 ]; then
        log "‚úÖ Copie NAS r√©ussie"
    else
        log "‚ö†Ô∏è √âchec copie NAS (non bloquant)"
    fi
else
    log "‚ö†Ô∏è NAS non mont√© (skip)"
fi

# √âtape 3 : Upload vers S3
log ""
log "3Ô∏è‚É£ Upload vers S3..."

if command -v aws > /dev/null 2>&1; then
    aws s3 cp "$BACKUP_FILE" "$S3_BUCKET/$(basename "$BACKUP_FILE")" \
        --storage-class STANDARD_IA

    if [ $? -eq 0 ]; then
        log "‚úÖ Upload S3 r√©ussi"
    else
        log "‚ö†Ô∏è √âchec upload S3 (non bloquant)"
    fi
else
    log "‚ö†Ô∏è AWS CLI non disponible (skip)"
fi

# R√©sum√©
log ""
log "=========================================="
log "üìä R√©sum√©"
log "=========================================="
log "‚úÖ Local : $BACKUP_FILE"

if [ -f "$NAS_DIR/$(basename "$BACKUP_FILE")" ]; then
    log "‚úÖ NAS : Copi√©"
else
    log "‚ùå NAS : √âchec"
fi

if aws s3 ls "$S3_BUCKET/$(basename "$BACKUP_FILE")" > /dev/null 2>&1; then
    log "‚úÖ S3 : Upload√©"
else
    log "‚ùå S3 : √âchec"
fi

log "=========================================="
log "‚úÖ Backup multi-destinations termin√©"
log "=========================================="
```

**Principe 3-2-1 respect√© :**
- ‚úÖ 3 copies (local + NAS + S3)
- ‚úÖ 2 supports (disque local + cloud)
- ‚úÖ 1 hors site (S3)

---

## 8. Monitoring et Alertes

### 8.1. Pourquoi Monitorer les Backups ?

**Un backup non surveill√© = pas de backup**

**Sc√©narios catastrophes √©vit√©s par le monitoring :**
- Backup √©choue pendant 2 semaines ‚Üí d√©tect√© imm√©diatement
- Disque plein ‚Üí alerte avant saturation
- Backup corrompu ‚Üí d√©tect√© et corrig√©
- Script mal configur√© ‚Üí identifi√© rapidement

### 8.2. M√©triques √† Surveiller

| M√©trique | Seuil Alerte | Impact |
|----------|--------------|--------|
| **Succ√®s/√âchec** | 1 √©chec | Critique |
| **Dur√©e backup** | > 2√ó normale | Avertissement |
| **Taille backup** | > 2√ó normale | Avertissement |
| **Espace disque** | > 85% | Critique |
| **√Çge du dernier backup** | > 36h | Critique |
| **Backups corrompus** | > 0 | Critique |

### 8.3. Script de Monitoring Simple

```bash
#!/bin/bash
# monitor_backups.sh

BACKUP_DIR="/var/backups/postgresql"
ALERT_EMAIL="admin@example.com"
MAX_AGE_HOURS=36  # Alerte si dernier backup > 36h
MIN_DISK_SPACE=15  # GB minimum

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

send_alert() {
    local subject="$1"
    local body="$2"
    echo "$body" | mail -s "‚ö†Ô∏è $subject" "$ALERT_EMAIL"
    log "üìß Alerte envoy√©e : $subject"
}

log "=========================================="
log "üîç Monitoring des Backups PostgreSQL"
log "=========================================="

ALERTS=()

# V√©rification 1 : Dernier backup
log "V√©rification du dernier backup..."
LATEST_BACKUP=$(find "$BACKUP_DIR" -name "*.dump" -type f -printf '%T@ %p\n' | sort -rn | head -1 | cut -d' ' -f2)

if [ -z "$LATEST_BACKUP" ]; then
    ALERTS+=("‚ùå AUCUN BACKUP TROUV√â")
    log "‚ùå Aucun backup trouv√© !"
else
    LATEST_AGE_HOURS=$(( ($(date +%s) - $(stat -c %Y "$LATEST_BACKUP")) / 3600 ))
    log "Dernier backup : $(basename "$LATEST_BACKUP") ($LATEST_AGE_HOURS heures)"

    if [ "$LATEST_AGE_HOURS" -gt "$MAX_AGE_HOURS" ]; then
        ALERTS+=("‚ö†Ô∏è Dernier backup trop ancien : ${LATEST_AGE_HOURS}h (max: ${MAX_AGE_HOURS}h)")
        log "‚ö†Ô∏è Backup trop ancien !"
    else
        log "‚úÖ √Çge du backup OK"
    fi
fi

# V√©rification 2 : Espace disque
log ""
log "V√©rification de l'espace disque..."
AVAILABLE_GB=$(df -BG "$BACKUP_DIR" | tail -1 | awk '{print $4}' | sed 's/G//')
USAGE_PCT=$(df -h "$BACKUP_DIR" | tail -1 | awk '{print $5}' | sed 's/%//')

log "Espace disponible : ${AVAILABLE_GB}GB (${USAGE_PCT}% utilis√©)"

if [ "$AVAILABLE_GB" -lt "$MIN_DISK_SPACE" ]; then
    ALERTS+=("‚ùå Espace disque critique : ${AVAILABLE_GB}GB restant (min: ${MIN_DISK_SPACE}GB)")
    log "‚ùå Espace disque critique !"
elif [ "$USAGE_PCT" -gt 85 ]; then
    ALERTS+=("‚ö†Ô∏è Disque √† ${USAGE_PCT}% (seuil: 85%)")
    log "‚ö†Ô∏è Disque bient√¥t plein"
else
    log "‚úÖ Espace disque OK"
fi

# V√©rification 3 : Int√©grit√© des backups r√©cents
log ""
log "V√©rification de l'int√©grit√©..."
CORRUPTED=0

# V√©rifier les 3 derniers backups
for dump_file in $(find "$BACKUP_DIR" -name "*.dump" -type f -printf '%T@ %p\n' | sort -rn | head -3 | cut -d' ' -f2); do
    if ! pg_restore --list "$dump_file" > /dev/null 2>&1; then
        ALERTS+=("‚ùå Backup corrompu : $(basename "$dump_file")")
        log "‚ùå Corrompu : $(basename "$dump_file")"
        ((CORRUPTED++))
    fi
done

if [ $CORRUPTED -eq 0 ]; then
    log "‚úÖ Int√©grit√© OK"
else
    log "‚ùå $CORRUPTED backup(s) corrompu(s)"
fi

# V√©rification 4 : Nombre de backups
log ""
log "V√©rification du nombre de backups..."
BACKUP_COUNT=$(find "$BACKUP_DIR" -name "*.dump" -type f | wc -l)
log "Nombre de backups : $BACKUP_COUNT"

if [ "$BACKUP_COUNT" -lt 3 ]; then
    ALERTS+=("‚ö†Ô∏è Trop peu de backups : $BACKUP_COUNT (min recommand√©: 7)")
    log "‚ö†Ô∏è Peu de backups disponibles"
else
    log "‚úÖ Nombre de backups suffisant"
fi

# R√©sum√© et envoi d'alertes
log ""
log "=========================================="
log "üìä R√âSUM√â"
log "=========================================="

if [ ${#ALERTS[@]} -eq 0 ]; then
    log "‚úÖ Tous les contr√¥les pass√©s avec succ√®s"
    log "=========================================="
    exit 0
else
    log "‚ö†Ô∏è ${#ALERTS[@]} alerte(s) d√©tect√©e(s) :"
    for alert in "${ALERTS[@]}"; do
        log "  $alert"
    done
    log "=========================================="

    # Envoyer email d'alerte
    ALERT_BODY=$(printf "%s\n" "${ALERTS[@]}")
    send_alert "Monitoring Backups PostgreSQL - Alertes" "$ALERT_BODY"

    exit 1
fi
```

**Automatiser le monitoring :**

```bash
# Dans crontab : v√©rifier toutes les heures
0 * * * * /usr/local/bin/monitor_backups.sh >> /var/log/postgresql_backup/monitor.log 2>&1
```

### 8.4. Dashboard de Monitoring (Script de Rapport)

```bash
#!/bin/bash
# backup_dashboard.sh

BACKUP_DIR="/var/backups/postgresql"

echo "=========================================="
echo "üìä DASHBOARD BACKUPS POSTGRESQL"
echo "=========================================="
echo "Date : $(date '+%Y-%m-%d %H:%M:%S')"
echo ""

# Section 1 : Statistiques g√©n√©rales
echo "üì¶ STATISTIQUES G√âN√âRALES"
echo "=========================================="
TOTAL_BACKUPS=$(find "$BACKUP_DIR" -name "*.dump" | wc -l)
TOTAL_SIZE=$(du -sh "$BACKUP_DIR" | cut -f1)
echo "Nombre total de backups : $TOTAL_BACKUPS"
echo "Espace utilis√© : $TOTAL_SIZE"
echo ""

# Section 2 : Dernier backup
echo "üïí DERNIER BACKUP"
echo "=========================================="
LATEST=$(find "$BACKUP_DIR" -name "*.dump" -type f -printf '%T@ %p\n' | sort -rn | head -1)
if [ -n "$LATEST" ]; then
    LATEST_FILE=$(echo "$LATEST" | cut -d' ' -f2)
    LATEST_DATE=$(stat -c %y "$LATEST_FILE" | cut -d. -f1)
    LATEST_SIZE=$(du -h "$LATEST_FILE" | cut -f1)
    LATEST_AGE_HOURS=$(( ($(date +%s) - $(stat -c %Y "$LATEST_FILE")) / 3600 ))

    echo "Fichier : $(basename "$LATEST_FILE")"
    echo "Date : $LATEST_DATE ($LATEST_AGE_HOURS heures)"
    echo "Taille : $LATEST_SIZE"
else
    echo "‚ùå Aucun backup trouv√©"
fi
echo ""

# Section 3 : R√©partition par type (si GFS)
echo "üìÖ R√âPARTITION PAR TYPE"
echo "=========================================="
DAILY=$(find "$BACKUP_DIR" -name "*daily*.dump" | wc -l)
WEEKLY=$(find "$BACKUP_DIR" -name "*weekly*.dump" | wc -l)
MONTHLY=$(find "$BACKUP_DIR" -name "*monthly*.dump" | wc -l)
YEARLY=$(find "$BACKUP_DIR" -name "*yearly*.dump" | wc -l)

echo "Quotidiens : $DAILY"
echo "Hebdomadaires : $WEEKLY"
echo "Mensuels : $MONTHLY"
echo "Annuels : $YEARLY"
echo ""

# Section 4 : Espace disque
echo "üíæ ESPACE DISQUE"
echo "=========================================="
df -h "$BACKUP_DIR" | tail -1 | awk '{print "Partition : "$1"\nTaille : "$2"\nUtilis√© : "$3" ("$5")\nDisponible : "$4}'
echo ""

# Section 5 : Les 5 backups les plus r√©cents
echo "üìã 5 BACKUPS LES PLUS R√âCENTS"
echo "=========================================="
find "$BACKUP_DIR" -name "*.dump" -type f -printf '%T@ %p\n' | sort -rn | head -5 | while read timestamp file; do
    filename=$(basename "$file")
    size=$(du -h "$file" | cut -f1)
    date=$(date -d @"${timestamp%.*}" '+%Y-%m-%d %H:%M:%S')
    echo "‚Ä¢ $filename - $size - $date"
done
echo ""

# Section 6 : Sant√©
echo "üè• SANT√â DES BACKUPS"
echo "=========================================="

# V√©rifier les 3 derniers
RECENT_BACKUPS=$(find "$BACKUP_DIR" -name "*.dump" -type f -printf '%T@ %p\n' | sort -rn | head -3 | cut -d' ' -f2)
CORRUPTED_COUNT=0

for backup in $RECENT_BACKUPS; do
    if pg_restore --list "$backup" > /dev/null 2>&1; then
        echo "‚úÖ $(basename "$backup") : OK"
    else
        echo "‚ùå $(basename "$backup") : CORROMPU"
        ((CORRUPTED_COUNT++))
    fi
done

if [ $CORRUPTED_COUNT -eq 0 ]; then
    echo ""
    echo "‚úÖ Tous les backups r√©cents sont valides"
else
    echo ""
    echo "‚ö†Ô∏è $CORRUPTED_COUNT backup(s) corrompu(s) d√©tect√©(s) !"
fi

echo ""
echo "=========================================="
echo "Fin du rapport"
echo "=========================================="
```

**G√©n√©rer un rapport quotidien :**

```bash
# Dans crontab : rapport tous les matins √† 9h
0 9 * * * /usr/local/bin/backup_dashboard.sh | mail -s "Rapport Backups PostgreSQL" admin@example.com
```

### 8.5. Int√©gration avec des Outils de Monitoring

#### 8.5.1. Prometheus + Grafana

**Script d'export de m√©triques :**

```bash
#!/bin/bash
# export_prometheus_metrics.sh

BACKUP_DIR="/var/backups/postgresql"
METRICS_FILE="/var/lib/node_exporter/textfile_collector/postgresql_backup.prom"

# Calculer les m√©triques
BACKUP_COUNT=$(find "$BACKUP_DIR" -name "*.dump" | wc -l)
TOTAL_SIZE_BYTES=$(du -sb "$BACKUP_DIR" | cut -f1)
LATEST_TIMESTAMP=$(find "$BACKUP_DIR" -name "*.dump" -type f -printf '%T@\n' | sort -rn | head -1)
LATEST_AGE_SECONDS=$(( $(date +%s) - ${LATEST_TIMESTAMP%.*} ))

# G√©n√©rer le fichier de m√©triques Prometheus
cat > "$METRICS_FILE" << EOF
# HELP postgresql_backup_count Number of backup files
# TYPE postgresql_backup_count gauge
postgresql_backup_count $BACKUP_COUNT

# HELP postgresql_backup_size_bytes Total size of backups in bytes
# TYPE postgresql_backup_size_bytes gauge
postgresql_backup_size_bytes $TOTAL_SIZE_BYTES

# HELP postgresql_backup_age_seconds Age of the latest backup in seconds
# TYPE postgresql_backup_age_seconds gauge
postgresql_backup_age_seconds $LATEST_AGE_SECONDS
EOF
```

**Automatiser l'export :**

```bash
# Dans crontab : toutes les 5 minutes
*/5 * * * * /usr/local/bin/export_prometheus_metrics.sh
```

#### 8.5.2. Alertes Slack/Discord

```bash
#!/bin/bash
# send_slack_alert.sh

SLACK_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

send_slack() {
    local message="$1"
    local color="${2:-#ff0000}"  # Rouge par d√©faut

    curl -X POST "$SLACK_WEBHOOK_URL" \
        -H 'Content-Type: application/json' \
        -d "{
            \"attachments\": [
                {
                    \"color\": \"$color\",
                    \"title\": \"üîî Alerte Backup PostgreSQL\",
                    \"text\": \"$message\",
                    \"footer\": \"Serveur: $(hostname)\",
                    \"ts\": $(date +%s)
                }
            ]
        }"
}

# Exemple d'utilisation
if [ $BACKUP_FAILED ]; then
    send_slack "‚ùå √âchec du backup de la base production" "#ff0000"
else
    send_slack "‚úÖ Backup r√©ussi : 50GB en 30min" "#00ff00"
fi
```

---

## 9. Scripts de V√©rification

### 9.1. Script de Test de Restauration

**Le test ultime : restaurer le backup**

```bash
#!/bin/bash
# test_restore.sh

BACKUP_FILE="$1"
TEST_DB="test_restore_$(date +%s)"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

log "=========================================="
log "üß™ Test de Restauration"
log "=========================================="
log "Backup : $BACKUP_FILE"
log "Base de test : $TEST_DB"
log ""

# V√©rifier que le backup existe
if [ ! -f "$BACKUP_FILE" ]; then
    log "‚ùå Fichier de backup introuvable"
    exit 1
fi

# V√©rifier l'int√©grit√©
log "1Ô∏è‚É£ V√©rification de l'int√©grit√©..."
if pg_restore --list "$BACKUP_FILE" > /dev/null 2>&1; then
    log "‚úÖ Backup valide"
else
    log "‚ùå Backup corrompu"
    exit 1
fi

# Cr√©er une base de test
log ""
log "2Ô∏è‚É£ Cr√©ation de la base de test..."
createdb "$TEST_DB"

if [ $? -ne 0 ]; then
    log "‚ùå Impossible de cr√©er la base de test"
    exit 1
fi
log "‚úÖ Base cr√©√©e"

# Restaurer
log ""
log "3Ô∏è‚É£ Restauration en cours..."
START_TIME=$(date +%s)

pg_restore -d "$TEST_DB" -j 4 --no-owner --no-acl "$BACKUP_FILE" 2>&1 | grep -i error

RESTORE_STATUS=${PIPESTATUS[0]}
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

if [ $RESTORE_STATUS -eq 0 ]; then
    log "‚úÖ Restauration r√©ussie en ${DURATION}s"
else
    log "‚ö†Ô∏è Restauration termin√©e avec avertissements"
fi

# V√©rifier la base restaur√©e
log ""
log "4Ô∏è‚É£ V√©rification de la base restaur√©e..."

# Compter les tables
TABLE_COUNT=$(psql -t -d "$TEST_DB" -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public'" | xargs)
log "Nombre de tables : $TABLE_COUNT"

# Taille de la base
DB_SIZE=$(psql -t -d "$TEST_DB" -c "SELECT pg_size_pretty(pg_database_size('$TEST_DB'))" | xargs)
log "Taille de la base : $DB_SIZE"

# V√©rifier qu'il y a des donn√©es
TOTAL_ROWS=0
for table in $(psql -t -d "$TEST_DB" -c "SELECT tablename FROM pg_tables WHERE schemaname = 'public'"); do
    ROW_COUNT=$(psql -t -d "$TEST_DB" -c "SELECT COUNT(*) FROM $table" 2>/dev/null | xargs)
    TOTAL_ROWS=$((TOTAL_ROWS + ROW_COUNT))
done
log "Nombre total de lignes : $TOTAL_ROWS"

if [ $TOTAL_ROWS -gt 0 ]; then
    log "‚úÖ Donn√©es pr√©sentes"
else
    log "‚ö†Ô∏è Aucune donn√©e trouv√©e"
fi

# Nettoyage
log ""
log "5Ô∏è‚É£ Nettoyage..."
dropdb "$TEST_DB"
log "‚úÖ Base de test supprim√©e"

log ""
log "=========================================="
log "‚úÖ Test de restauration termin√© avec succ√®s"
log "=========================================="
log "R√©sum√© :"
log "  ‚Ä¢ Dur√©e restauration : ${DURATION}s"
log "  ‚Ä¢ Tables : $TABLE_COUNT"
log "  ‚Ä¢ Lignes : $TOTAL_ROWS"
log "  ‚Ä¢ Taille : $DB_SIZE"
log "=========================================="
```

**Automatiser les tests mensuels :**

```bash
# Dans crontab : test le 1er du mois √† 5h
0 5 1 * * /usr/local/bin/test_restore.sh /var/backups/postgresql/latest.dump >> /var/log/postgresql_backup/restore_test.log 2>&1
```

### 9.2. Script de Comparaison Taille Source vs Backup

```bash
#!/bin/bash
# compare_sizes.sh

DATABASE="production"
BACKUP_FILE="$1"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

log "=========================================="
log "üìä Comparaison Taille Source vs Backup"
log "=========================================="

# Taille de la base source
SOURCE_SIZE_BYTES=$(psql -t -d "$DATABASE" -c "SELECT pg_database_size('$DATABASE')" | xargs)
SOURCE_SIZE_PRETTY=$(psql -t -d "$DATABASE" -c "SELECT pg_size_pretty(pg_database_size('$DATABASE'))" | xargs)

# Taille du backup
BACKUP_SIZE_BYTES=$(stat -c %s "$BACKUP_FILE")
BACKUP_SIZE_PRETTY=$(du -h "$BACKUP_FILE" | cut -f1)

# Ratio de compression
RATIO=$(echo "scale=2; $BACKUP_SIZE_BYTES * 100 / $SOURCE_SIZE_BYTES" | bc)

log "Base source : $SOURCE_SIZE_PRETTY ($SOURCE_SIZE_BYTES bytes)"
log "Backup : $BACKUP_SIZE_PRETTY ($BACKUP_SIZE_BYTES bytes)"
log "Ratio compression : ${RATIO}%"

# Alertes
if (( $(echo "$RATIO > 150" | bc -l) )); then
    log "‚ö†Ô∏è ATTENTION : Backup plus gros que la source !"
elif (( $(echo "$RATIO < 10" | bc -l) )); then
    log "‚ö†Ô∏è ATTENTION : Compression anormalement √©lev√©e"
else
    log "‚úÖ Ratio normal"
fi

log "=========================================="
```

### 9.3. Script de V√©rification d'Int√©grit√© Compl√®te

```bash
#!/bin/bash
# verify_all_backups.sh

BACKUP_DIR="/var/backups/postgresql"
LOG_FILE="/var/log/postgresql_backup/integrity_$(date +%Y%m%d).log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "=========================================="
log "üîç V√©rification Int√©grit√© de TOUS les Backups"
log "=========================================="

TOTAL=0
VALID=0
CORRUPTED=0
ERRORS=()

# Parcourir tous les backups
while IFS= read -r dump_file; do
    ((TOTAL++))
    filename=$(basename "$dump_file")

    log "V√©rification : $filename..."

    if pg_restore --list "$dump_file" > /dev/null 2>&1; then
        log "  ‚úÖ OK"
        ((VALID++))
    else
        log "  ‚ùå CORROMPU"
        ((CORRUPTED++))
        ERRORS+=("$filename")
    fi
done < <(find "$BACKUP_DIR" -name "*.dump" -type f)

# R√©sum√©
log ""
log "=========================================="
log "üìä R√âSUM√â"
log "=========================================="
log "Total v√©rifi√© : $TOTAL"
log "Valides : $VALID"
log "Corrompus : $CORRUPTED"

if [ $CORRUPTED -gt 0 ]; then
    log ""
    log "‚ö†Ô∏è Backups corrompus d√©tect√©s :"
    for error in "${ERRORS[@]}"; do
        log "  ‚Ä¢ $error"
    done
    log ""
    log "‚ùå V√©rification termin√©e avec erreurs"
    exit 1
else
    log ""
    log "‚úÖ Tous les backups sont valides"
    exit 0
fi
```

---

## 10. Bonnes Pratiques

### 10.1. Checklist de Production

**Avant de mettre en production :**

- [ ] **Scripts test√©s** manuellement plusieurs fois
- [ ] **Logs configur√©s** et centralis√©s
- [ ] **Rotation mise en place** (√©viter saturation disque)
- [ ] **Alertes configur√©es** (email, Slack, etc.)
- [ ] **Monitoring actif** (dashboard, m√©triques)
- [ ] **Stockage distant** configur√© (NAS, Cloud)
- [ ] **Tests de restauration** r√©guliers automatis√©s
- [ ] **Documentation** √† jour (runbook)
- [ ] **Credentials s√©curis√©s** (.pgpass avec chmod 600)
- [ ] **Politique de r√©tention** d√©finie (GFS recommand√©)
- [ ] **Backup des objets globaux** (r√¥les, tablespaces)
- [ ] **Cron configur√©** et v√©rifi√©
- [ ] **Espace disque suffisant** (minimum 2√ó taille base)

### 10.2. Architecture Recommand√©e

```
Production PostgreSQL Server
         ‚îÇ
         ‚îú‚îÄ‚Üí [Backup Quotidien] @ 2h
         ‚îÇ       ‚îÇ
         ‚îÇ       ‚îú‚îÄ‚Üí Local (/var/backups)
         ‚îÇ       ‚îú‚îÄ‚Üí NAS (rsync @ 3h)
         ‚îÇ       ‚îî‚îÄ‚Üí S3 (aws s3 sync @ 4h)
         ‚îÇ
         ‚îú‚îÄ‚Üí [Backup Hebdomadaire] @ Dimanche 3h
         ‚îÇ       ‚îî‚îÄ‚Üí Archivage long terme
         ‚îÇ
         ‚îú‚îÄ‚Üí [Monitoring] @ Toutes les heures
         ‚îÇ       ‚îî‚îÄ‚Üí Alertes si probl√®me
         ‚îÇ
         ‚îî‚îÄ‚Üí [Test Restauration] @ 1er du mois
                 ‚îî‚îÄ‚Üí Rapport d'int√©grit√©
```

### 10.3. S√©curit√©

**Protection des Backups :**

```bash
# Permissions strictes
chmod 700 /var/backups/postgresql
chmod 600 /var/backups/postgresql/*.dump

# Propri√©taire postgres uniquement
chown -R postgres:postgres /var/backups/postgresql

# Chiffrer les backups sensibles (optionnel)
gpg --encrypt --recipient admin@example.com backup.dump
```

**Protection des Credentials :**

```bash
# Fichier .pgpass
chmod 600 ~/.pgpass
chown postgres:postgres ~/.pgpass

# Ne JAMAIS mettre de mots de passe dans les scripts
# Utiliser .pgpass ou variables d'environnement
```

### 10.4. Performance

**Optimiser les Backups :**

```bash
# 1. Utiliser le parall√©lisme
pg_dump -F d -j 8 mabase -f backup/

# 2. Compression adapt√©e
pg_dump -F c -Z 6 mabase  # √âquilibre vitesse/compression

# 3. Exclure les tables volumineuses non critiques
pg_dump -T logs -T cache mabase

# 4. Planifier hors heures de pointe
# Cron √† 2h du matin, pas √† 14h !

# 5. Utiliser des liens symboliques pour "latest"
ln -sf backup_20251121.dump latest.dump
```

### 10.5. Documentation (Runbook)

**Cr√©er un document de proc√©dure :**

```markdown
# Runbook : Backups PostgreSQL

## Contacts
- Responsable : admin@example.com
- Astreinte : +33 6 XX XX XX XX

## Emplacements
- Scripts : /usr/local/bin/
- Backups : /var/backups/postgresql/
- Logs : /var/log/postgresql_backup/

## Proc√©dures

### Backup Manuel d'Urgence
sudo /usr/local/bin/backup_production.sh

### Restauration d'Urgence
1. Arr√™ter l'application
2. sudo /usr/local/bin/restore_latest.sh
3. V√©rifier l'int√©grit√©
4. Red√©marrer l'application

### Probl√®mes Courants

#### Backup √©choue
1. V√©rifier l'espace disque : df -h /var/backups
2. V√©rifier PostgreSQL : pg_isready
3. Consulter les logs : tail -f /var/log/postgresql_backup/backup.log

#### Disque plein
1. Lancer rotation manuelle : /usr/local/bin/rotate_advanced.sh
2. Si insuffisant, copier vers NAS puis supprimer localement
3. Augmenter la r√©tention si r√©current

## Tests
- Restauration test√©e : 1er de chaque mois
- Dernier test : 2025-11-01 ‚úÖ
```

### 10.6. √âvolution et Am√©lioration Continue

**M√©triques √† suivre mensuellement :**
- Taille moyenne des backups (tendance)
- Dur√©e moyenne des backups (d√©gradation ?)
- Taux de r√©ussite (objectif : 99.9%)
- Espace disque consomm√©
- Co√ªts cloud (S3, etc.)

**Questions √† se poser :**
- Les backups sont-ils toujours adapt√©s √† la taille de la base ?
- Le temps de restauration est-il acceptable ?
- Les tests de restauration sont-ils r√©guliers ?
- Les alertes sont-elles pertinentes (pas trop de faux positifs) ?
- La documentation est-elle √† jour ?

---

## Conclusion

### Ce que vous avez appris

- ‚úÖ **Strat√©gies de backup** : Fr√©quence, r√©tention, GFS
- ‚úÖ **Scripts de base √† avanc√©s** : Du minimal au production-ready
- ‚úÖ **Automatisation avec Cron** : Planification et surveillance
- ‚úÖ **Rotation intelligente** : G√©rer l'historique sans saturer
- ‚úÖ **Destinations multiples** : Local, NAS, Cloud (r√®gle 3-2-1)
- ‚úÖ **Monitoring et alertes** : D√©tecter les probl√®mes avant la catastrophe
- ‚úÖ **Tests de restauration** : Valider que les backups fonctionnent
- ‚úÖ **Bonnes pratiques** : S√©curit√©, performance, documentation

### Points Cl√©s √† Retenir

1. **Un backup non test√© = pas de backup**
   - Testez r√©guli√®rement la restauration

2. **Appliquez la r√®gle 3-2-1**
   - 3 copies, 2 supports, 1 hors site

3. **Automatisez tout**
   - Scripts + Cron + Monitoring = S√©r√©nit√©

4. **Surveillez vos backups**
   - Alertes imm√©diates en cas de probl√®me

5. **Documentez**
   - Runbook √† jour = Intervention rapide

### Prochaines √âtapes

1. **Impl√©menter un script simple** pour votre environnement
2. **Ajouter la rotation** pour ne pas saturer le disque
3. **Configurer Cron** pour automatiser
4. **Mettre en place les alertes** (email minimum)
5. **Tester une restauration** manuelle
6. **√âtendre vers le cloud** (S3, etc.)
7. **Automatiser les tests** mensuels

### Ressources Compl√©mentaires

**Documentation PostgreSQL :**
- pg_dump : https://www.postgresql.org/docs/18/app-pgdump.html
- pg_restore : https://www.postgresql.org/docs/18/app-pgrestore.html
- Backup & Restore : https://www.postgresql.org/docs/18/backup.html

**Outils tiers recommand√©s :**
- **pgBackRest** : https://pgbackrest.org/
- **Barman** : https://www.pgbarman.org/
- **WAL-G** : https://github.com/wal-g/wal-g

**G√©n√©rateur Cron :**
- https://crontab.guru/

---

**Version :** 1.0 - Novembre 2025
**PostgreSQL :** Version 18
**Auteur :** Formation PostgreSQL pour D√©veloppeurs et DevOps

---

## Fin de l'Annexe G.2

Vous disposez maintenant de tous les outils pour mettre en place un syst√®me de backup automatis√© robuste, fiable et professionnel pour PostgreSQL ! üöÄ

**N'oubliez jamais : La meilleure sauvegarde est celle que vous avez test√©e !** ‚úÖ

‚è≠Ô∏è [Scripts de monitoring syst√®me](/annexes/commandes-shell-scripts/03-scripts-monitoring-systeme.md)
