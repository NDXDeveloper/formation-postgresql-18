üîù Retour au [Sommaire](/SOMMAIRE.md)

# Audit de Requ√™tes PostgreSQL
## Guide

---

## Table des Mati√®res

1. [Introduction √† l'Audit de Requ√™tes](#1-introduction-%C3%A0-laudit-de-requ%C3%AAtes)
2. [Pourquoi Auditer les Requ√™tes ?](#2-pourquoi-auditer-les-requ%C3%AAtes-)
3. [Le Cycle de Vie d'une Requ√™te](#3-le-cycle-de-vie-dune-requ%C3%AAte)
4. [Outils d'Audit de Requ√™tes](#4-outils-daudit-de-requ%C3%AAtes)
5. [EXPLAIN : Comprendre les Plans d'Ex√©cution](#5-explain--comprendre-les-plans-dex%C3%A9cution)
6. [Identification des Requ√™tes Lentes](#6-identification-des-requ%C3%AAtes-lentes)
7. [Analyse des Patterns de Performance](#7-analyse-des-patterns-de-performance)
8. [Probl√®mes Courants et Solutions](#8-probl%C3%A8mes-courants-et-solutions)
9. [Optimisation des Requ√™tes](#9-optimisation-des-requ%C3%AAtes)
10. [Anti-Patterns N+1](#10-anti-patterns-n1)
11. [Requ√™tes Complexes et Jointures](#11-requ%C3%AAtes-complexes-et-jointures)
12. [Agr√©gations et Performances](#12-agr%C3%A9gations-et-performances)
13. [PostgreSQL 18 : Nouveaut√©s d'Optimisation](#13-postgresql-18--nouveaut%C3%A9s-doptimisation)
14. [Monitoring en Production](#14-monitoring-en-production)
15. [Checklist d'Audit Compl√®te](#15-checklist-daudit-compl%C3%A8te)
16. [Cas Pratiques d'Optimisation](#16-cas-pratiques-doptimisation)
17. [Conclusion et Bonnes Pratiques](#17-conclusion-et-bonnes-pratiques)

---

## 1. Introduction √† l'Audit de Requ√™tes

### 1.1. Qu'est-ce qu'un Audit de Requ√™tes ?

Un **audit de requ√™tes** est un processus syst√©matique d'analyse et d'√©valuation des requ√™tes SQL ex√©cut√©es sur une base de donn√©es PostgreSQL pour :

- **Identifier** les requ√™tes lentes ou probl√©matiques
- **Comprendre** comment PostgreSQL ex√©cute chaque requ√™te
- **Optimiser** les performances en modifiant les requ√™tes ou la structure de la base
- **Pr√©venir** les d√©gradations futures de performance

### 1.2. Diff√©rence avec l'Audit d'Indexation

| Aspect | Audit d'Indexation | Audit de Requ√™tes |
|--------|-------------------|-------------------|
| **Focus** | Structure (index) | Comportement (requ√™tes) |
| **Question** | "Ai-je les bons index ?" | "Mes requ√™tes sont-elles optimales ?" |
| **Action** | Cr√©er/supprimer index | R√©√©crire requ√™tes |
| **Niveau** | Infrastructure | Application |

**Compl√©mentarit√©** : Les deux audits sont compl√©mentaires et doivent √™tre men√©s ensemble.

### 1.3. √Ä Qui s'Adresse cet Audit ?

- **D√©veloppeurs** : Qui √©crivent les requ√™tes SQL
- **DevOps/SRE** : Qui maintiennent les syst√®mes en production
- **DBA** : Qui optimisent les performances de la base
- **Product Owners** : Qui veulent comprendre les causes des lenteurs

### 1.4. Quand Effectuer un Audit de Requ√™tes ?

**D√©clencheurs d'audit** :
- ‚úÖ Application lente ou temps de r√©ponse d√©grad√©
- ‚úÖ Pics de charge CPU/M√©moire inexpliqu√©s
- ‚úÖ Plaintes utilisateurs sur la lenteur
- ‚úÖ Avant une mise en production majeure
- ‚úÖ Apr√®s ajout de nouvelles fonctionnalit√©s
- ‚úÖ P√©riodiquement (mensuel/trimestriel)

---

## 2. Pourquoi Auditer les Requ√™tes ?

### 2.1. Les Cons√©quences de Requ√™tes Non Optimis√©es

#### Impact sur les Performances

**Sympt√¥mes** :
- Temps de r√©ponse de plusieurs secondes (voire minutes)
- Application qui "rame" ou freeze
- Timeouts fr√©quents
- Impossibilit√© de scaler

**Exemple concret** :
```sql
-- Requ√™te non optimis√©e : 45 secondes
SELECT * FROM commandes WHERE client_id IN (
    SELECT id FROM clients WHERE ville = 'Paris'
);

-- Apr√®s optimisation : 0.2 secondes (225√ó plus rapide)
SELECT c.*
FROM commandes c
JOIN clients cl ON c.client_id = cl.id
WHERE cl.ville = 'Paris';
```

#### Impact sur les Ressources

**Requ√™tes gourmandes** causent :
- Saturation CPU (100% d'utilisation)
- Consommation m√©moire excessive (risque d'OOM)
- I/O disque massif (latence)
- Blocage d'autres requ√™tes (contention)

**Co√ªt cloud** :
Une requ√™te mal optimis√©e peut co√ªter **10√ó plus cher** en ressources cloud.

#### Impact sur l'Exp√©rience Utilisateur

- ‚ùå Utilisateurs frustr√©s
- ‚ùå Abandon de paniers d'achat
- ‚ùå Perte de clients
- ‚ùå Mauvaise r√©putation

**R√®gle d'or** :
- Requ√™te simple : < 100 ms
- Requ√™te complexe : < 1 seconde
- Rapport/export : < 10 secondes

### 2.2. Les B√©n√©fices d'un Audit R√©gulier

#### Am√©lioration des Performances

- ‚úÖ R√©duction des temps de r√©ponse de **10√ó √† 100√ó**
- ‚úÖ Meilleure utilisation des ressources
- ‚úÖ Scalabilit√© am√©lior√©e

#### R√©duction des Co√ªts

- ‚úÖ Moins de serveurs n√©cessaires
- ‚úÖ Factures cloud r√©duites
- ‚úÖ Moins d'incidents de production

#### Qualit√© du Code

- ‚úÖ Code SQL plus maintenable
- ‚úÖ Patterns de requ√™tes document√©s
- ‚úÖ Standards d'√©quipe √©tablis

#### Connaissance Approfondie

- ‚úÖ Compr√©hension du planificateur PostgreSQL
- ‚úÖ Expertise en optimisation
- ‚úÖ Capacit√© √† pr√©voir les probl√®mes

---

## 3. Le Cycle de Vie d'une Requ√™te

### 3.1. Les 5 Phases d'Ex√©cution

Comprendre le cycle de vie d'une requ√™te est essentiel pour l'optimiser.

#### Phase 1 : Parsing (Analyse Syntaxique)

**R√¥le** : V√©rifier que la requ√™te SQL est syntaxiquement correcte.

```sql
-- Parsing OK
SELECT nom FROM employes WHERE id = 1;

-- Parsing ERROR
SELECT nom FORM employes WHERE id = 1;
--           ^^^^ Erreur de syntaxe
```

**Co√ªt** : N√©gligeable (< 1 ms)

#### Phase 2 : Rewrite (R√©√©criture)

**R√¥le** : Transformer la requ√™te en utilisant les r√®gles (views, triggers).

**Exemple** :
```sql
-- Vue d√©finie
CREATE VIEW employes_actifs AS
SELECT * FROM employes WHERE actif = true;

-- Requ√™te utilisateur
SELECT * FROM employes_actifs WHERE salaire > 50000;

-- R√©√©criture interne
SELECT * FROM employes WHERE actif = true AND salaire > 50000;
```

**Co√ªt** : Faible (< 5 ms)

#### Phase 3 : Planning (Planification)

**R√¥le** : **Le c≈ìur de l'optimisation**. Le planificateur choisit le meilleur plan d'ex√©cution.

**D√©cisions prises** :
- Utiliser un index ou faire un sequential scan ?
- Quel ordre pour les jointures ?
- Utiliser des hash joins ou nested loops ?
- Parall√©liser l'ex√©cution ?

**Co√ªt** : Variable (1-100 ms selon la complexit√©)

**Importance** : C'est ici que se joue la performance. Un mauvais plan = requ√™te lente.

#### Phase 4 : Execution (Ex√©cution)

**R√¥le** : Ex√©cuter le plan choisi et r√©cup√©rer les donn√©es.

**Op√©rations** :
- Lecture des pages de donn√©es
- Filtrage des lignes
- Jointures
- Tri
- Agr√©gations

**Co√ªt** : Variable (peut √™tre tr√®s √©lev√©)

#### Phase 5 : Result (Retour des R√©sultats)

**R√¥le** : Renvoyer les r√©sultats au client.

**Co√ªt** : Proportionnel au nombre de lignes retourn√©es.

### 3.2. Sch√©ma du Cycle de Vie

```
SQL Query
   ‚Üì
[1. PARSING] ‚Üê Syntaxe correcte ?
   ‚Üì
[2. REWRITE] ‚Üê Application des r√®gles
   ‚Üì
[3. PLANNING] ‚Üê Choix du meilleur plan (CRITIQUE)
   ‚Üì
[4. EXECUTION] ‚Üê Ex√©cution du plan
   ‚Üì
[5. RESULT] ‚Üê Retour des r√©sultats
   ‚Üì
Client Application
```

### 3.3. O√π se Concentrer pour l'Audit ?

**Priorit√©s** :
1. **Planning** (Phase 3) : Le planificateur choisit-il le bon plan ?
2. **Execution** (Phase 4) : Les op√©rations sont-elles efficaces ?
3. **Result** (Phase 5) : Retourne-t-on trop de donn√©es ?

Les phases 1 et 2 sont rarement probl√©matiques.

---

## 4. Outils d'Audit de Requ√™tes

### 4.1. pg_stat_statements (Essentiel)

**Description** : Extension qui enregistre toutes les requ√™tes ex√©cut√©es avec leurs statistiques.

#### Installation

```sql
-- 1. Modifier postgresql.conf
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';

-- 2. Red√©marrer PostgreSQL (n√©cessaire)

-- 3. Cr√©er l'extension
CREATE EXTENSION pg_stat_statements;
```

#### Utilisation

**Requ√™tes les plus lentes (par temps moyen)** :
```sql
SELECT
    substring(query, 1, 100) AS query_short,
    calls,
    ROUND(mean_exec_time::numeric, 2) AS avg_ms,
    ROUND(total_exec_time::numeric, 2) AS total_ms
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 20;
```

**Requ√™tes les plus co√ªteuses (par temps total)** :
```sql
SELECT
    substring(query, 1, 100) AS query_short,
    calls,
    ROUND(total_exec_time::numeric, 2) AS total_ms,
    ROUND(100.0 * total_exec_time / SUM(total_exec_time) OVER (), 2) AS pct_total
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 20;
```

**Requ√™tes les plus fr√©quentes** :
```sql
SELECT
    substring(query, 1, 100) AS query_short,
    calls,
    ROUND(mean_exec_time::numeric, 2) AS avg_ms
FROM pg_stat_statements
ORDER BY calls DESC
LIMIT 20;
```

#### Configuration Recommand√©e

```sql
-- Nombre de requ√™tes √† tracker (d√©faut: 5000)
ALTER SYSTEM SET pg_stat_statements.max = 10000;

-- Tracker les requ√™tes dans les fonctions PL/pgSQL
ALTER SYSTEM SET pg_stat_statements.track = 'all';

-- Sauvegarder les stats √† l'arr√™t
ALTER SYSTEM SET pg_stat_statements.save = on;
```

#### R√©initialisation

```sql
-- R√©initialiser toutes les statistiques
SELECT pg_stat_statements_reset();
```

**Attention** : Faites cela en connaissance de cause (perte de l'historique).

### 4.2. EXPLAIN et EXPLAIN ANALYZE

**Description** : Commandes pour afficher et analyser les plans d'ex√©cution.

#### EXPLAIN (Estimation)

```sql
EXPLAIN SELECT * FROM employes WHERE nom = 'Dupont';
```

**R√©sultat** : Plan d'ex√©cution **estim√©** (sans ex√©cuter r√©ellement).

**Avantages** :
- ‚úÖ Rapide (pas d'ex√©cution)
- ‚úÖ Sans risque (pas de modification)

**Inconv√©nients** :
- ‚ùå Estimations peuvent √™tre inexactes
- ‚ùå Ne montre pas les temps r√©els

#### EXPLAIN ANALYZE (Ex√©cution R√©elle)

```sql
EXPLAIN ANALYZE SELECT * FROM employes WHERE nom = 'Dupont';
```

**R√©sultat** : Plan d'ex√©cution avec **temps r√©els d'ex√©cution**.

**Avantages** :
- ‚úÖ Temps r√©els mesur√©s
- ‚úÖ D√©tecte les √©carts estimation vs r√©alit√©

**Inconv√©nients** :
- ‚ùå Ex√©cute r√©ellement la requ√™te (attention aux DELETE/UPDATE)
- ‚ùå Plus lent

#### Options d'EXPLAIN

```sql
EXPLAIN (
    ANALYZE true,      -- Ex√©cuter r√©ellement
    BUFFERS true,      -- Montrer l'utilisation des buffers
    VERBOSE true,      -- Informations d√©taill√©es
    FORMAT JSON        -- Format JSON (ou TEXT, XML, YAML)
) SELECT ...;
```

**Recommandation** : Toujours utiliser `ANALYZE` et `BUFFERS` pour un audit complet.

### 4.3. PostgreSQL 18 : Am√©liorations d'EXPLAIN

**Nouveaut√©** : Affichage automatique des buffers et statistiques I/O enrichies.

```sql
-- PostgreSQL 18 : Plus de d√©tails par d√©faut
EXPLAIN (ANALYZE) SELECT * FROM employes WHERE nom = 'Dupont';

-- Nouvelles m√©triques :
-- - I/O timing par op√©ration
-- - WAL generation
-- - Statistiques par backend
```

### 4.4. pg_stat_activity

**Description** : Vue montrant les requ√™tes **en cours d'ex√©cution**.

```sql
SELECT
    pid,
    usename,
    application_name,
    state,
    query,
    query_start,
    state_change
FROM pg_stat_activity
WHERE state = 'active'
  AND query NOT LIKE '%pg_stat_activity%'
ORDER BY query_start;
```

**Cas d'usage** :
- Identifier les requ√™tes qui tournent depuis longtemps
- D√©tecter les requ√™tes bloqu√©es
- Voir la charge en temps r√©el

#### Tuer une Requ√™te Lente

```sql
-- Annuler une requ√™te (soft)
SELECT pg_cancel_backend(pid);

-- Terminer le processus (hard)
SELECT pg_terminate_backend(pid);
```

**Attention** : `pg_terminate_backend` tue la connexion enti√®re, pas seulement la requ√™te.

### 4.5. auto_explain (Extension)

**Description** : Enregistre automatiquement les plans d'ex√©cution des requ√™tes lentes.

#### Configuration

```sql
-- Charger l'extension
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements,auto_explain';

-- Red√©marrer PostgreSQL

-- Configurer auto_explain
ALTER SYSTEM SET auto_explain.log_min_duration = 1000;  -- 1 seconde
ALTER SYSTEM SET auto_explain.log_analyze = on;
ALTER SYSTEM SET auto_explain.log_buffers = on;
ALTER SYSTEM SET auto_explain.log_timing = on;
ALTER SYSTEM SET auto_explain.log_nested_statements = on;

-- Recharger la configuration
SELECT pg_reload_conf();
```

**R√©sultat** : Les plans des requ√™tes > 1 sec sont automatiquement enregistr√©s dans les logs PostgreSQL.

**Avantage** : Capture passive des requ√™tes lentes en production.

### 4.6. pgBadger

**Description** : Analyseur de logs PostgreSQL g√©n√©rant des rapports HTML d√©taill√©s.

#### Installation

```bash
# Debian/Ubuntu
apt-get install pgbadger

# Ou depuis les sources
cpan App::pgBadger
```

#### Configuration des Logs PostgreSQL

```sql
-- Configuration pour pgBadger
ALTER SYSTEM SET log_min_duration_statement = 0;  -- Tout logger (ou 1000 pour > 1s)
ALTER SYSTEM SET log_line_prefix = '%t [%p]: user=%u,db=%d,app=%a,client=%h ';
ALTER SYSTEM SET log_checkpoints = on;
ALTER SYSTEM SET log_connections = on;
ALTER SYSTEM SET log_disconnections = on;
ALTER SYSTEM SET log_lock_waits = on;
ALTER SYSTEM SET log_temp_files = 0;
ALTER SYSTEM SET log_autovacuum_min_duration = 0;

SELECT pg_reload_conf();
```

#### G√©n√©ration du Rapport

```bash
# Analyser les logs
pgbadger /var/log/postgresql/postgresql-*.log -o rapport.html

# Ouvrir le rapport
firefox rapport.html
```

**Rapport contient** :
- Top 20 requ√™tes les plus lentes
- Requ√™tes les plus fr√©quentes
- Requ√™tes les plus co√ªteuses
- Distribution temporelle
- Locks et deadlocks
- Checkpoints et autovacuum

### 4.7. Tableau R√©capitulatif des Outils

| Outil | Utilit√© | Quand l'utiliser |
|-------|---------|------------------|
| **pg_stat_statements** | Statistiques agr√©g√©es | Identifier patterns g√©n√©raux |
| **EXPLAIN ANALYZE** | Analyse d√©taill√©e | Optimiser une requ√™te sp√©cifique |
| **pg_stat_activity** | Requ√™tes en cours | Debugging temps r√©el |
| **auto_explain** | Capture automatique | Monitoring passif production |
| **pgBadger** | Rapport global | Audit p√©riodique complet |

---

## 5. EXPLAIN : Comprendre les Plans d'Ex√©cution

### 5.1. Anatomie d'un Plan d'Ex√©cution

Un plan d'ex√©cution est un **arbre d'op√©rations** que PostgreSQL va effectuer pour ex√©cuter la requ√™te.

#### Exemple Simple

```sql
EXPLAIN ANALYZE
SELECT * FROM employes WHERE nom = 'Dupont';
```

**R√©sultat** :
```
Index Scan using idx_employes_nom on employes
  (cost=0.42..8.44 rows=1 width=128)
  (actual time=0.023..0.024 rows=1 loops=1)
  Index Cond: (nom = 'Dupont'::text)
Planning Time: 0.123 ms
Execution Time: 0.045 ms
```

### 5.2. D√©cryptage des √âl√©ments

#### Type de Scan

**Types courants** :
- `Seq Scan` : Balayage s√©quentiel (lit toute la table)
- `Index Scan` : Utilise un index
- `Index Only Scan` : Lit uniquement l'index (optimal)
- `Bitmap Heap Scan` : Combine plusieurs index
- `Nested Loop` : Jointure en boucles imbriqu√©es
- `Hash Join` : Jointure avec table de hachage
- `Merge Join` : Jointure par fusion (donn√©es tri√©es)

#### Cost (Co√ªt Estim√©)

```
cost=0.42..8.44
     ^^^^  ^^^^
     start end
```

**Interpr√©tation** :
- `start` : Co√ªt avant de retourner la premi√®re ligne
- `end` : Co√ªt total pour toutes les lignes
- **Unit√© arbitraire** : Compare des co√ªts relatifs, pas des temps absolus

**R√®gle** : Plus le co√ªt est bas, mieux c'est.

#### Rows (Lignes Estim√©es)

```
rows=1
```

**Interpr√©tation** : Le planificateur estime retourner **1 ligne**.

**Attention** : Si l'estimation est tr√®s diff√©rente de la r√©alit√© (`actual rows`), les statistiques sont obsol√®tes ‚Üí `ANALYZE` n√©cessaire.

#### Width (Largeur des Lignes)

```
width=128
```

**Interpr√©tation** : Chaque ligne fait en moyenne **128 octets**.

#### Actual Time (Temps R√©el)

```
actual time=0.023..0.024
            ^^^^^  ^^^^^
            start  end
```

**Interpr√©tation** :
- Temps r√©el mesur√© lors de l'ex√©cution
- En millisecondes
- **C'est √ßa qui compte vraiment !**

#### Loops (Boucles)

```
loops=1
```

**Interpr√©tation** : Cette op√©ration a √©t√© ex√©cut√©e **1 fois**.

**Attention** : Si `loops=1000`, multipliez le temps par 1000 !

**Exemple probl√©matique** :
```
actual time=0.1..0.1 rows=1 loops=10000
```
Temps r√©el total = `0.1 ms √ó 10000 = 1000 ms = 1 seconde`

### 5.3. Types de Scans D√©taill√©s

#### Seq Scan (Sequential Scan)

**Description** : Lit toute la table ligne par ligne.

```
Seq Scan on employes  (cost=0.00..1234.56 rows=10000 width=128)
  Filter: (nom = 'Dupont'::text)
```

**Quand est-ce utilis√© ?**
- Pas d'index disponible
- Table petite (< 1000 lignes)
- Requ√™te retourne > 10% de la table
- Le planificateur estime que c'est plus rapide

**Probl√®me** : Sur grandes tables, tr√®s lent.

**Solution** : Cr√©er un index sur la colonne filtr√©e.

#### Index Scan

**Description** : Utilise un index pour localiser les lignes.

```
Index Scan using idx_employes_nom on employes  (cost=0.42..8.44 rows=1 width=128)
  Index Cond: (nom = 'Dupont'::text)
```

**Avantages** :
- ‚úÖ Rapide pour retrouver peu de lignes
- ‚úÖ Utilise l'index efficacement

**Inconv√©nients** :
- ‚ùå Doit lire l'index **puis** la table
- ‚ùå Peut √™tre lent si beaucoup de lignes √† retourner

#### Index Only Scan

**Description** : Lit **uniquement** l'index, sans acc√©der √† la table.

```
Index Only Scan using idx_employes_nom_include on employes
  (cost=0.42..4.44 rows=1 width=64)
  Index Cond: (nom = 'Dupont'::text)
  Heap Fetches: 0
```

**Conditions** :
- Index contient toutes les colonnes n√©cessaires (covering index)
- Visibility Map √† jour (via VACUUM)

**Avantages** :
- ‚úÖ Le plus rapide
- ‚úÖ Minimal I/O

**Solution** : Utiliser `INCLUDE` dans les index.

```sql
CREATE INDEX idx_covering ON employes(nom) INCLUDE (prenom, salaire);
```

#### Bitmap Heap Scan

**Description** : Combine plusieurs index, cr√©e un bitmap en m√©moire, puis lit les pages.

```
Bitmap Heap Scan on employes  (cost=12.34..234.56 rows=50 width=128)
  Recheck Cond: ((ville = 'Paris'::text) OR (ville = 'Lyon'::text))
  ->  BitmapOr  (cost=12.34..12.34 rows=50 width=0)
        ->  Bitmap Index Scan on idx_ville  (cost=0.00..6.17 rows=25 width=0)
              Index Cond: (ville = 'Paris'::text)
        ->  Bitmap Index Scan on idx_ville  (cost=0.00..6.17 rows=25 width=0)
              Index Cond: (ville = 'Lyon'::text)
```

**Quand est-ce utilis√© ?**
- Requ√™tes avec `OR`
- Requ√™tes avec plusieurs conditions sur index diff√©rents
- Nombre mod√©r√© de lignes √† retourner

**Avantages** :
- ‚úÖ Combine efficacement plusieurs index
- ‚úÖ R√©duit les acc√®s disque al√©atoires

### 5.4. Types de Jointures

#### Nested Loop (Boucles Imbriqu√©es)

**Description** : Pour chaque ligne de la premi√®re table, parcourt la seconde.

```
Nested Loop  (cost=0.42..234.56 rows=100 width=256)
  ->  Seq Scan on commandes  (cost=0.00..12.34 rows=100 width=128)
  ->  Index Scan using clients_pkey on clients  (cost=0.42..2.22 rows=1 width=128)
        Index Cond: (id = commandes.client_id)
```

**Quand est-ce utilis√© ?**
- Petite table externe
- Index sur la table interne
- Peu de lignes √† joindre

**Complexit√©** : O(n √ó m) o√π n et m sont les tailles des tables.

**Avantages** :
- ‚úÖ Efficace pour petits datasets
- ‚úÖ Commence √† retourner des lignes imm√©diatement

**Inconv√©nients** :
- ‚ùå Tr√®s lent si beaucoup de lignes

#### Hash Join

**Description** : Cr√©e une table de hachage en m√©moire pour la premi√®re table, puis la parcourt.

```
Hash Join  (cost=123.45..567.89 rows=1000 width=256)
  Hash Cond: (commandes.client_id = clients.id)
  ->  Seq Scan on commandes  (cost=0.00..234.56 rows=5000 width=128)
  ->  Hash  (cost=67.89..67.89 rows=1000 width=128)
        ->  Seq Scan on clients  (cost=0.00..67.89 rows=1000 width=128)
```

**Quand est-ce utilis√© ?**
- Jointures sur de grandes tables
- Pas d'index disponible
- Suffisamment de `work_mem`

**Complexit√©** : O(n + m)

**Avantages** :
- ‚úÖ Tr√®s efficace pour grandes tables
- ‚úÖ Lin√©aire

**Inconv√©nients** :
- ‚ùå N√©cessite assez de m√©moire (`work_mem`)
- ‚ùå Ne retourne pas de lignes avant la fin de la construction du hash

#### Merge Join

**Description** : Trie les deux tables, puis les fusionne.

```
Merge Join  (cost=123.45..567.89 rows=1000 width=256)
  Merge Cond: (commandes.client_id = clients.id)
  ->  Sort  (cost=67.89..72.34 rows=5000 width=128)
        Sort Key: commandes.client_id
        ->  Seq Scan on commandes  (cost=0.00..234.56 rows=5000 width=128)
  ->  Sort  (cost=55.56..58.12 rows=1000 width=128)
        Sort Key: clients.id
        ->  Seq Scan on clients  (cost=0.00..67.89 rows=1000 width=128)
```

**Quand est-ce utilis√© ?**
- Les deux tables sont d√©j√† tri√©es (ou ont des index)
- Jointure sur √©galit√©

**Complexit√©** : O(n log n + m log m) pour les tris, puis O(n + m) pour la fusion

**Avantages** :
- ‚úÖ Efficace si donn√©es d√©j√† tri√©es
- ‚úÖ Pas de m√©moire suppl√©mentaire n√©cessaire

**Inconv√©nients** :
- ‚ùå Co√ªt des tris si non tri√©es

### 5.5. Op√©rations de Tri

#### Sort

```
Sort  (cost=123.45..126.78 rows=1000 width=128)
  Sort Key: salaire DESC
  Sort Method: quicksort  Memory: 71kB
  ->  Seq Scan on employes  (cost=0.00..67.89 rows=1000 width=128)
```

**M√©thodes de tri** :
- `quicksort` : En m√©moire (rapide)
- `top-N heapsort` : Tri partiel (LIMIT)
- `external merge` : Sur disque (lent, si d√©passement de `work_mem`)

**Si "external merge"** :
```
Sort Method: external merge  Disk: 12345kB
```

**Probl√®me** : Le tri utilise le disque (tr√®s lent).

**Solution** : Augmenter `work_mem`.

### 5.6. Buffers (Utilisation M√©moire)

Avec `EXPLAIN (ANALYZE, BUFFERS)` :

```
Buffers: shared hit=123 read=45 dirtied=10 written=5
```

**Signification** :
- `shared hit=123` : 123 pages lues depuis le **cache** (RAM) ‚úÖ
- `read=45` : 45 pages lues depuis le **disque** ‚ùå
- `dirtied=10` : 10 pages modifi√©es
- `written=5` : 5 pages √©crites sur disque

**Objectif** : Maximiser `hit`, minimiser `read`.

**Cache Hit Ratio** :
```
hit_ratio = hit / (hit + read)
```

**Objectif** : > 99%

### 5.7. PostgreSQL 18 : Am√©liorations EXPLAIN

**Nouveaut√©s** :
- Statistiques I/O par backend
- G√©n√©ration WAL par op√©ration
- Temps pass√© dans chaque phase
- Auto-affichage des buffers (plus besoin de sp√©cifier)

```sql
-- PostgreSQL 18
EXPLAIN (ANALYZE) SELECT ...;

-- Affiche automatiquement :
-- - Buffers
-- - I/O timing
-- - WAL generation
```

---

## 6. Identification des Requ√™tes Lentes

### 6.1. D√©finir "Lent"

**Seuils recommand√©s** :

| Type de requ√™te | Temps acceptable | Temps lent |
|-----------------|------------------|------------|
| Requ√™te simple (PK) | < 10 ms | > 50 ms |
| Requ√™te avec jointure | < 100 ms | > 500 ms |
| Rapport/agr√©gation | < 1 sec | > 5 sec |
| Export/batch | < 10 sec | > 30 sec |

**Contexte** : Ces seuils d√©pendent de votre application.

### 6.2. M√©thode 1 : pg_stat_statements

**Top 20 requ√™tes les plus lentes (moyenne)** :
```sql
SELECT
    queryid,
    substring(query, 1, 100) AS query_short,
    calls,
    ROUND(mean_exec_time::numeric, 2) AS avg_ms,
    ROUND(stddev_exec_time::numeric, 2) AS stddev_ms,
    ROUND(total_exec_time::numeric, 2) AS total_ms
FROM pg_stat_statements
WHERE mean_exec_time > 100  -- Plus de 100 ms
ORDER BY mean_exec_time DESC
LIMIT 20;
```

**Top 20 requ√™tes les plus co√ªteuses (temps cumul√©)** :
```sql
SELECT
    queryid,
    substring(query, 1, 100) AS query_short,
    calls,
    ROUND(mean_exec_time::numeric, 2) AS avg_ms,
    ROUND(total_exec_time::numeric, 2) AS total_ms,
    ROUND(100.0 * total_exec_time / SUM(total_exec_time) OVER (), 2) AS pct_total_time
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 20;
```

**Requ√™tes avec forte variabilit√©** :
```sql
SELECT
    queryid,
    substring(query, 1, 100) AS query_short,
    calls,
    ROUND(mean_exec_time::numeric, 2) AS avg_ms,
    ROUND(stddev_exec_time::numeric, 2) AS stddev_ms,
    ROUND(stddev_exec_time / NULLIF(mean_exec_time, 0), 2) AS coefficient_variation
FROM pg_stat_statements
WHERE calls > 100
  AND stddev_exec_time > mean_exec_time  -- Variabilit√© √©lev√©e
ORDER BY coefficient_variation DESC
LIMIT 20;
```

**Interpr√©tation** : Variabilit√© √©lev√©e peut indiquer :
- Plans d'ex√©cution instables
- Donn√©es mal distribu√©es
- Contention

### 6.3. M√©thode 2 : Logs PostgreSQL

#### Configuration

```sql
-- Logger toutes les requ√™tes > 1 seconde
ALTER SYSTEM SET log_min_duration_statement = 1000;

-- Inclure le temps d'ex√©cution
ALTER SYSTEM SET log_duration = off;  -- √âvite la duplication

SELECT pg_reload_conf();
```

#### Analyse des Logs

```bash
# Chercher les requ√™tes lentes
grep "duration:" /var/log/postgresql/postgresql-*.log | sort -t: -k2 -n

# Exemple de sortie :
# 2025-11-21 10:23:45 UTC [12345]: duration: 5234.567 ms  statement: SELECT ...
```

### 6.4. M√©thode 3 : auto_explain

**Configuration** (d√©j√† vue) :
```sql
ALTER SYSTEM SET auto_explain.log_min_duration = 1000;  -- 1 sec
ALTER SYSTEM SET auto_explain.log_analyze = on;
ALTER SYSTEM SET auto_explain.log_buffers = on;
```

**R√©sultat** : Plans d'ex√©cution des requ√™tes lentes dans les logs.

### 6.5. M√©thode 4 : pg_stat_activity (Temps R√©el)

**Requ√™tes en cours depuis > 5 secondes** :
```sql
SELECT
    pid,
    usename,
    datname,
    query_start,
    NOW() - query_start AS duration,
    state,
    wait_event_type,
    wait_event,
    substring(query, 1, 100) AS query_short
FROM pg_stat_activity
WHERE state = 'active'
  AND query_start < NOW() - INTERVAL '5 seconds'
  AND query NOT LIKE '%pg_stat_activity%'
ORDER BY query_start;
```

**Si `wait_event_type` est pr√©sent** : La requ√™te attend une ressource (I/O, lock, etc.).

### 6.6. M√©thode 5 : pgBadger

```bash
pgbadger /var/log/postgresql/postgresql-*.log -o rapport.html
```

**Section "Slowest queries"** : Liste d√©taill√©e des requ√™tes les plus lentes.

---

## 7. Analyse des Patterns de Performance

### 7.1. Pattern 1 : Sequential Scans sur Grandes Tables

**Sympt√¥me dans EXPLAIN** :
```
Seq Scan on large_table  (cost=0.00..123456.78 rows=1000000 width=128)
```

**Probl√®me** : Lit **toute la table** au lieu d'utiliser un index.

**Causes** :
- Aucun index disponible
- Index non utilis√© par le planificateur
- Statistiques obsol√®tes

**Solutions** :
1. Cr√©er un index appropri√©
2. Mettre √† jour les statistiques (`ANALYZE`)
3. V√©rifier `random_page_cost`

**Exemple** :
```sql
-- Avant (Seq Scan)
SELECT * FROM commandes WHERE client_id = 123;

-- Cr√©er index
CREATE INDEX idx_commandes_client ON commandes(client_id);

-- Apr√®s (Index Scan)
SELECT * FROM commandes WHERE client_id = 123;
```

### 7.2. Pattern 2 : Sous-Requ√™tes Corr√©l√©es

**Sympt√¥me dans EXPLAIN** :
```
Seq Scan on commandes  (cost=0.00..12345.67 rows=1000 width=128)
  Filter: (total > (SubPlan 1))
  SubPlan 1
    ->  Aggregate  (cost=12.34..12.35 rows=1 width=8)
          ->  Seq Scan on commandes c2  (cost=0.00..12.34 rows=1 width=4)
                Filter: (c2.client_id = commandes.client_id)
```

**Probl√®me** : La sous-requ√™te est ex√©cut√©e **pour chaque ligne** de la table externe.

**Exemple probl√©matique** :
```sql
-- Sous-requ√™te corr√©l√©e (lent)
SELECT c.id, c.total,
       (SELECT AVG(c2.total)
        FROM commandes c2
        WHERE c2.client_id = c.client_id) AS avg_client
FROM commandes c;
```

**Solution** : R√©√©crire avec JOIN ou CTE :
```sql
-- R√©√©criture avec CTE (rapide)
WITH avg_by_client AS (
    SELECT client_id, AVG(total) AS avg_total
    FROM commandes
    GROUP BY client_id
)
SELECT c.id, c.total, abc.avg_total AS avg_client
FROM commandes c
JOIN avg_by_client abc ON abc.client_id = c.client_id;
```

### 7.3. Pattern 3 : Sorts avec External Merge (Disque)

**Sympt√¥me dans EXPLAIN** :
```
Sort  (cost=123.45..126.78 rows=100000 width=128)
  Sort Key: salaire DESC
  Sort Method: external merge  Disk: 12345kB
```

**Probl√®me** : Le tri d√©borde sur **disque** (tr√®s lent).

**Cause** : `work_mem` trop faible.

**Solutions** :
1. Augmenter `work_mem` globalement
2. Augmenter `work_mem` pour cette session
3. Limiter les r√©sultats (LIMIT)
4. Utiliser un index pour √©viter le tri

**Exemple** :
```sql
-- Augmenter work_mem pour cette session
SET work_mem = '256MB';

-- Ex√©cuter la requ√™te
SELECT * FROM employes ORDER BY salaire DESC;

-- Ou cr√©er un index pour √©viter le tri
CREATE INDEX idx_employes_salaire ON employes(salaire DESC);
```

### 7.4. Pattern 4 : Nested Loops avec Beaucoup de Lignes

**Sympt√¥me dans EXPLAIN** :
```
Nested Loop  (cost=0.42..123456.78 rows=100000 width=256)
  ->  Seq Scan on commandes  (cost=0.00..234.56 rows=10000 width=128)
  ->  Index Scan using clients_pkey on clients  (cost=0.42..12.34 rows=1 width=128)
```

**Probl√®me** : Nested Loop avec 10,000 lignes externes = 10,000 acc√®s √† l'index.

**Solution** : Forcer un Hash Join ou Merge Join.

**Exemple** :
```sql
-- D√©sactiver nested loop pour cette requ√™te
SET enable_nestloop = off;

SELECT ...;

-- R√©activer
SET enable_nestloop = on;
```

**Mieux** : Am√©liorer les statistiques ou ajouter un index pour que le planificateur choisisse le bon plan.

### 7.5. Pattern 5 : Trop de Donn√©es Retourn√©es

**Sympt√¥me** : `rows=1000000` dans EXPLAIN.

**Probl√®me** : L'application r√©cup√®re **toutes les lignes** alors qu'elle n'en a besoin que d'une partie.

**Solutions** :
1. Ajouter un `LIMIT`
2. Paginer les r√©sultats
3. Filtrer davantage avec `WHERE`

**Exemple** :
```sql
-- Mauvais : R√©cup√®re 1 million de lignes
SELECT * FROM logs;

-- Bon : Pagination
SELECT * FROM logs
ORDER BY timestamp DESC
LIMIT 100 OFFSET 0;
```

### 7.6. Pattern 6 : Fonctions Non Index√©es

**Sympt√¥me dans EXPLAIN** :
```
Seq Scan on users  (cost=0.00..1234.56 rows=1000 width=128)
  Filter: (lower(email) = 'user@example.com'::text)
```

**Probl√®me** : `lower(email)` emp√™che l'utilisation de l'index sur `email`.

**Solution** : Index sur expression.

```sql
-- Cr√©er index sur expression
CREATE INDEX idx_users_email_lower ON users(lower(email));

-- Maintenant : Index Scan
SELECT * FROM users WHERE lower(email) = 'user@example.com';
```

### 7.7. Pattern 7 : Statistiques Obsol√®tes

**Sympt√¥me dans EXPLAIN** :
```
Hash Join  (cost=123.45..567.89 rows=1000 width=256)
  (actual time=1234.56..5678.90 rows=500000 loops=1)
```

**Probl√®me** : Estimation `rows=1000` tr√®s diff√©rente de la r√©alit√© `actual rows=500000`.

**Cause** : Statistiques PostgreSQL obsol√®tes.

**Solution** : Ex√©cuter `ANALYZE`.

```sql
-- Pour une table sp√©cifique
ANALYZE commandes;

-- Pour toute la base
ANALYZE;

-- V√©rifier les derni√®res stats
SELECT
    schemaname,
    tablename,
    last_analyze,
    last_autoanalyze
FROM pg_stat_user_tables
WHERE tablename = 'commandes';
```

---

## 8. Probl√®mes Courants et Solutions

### 8.1. Probl√®me 1 : Index Non Utilis√©

**Sympt√¥me** : Index existant mais `Seq Scan` dans EXPLAIN.

**Causes possibles** :

#### Cause 1a : Statistiques Obsol√®tes
```sql
ANALYZE table_name;
```

#### Cause 1b : `random_page_cost` Trop √âlev√©
```sql
-- Pour SSD
SHOW random_page_cost;  -- Si 4.0, trop haut

ALTER SYSTEM SET random_page_cost = 1.1;
SELECT pg_reload_conf();
```

#### Cause 1c : Requ√™te Retourne > 10% de la Table
Le planificateur pr√©f√®re parfois `Seq Scan` si beaucoup de lignes sont retourn√©es.

**Solution** : Aucune, c'est le comportement optimal.

#### Cause 1d : Type de Donn√©es Incompatible
```sql
-- Index existe sur id (integer)
CREATE INDEX idx_commandes_id ON commandes(id);

-- Mais requ√™te utilise text
SELECT * FROM commandes WHERE id = '123';  -- text, pas integer
```

**Solution** : Cast explicite ou corriger le type dans la requ√™te.
```sql
SELECT * FROM commandes WHERE id = 123;  -- integer
```

### 8.2. Probl√®me 2 : Requ√™te Lente Seulement Parfois

**Sympt√¥me** : Requ√™te rapide la plupart du temps, mais parfois tr√®s lente.

**Causes possibles** :

#### Cause 2a : Cache Froid vs Cache Chaud
- **Cache froid** : Premi√®re ex√©cution, donn√©es sur disque (lent)
- **Cache chaud** : Donn√©es en m√©moire (rapide)

**Solution** : Augmenter `shared_buffers` ou accepter cette variabilit√©.

#### Cause 2b : Contention (Locks)
D'autres requ√™tes verrouillent les donn√©es.

**D√©tection** :
```sql
SELECT
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS blocking_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

**Solution** : Optimiser les transactions concurrentes ou r√©duire les locks.

#### Cause 2c : Plans d'Ex√©cution Instables
Param√®tres de requ√™te diff√©rents entra√Ænent des plans diff√©rents.

**D√©tection** : Variabilit√© √©lev√©e dans `pg_stat_statements` (`stddev_exec_time >> mean_exec_time`).

**Solution** :
- Utiliser `PREPARE` pour fixer le plan
- Ajuster les statistiques
- R√©√©crire la requ√™te pour √™tre plus stable

### 8.3. Probl√®me 3 : OUT OF MEMORY

**Sympt√¥me** : Erreur `ERROR: out of memory` lors de l'ex√©cution d'une requ√™te.

**Causes possibles** :

#### Cause 3a : `work_mem` Trop √âlev√© √ó Trop de Connexions
```
M√©moire totale = max_connections √ó work_mem √ó complexit√©_requ√™te
```

**Solution** : R√©duire `work_mem` ou `max_connections`, ou utiliser PgBouncer.

#### Cause 3b : Hash Join Trop Gourmand
```sql
-- Requ√™te cr√©e une √©norme table de hash
SELECT ... FROM huge_table1 JOIN huge_table2 ...;
```

**Solution** :
- Augmenter `work_mem` temporairement pour cette requ√™te
- Filtrer davantage avant la jointure
- Ajouter des index

#### Cause 3c : Tri Massif en M√©moire
```sql
SELECT * FROM huge_table ORDER BY random();  -- Tr√®s co√ªteux
```

**Solution** : √âviter les tris al√©atoires, limiter les r√©sultats.

### 8.4. Probl√®me 4 : Deadlock (Interblocage)

**Sympt√¥me** : Erreur `ERROR: deadlock detected`.

**Exemple** :
```
Transaction 1:
BEGIN;
UPDATE commandes SET total = 100 WHERE id = 1;  -- Lock commandes(1)
UPDATE clients SET credit = 50 WHERE id = 10;   -- Attend lock clients(10)

Transaction 2:
BEGIN;
UPDATE clients SET credit = 50 WHERE id = 10;   -- Lock clients(10)
UPDATE commandes SET total = 100 WHERE id = 1;  -- Attend lock commandes(1)

‚Üí DEADLOCK
```

**Solutions** :
1. **Ordonner les verrous** : Toujours acqu√©rir les locks dans le m√™me ordre
2. **Transactions courtes** : R√©duire la dur√©e des transactions
3. **Isolation niveau** : Ajuster le niveau d'isolation si appropri√©

### 8.5. Probl√®me 5 : Planificateur Choisit le Mauvais Plan

**Sympt√¥me** : EXPLAIN montre un plan sous-optimal √©vident.

**Causes** :

#### Cause 5a : Co√ªts Mal Configur√©s
```sql
-- V√©rifier random_page_cost, seq_page_cost
SHOW random_page_cost;
SHOW seq_page_cost;
```

#### Cause 5b : Statistiques Incorrectes
```sql
ANALYZE table_name;
```

#### Cause 5c : Param√®tres de Planification
```sql
-- Augmenter les ressources allou√©es au planificateur
SET random_page_cost = 1.1;  -- SSD
SET cpu_tuple_cost = 0.01;
SET cpu_index_tuple_cost = 0.005;
SET cpu_operator_cost = 0.0025;
```

**Solution de dernier recours** : Hints (non natif dans PostgreSQL, mais extensions existent comme `pg_hint_plan`).

---

## 9. Optimisation des Requ√™tes

### 9.1. Principe G√©n√©ral d'Optimisation

**Ordre de priorit√©** :
1. **R√©duire les donn√©es scann√©es** : Filtrer t√¥t avec WHERE
2. **Utiliser les index** : Cr√©er index appropri√©s
3. **√âviter les op√©rations co√ªteuses** : Sous-requ√™tes corr√©l√©es, fonctions non index√©es
4. **Simplifier les jointures** : Moins de tables jointes = plus rapide
5. **Limiter les r√©sultats** : LIMIT, pagination

### 9.2. Technique 1 : R√©√©crire les Sous-Requ√™tes

#### Avant : Sous-Requ√™te Corr√©l√©e

```sql
-- Lent : Sous-requ√™te ex√©cut√©e pour chaque ligne
SELECT
    c.id,
    c.nom,
    (SELECT COUNT(*)
     FROM commandes cmd
     WHERE cmd.client_id = c.id) AS nb_commandes
FROM clients c;
```

**Plan d'ex√©cution** : `SubPlan` ex√©cut√© N fois.

#### Apr√®s : JOIN ou CTE

```sql
-- Rapide : Agr√©gation puis jointure
SELECT
    c.id,
    c.nom,
    COALESCE(cmd_counts.nb_commandes, 0) AS nb_commandes
FROM clients c
LEFT JOIN (
    SELECT client_id, COUNT(*) AS nb_commandes
    FROM commandes
    GROUP BY client_id
) cmd_counts ON cmd_counts.client_id = c.id;
```

**Gain typique** : 10√ó √† 100√ó plus rapide.

### 9.3. Technique 2 : EXISTS vs IN vs JOIN

#### Probl√®me avec IN + Sous-Requ√™te

```sql
-- Potentiellement lent
SELECT * FROM clients
WHERE id IN (SELECT client_id FROM commandes WHERE total > 1000);
```

**Probl√®me** : Si la sous-requ√™te retourne beaucoup de lignes, `IN` peut √™tre lent.

#### Solution 1 : EXISTS (Souvent Plus Rapide)

```sql
-- Souvent plus rapide
SELECT * FROM clients c
WHERE EXISTS (
    SELECT 1 FROM commandes cmd
    WHERE cmd.client_id = c.id AND cmd.total > 1000
);
```

**Avantage** : S'arr√™te d√®s qu'une ligne est trouv√©e (pas besoin de toutes les lire).

#### Solution 2 : JOIN (Alternative)

```sql
-- √âquivalent avec JOIN
SELECT DISTINCT c.*
FROM clients c
JOIN commandes cmd ON cmd.client_id = c.id
WHERE cmd.total > 1000;
```

**Note** : Le `DISTINCT` est n√©cessaire pour √©viter les doublons.

#### Comparaison

| Technique | Quand l'utiliser |
|-----------|------------------|
| **IN** | Petite liste de valeurs litt√©rales |
| **EXISTS** | V√©rifier l'existence (pas besoin des valeurs) |
| **JOIN** | Besoin des colonnes de la sous-requ√™te |

### 9.4. Technique 3 : CTE vs Sous-Requ√™tes

#### CTE (Common Table Expression)

```sql
-- CTE
WITH commandes_recentes AS (
    SELECT client_id, COUNT(*) AS nb
    FROM commandes
    WHERE date_commande > CURRENT_DATE - INTERVAL '30 days'
    GROUP BY client_id
)
SELECT c.nom, cr.nb
FROM clients c
JOIN commandes_recentes cr ON cr.client_id = c.id;
```

**Avantages** :
- ‚úÖ Plus lisible
- ‚úÖ Peut √™tre r√©f√©renc√© plusieurs fois
- ‚úÖ Facilite la maintenance

#### CTE MATERIALIZED (PostgreSQL 12+)

```sql
-- Forcer la mat√©rialisation
WITH commandes_recentes AS MATERIALIZED (
    SELECT client_id, COUNT(*) AS nb
    FROM commandes
    WHERE date_commande > CURRENT_DATE - INTERVAL '30 days'
    GROUP BY client_id
)
SELECT ...;
```

**Quand utiliser MATERIALIZED** :
- CTE utilis√© plusieurs fois
- CTE co√ªteux √† calculer
- √âviter la r√©√©valuation

**Quand NE PAS utiliser MATERIALIZED** :
- CTE utilis√© une seule fois
- CTE simple
- Le planificateur peut optimiser sans mat√©rialisation

### 9.5. Technique 4 : √âviter SELECT *

#### Probl√®me

```sql
-- R√©cup√®re TOUTES les colonnes (m√™me si inutiles)
SELECT * FROM employes WHERE id = 123;
```

**Probl√®mes** :
- Transf√®re des donn√©es inutiles
- Emp√™che les Index Only Scans
- Utilise plus de bande passante

#### Solution

```sql
-- R√©cup√©rer uniquement les colonnes n√©cessaires
SELECT id, nom, prenom FROM employes WHERE id = 123;
```

**Avantages** :
- ‚úÖ Moins de donn√©es transf√©r√©es
- ‚úÖ Permet Index Only Scan si covering index
- ‚úÖ Plus rapide

### 9.6. Technique 5 : Utiliser LIMIT et Pagination

#### Probl√®me : R√©cup√©rer Toutes les Lignes

```sql
-- R√©cup√®re 1 million de lignes
SELECT * FROM logs ORDER BY timestamp DESC;
```

**Probl√®me** : Surcharge m√©moire et r√©seau.

#### Solution : Pagination

```sql
-- Page 1
SELECT * FROM logs
ORDER BY timestamp DESC
LIMIT 100 OFFSET 0;

-- Page 2
SELECT * FROM logs
ORDER BY timestamp DESC
LIMIT 100 OFFSET 100;
```

**Limite de OFFSET** : Sur grandes offsets (OFFSET 1000000), devient lent.

#### Solution Avanc√©e : Keyset Pagination (Cursor)

```sql
-- Page 1
SELECT * FROM logs
ORDER BY timestamp DESC
LIMIT 100;

-- R√©cup√©rer le dernier timestamp (ex: 2025-11-21 10:00:00)

-- Page 2
SELECT * FROM logs
WHERE timestamp < '2025-11-21 10:00:00'
ORDER BY timestamp DESC
LIMIT 100;
```

**Avantages** :
- ‚úÖ Performances constantes m√™me sur grandes pages
- ‚úÖ Utilise l'index efficacement

### 9.7. Technique 6 : Batching (Lots)

#### Probl√®me : Trop de Requ√™tes Individuelles

```sql
-- 1000 requ√™tes individuelles
for id in ids:
    SELECT * FROM produits WHERE id = id;
```

**Probl√®me** : Overhead r√©seau et parsing √ó 1000.

#### Solution : Requ√™te en Lot

```sql
-- 1 seule requ√™te
SELECT * FROM produits WHERE id = ANY(ARRAY[1, 2, 3, ..., 1000]);
```

**Gain** : 10√ó √† 100√ó plus rapide.

### 9.8. Technique 7 : Pr√©paration de Requ√™tes (PREPARE)

#### Probl√®me : Parsing R√©p√©t√©

Chaque ex√©cution de requ√™te :
1. Parse la requ√™te
2. Planifie
3. Ex√©cute

**Pour des requ√™tes r√©p√©t√©es**, le parsing est du gaspillage.

#### Solution : PREPARE

```sql
-- Pr√©parer la requ√™te
PREPARE get_employe (int) AS
    SELECT * FROM employes WHERE id = $1;

-- Ex√©cuter (pas de parsing)
EXECUTE get_employe(123);
EXECUTE get_employe(456);
EXECUTE get_employe(789);

-- Lib√©rer
DEALLOCATE get_employe;
```

**Avantages** :
- ‚úÖ Pas de parsing r√©p√©t√©
- ‚úÖ Plan d'ex√©cution r√©utilis√© (parfois)
- ‚úÖ Plus rapide

**Utilisation typique** : Dans les drivers (psycopg3, pg pour Node.js, etc.).

---

## 10. Anti-Patterns N+1

### 10.1. Qu'est-ce que le N+1 ?

Le **N+1 problem** est un anti-pattern o√π une requ√™te initiale r√©cup√®re N enregistrements, puis N requ√™tes suppl√©mentaires sont ex√©cut√©es pour r√©cup√©rer des donn√©es li√©es.

**R√©sultat** : N+1 requ√™tes au lieu d'une seule requ√™te optimis√©e.

### 10.2. Exemple du Probl√®me

#### Code Application (Python avec ORM)

```python
# Requ√™te 1 : R√©cup√©rer tous les clients
clients = Client.query.all()  # 1 requ√™te

# Requ√™tes 2 √† N+1 : Pour chaque client, r√©cup√©rer ses commandes
for client in clients:
    commandes = client.commandes  # 1 requ√™te par client
    print(f"{client.nom} a {len(commandes)} commandes")
```

**SQL g√©n√©r√©** :
```sql
-- Requ√™te 1
SELECT * FROM clients;  -- Retourne 1000 clients

-- Requ√™tes 2 √† 1001
SELECT * FROM commandes WHERE client_id = 1;
SELECT * FROM commandes WHERE client_id = 2;
SELECT * FROM commandes WHERE client_id = 3;
...
SELECT * FROM commandes WHERE client_id = 1000;
```

**Total** : **1001 requ√™tes** ! üò±

### 10.3. D√©tection

#### Dans pg_stat_statements

Beaucoup d'appels de la m√™me requ√™te avec param√®tres diff√©rents :
```sql
SELECT
    query,
    calls
FROM pg_stat_statements
WHERE calls > 1000
ORDER BY calls DESC;
```

Si vous voyez :
```
query: SELECT * FROM commandes WHERE client_id = $1
calls: 10000
```

**Suspect de N+1**.

#### Dans les Logs

```
SELECT * FROM commandes WHERE client_id = 1;
SELECT * FROM commandes WHERE client_id = 2;
SELECT * FROM commandes WHERE client_id = 3;
...
```

R√©p√©tition √©vidente.

### 10.4. Solutions

#### Solution 1 : Eager Loading (ORM)

**Python (SQLAlchemy)** :
```python
# Avec joinedload : 1 seule requ√™te avec JOIN
clients = Client.query.options(joinedload(Client.commandes)).all()

for client in clients:
    commandes = client.commandes  # Pas de requ√™te suppl√©mentaire
    print(f"{client.nom} a {len(commandes)} commandes")
```

**SQL g√©n√©r√©** :
```sql
-- 1 seule requ√™te avec JOIN
SELECT clients.*, commandes.*
FROM clients
LEFT JOIN commandes ON commandes.client_id = clients.id;
```

**R√©sultat** : **1 requ√™te** au lieu de 1001.

#### Solution 2 : Requ√™te Manuelle Optimis√©e

```python
# 1. R√©cup√©rer les clients
clients = Client.query.all()
client_ids = [c.id for c in clients]

# 2. R√©cup√©rer toutes les commandes en une seule fois
commandes = Commande.query.filter(Commande.client_id.in_(client_ids)).all()

# 3. Grouper en m√©moire
commandes_by_client = {}
for cmd in commandes:
    commandes_by_client.setdefault(cmd.client_id, []).append(cmd)

# 4. Utiliser
for client in clients:
    client_commandes = commandes_by_client.get(client.id, [])
    print(f"{client.nom} a {len(client_commandes)} commandes")
```

**SQL g√©n√©r√©** :
```sql
-- Requ√™te 1
SELECT * FROM clients;

-- Requ√™te 2 (1 seule fois)
SELECT * FROM commandes WHERE client_id IN (1, 2, 3, ..., 1000);
```

**R√©sultat** : **2 requ√™tes** au lieu de 1001.

#### Solution 3 : Utiliser LATERAL JOIN (PostgreSQL)

```sql
-- Pour chaque client, r√©cup√©rer ses 5 derni√®res commandes
SELECT
    c.id,
    c.nom,
    cmd.*
FROM clients c
LEFT JOIN LATERAL (
    SELECT *
    FROM commandes
    WHERE client_id = c.id
    ORDER BY date_commande DESC
    LIMIT 5
) cmd ON true;
```

**Avantage** : Permet des sous-requ√™tes corr√©l√©es **efficaces** dans le FROM.

### 10.5. Impact Performance

**Exemple avec 1000 clients** :

| Approche | Nb Requ√™tes | Temps |
|----------|-------------|-------|
| N+1 (Lazy Loading) | 1001 | 10 secondes |
| Eager Loading (JOIN) | 1 | 0.1 secondes |
| 2 Requ√™tes (IN) | 2 | 0.15 secondes |

**Gain** : **100√ó plus rapide** avec Eager Loading.

---

## 11. Requ√™tes Complexes et Jointures

### 11.1. Optimiser l'Ordre des Jointures

Le planificateur PostgreSQL essaie de choisir le meilleur ordre, mais comprendre les principes aide.

**Principe** : Joindre d'abord les tables qui **r√©duisent le plus** le nombre de lignes.

#### Exemple

```sql
-- 3 tables
-- clients : 1,000,000 lignes
-- commandes : 10,000,000 lignes
-- produits : 100,000 lignes

-- Requ√™te
SELECT *
FROM clients c
JOIN commandes cmd ON cmd.client_id = c.id
JOIN produits p ON p.id = cmd.produit_id
WHERE c.pays = 'France'       -- R√©duit √† 100,000 clients
  AND cmd.statut = 'valid√©'   -- R√©duit √† 1,000,000 commandes
  AND p.categorie = 'A';      -- R√©duit √† 10,000 produits
```

**Ordre optimal** :
1. Filtrer `produits` (100,000 ‚Üí 10,000)
2. Filtrer `commandes` (10,000,000 ‚Üí 1,000,000)
3. Joindre avec `clients` filtr√©s (1,000,000 ‚Üí 100,000)
4. Joindre les r√©sultats

**Planificateur PostgreSQL** : Calcule automatiquement l'ordre optimal (g√©n√©ralement).

### 11.2. √âviter les Jointures Cart√©siennes Accidentelles

#### Probl√®me : Jointure Manquante

```sql
-- ERREUR : Oubli de condition de jointure
SELECT *
FROM clients, commandes
WHERE clients.pays = 'France';
```

**R√©sultat** : Produit cart√©sien = 1,000,000 clients √ó 10,000,000 commandes = 10,000,000,000,000 lignes ! üí•

**Solution** : Toujours inclure les conditions de jointure.

```sql
-- CORRECT
SELECT *
FROM clients c
JOIN commandes cmd ON cmd.client_id = c.id
WHERE c.pays = 'France';
```

### 11.3. Utiliser les Bons Types de Jointures

#### INNER JOIN vs LEFT JOIN

```sql
-- INNER JOIN : Uniquement les clients avec commandes
SELECT c.nom, cmd.total
FROM clients c
INNER JOIN commandes cmd ON cmd.client_id = c.id;

-- LEFT JOIN : Tous les clients, m√™me sans commandes
SELECT c.nom, COALESCE(cmd.total, 0) AS total
FROM clients c
LEFT JOIN commandes cmd ON cmd.client_id = c.id;
```

**Performance** : `INNER JOIN` est souvent plus rapide (moins de lignes).

**Conseil** : Utilisez `INNER JOIN` sauf si vous avez vraiment besoin des lignes non correspondantes.

### 11.4. Jointures sur Index

**R√®gle** : Les colonnes de jointure **doivent √™tre index√©es**.

```sql
-- Jointure sur client_id
SELECT *
FROM commandes cmd
JOIN clients c ON c.id = cmd.client_id;

-- Index n√©cessaires :
-- clients.id ‚Üí PRIMARY KEY (auto-index√©)
-- commandes.client_id ‚Üí DOIT √™tre index√©

CREATE INDEX idx_commandes_client ON commandes(client_id);
```

### 11.5. Filtrer Avant de Joindre

**Principe** : R√©duire le nombre de lignes **avant** la jointure.

#### Sous-Optimal

```sql
-- Jointure puis filtrage
SELECT c.nom, cmd.total
FROM clients c
JOIN commandes cmd ON cmd.client_id = c.id
WHERE c.pays = 'France'
  AND cmd.date_commande > '2025-01-01';
```

**Probl√®me** : Joint **toutes** les lignes, puis filtre.

#### Optimal

```sql
-- Filtrage puis jointure
SELECT c.nom, cmd.total
FROM (
    SELECT * FROM clients WHERE pays = 'France'
) c
JOIN (
    SELECT * FROM commandes WHERE date_commande > '2025-01-01'
) cmd ON cmd.client_id = c.id;
```

**Note** : Le planificateur PostgreSQL fait souvent cette optimisation automatiquement (predicate pushdown).

### 11.6. Lateral Joins pour Sous-Requ√™tes Corr√©l√©es

**Cas d'usage** : R√©cup√©rer les N meilleurs/derniers √©l√©ments pour chaque groupe.

```sql
-- Top 3 commandes par client
SELECT
    c.id,
    c.nom,
    cmd.date_commande,
    cmd.total
FROM clients c
LEFT JOIN LATERAL (
    SELECT *
    FROM commandes
    WHERE client_id = c.id
    ORDER BY total DESC
    LIMIT 3
) cmd ON true;
```

**Avantage** : Beaucoup plus efficace qu'une sous-requ√™te corr√©l√©e classique.

---

## 12. Agr√©gations et Performances

### 12.1. Optimiser GROUP BY

#### Probl√®me : GROUP BY sans Index

```sql
-- Agr√©gation sur colonne non index√©e
SELECT client_id, SUM(total)
FROM commandes
GROUP BY client_id;
```

**EXPLAIN peut montrer** :
```
HashAggregate  (cost=123456.78..123567.89 rows=10000 width=16)
  ->  Seq Scan on commandes  (cost=0.00..100000.00 rows=10000000 width=12)
```

**Probl√®me** : Seq Scan + HashAggregate peut √™tre lent.

#### Solution : Index sur Colonne de GROUP BY

```sql
CREATE INDEX idx_commandes_client ON commandes(client_id);

-- Maintenant potentiellement :
-- Index Scan ou GroupAggregate (plus efficace)
```

### 12.2. Pr√©-Agr√©gation avec Vues Mat√©rialis√©es

Pour des agr√©gations **tr√®s co√ªteuses** et **peu changeantes** :

```sql
-- Vue mat√©rialis√©e
CREATE MATERIALIZED VIEW stats_clients AS
SELECT
    client_id,
    COUNT(*) AS nb_commandes,
    SUM(total) AS total_depense,
    AVG(total) AS moyenne_commande
FROM commandes
GROUP BY client_id;

-- Index sur la vue
CREATE INDEX idx_stats_clients ON stats_clients(client_id);

-- Utilisation (tr√®s rapide)
SELECT * FROM stats_clients WHERE client_id = 123;

-- Rafra√Æchissement (quand n√©cessaire)
REFRESH MATERIALIZED VIEW CONCURRENTLY stats_clients;
```

**Avantages** :
- ‚úÖ Requ√™te instantan√©e (donn√©es pr√©-calcul√©es)
- ‚úÖ Pas de recalcul √† chaque fois

**Inconv√©nients** :
- ‚ùå Donn√©es pas en temps r√©el
- ‚ùå N√©cessite rafra√Æchissement manuel ou planifi√©

### 12.3. Utiliser FILTER pour Agr√©gations Conditionnelles

#### Sous-Optimal : CASE dans l'Agr√©gation

```sql
SELECT
    client_id,
    SUM(CASE WHEN statut = 'valid√©' THEN total ELSE 0 END) AS total_valide,
    SUM(CASE WHEN statut = 'annul√©' THEN total ELSE 0 END) AS total_annule
FROM commandes
GROUP BY client_id;
```

#### Optimal : FILTER Clause

```sql
SELECT
    client_id,
    SUM(total) FILTER (WHERE statut = 'valid√©') AS total_valide,
    SUM(total) FILTER (WHERE statut = 'annul√©') AS total_annule
FROM commandes
GROUP BY client_id;
```

**Avantages** :
- ‚úÖ Plus lisible
- ‚úÖ L√©g√®rement plus performant

### 12.4. Window Functions vs Sous-Requ√™tes

#### Sous-Optimal : Sous-Requ√™te pour Chaque Calcul

```sql
SELECT
    id,
    total,
    (SELECT AVG(total) FROM commandes) AS moyenne_globale,
    (SELECT MAX(total) FROM commandes) AS max_global
FROM commandes;
```

**Probl√®me** : Sous-requ√™tes r√©p√©t√©es.

#### Optimal : Window Functions

```sql
SELECT
    id,
    total,
    AVG(total) OVER () AS moyenne_globale,
    MAX(total) OVER () AS max_global
FROM commandes;
```

**Avantages** :
- ‚úÖ Un seul scan de la table
- ‚úÖ Plus efficace

### 12.5. Limiter les Agr√©gations avec HAVING

```sql
-- Agr√©gation puis filtrage
SELECT client_id, COUNT(*) AS nb
FROM commandes
GROUP BY client_id
HAVING COUNT(*) > 10;
```

**Optimal** : Le planificateur filtre efficacement apr√®s l'agr√©gation.

---

## 13. PostgreSQL 18 : Nouveaut√©s d'Optimisation

### 13.1. Skip Scan pour Index Multi-Colonnes

**Description** : Permet d'utiliser un index multi-colonnes m√™me sans filtrer la premi√®re colonne.

**Avant PostgreSQL 18** :
```sql
CREATE INDEX idx_ventes_region_date ON ventes(region, date_vente);

-- Index NON utilis√©
SELECT * FROM ventes WHERE date_vente = '2025-01-01';
```

**PostgreSQL 18** :
```sql
-- Index UTILIS√â avec Skip Scan
SELECT * FROM ventes WHERE date_vente = '2025-01-01';
```

**D√©tection dans EXPLAIN** :
```
Index Skip Scan using idx_ventes_region_date on ventes
  Skip Cond: (date_vente = '2025-01-01'::date)
```

**Impact** : R√©duit le besoin de cr√©er des index redondants.

### 13.2. Optimisation OR ‚Üí ANY

**Description** : Transformation automatique des OR en ANY pour permettre l'utilisation d'index.

**Avant PostgreSQL 18** :
```sql
-- Seq Scan (OR emp√™che index)
SELECT * FROM produits WHERE id = 1 OR id = 2 OR id = 3;
```

**PostgreSQL 18** :
```sql
-- Transformation automatique en :
SELECT * FROM produits WHERE id = ANY(ARRAY[1, 2, 3]);
-- Index Scan possible
```

**Pas de changement de code n√©cessaire** : Optimisation automatique.

### 13.3. Auto-√âlimination des Self-Joins

**Description** : Le planificateur d√©tecte et √©limine les self-joins inutiles.

**Exemple** :
```sql
-- Requ√™te avec self-join redondant
SELECT e1.nom, e1.salaire
FROM employes e1
JOIN employes e2 ON e1.id = e2.id
WHERE e1.salaire > 50000;
```

**PostgreSQL 18** : Simplifie automatiquement en :
```sql
SELECT nom, salaire FROM employes WHERE salaire > 50000;
```

**D√©tection dans EXPLAIN** :
```
-- Message dans les logs du planificateur
-- "Self-join eliminated"
```

### 13.4. R√©organisation Automatique des DISTINCT

**Description** : Optimise les requ√™tes avec plusieurs DISTINCT.

**Exemple** :
```sql
SELECT DISTINCT ON (client_id, produit_id) *
FROM ventes
ORDER BY client_id, produit_id, date_vente DESC;
```

**PostgreSQL 18** : R√©organise automatiquement pour utiliser les index efficacement.

### 13.5. EXPLAIN Enrichi

**Nouvelles m√©triques** :
- Statistiques I/O par op√©ration
- G√©n√©ration WAL
- Temps par phase
- Buffers automatiquement affich√©s

```sql
-- PostgreSQL 18
EXPLAIN (ANALYZE) SELECT ...;

-- Affiche automatiquement :
-- I/O Read Time
-- I/O Write Time
-- WAL Bytes
-- Local Buffers
```

---

## 14. Monitoring en Production

### 14.1. M√©triques Cl√©s √† Surveiller

#### M√©trique 1 : Temps de R√©ponse Moyen

```sql
SELECT
    ROUND(mean_exec_time::numeric, 2) AS avg_response_ms
FROM pg_stat_statements
WHERE query LIKE '%SELECT%'
ORDER BY mean_exec_time DESC
LIMIT 1;
```

**Alerte** : Si > 100 ms pour requ√™tes simples.

#### M√©trique 2 : Requ√™tes Lentes (> 1 sec)

```sql
SELECT COUNT(*)
FROM pg_stat_statements
WHERE mean_exec_time > 1000;
```

**Alerte** : Si > 10 requ√™tes lentes.

#### M√©trique 3 : Charge Globale (Temps CPU)

```sql
SELECT
    SUM(total_exec_time) AS total_query_time_ms
FROM pg_stat_statements;
```

**Utilisation** : Suivre l'√©volution dans le temps.

#### M√©trique 4 : Requ√™tes Actives

```sql
SELECT COUNT(*)
FROM pg_stat_activity
WHERE state = 'active'
  AND query NOT LIKE '%pg_stat_activity%';
```

**Alerte** : Si > `max_connections √ó 0.8`.

#### M√©trique 5 : Requ√™tes Bloqu√©es

```sql
SELECT COUNT(*)
FROM pg_stat_activity
WHERE wait_event_type IS NOT NULL
  AND state = 'active';
```

**Alerte** : Si > 0 pendant longtemps.

### 14.2. Alertes Recommand√©es

**Prometheus + Alertmanager** :

```yaml
# Requ√™tes lentes
- alert: SlowQueries
  expr: pg_stat_statements_mean_exec_time_seconds > 1
  for: 5m
  annotations:
    summary: "Requ√™tes lentes d√©tect√©es"

# Connexions satur√©es
- alert: ConnectionsSaturated
  expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
  for: 5m
  annotations:
    summary: "Connexions proches de la limite"
```

### 14.3. Dashboards (Grafana)

**Panels recommand√©s** :
- Temps de r√©ponse moyen (temps s√©rie)
- Top 10 requ√™tes les plus lentes
- Nombre de requ√™tes actives
- Nombre de connexions
- Cache hit ratio
- Locks actifs

**Template Grafana** : https://grafana.com/grafana/dashboards/9628

### 14.4. Logs et Analyse Continue

**Configuration logs** :
```sql
ALTER SYSTEM SET log_min_duration_statement = 1000;  -- 1 sec
ALTER SYSTEM SET log_line_prefix = '%t [%p]: user=%u,db=%d,app=%a ';
ALTER SYSTEM SET log_lock_waits = on;
```

**Analyse quotidienne avec pgBadger** :
```bash
# Script cron quotidien
pgbadger /var/log/postgresql/postgresql-$(date -d yesterday +%Y-%m-%d).log \
    -o /var/www/reports/pgbadger-$(date -d yesterday +%Y-%m-%d).html
```

---

## 15. Checklist d'Audit Compl√®te

### 15.1. Phase 1 : Pr√©paration

- [ ] Installer `pg_stat_statements`
- [ ] Configurer `auto_explain`
- [ ] Activer logs avec `log_min_duration_statement`
- [ ] Configurer monitoring (Prometheus/Grafana)
- [ ] Documenter l'architecture et les tables principales

### 15.2. Phase 2 : Collecte de Donn√©es

- [ ] Collecter statistiques pendant 1-7 jours (`pg_stat_statements`)
- [ ] G√©n√©rer rapport pgBadger
- [ ] Exporter les m√©triques de performance
- [ ] Identifier les heures de pointe

### 15.3. Phase 3 : Identification des Requ√™tes Probl√©matiques

- [ ] Top 20 requ√™tes les plus lentes (moyenne)
- [ ] Top 20 requ√™tes les plus co√ªteuses (temps total)
- [ ] Requ√™tes avec forte variabilit√©
- [ ] Requ√™tes g√©n√©rant beaucoup de WAL
- [ ] Requ√™tes avec locks fr√©quents

### 15.4. Phase 4 : Analyse D√©taill√©e

Pour chaque requ√™te probl√©matique :

- [ ] Ex√©cuter `EXPLAIN (ANALYZE, BUFFERS)`
- [ ] Identifier le type de scan (Seq Scan sur grande table ?)
- [ ] V√©rifier utilisation des index
- [ ] Mesurer cache hit ratio
- [ ] D√©tecter sous-requ√™tes corr√©l√©es
- [ ] Rechercher N+1 patterns

### 15.5. Phase 5 : Optimisation

- [ ] Cr√©er index manquants
- [ ] R√©√©crire requ√™tes inefficaces
- [ ] Impl√©menter eager loading (anti N+1)
- [ ] Ajouter LIMIT/pagination
- [ ] Optimiser jointures
- [ ] Remplacer sous-requ√™tes par CTE/JOIN

### 15.6. Phase 6 : Validation

- [ ] Mesurer performances avant/apr√®s
- [ ] V√©rifier plans d'ex√©cution (EXPLAIN)
- [ ] Tester en environnement de staging
- [ ] Valider sous charge (load testing)
- [ ] V√©rifier pas de r√©gression sur autres requ√™tes

### 15.7. Phase 7 : Documentation

- [ ] Documenter chaque optimisation
- [ ] Cr√©er runbook pour requ√™tes critiques
- [ ] D√©finir SLA par type de requ√™te
- [ ] Partager best practices avec l'√©quipe

### 15.8. Phase 8 : Monitoring Continu

- [ ] Mettre en place alertes
- [ ] Planifier audits r√©guliers (mensuel/trimestriel)
- [ ] Suivre √©volution des m√©triques
- [ ] R√©viser strat√©gie selon croissance

---

## 16. Cas Pratiques d'Optimisation

### 16.1. Cas 1 : Tableau de Bord Lent

#### Probl√®me Initial

**Requ√™te** :
```sql
-- Temps : 15 secondes
SELECT
    c.nom,
    COUNT(cmd.id) AS nb_commandes,
    SUM(cmd.total) AS total_depense
FROM clients c
LEFT JOIN commandes cmd ON cmd.client_id = c.id
WHERE cmd.date_commande > CURRENT_DATE - INTERVAL '30 days'
GROUP BY c.id, c.nom
ORDER BY total_depense DESC
LIMIT 10;
```

**EXPLAIN montre** :
- `Seq Scan` sur `commandes`
- `HashAggregate` co√ªteux
- Tri (`Sort`) sur disque (external merge)

#### Optimisations Appliqu√©es

**1. Index sur date_commande** :
```sql
CREATE INDEX idx_commandes_date ON commandes(date_commande);
```

**2. Index composite** :
```sql
CREATE INDEX idx_commandes_client_date ON commandes(client_id, date_commande);
```

**3. R√©√©criture avec CTE** :
```sql
WITH recent_sales AS (
    SELECT client_id, COUNT(*) AS nb, SUM(total) AS total
    FROM commandes
    WHERE date_commande > CURRENT_DATE - INTERVAL '30 days'
    GROUP BY client_id
)
SELECT c.nom, rs.nb AS nb_commandes, rs.total AS total_depense
FROM recent_sales rs
JOIN clients c ON c.id = rs.client_id
ORDER BY rs.total DESC
LIMIT 10;
```

**4. Augmenter work_mem** (si tri sur disque) :
```sql
SET work_mem = '256MB';
```

#### R√©sultat

**Temps apr√®s optimisation** : 0.2 secondes (75√ó plus rapide).

### 16.2. Cas 2 : Recherche Produits Lente

#### Probl√®me Initial

**Requ√™te** :
```sql
-- Temps : 5 secondes
SELECT *
FROM produits
WHERE lower(nom) LIKE '%postgresql%'
   OR lower(description) LIKE '%postgresql%';
```

**EXPLAIN montre** :
- `Seq Scan` (pas d'index utilisable)
- Fonction `lower()` emp√™che utilisation index

#### Optimisations Appliqu√©es

**1. Full-Text Search avec GIN** :
```sql
-- Ajouter colonne tsvector
ALTER TABLE produits ADD COLUMN search_vector tsvector;

-- Calculer le vecteur
UPDATE produits SET search_vector =
    to_tsvector('french', coalesce(nom, '') || ' ' || coalesce(description, ''));

-- Index GIN
CREATE INDEX idx_produits_search ON produits USING gin(search_vector);

-- Trigger pour maintenir √† jour
CREATE TRIGGER produits_search_update
BEFORE INSERT OR UPDATE ON produits
FOR EACH ROW EXECUTE FUNCTION
    tsvector_update_trigger(search_vector, 'pg_catalog.french', nom, description);
```

**2. Requ√™te optimis√©e** :
```sql
SELECT *
FROM produits
WHERE search_vector @@ to_tsquery('french', 'postgresql');
```

#### R√©sultat

**Temps apr√®s optimisation** : 0.05 secondes (100√ó plus rapide).

### 16.3. Cas 3 : Rapport Mensuel Tr√®s Lent

#### Probl√®me Initial

**Requ√™te** :
```sql
-- Temps : 120 secondes (2 minutes)
SELECT
    DATE_TRUNC('day', date_commande) AS jour,
    COUNT(*) AS nb_commandes,
    SUM(total) AS chiffre_affaire,
    AVG(total) AS panier_moyen
FROM commandes
WHERE date_commande >= '2025-01-01'
  AND date_commande < '2025-02-01'
GROUP BY DATE_TRUNC('day', date_commande)
ORDER BY jour;
```

**EXPLAIN montre** :
- `Seq Scan` sur 100 millions de lignes
- Agr√©gation co√ªteuse

#### Optimisations Appliqu√©es

**1. Index BRIN sur date** (donn√©es s√©quentielles) :
```sql
CREATE INDEX idx_commandes_date_brin ON commandes USING brin(date_commande);
```

**2. Vue mat√©rialis√©e pour statistiques quotidiennes** :
```sql
CREATE MATERIALIZED VIEW stats_quotidiennes AS
SELECT
    DATE_TRUNC('day', date_commande) AS jour,
    COUNT(*) AS nb_commandes,
    SUM(total) AS chiffre_affaire,
    AVG(total) AS panier_moyen
FROM commandes
GROUP BY DATE_TRUNC('day', date_commande);

CREATE INDEX idx_stats_jour ON stats_quotidiennes(jour);

-- Rafra√Æchissement quotidien (cron ou pg_cron)
REFRESH MATERIALIZED VIEW CONCURRENTLY stats_quotidiennes;
```

**3. Requ√™te sur la vue** :
```sql
-- Temps : 0.01 secondes
SELECT * FROM stats_quotidiennes
WHERE jour >= '2025-01-01' AND jour < '2025-02-01'
ORDER BY jour;
```

#### R√©sultat

**Temps apr√®s optimisation** : 0.01 secondes (12000√ó plus rapide).

### 16.4. Cas 4 : N+1 dans API REST

#### Probl√®me Initial

**Code API (Python/Flask)** :
```python
@app.route('/api/clients')
def get_clients():
    clients = Client.query.all()  # Requ√™te 1
    result = []
    for client in clients:
        result.append({
            'id': client.id,
            'nom': client.nom,
            'nb_commandes': len(client.commandes),  # Requ√™te N (lazy load)
            'total_depense': sum(c.total for c in client.commandes)
        })
    return jsonify(result)
```

**Probl√®me** : 1 + N requ√™tes (N = nombre de clients).

#### Optimisation

**Eager loading avec joinedload** :
```python
@app.route('/api/clients')
def get_clients():
    # 1 seule requ√™te avec JOIN
    clients = Client.query.options(joinedload(Client.commandes)).all()
    result = []
    for client in clients:
        result.append({
            'id': client.id,
            'nom': client.nom,
            'nb_commandes': len(client.commandes),  # Pas de requ√™te
            'total_depense': sum(c.total for c in client.commandes)
        })
    return jsonify(result)
```

**Ou mieux : Agr√©gation en SQL** :
```python
@app.route('/api/clients')
def get_clients():
    results = db.session.query(
        Client.id,
        Client.nom,
        func.count(Commande.id).label('nb_commandes'),
        func.sum(Commande.total).label('total_depense')
    ).outerjoin(Commande).group_by(Client.id).all()

    return jsonify([{
        'id': r.id,
        'nom': r.nom,
        'nb_commandes': r.nb_commandes or 0,
        'total_depense': r.total_depense or 0
    } for r in results])
```

#### R√©sultat

**Temps de r√©ponse API** : 3 secondes ‚Üí 0.3 secondes (10√ó plus rapide).

---

## 17. Conclusion et Bonnes Pratiques

### 17.1. Les 15 R√®gles d'Or de l'Audit de Requ√™tes

#### 1. Mesurez Avant d'Optimiser
**R√®gle** : Toujours mesurer les performances avant et apr√®s optimisation.

**Outil** : `EXPLAIN (ANALYZE, BUFFERS)` + `pg_stat_statements`.

#### 2. Utilisez pg_stat_statements
**R√®gle** : Installez et activez `pg_stat_statements` sur toute base de production.

**Avantage** : Visibilit√© compl√®te sur toutes les requ√™tes.

#### 3. Analysez les Plans d'Ex√©cution
**R√®gle** : Pour toute requ√™te lente, regardez le plan avec `EXPLAIN ANALYZE`.

**Focus** : Types de scans, jointures, sorts.

#### 4. Indexez Intelligemment
**R√®gle** : Cr√©ez des index sur les colonnes fr√©quemment filtr√©es, tri√©es ou jointes.

**Attention** : Pas trop d'index (p√©nalise les √©critures).

#### 5. √âvitez les Sous-Requ√™tes Corr√©l√©es
**R√®gle** : Remplacez par JOIN, CTE ou window functions.

**Gain** : Souvent 10√ó √† 100√ó plus rapide.

#### 6. Combattez le N+1
**R√®gle** : Utilisez eager loading dans les ORM.

**D√©tection** : Beaucoup d'appels de la m√™me requ√™te dans `pg_stat_statements`.

#### 7. Limitez les R√©sultats
**R√®gle** : Utilisez `LIMIT` et pagination.

**√âvitez** : `SELECT *` sans limite sur grandes tables.

#### 8. Filtrez T√¥t
**R√®gle** : Appliquez les filtres `WHERE` avant les jointures.

**Note** : PostgreSQL optimise souvent automatiquement (predicate pushdown).

#### 9. Pr√©parez les Requ√™tes R√©p√©t√©es
**R√®gle** : Utilisez `PREPARE` ou prepared statements dans les drivers.

**Gain** : √âlimine le parsing r√©p√©t√©.

#### 10. Surveillez les Statistiques
**R√®gle** : Ex√©cutez `ANALYZE` r√©guli√®rement (ou configurez autovacuum correctement).

**Sympt√¥me** : Estimations tr√®s diff√©rentes de la r√©alit√© dans EXPLAIN.

#### 11. Optimisez work_mem
**R√®gle** : Augmentez `work_mem` si vous voyez des tris "external merge" (disque).

**Formule** : `work_mem = RAM / (max_connections √ó 3)`.

#### 12. Utilisez les CTEs Judicieusement
**R√®gle** : CTE pour lisibilit√©, mais attention √† la mat√©rialisation.

**PostgreSQL 12+** : Contr√¥lez avec `MATERIALIZED` / `NOT MATERIALIZED`.

#### 13. Profilez en Production
**R√®gle** : Utilisez `auto_explain` pour capturer passivement les requ√™tes lentes.

**Config** : `auto_explain.log_min_duration = 1000` (1 sec).

#### 14. Documentez les Optimisations
**R√®gle** : Documentez pourquoi chaque requ√™te a √©t√© optimis√©e.

**Utilit√©** : √âvite les r√©gressions futures, facilite la maintenance.

#### 15. Auditez R√©guli√®rement
**R√®gle** : Audit mensuel ou trimestriel selon criticit√©.

**√âvolution** : Les patterns d'acc√®s changent avec le temps.

### 17.2. Checklist Rapide

**Avant de d√©ployer une nouvelle fonctionnalit√©** :
- [ ] Testez les nouvelles requ√™tes avec `EXPLAIN ANALYZE`
- [ ] V√©rifiez l'absence de N+1
- [ ] Validez la pr√©sence des index n√©cessaires
- [ ] Testez sous charge (load testing)
- [ ] Configurez monitoring et alertes

**Audit mensuel** :
- [ ] Top 20 requ√™tes les plus lentes
- [ ] Identifier nouveaux patterns N+1
- [ ] V√©rifier croissance des temps de r√©ponse
- [ ] Analyser rapport pgBadger
- [ ] Mettre √† jour documentation

**Investigation d'un probl√®me de performance** :
- [ ] Identifier la requ√™te probl√©matique (`pg_stat_activity`)
- [ ] Analyser le plan (`EXPLAIN ANALYZE`)
- [ ] V√©rifier les statistiques (`ANALYZE`)
- [ ] Tester optimisations en staging
- [ ] D√©ployer et mesurer

### 17.3. PostgreSQL 18 : Points Cl√©s

Les nouveaut√©s PostgreSQL 18 facilitent l'optimisation :

1. **Skip Scan** : Moins d'index redondants n√©cessaires
2. **Optimisation OR‚ÜíANY** : Requ√™tes avec OR automatiquement optimis√©es
3. **Auto-√©limination self-joins** : Simplification automatique
4. **EXPLAIN enrichi** : Meilleure observabilit√©

**Action** : Auditez vos requ√™tes apr√®s migration vers PostgreSQL 18 pour b√©n√©ficier des optimisations automatiques.

### 17.4. Outils Recommand√©s

**Analyse** :
- pg_stat_statements (essentiel)
- EXPLAIN ANALYZE (quotidien)
- pgBadger (hebdomadaire/mensuel)

**Monitoring** :
- Prometheus + postgres_exporter
- Grafana (dashboards)
- auto_explain (capture passive)

**Testing** :
- pgbench (load testing)
- HypoPG (test d'index)

### 17.5. Ressources Compl√©mentaires

#### Documentation
- **PostgreSQL 18 Performance** : https://www.postgresql.org/docs/18/performance-tips.html
- **EXPLAIN** : https://www.postgresql.org/docs/18/using-explain.html

#### Livres
- *PostgreSQL Query Performance Tuning* par Henrietta Dombrovskaya
- *High Performance PostgreSQL for Rails* par Andrew Atkinson

#### Communaut√©s
- Reddit : r/PostgreSQL
- Slack : postgres.slack.com
- Discord : PostgreSQL Community

---

## Conclusion Finale

L'audit de requ√™tes est un **processus continu** qui n√©cessite :
- **Discipline** : Audits r√©guliers
- **Outils** : pg_stat_statements, EXPLAIN, monitoring
- **Expertise** : Compr√©hension du planificateur PostgreSQL
- **Collaboration** : Entre d√©veloppeurs et DBAs

**Les requ√™tes optimis√©es** sont la cl√© de la performance d'une application PostgreSQL. Investissez du temps dans l'audit et l'optimisation, les gains sont souvent **spectaculaires** (10√ó √† 1000√ó plus rapide).

Avec **PostgreSQL 18**, le planificateur est plus intelligent que jamais. Mais comprendre comment il fonctionne reste **essentiel** pour √©crire des requ√™tes efficaces et diagnostiquer les probl√®mes.

**Derni√®re recommandation** : **Commencez simple**. Optimisez d'abord les requ√™tes les plus lentes ou les plus fr√©quentes. L'impact sera maximal avec un effort minimal.

---


‚è≠Ô∏è [Audit de sch√©ma](/annexes/checklist-performance/04-audit-schema.md)
