üîù Retour au [Sommaire](/SOMMAIRE.md)

# 18.5. TimescaleDB : S√©ries temporelles et hypertables

## Introduction

TimescaleDB est l'une des extensions les plus populaires et puissantes de PostgreSQL. Elle transforme PostgreSQL en une base de donn√©es optimis√©e pour les **s√©ries temporelles** (time-series data), tout en conservant toute la puissance et la flexibilit√© du SQL standard. Ce chapitre vous expliquera comment TimescaleDB fonctionne et comment l'utiliser efficacement.

---

## Qu'est-ce qu'une S√©rie Temporelle ?

### D√©finition Simple

Une **s√©rie temporelle** est une s√©quence de donn√©es index√©es dans le temps. Autrement dit, ce sont des donn√©es qui √©voluent au fil du temps et dont l'ordre temporel est crucial.

### Exemples Concrets de S√©ries Temporelles

**Dans le monde r√©el, les s√©ries temporelles sont partout** :

1. **Monitoring IT et DevOps**
   - Utilisation CPU, RAM, disque toutes les 10 secondes
   - Temps de r√©ponse HTTP de vos serveurs
   - Nombre de requ√™tes par minute sur une API
   - Logs d'application avec timestamp

2. **IoT (Internet des Objets)**
   - Temp√©rature et humidit√© d'un capteur m√©t√©o toutes les minutes
   - Position GPS d'un v√©hicule toutes les secondes
   - Consommation √©lectrique d'un b√¢timent toutes les 15 minutes
   - Battements cardiaques d'une montre connect√©e

3. **Finance et Trading**
   - Prix d'une action boursi√®re toutes les millisecondes
   - Taux de change EUR/USD toutes les secondes
   - Transactions par carte bancaire avec timestamp
   - Cours des cryptomonnaies

4. **E-commerce et Analytics**
   - Visites sur un site web par heure
   - Ventes journali√®res d'un produit
   - Clics sur une publicit√©
   - Sessions utilisateurs

5. **Industrie et Machines**
   - Vibrations d'une machine toutes les 100ms
   - Pression dans une canalisation
   - Vitesse de rotation d'un moteur
   - Production d'une usine par heure

### Caract√©ristiques Communes

Les s√©ries temporelles partagent g√©n√©ralement ces propri√©t√©s :

‚úÖ **Horodatage obligatoire** : Chaque mesure a un timestamp
‚úÖ **Insertion majoritaire** : 95%+ des op√©rations sont des INSERT
‚úÖ **Lecture par plages temporelles** : "Donn√©es des 7 derniers jours"
‚úÖ **Volume √©lev√©** : Des millions √† des milliards de points de donn√©es
‚úÖ **Donn√©es r√©centes = plus importantes** : Les donn√©es anciennes sont moins consult√©es
‚úÖ **Agr√©gations temporelles fr√©quentes** : Moyennes par heure, sommes par jour, etc.

---

## Pourquoi PostgreSQL Standard N'est Pas Optimal ?

### Les Limites de PostgreSQL pour les S√©ries Temporelles

PostgreSQL est excellent pour les charges de travail g√©n√©riques, mais il rencontre des d√©fis avec les s√©ries temporelles massives :

#### 1. Performance d'Insertion

**Probl√®me** : Ins√©rer des millions de lignes par minute dans une table unique devient lent.

```sql
-- Table PostgreSQL classique
CREATE TABLE sensor_data (
    time TIMESTAMPTZ NOT NULL,
    sensor_id INTEGER NOT NULL,
    temperature NUMERIC,
    humidity NUMERIC
);

-- Apr√®s quelques milliards de lignes, les INSERT ralentissent consid√©rablement
-- Index B-Tree devient √©norme et co√ªteux √† maintenir
```

#### 2. Requ√™tes par Plage Temporelle

**Probl√®me** : Interroger une plage de temps sp√©cifique n√©cessite de scanner toute la table ou un index massif.

```sql
-- Requ√™te typique : donn√©es des 7 derniers jours
SELECT AVG(temperature)
FROM sensor_data
WHERE time > NOW() - INTERVAL '7 days';

-- PostgreSQL doit scanner l'index entier ou une grande partie de la table
-- M√™me avec un index sur 'time', c'est inefficace sur des milliards de lignes
```

#### 3. Maintenance et R√©tention des Donn√©es

**Probl√®me** : Supprimer les donn√©es anciennes (data retention) est co√ªteux.

```sql
-- Supprimer les donn√©es de plus de 1 an
DELETE FROM sensor_data
WHERE time < NOW() - INTERVAL '1 year';

-- Cette op√©ration peut prendre des heures et verrouiller la table
-- G√©n√®re beaucoup de bloat (espace mort) n√©cessitant un VACUUM
```

#### 4. Taille de la Table et des Index

**Probl√®me** : Tables et index deviennent gigantesques, affectant toutes les op√©rations.

```
Table sensor_data : 500 GB
Index on (time) : 100 GB
Index on (sensor_id, time) : 120 GB
Total : 720 GB en m√©moire pour √™tre performant
```

### Le Besoin d'une Solution Sp√©cialis√©e

C'est exactement pourquoi **TimescaleDB** existe : optimiser PostgreSQL pour ces cas d'usage sp√©cifiques.

---

## Pr√©sentation de TimescaleDB

### Qu'est-ce que TimescaleDB ?

**TimescaleDB** est une extension open-source de PostgreSQL qui ajoute :

- ‚úÖ **Partitionnement automatique** par temps (chunking)
- ‚úÖ **Compression native** des donn√©es anciennes
- ‚úÖ **Fonctions de s√©ries temporelles** (agr√©gations, interpolation, etc.)
- ‚úÖ **R√©tention automatique** des donn√©es (data retention policies)
- ‚úÖ **Continuous Aggregates** (vues mat√©rialis√©es incr√©mentales)
- ‚úÖ **Support distribu√©** (TimescaleDB Distributed) pour le scale-out

### Architecture : L'Extension Intelligente

TimescaleDB ne remplace pas PostgreSQL, **il l'augmente** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Votre Application              ‚îÇ
‚îÇ      (utilise du SQL normal)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îÇ SQL Standard
               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         TimescaleDB                 ‚îÇ
‚îÇ  (extension PostgreSQL)             ‚îÇ
‚îÇ  - Hypertables                      ‚îÇ
‚îÇ  - Compression                      ‚îÇ
‚îÇ  - Fonctions time-series            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       PostgreSQL Core               ‚îÇ
‚îÇ  - ACID, transactions               ‚îÇ
‚îÇ  - Index, contraintes               ‚îÇ
‚îÇ  - JOINs, fonctions                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Avantages majeurs** :

- üéØ Vous utilisez du SQL standard (aucun nouveau langage √† apprendre)
- üéØ Compatible avec tous les outils PostgreSQL (psql, pgAdmin, drivers)
- üéØ Toutes les fonctionnalit√©s PostgreSQL restent disponibles
- üéØ Performances 10x √† 100x meilleures pour les s√©ries temporelles

### Versions et Licences

**TimescaleDB Community (Apache 2.0)** :
- Gratuit et open-source
- Hypertables, compression, continuous aggregates
- Parfait pour la plupart des cas d'usage

**TimescaleDB Enterprise** :
- Fonctionnalit√©s avanc√©es (multi-node, replication policies)
- Support commercial

**TimescaleDB Cloud** :
- Service manag√© (SaaS)
- H√©berg√© et g√©r√© par Timescale

---

## Le Concept d'Hypertable

### Qu'est-ce qu'une Hypertable ?

Une **hypertable** est l'abstraction centrale de TimescaleDB. C'est une table PostgreSQL normale vue de l'ext√©rieur, mais qui est automatiquement partitionn√©e en **chunks** (morceaux) en coulisses.

### Visualisation : Table Normale vs Hypertable

#### Table PostgreSQL Standard

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          sensor_data                      ‚îÇ
‚îÇ  (Une seule table, tous les temps)        ‚îÇ
‚îÇ                                           ‚îÇ
‚îÇ  2023-01-01 ... 2025-11-22                ‚îÇ
‚îÇ  5 milliards de lignes                    ‚îÇ
‚îÇ  500 GB                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Probl√®me** : Toutes les donn√©es dans une seule structure monumentale.

#### Hypertable TimescaleDB

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         sensor_data (Hypertable)                    ‚îÇ
‚îÇ         Vue logique unifi√©e                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ             ‚îÇ             ‚îÇ            ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Chunk 1 ‚îÇ  ‚îÇ Chunk 2 ‚îÇ   ‚îÇ Chunk 3 ‚îÇ   ‚îÇ Chunk 4 ‚îÇ
   ‚îÇ Nov 15  ‚îÇ  ‚îÇ Nov 16  ‚îÇ   ‚îÇ Nov 17  ‚îÇ   ‚îÇ Nov 18  ‚îÇ
   ‚îÇ 10M row ‚îÇ  ‚îÇ 11M row ‚îÇ   ‚îÇ 10M row ‚îÇ   ‚îÇ  9M row ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì            ‚Üì              ‚Üì              ‚Üì
   Compression   Compression      Active         Active
    (20:1)        (20:1)      (non compress√©) (non compress√©)
```

**Avantages** :

1. **Insertion rapide** : Seulement dans le chunk actif (r√©cent)
2. **Requ√™tes efficaces** : Seuls les chunks concern√©s sont lus
3. **Compression s√©lective** : Chunks anciens compress√©s, r√©cents non
4. **Suppression rapide** : Suppression d'un chunk entier = DROP TABLE (instantan√©)
5. **Maintenance l√©g√®re** : VACUUM/REINDEX op√®re chunk par chunk

### Partitionnement Automatique par Temps

TimescaleDB cr√©e automatiquement des chunks bas√©s sur un **intervalle de temps** que vous d√©finissez :

**Exemples d'intervalles** :

- Donn√©es tr√®s fr√©quentes (IoT, logs) : **1 jour par chunk**
- Donn√©es mod√©r√©es (metrics) : **7 jours par chunk**
- Donn√©es √©parses (analytics) : **1 mois par chunk**

```sql
-- Cr√©ation d'une hypertable avec chunks de 7 jours
SELECT create_hypertable('sensor_data', by_range('time'), chunk_time_interval => INTERVAL '7 days');
```

TimescaleDB :
- ‚úÖ Cr√©e automatiquement les chunks au fur et √† mesure
- ‚úÖ Route les INSERT vers le bon chunk
- ‚úÖ Optimise les SELECT pour ne lire que les chunks n√©cessaires
- ‚úÖ Applique la compression sur les chunks anciens

---

## Installation de TimescaleDB

### Pr√©requis

- PostgreSQL 12, 13, 14, 15, 16, 17 ou 18
- Droits d'administration syst√®me (pour installer l'extension)
- Droits de superutilisateur PostgreSQL (pour activer l'extension)

### Installation sur Ubuntu/Debian

```bash
# 1. Ajouter le d√©p√¥t Timescale
sudo sh -c "echo 'deb https://packagecloud.io/timescale/timescaledb/ubuntu/ $(lsb_release -c -s) main' > /etc/apt/sources.list.d/timescaledb.list"

# 2. Importer la cl√© GPG
wget --quiet -O - https://packagecloud.io/timescale/timescaledb/gpgkey | sudo apt-key add -

# 3. Mettre √† jour et installer
sudo apt update
sudo apt install timescaledb-2-postgresql-18

# 4. Configurer TimescaleDB (recommand√©)
sudo timescaledb-tune --quiet --yes

# 5. Red√©marrer PostgreSQL
sudo systemctl restart postgresql
```

### Installation sur Red Hat/CentOS/Fedora

```bash
# 1. Ajouter le d√©p√¥t
sudo tee /etc/yum.repos.d/timescale_timescaledb.repo <<EOL
[timescale_timescaledb]
name=timescale_timescaledb
baseurl=https://packagecloud.io/timescale/timescaledb/el/$(rpm -E %{rhel})/\$basearch
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/timescale/timescaledb/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
EOL

# 2. Installer
sudo yum install timescaledb-2-postgresql-18

# 3. Configurer
sudo timescaledb-tune --quiet --yes

# 4. Red√©marrer
sudo systemctl restart postgresql
```

### Installation sur macOS (Homebrew)

```bash
# Installer TimescaleDB
brew install timescaledb

# Configurer
timescaledb-tune --quiet --yes

# Red√©marrer PostgreSQL
brew services restart postgresql
```

### Installation avec Docker

```bash
# Pull de l'image officielle
docker pull timescale/timescaledb:latest-pg18

# Lancer un conteneur
docker run -d --name timescaledb \
  -p 5432:5432 \
  -e POSTGRES_PASSWORD=password \
  timescale/timescaledb:latest-pg18
```

### Configuration Manuelle (si timescaledb-tune non utilis√©)

√âditez `postgresql.conf` :

```ini
# Ajouter timescaledb au pr√©chargement
shared_preload_libraries = 'timescaledb'

# Recommandations TimescaleDB
max_background_workers = 16
max_parallel_workers = 8
```

**Red√©marrez PostgreSQL** apr√®s modification.

### Activation dans la Base de Donn√©es

```sql
-- Se connecter √† la base
psql -U postgres -d mydb

-- Activer l'extension
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- V√©rifier l'installation
\dx timescaledb
```

**R√©sultat attendu** :
```
Name        | Version | Schema  | Description
------------+---------+---------+--------------------------------
timescaledb | 2.15.0  | public  | Enables scalable inserts and...
```

---

## Cr√©er et Utiliser une Hypertable

### √âtape 1 : Cr√©er une Table Standard

Commencez par cr√©er une table PostgreSQL normale :

```sql
CREATE TABLE sensor_data (
    time TIMESTAMPTZ NOT NULL,
    sensor_id INTEGER NOT NULL,
    temperature NUMERIC(5,2),
    humidity NUMERIC(5,2),
    location TEXT
);
```

**Points importants** :

- ‚úÖ La colonne de temps doit √™tre de type `TIMESTAMP`, `TIMESTAMPTZ`, ou `DATE`
- ‚úÖ La colonne de temps doit avoir la contrainte `NOT NULL`
- ‚úÖ Il n'est pas n√©cessaire de d√©finir de cl√© primaire √† ce stade

### √âtape 2 : Convertir en Hypertable

```sql
-- Convertir la table en hypertable
SELECT create_hypertable('sensor_data', by_range('time'));
```

**Avec options** :

```sql
-- Sp√©cifier l'intervalle des chunks (d√©faut : 7 jours)
SELECT create_hypertable(
    'sensor_data',
    by_range('time'),
    chunk_time_interval => INTERVAL '1 day'
);

-- Avec partitionnement spatial suppl√©mentaire (optionnel)
SELECT create_hypertable(
    'sensor_data',
    by_range('time'),
    partitioning_column => 'sensor_id',
    number_partitions => 4,
    chunk_time_interval => INTERVAL '1 day'
);
```

**Explication des param√®tres** :

- `'sensor_data'` : Nom de la table √† convertir
- `by_range('time')` : Colonne de temps pour le partitionnement
- `chunk_time_interval` : Dur√©e de chaque chunk (1 jour, 7 jours, 1 mois, etc.)
- `partitioning_column` : Colonne suppl√©mentaire pour le partitionnement spatial (optionnel)
- `number_partitions` : Nombre de partitions spatiales (si partitionnement spatial)

### √âtape 3 : Utiliser comme une Table Normale

**Insertion de donn√©es** :

```sql
-- Insertion simple
INSERT INTO sensor_data (time, sensor_id, temperature, humidity, location)
VALUES
    (NOW(), 1, 22.5, 45.0, 'Room A'),
    (NOW(), 2, 23.1, 47.5, 'Room B');

-- Insertion en masse
INSERT INTO sensor_data (time, sensor_id, temperature, humidity, location)
SELECT
    NOW() - INTERVAL '1 hour' * generate_series(1, 10000),
    (random() * 100)::INTEGER,
    20 + (random() * 10)::NUMERIC(5,2),
    40 + (random() * 20)::NUMERIC(5,2),
    'Room ' || (random() * 10)::INTEGER;
```

**Requ√™tes SQL standard** :

```sql
-- Moyenne de temp√©rature par capteur sur les derni√®res 24h
SELECT
    sensor_id,
    AVG(temperature) AS avg_temp,
    COUNT(*) AS measurements
FROM sensor_data
WHERE time > NOW() - INTERVAL '24 hours'
GROUP BY sensor_id
ORDER BY avg_temp DESC;

-- √âvolution horaire
SELECT
    time_bucket('1 hour', time) AS hour,
    AVG(temperature) AS avg_temp,
    MAX(temperature) AS max_temp,
    MIN(temperature) AS min_temp
FROM sensor_data
WHERE time > NOW() - INTERVAL '7 days'
GROUP BY hour
ORDER BY hour DESC;
```

**L'hypertable se comporte comme une table PostgreSQL normale** : vous utilisez INSERT, SELECT, UPDATE, DELETE classiques.

### √âtape 4 : Ajouter des Index (Recommand√©)

```sql
-- Index sur le temps (cr√©√© automatiquement)
-- TimescaleDB cr√©e automatiquement un index sur la colonne de temps

-- Index composite pour am√©liorer les filtres fr√©quents
CREATE INDEX idx_sensor_time ON sensor_data (sensor_id, time DESC);

-- Index pour les recherches par localisation
CREATE INDEX idx_location ON sensor_data (location, time DESC);
```

**Bonnes pratiques d'indexation** :

- ‚úÖ Toujours inclure la colonne de temps dans les index composites
- ‚úÖ Utilisez `DESC` sur le temps si vous requ√™tez souvent les donn√©es r√©centes
- ‚úÖ N'ajoutez des index que sur les colonnes r√©ellement utilis√©es dans les WHERE

---

## Fonctions Sp√©cifiques aux S√©ries Temporelles

TimescaleDB ajoute des fonctions SQL puissantes pour les s√©ries temporelles.

### 1. time_bucket() : Agr√©gation Temporelle

`time_bucket()` regroupe les donn√©es par intervalles de temps r√©guliers. C'est comme `date_trunc()` mais plus flexible.

**Syntaxe** :
```sql
time_bucket(interval, timestamp_column)
```

**Exemples** :

```sql
-- Temp√©rature moyenne par heure
SELECT
    time_bucket('1 hour', time) AS hour,
    AVG(temperature) AS avg_temp
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 day'
GROUP BY hour
ORDER BY hour;

-- Comptage par intervalle de 5 minutes
SELECT
    time_bucket('5 minutes', time) AS bucket,
    COUNT(*) AS events
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 hour'
GROUP BY bucket
ORDER BY bucket DESC;

-- Par jour
SELECT
    time_bucket('1 day', time) AS day,
    sensor_id,
    MAX(temperature) - MIN(temperature) AS temp_range
FROM sensor_data
WHERE time > NOW() - INTERVAL '30 days'
GROUP BY day, sensor_id
ORDER BY day DESC;
```

**Alignement des buckets** :

```sql
-- Aligner les buckets sur une heure sp√©cifique (ex: 9h00)
SELECT
    time_bucket('1 hour', time, TIMESTAMPTZ '2025-01-01 09:00:00') AS hour,
    AVG(temperature)
FROM sensor_data
GROUP BY hour;
```

### 2. first() et last() : Premi√®re et Derni√®re Valeur

R√©cup√©rer la premi√®re ou derni√®re valeur dans un groupe temporel.

```sql
-- Premi√®re et derni√®re temp√©rature de chaque capteur par heure
SELECT
    time_bucket('1 hour', time) AS hour,
    sensor_id,
    first(temperature, time) AS first_temp,
    last(temperature, time) AS last_temp
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 day'
GROUP BY hour, sensor_id
ORDER BY hour DESC;
```

### 3. histogram() : Distribution de Valeurs

Cr√©er un histogramme de distribution.

```sql
-- Distribution des temp√©ratures en 10 buckets
SELECT histogram(temperature, 20.0, 30.0, 10)
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 day';
```

### 4. interpolate() : Interpolation Lin√©aire

Combler les valeurs manquantes par interpolation.

```sql
-- Cr√©er une s√©rie temporelle compl√®te avec interpolation
SELECT
    time_bucket_gapfill('5 minutes', time) AS bucket,
    sensor_id,
    interpolate(AVG(temperature)) AS temperature
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 hour'
  AND sensor_id = 1
GROUP BY bucket, sensor_id
ORDER BY bucket;
```

**Note** : `time_bucket_gapfill()` remplit les trous temporels et `interpolate()` calcule les valeurs manquantes.

### 5. Fonctions d'Agr√©gation Sp√©cialis√©es

```sql
-- Calculer des statistiques hypersp√©cifiques
SELECT
    time_bucket('1 hour', time) AS hour,
    approx_percentile(0.95, percentile_agg(temperature)) AS p95_temp,
    approx_percentile(0.99, percentile_agg(temperature)) AS p99_temp
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 day'
GROUP BY hour;
```

---

## Compression des Donn√©es

### Pourquoi Compresser ?

Les donn√©es de s√©ries temporelles sont hautement compressibles car :

- Les valeurs √©voluent graduellement (temp√©rature de 22.1¬∞C √† 22.2¬∞C)
- Les timestamps sont pr√©visibles (intervalles r√©guliers)
- Les m√©tadonn√©es se r√©p√®tent (m√™me sensor_id pendant des heures)

**Gains typiques** : 10x √† 20x de r√©duction de taille !

### Activer la Compression

#### √âtape 1 : D√©finir une Politique de Compression

```sql
-- Compresser les chunks de plus de 7 jours
ALTER TABLE sensor_data SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'sensor_id',
    timescaledb.compress_orderby = 'time DESC'
);
```

**Param√®tres** :

- `timescaledb.compress` : Active la compression sur la table
- `compress_segmentby` : Colonnes pour regrouper les donn√©es (ex: sensor_id, location)
- `compress_orderby` : Ordre de tri dans les segments compress√©s (g√©n√©ralement temps d√©croissant)

#### √âtape 2 : Ajouter une Politique Automatique

```sql
-- Compresser automatiquement apr√®s 7 jours
SELECT add_compression_policy('sensor_data', INTERVAL '7 days');
```

**Ce qui se passe** :

1. TimescaleDB ex√©cute r√©guli√®rement un job de compression
2. Les chunks de plus de 7 jours sont compress√©s automatiquement
3. Les donn√©es restent interrogeables normalement

### Compression Manuelle

```sql
-- Compresser un chunk sp√©cifique
SELECT compress_chunk('_timescaledb_internal._hyper_1_1_chunk');

-- Compresser tous les chunks avant une date
SELECT compress_chunk(i)
FROM show_chunks('sensor_data', older_than => INTERVAL '30 days') i;
```

### D√©compresser (si n√©cessaire)

```sql
-- D√©compresser un chunk pour permettre les UPDATE/DELETE
SELECT decompress_chunk('_timescaledb_internal._hyper_1_1_chunk');
```

**Note** : Les chunks compress√©s sont **en lecture seule**. Pour modifier des donn√©es, il faut d'abord d√©compresser.

### V√©rifier la Compression

```sql
-- Statistiques de compression
SELECT
    chunk_name,
    before_compression_total_bytes,
    after_compression_total_bytes,
    before_compression_total_bytes::FLOAT / after_compression_total_bytes AS compression_ratio
FROM chunk_compression_stats('sensor_data')
ORDER BY chunk_name;
```

**R√©sultat typique** :
```
chunk_name         | before_bytes | after_bytes | ratio
-------------------+--------------+-------------+-------
_hyper_1_1_chunk   | 536870912    | 26843545    | 20.0
_hyper_1_2_chunk   | 536870912    | 28932456    | 18.5
```

---

## R√©tention des Donn√©es (Data Retention)

### Le Probl√®me

Les s√©ries temporelles accumulent √©norm√©ment de donn√©es. Stocker ind√©finiment n'est pas viable :

- Co√ªt de stockage croissant
- Performances d√©grad√©es
- Donn√©es anciennes rarement consult√©es

### Solution : Politique de R√©tention

D√©finissez une dur√©e de conservation, apr√®s quoi les donn√©es sont automatiquement supprim√©es.

```sql
-- Supprimer automatiquement les donn√©es de plus de 90 jours
SELECT add_retention_policy('sensor_data', INTERVAL '90 days');
```

**Comment √ßa marche** :

- TimescaleDB ex√©cute un job p√©riodique (par d√©faut toutes les heures)
- Les chunks entiers plus anciens que la r√©tention sont **DROP**p√©s (suppression instantan√©e)
- Pas de VACUUM co√ªteux, pas de bloat

### Gestion des Politiques

```sql
-- Lister toutes les politiques sur une hypertable
SELECT * FROM timescaledb_information.jobs
WHERE hypertable_name = 'sensor_data';

-- Modifier une politique de r√©tention
SELECT alter_job(
    1001,  -- job_id (trouv√© ci-dessus)
    schedule_interval => INTERVAL '6 hours'
);

-- Supprimer une politique
SELECT remove_retention_policy('sensor_data');
```

### R√©tention Manuelle

```sql
-- Supprimer manuellement les chunks anciens
SELECT drop_chunks('sensor_data', older_than => INTERVAL '1 year');

-- Supprimer avec clause WHERE (plus s√©lectif)
SELECT drop_chunks('sensor_data', older_than => INTERVAL '6 months', cascade_to_materializations => false);
```

---

## Continuous Aggregates (Agr√©gations Continues)

### Le Probl√®me

Calculer des agr√©gations sur des milliards de lignes est lent :

```sql
-- Cette requ√™te peut prendre plusieurs minutes
SELECT
    time_bucket('1 hour', time) AS hour,
    sensor_id,
    AVG(temperature) AS avg_temp
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 year'
GROUP BY hour, sensor_id;
```

### La Solution : Continuous Aggregates

Une **continuous aggregate** est une vue mat√©rialis√©e sp√©ciale qui :

- ‚úÖ Se rafra√Æchit automatiquement et incr√©mentalement
- ‚úÖ Ne recalcule que les nouvelles donn√©es (pas tout)
- ‚úÖ Peut √™tre interrog√©e comme une table normale
- ‚úÖ Am√©liore les performances de 10x √† 1000x

### Cr√©er une Continuous Aggregate

```sql
-- Vue mat√©rialis√©e des moyennes horaires
CREATE MATERIALIZED VIEW sensor_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS hour,
    sensor_id,
    AVG(temperature) AS avg_temp,
    MAX(temperature) AS max_temp,
    MIN(temperature) AS min_temp,
    COUNT(*) AS measurements
FROM sensor_data
GROUP BY hour, sensor_id;
```

### Ajouter une Politique de Rafra√Æchissement

```sql
-- Rafra√Æchir toutes les heures
SELECT add_continuous_aggregate_policy('sensor_hourly',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour'
);
```

**Param√®tres** :

- `start_offset` : D√©but de la fen√™tre √† rafra√Æchir (3h dans le pass√©)
- `end_offset` : Fin de la fen√™tre (1h dans le pass√©, pour laisser les donn√©es r√©centes se stabiliser)
- `schedule_interval` : Fr√©quence d'ex√©cution

### Interroger la Continuous Aggregate

```sql
-- Requ√™te instantan√©e sur les agr√©gations pr√©-calcul√©es
SELECT
    hour,
    sensor_id,
    avg_temp
FROM sensor_hourly
WHERE hour > NOW() - INTERVAL '7 days'
ORDER BY hour DESC;
```

**Performance** : Cette requ√™te est des ordres de grandeur plus rapide qu'agr√©ger les donn√©es brutes.

### Continuous Aggregates en Cascade

Vous pouvez cr√©er des agr√©gations sur d'autres agr√©gations :

```sql
-- Agr√©gation horaire (d√©j√† cr√©√©e)
CREATE MATERIALIZED VIEW sensor_hourly ...

-- Agr√©gation journali√®re bas√©e sur l'horaire
CREATE MATERIALIZED VIEW sensor_daily
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', hour) AS day,
    sensor_id,
    AVG(avg_temp) AS avg_temp,  -- Moyenne des moyennes horaires
    MAX(max_temp) AS max_temp,
    MIN(min_temp) AS min_temp
FROM sensor_hourly
GROUP BY day, sensor_id;
```

### Rafra√Æchissement Manuel

```sql
-- Rafra√Æchir manuellement une plage temporelle
CALL refresh_continuous_aggregate('sensor_hourly',
    '2025-11-01',
    '2025-11-22'
);
```

---

## Performance et Optimisation

### Choisir le Bon Intervalle de Chunk

**R√®gle g√©n√©rale** :

- **Petites tables** (< 1 million lignes/jour) : 7 jours par chunk
- **Tables moyennes** (1-10 millions/jour) : 1 jour par chunk
- **Tables massives** (> 10 millions/jour) : 12 heures ou moins

**Exemple de d√©cision** :

```
Cas d'usage : 100 capteurs, 1 mesure/seconde chacun
Donn√©es par jour : 100 * 60 * 60 * 24 = 8,64 millions de lignes/jour

Recommandation : chunk_time_interval = 1 jour
```

### Modifier l'Intervalle de Chunk

```sql
-- Changer l'intervalle pour les futurs chunks
SELECT set_chunk_time_interval('sensor_data', INTERVAL '1 day');
```

**Note** : Cela n'affecte que les nouveaux chunks. Les anciens restent inchang√©s.

### Index Strat√©giques

```sql
-- Index sur les colonnes fr√©quemment filtr√©es
CREATE INDEX idx_sensor_location_time ON sensor_data (sensor_id, location, time DESC);

-- Index partiel pour les cas sp√©cifiques
CREATE INDEX idx_high_temp ON sensor_data (time DESC)
WHERE temperature > 30.0;
```

### Partitionnement Spatial (Space Partitioning)

Pour des charges distribu√©es sur plusieurs dimensions :

```sql
-- Partitionner par temps ET par sensor_id
SELECT create_hypertable(
    'sensor_data',
    by_range('time'),
    partitioning_column => 'sensor_id',
    number_partitions => 4,
    chunk_time_interval => INTERVAL '1 day'
);
```

**Cas d'usage** : Quand vos requ√™tes filtrent souvent sur une autre colonne que le temps (ex: sensor_id, user_id, device_id).

### Monitoring des Performances

```sql
-- Voir la taille des chunks
SELECT
    chunk_name,
    range_start,
    range_end,
    pg_size_pretty(total_bytes) AS size,
    pg_size_pretty(index_bytes) AS index_size
FROM chunks_detailed_size('sensor_data')
ORDER BY range_start DESC
LIMIT 10;

-- Statistiques d'insertion
SELECT
    hypertable_name,
    num_chunks,
    num_dimensions
FROM timescaledb_information.hypertables
WHERE hypertable_name = 'sensor_data';
```

---

## Cas d'Usage R√©els et Patterns

### 1. Monitoring d'Infrastructure (DevOps)

**Sc√©nario** : Collecter des m√©triques syst√®me de 1000 serveurs toutes les 10 secondes.

```sql
-- Table des m√©triques
CREATE TABLE system_metrics (
    time TIMESTAMPTZ NOT NULL,
    hostname TEXT NOT NULL,
    cpu_percent NUMERIC(5,2),
    memory_percent NUMERIC(5,2),
    disk_io_read BIGINT,
    disk_io_write BIGINT
);

-- Conversion en hypertable
SELECT create_hypertable('system_metrics', by_range('time'), chunk_time_interval => INTERVAL '1 day');

-- Index pour requ√™tes par hostname
CREATE INDEX idx_hostname_time ON system_metrics (hostname, time DESC);

-- Agr√©gation continue : moyennes par minute
CREATE MATERIALIZED VIEW system_metrics_1min
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 minute', time) AS bucket,
    hostname,
    AVG(cpu_percent) AS avg_cpu,
    AVG(memory_percent) AS avg_memory,
    SUM(disk_io_read) AS total_read,
    SUM(disk_io_write) AS total_write
FROM system_metrics
GROUP BY bucket, hostname;

-- R√©tention : 90 jours pour les donn√©es brutes, 1 an pour les agr√©gations
SELECT add_retention_policy('system_metrics', INTERVAL '90 days');
SELECT add_retention_policy('system_metrics_1min', INTERVAL '1 year');

-- Compression apr√®s 3 jours
ALTER TABLE system_metrics SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'hostname'
);
SELECT add_compression_policy('system_metrics', INTERVAL '3 days');
```

### 2. IoT et Capteurs

**Sc√©nario** : 10 000 capteurs de temp√©rature/humidit√© rapportant toutes les 5 minutes.

```sql
-- Table des mesures IoT
CREATE TABLE iot_sensors (
    time TIMESTAMPTZ NOT NULL,
    device_id TEXT NOT NULL,
    sensor_type TEXT NOT NULL,
    value NUMERIC,
    battery_level INTEGER,
    signal_strength INTEGER
);

-- Hypertable avec partitionnement spatial
SELECT create_hypertable(
    'iot_sensors',
    by_range('time'),
    partitioning_column => 'device_id',
    number_partitions => 4,
    chunk_time_interval => INTERVAL '7 days'
);

-- Agr√©gation horaire par type de capteur
CREATE MATERIALIZED VIEW iot_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS hour,
    device_id,
    sensor_type,
    AVG(value) AS avg_value,
    MAX(value) AS max_value,
    MIN(value) AS min_value,
    AVG(battery_level) AS avg_battery
FROM iot_sensors
GROUP BY hour, device_id, sensor_type;

-- Alerte : batterie faible
SELECT device_id, AVG(battery_level) AS avg_battery
FROM iot_sensors
WHERE time > NOW() - INTERVAL '1 day'
GROUP BY device_id
HAVING AVG(battery_level) < 20;
```

### 3. Analytics E-commerce

**Sc√©nario** : √âv√©nements de tracking web (page views, clicks, purchases).

```sql
-- Table des √©v√©nements
CREATE TABLE web_events (
    time TIMESTAMPTZ NOT NULL,
    user_id UUID,
    session_id UUID NOT NULL,
    event_type TEXT NOT NULL,
    page_url TEXT,
    product_id INTEGER,
    revenue NUMERIC(10,2)
);

SELECT create_hypertable('web_events', by_range('time'), chunk_time_interval => INTERVAL '1 day');

-- Dashboard temps r√©el : agr√©gations par 5 minutes
CREATE MATERIALIZED VIEW web_events_5min
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('5 minutes', time) AS bucket,
    event_type,
    COUNT(*) AS event_count,
    COUNT(DISTINCT session_id) AS unique_sessions,
    SUM(revenue) AS total_revenue
FROM web_events
GROUP BY bucket, event_type;

-- Rafra√Æchissement toutes les 5 minutes
SELECT add_continuous_aggregate_policy('web_events_5min',
    start_offset => INTERVAL '15 minutes',
    end_offset => INTERVAL '5 minutes',
    schedule_interval => INTERVAL '5 minutes'
);

-- Requ√™te : Conversion funnel sur la derni√®re heure
SELECT
    event_type,
    COUNT(DISTINCT session_id) AS sessions
FROM web_events
WHERE time > NOW() - INTERVAL '1 hour'
GROUP BY event_type
ORDER BY event_type;
```

### 4. Finance et Trading

**Sc√©nario** : Prix de milliers d'actifs mis √† jour toutes les secondes.

```sql
-- Table des ticks de march√©
CREATE TABLE market_ticks (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    price NUMERIC(20,8),
    volume BIGINT,
    bid NUMERIC(20,8),
    ask NUMERIC(20,8)
);

SELECT create_hypertable('market_ticks', by_range('time'), chunk_time_interval => INTERVAL '1 day');

-- Index pour requ√™tes par symbole
CREATE INDEX idx_symbol_time ON market_ticks (symbol, time DESC);

-- Agr√©gation : Bougies OHLCV (Open, High, Low, Close, Volume) par minute
CREATE MATERIALIZED VIEW ohlcv_1min
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 minute', time) AS bucket,
    symbol,
    first(price, time) AS open,
    MAX(price) AS high,
    MIN(price) AS low,
    last(price, time) AS close,
    SUM(volume) AS volume
FROM market_ticks
GROUP BY bucket, symbol;

-- Compression agressive apr√®s 1 jour
ALTER TABLE market_ticks SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'symbol',
    timescaledb.compress_orderby = 'time DESC'
);
SELECT add_compression_policy('market_ticks', INTERVAL '1 day');

-- Requ√™te : Volatilit√© sur 24h
SELECT
    symbol,
    (MAX(price) - MIN(price)) / AVG(price) * 100 AS volatility_pct
FROM market_ticks
WHERE time > NOW() - INTERVAL '24 hours'
GROUP BY symbol
ORDER BY volatility_pct DESC
LIMIT 20;
```

---

## Migration depuis PostgreSQL Standard

### Sc√©nario

Vous avez d√©j√† une table PostgreSQL avec des millions de lignes et voulez migrer vers TimescaleDB.

### M√©thode 1 : Migration In-Place (Table Vide ou Petite)

```sql
-- 1. Installer TimescaleDB
CREATE EXTENSION timescaledb;

-- 2. Convertir la table existante (ATTENTION : table doit √™tre vide ou petite)
SELECT create_hypertable('sensor_data', by_range('time'));
```

**‚ö†Ô∏è Limitations** :

- La table ne doit pas avoir de cl√© primaire ou unique incluant la colonne de temps
- La table ne doit pas avoir de foreign keys pointant vers elle (pour l'instant)
- La conversion peut prendre du temps si la table est volumineuse

### M√©thode 2 : Migration avec Reconstruction (Recommand√© pour Tables Volumineuses)

```sql
-- 1. Cr√©er une nouvelle table avec le m√™me sch√©ma
CREATE TABLE sensor_data_new (LIKE sensor_data INCLUDING ALL);

-- 2. Convertir en hypertable
SELECT create_hypertable('sensor_data_new', by_range('time'), chunk_time_interval => INTERVAL '1 day');

-- 3. Copier les donn√©es (par lots pour √©viter les verrous)
INSERT INTO sensor_data_new
SELECT * FROM sensor_data
WHERE time >= '2024-01-01' AND time < '2024-02-01';

-- R√©p√©ter pour chaque mois...

-- 4. Renommer
BEGIN;
ALTER TABLE sensor_data RENAME TO sensor_data_old;
ALTER TABLE sensor_data_new RENAME TO sensor_data;
COMMIT;

-- 5. V√©rifier et supprimer l'ancienne table
DROP TABLE sensor_data_old;
```

### M√©thode 3 : Migration Progressive (Zero Downtime)

```sql
-- 1. Cr√©er la nouvelle hypertable
CREATE TABLE sensor_data_ts (LIKE sensor_data);
SELECT create_hypertable('sensor_data_ts', by_range('time'));

-- 2. Configurer la r√©plication logique (PostgreSQL 10+)
-- Ou utiliser un trigger pour dupliquer les INSERT

-- 3. Copier les donn√©es historiques en arri√®re-plan
INSERT INTO sensor_data_ts
SELECT * FROM sensor_data
WHERE time < NOW() - INTERVAL '1 hour'
ORDER BY time;

-- 4. Basculer l'application vers la nouvelle table
-- (sans downtime si r√©plication configur√©e)

-- 5. Supprimer l'ancienne table quand s√ªr
DROP TABLE sensor_data;
```

---

## Limitations et Consid√©rations

### Limitations Techniques

#### 1. UPDATE et DELETE sur Donn√©es Compress√©es

**Probl√®me** : Les chunks compress√©s sont en lecture seule.

**Solution** : D√©compresser temporairement ou √©viter les UPDATE/DELETE sur donn√©es anciennes.

```sql
-- D√©compresser pour permettre les modifications
SELECT decompress_chunk('_timescaledb_internal._hyper_1_1_chunk');

-- Modifier
UPDATE sensor_data SET temperature = 25.0 WHERE ...;

-- Recompresser
SELECT compress_chunk('_timescaledb_internal._hyper_1_1_chunk');
```

#### 2. Foreign Keys

Les foreign keys vers une hypertable sont **limit√©s** :

- ‚ùå Pas de FK pointant *vers* une colonne non-temps d'une hypertable
- ‚úÖ FK pointant *depuis* une hypertable vers une table normale (OK)

**Workaround** : Utiliser des contraintes applicatives ou des triggers.

#### 3. Triggers sur Hypertables

Les triggers fonctionnent, mais :

- Peuvent impacter les performances d'insertion (surtout BEFORE triggers)
- √âvaluez si la logique peut √™tre d√©port√©e en applicatif

#### 4. Contraintes UNIQUE

Les contraintes UNIQUE doivent inclure la colonne de partitionnement (temps).

```sql
-- ‚ùå Impossible
ALTER TABLE sensor_data ADD CONSTRAINT unique_sensor UNIQUE (sensor_id);

-- ‚úÖ Possible
ALTER TABLE sensor_data ADD CONSTRAINT unique_sensor_time UNIQUE (sensor_id, time);
```

### Consid√©rations Op√©rationnelles

#### 1. Surveillance des Jobs

Les politiques de compression, r√©tention, et refresh sont des jobs en arri√®re-plan.

```sql
-- V√©rifier l'√©tat des jobs
SELECT * FROM timescaledb_information.job_stats;

-- Voir les jobs √©chou√©s
SELECT * FROM timescaledb_information.job_stats
WHERE last_run_status = 'Failure';
```

#### 2. Ressources Serveur

- **CPU** : Compression et continuous aggregates consomment du CPU
- **I/O** : √âcritures intensives n√©cessitent des disques rapides (SSD)
- **M√©moire** : Configurez `shared_buffers` et `work_mem` g√©n√©reusement

#### 3. Backup et Restauration

**Logique (pg_dump)** :

```bash
# Dump avec TimescaleDB
pg_dump -d mydb -Fc -f backup.dump

# Restore (installer TimescaleDB d'abord sur la cible)
pg_restore -d mydb backup.dump
```

**Physique (pg_basebackup)** : Fonctionne normalement.

**Point-in-Time Recovery (PITR)** : Compatible sans probl√®me.

---

## Ressources et Documentation

### Documentation Officielle

- **Site officiel** : https://www.timescale.com/
- **Documentation** : https://docs.timescale.com/
- **GitHub** : https://github.com/timescale/timescaledb
- **Forum communautaire** : https://www.timescale.com/forum

### Tutoriels et Guides

- **Getting Started** : https://docs.timescale.com/getting-started/
- **API Reference** : https://docs.timescale.com/api/
- **Best Practices** : https://docs.timescale.com/use-timescale/latest/best-practices/

### Outils Compl√©mentaires

- **Promscale** : Stockage long-terme pour Prometheus
- **Grafana** : Visualisation (source de donn√©es TimescaleDB native)
- **Telegraf** : Collecte de m√©triques vers TimescaleDB
- **TimescaleDB Toolkit** : Extension avec fonctions avanc√©es (hyperfunctions)

### Support et Communaut√©

- **Slack** : https://slack.timescale.com/
- **Stack Overflow** : Tag [timescaledb]
- **Reddit** : r/PostgreSQL (beaucoup de discussions TimescaleDB)

---

## Comparaison : TimescaleDB vs Alternatives

### TimescaleDB vs InfluxDB

| Crit√®re | TimescaleDB | InfluxDB |
|---------|-------------|----------|
| **Langage** | SQL standard | InfluxQL/Flux |
| **Base** | PostgreSQL | Propre DB |
| **Relationnel** | ‚úÖ Oui (joins, FK) | ‚ùå Limit√© |
| **Compression** | ‚úÖ 10-20x | ‚úÖ 10x |
| **√âcosyst√®me** | PostgreSQL entier | Propre √©cosyst√®me |
| **Licence** | Apache 2.0 (base) | MIT (OSS) / Propri√©taire |
| **Cas d'usage** | S√©ries temporelles + relationnel | S√©ries temporelles pures |

**Verdict** : TimescaleDB si vous avez besoin de SQL et de fonctionnalit√©s relationnelles. InfluxDB si vous voulez une solution d√©di√©e time-series.

### TimescaleDB vs Cassandra

| Crit√®re | TimescaleDB | Cassandra |
|---------|-------------|-----------|
| **Architecture** | Monolithique (scale-up) | Distribu√©e (scale-out) |
| **Consistance** | ACID fort | Eventual consistency |
| **Langage** | SQL | CQL |
| **Complexit√©** | Simple | √âlev√©e |
| **Performance** | Excellente (single-node) | Excellente (multi-node) |

**Verdict** : TimescaleDB pour la simplicit√© et des volumes < 100 TB. Cassandra pour du multi-datacenter √† √©chelle plan√©taire.

### TimescaleDB vs PostgreSQL Natif (Partitions D√©claratives)

| Crit√®re | TimescaleDB | PostgreSQL Partitionn√© |
|---------|-------------|------------------------|
| **Gestion partitions** | Automatique | Manuelle |
| **Compression** | Native | Externe (TOAST) |
| **Continuous Aggregates** | ‚úÖ Oui | ‚ùå Non |
| **Fonctions time-series** | ‚úÖ Riches | ‚ùå Basiques |
| **R√©tention automatique** | ‚úÖ Oui | ‚ùå Manuelle |

**Verdict** : TimescaleDB est une √©volution naturelle de PostgreSQL pour les s√©ries temporelles, avec beaucoup moins d'effort manuel.

---

## Bonnes Pratiques - R√©capitulatif

### 1. Design de Schema

‚úÖ **√Ä faire** :
- Utilisez `TIMESTAMPTZ` pour la colonne de temps (gestion des fuseaux horaires)
- Choisissez un `chunk_time_interval` adapt√© √† votre d√©bit
- Ajoutez des index sur les colonnes fr√©quemment filtr√©es avec temps

‚ùå **√Ä √©viter** :
- Ne pas inclure trop de colonnes (pensez normalisation)
- √âviter les contraintes UNIQUE sans la colonne de temps
- Ne pas utiliser de types exotiques non n√©cessaires

### 2. Insertion de Donn√©es

‚úÖ **√Ä faire** :
- Ins√©rez par lots (batch) pour meilleures performances
- Utilisez `COPY` pour imports massifs
- Assurez-vous que les timestamps sont dans un ordre croissant (ou proche)

‚ùå **√Ä √©viter** :
- Insertions ligne par ligne en haute fr√©quence (utilisez des buffers)
- Insertions d√©sordonn√©es temporellement (impacte le partitionnement)
- Transactions trop longues (verrouillage)

### 3. Requ√™tes

‚úÖ **√Ä faire** :
- Filtrez toujours sur la colonne de temps
- Utilisez `time_bucket()` pour les agr√©gations temporelles
- Cr√©ez des continuous aggregates pour les dashboards

‚ùå **√Ä √©viter** :
- Requ√™tes sans filtre temporel (scan complet de l'hypertable)
- Agr√©gations lourdes sur donn√©es brutes non compress√©es
- Trop de JOINs complexes sur hypertables massives

### 4. Maintenance

‚úÖ **√Ä faire** :
- Configurez la compression apr√®s quelques jours
- D√©finissez des politiques de r√©tention claires
- Surveillez les jobs (compression, retention, refresh)
- Testez r√©guli√®rement vos backups

‚ùå **√Ä √©viter** :
- Laisser les donn√©es s'accumuler sans compression ni r√©tention
- Oublier de monitorer la croissance du disque
- N√©gliger les logs d'erreur des jobs

### 5. Performance

‚úÖ **√Ä faire** :
- Ajustez `shared_buffers`, `work_mem` pour votre charge
- Utilisez des SSD pour les I/O intensives
- Cr√©ez des continuous aggregates pour les rapports fr√©quents
- Partitionnez spatialement si filtres sur plusieurs dimensions

‚ùå **√Ä √©viter** :
- Sous-dimensionner le serveur (CPU, RAM, I/O)
- N√©gliger l'optimisation des index
- Compresser des chunks trop r√©cents (donn√©es encore actives)

---

## Conclusion

TimescaleDB transforme PostgreSQL en une plateforme exceptionnelle pour les s√©ries temporelles, en conservant toute la puissance du SQL relationnel. Les concepts cl√©s √† retenir :

### Points Essentiels

- üéØ **Hypertables** : Tables partitionn√©es automatiquement en chunks temporels
- üéØ **Compression** : R√©duction de 10-20x de la taille avec lecture transparente
- üéØ **Continuous Aggregates** : Vues mat√©rialis√©es incr√©mentales pour performances extr√™mes
- üéØ **R√©tention automatique** : Suppression instantan√©e des donn√©es anciennes
- üéØ **Fonctions time-series** : `time_bucket()`, `first()`, `last()`, interpolation, etc.

### Quand Utiliser TimescaleDB ?

‚úÖ **OUI, utilisez TimescaleDB si** :
- Vous avez des donn√©es horodat√©es (logs, m√©triques, IoT, analytics)
- Vous ins√©rez massivement et lisez par plages temporelles
- Vous voulez combiner relationnel (JOINs) et time-series
- Vous aimez SQL et l'√©cosyst√®me PostgreSQL

‚ùå **NON, peut-√™tre pas si** :
- Vos donn√©es ne sont pas temporelles (utilisez PostgreSQL standard)
- Vous avez besoin de scale-out multi-datacenter (Cassandra, CockroachDB)
- Votre charge est majoritairement des UPDATE/DELETE (pas optimal pour time-series)

### Prochaines √âtapes

1. **Installez TimescaleDB** sur un environnement de d√©veloppement
2. **Cr√©ez votre premi√®re hypertable** avec vos donn√©es
3. **Exp√©rimentez** avec compression et continuous aggregates
4. **√âvaluez les performances** par rapport √† PostgreSQL standard
5. **D√©ployez progressivement** en production

TimescaleDB est mature, stable, et largement adopt√© dans l'industrie (Cisco, IBM, Walmart, etc.). C'est un choix solide pour toute application n√©cessitant des capacit√©s de s√©ries temporelles √† l'√©chelle.

---

## Annexe : Commandes de R√©f√©rence Rapide

### Installation

```bash
# Ubuntu/Debian
sudo apt install timescaledb-2-postgresql-18

# Configuration
sudo timescaledb-tune --quiet --yes
sudo systemctl restart postgresql
```

### Cr√©ation Hypertable

```sql
CREATE EXTENSION timescaledb;

CREATE TABLE my_table (time TIMESTAMPTZ NOT NULL, ...);
SELECT create_hypertable('my_table', by_range('time'), chunk_time_interval => INTERVAL '1 day');
```

### Compression

```sql
ALTER TABLE my_table SET (timescaledb.compress, timescaledb.compress_segmentby = 'device_id');
SELECT add_compression_policy('my_table', INTERVAL '7 days');
```

### R√©tention

```sql
SELECT add_retention_policy('my_table', INTERVAL '90 days');
```

### Continuous Aggregate

```sql
CREATE MATERIALIZED VIEW my_agg
WITH (timescaledb.continuous) AS
SELECT time_bucket('1 hour', time) AS hour, AVG(value)
FROM my_table
GROUP BY hour;

SELECT add_continuous_aggregate_policy('my_agg',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour'
);
```

### Monitoring

```sql
-- Taille des chunks
SELECT * FROM chunks_detailed_size('my_table');

-- Jobs actifs
SELECT * FROM timescaledb_information.jobs;

-- Statistiques compression
SELECT * FROM chunk_compression_stats('my_table');
```

‚è≠Ô∏è [pgvector : IA, embeddings et recherche vectorielle](/18-extensions-et-integrations/06-pgvector.md)
