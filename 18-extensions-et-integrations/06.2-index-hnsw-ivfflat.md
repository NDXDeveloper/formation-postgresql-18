ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 18.6.2. Index HNSW et IVFFlat

## Introduction

Dans le chapitre prÃ©cÃ©dent, nous avons vu comment effectuer des recherches de similaritÃ© avec pgvector. Mais il y a un problÃ¨me : sans index, PostgreSQL doit comparer votre vecteur de recherche avec **TOUS** les vecteurs de la table. C'est comme chercher un livre dans une bibliothÃ¨que en regardant tous les livres un par un !

Pour 1 million de vecteurs, une recherche sans index peut prendre **15 secondes**. Avec un bon index, la mÃªme recherche prend **0.01 seconde** â€” soit **1500Ã— plus rapide** ! ğŸš€

Ce chapitre explique les deux types d'index principaux de pgvector : **IVFFlat** et **HNSW**.

### Analogie : BibliothÃ¨ques organisÃ©es

**Sans index (scan sÃ©quentiel)** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BibliothÃ¨que dÃ©sorganisÃ©e                              â”‚
â”‚  ğŸ“šğŸ“—ğŸ“˜ğŸ“™ğŸ“šğŸ“—ğŸ“˜ğŸ“™ğŸ“šğŸ“—ğŸ“˜ğŸ“™ğŸ“šğŸ“—ğŸ“˜ğŸ“™ğŸ“šğŸ“—ğŸ“˜ğŸ“™             â”‚
â”‚  Vous devez vÃ©rifier chaque livre un par un             â”‚
â”‚  Temps : 15 minutes pour 1000 livres                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avec index IVFFlat** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BibliothÃ¨que par sections                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Fiction  â”‚ â”‚ Science  â”‚ â”‚ Histoire â”‚                 â”‚
â”‚  â”‚ ğŸ“šğŸ“šğŸ“š   â”‚ â”‚ ğŸ“—ğŸ“—ğŸ“—   â”‚ â”‚ ğŸ“˜ğŸ“˜ğŸ“˜   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚  Vous allez directement dans 1-2 sections               â”‚
â”‚  Temps : 30 secondes pour 1000 livres                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avec index HNSW** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BibliothÃ¨que avec index hiÃ©rarchique                   â”‚
â”‚  Niveau 1 : Grands thÃ¨mes (5 catÃ©gories)                â”‚
â”‚  Niveau 2 : Sous-thÃ¨mes (50 catÃ©gories)                 â”‚
â”‚  Niveau 3 : Ã‰tagÃ¨res prÃ©cises (500 emplacements)        â”‚
â”‚  Navigation ultra-rapide via liens intelligents         â”‚
â”‚  Temps : 5 secondes pour 1000 livres                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pourquoi les Index Vectoriels sont DiffÃ©rents

### Index B-Tree classiques : Inefficaces pour les vecteurs

Les index PostgreSQL classiques (B-Tree) fonctionnent bien pour :
- Nombres : `WHERE prix > 100`
- Texte : `WHERE nom = 'Dupont'`
- Dates : `WHERE date_creation > '2024-01-01'`

**Pourquoi ?** Ces donnÃ©es sont **ordonnables** : on peut dire que 5 < 10, "Alice" < "Bob", etc.

**Mais les vecteurs ?** Comment ordonner ces vecteurs ?
```
[0.1, 0.2, 0.3, ..., 0.9]
[0.5, 0.1, 0.8, ..., 0.2]
[0.3, 0.7, 0.2, ..., 0.6]
```

Il n'y a **pas d'ordre naturel** ! Un vecteur n'est ni "plus grand" ni "plus petit" qu'un autre.

### Recherche de proximitÃ© vs Recherche exacte

**Recherche classique (exacte)** :
```sql
SELECT * FROM clients WHERE nom = 'Dupont';
-- Retourne EXACTEMENT les Dupont
```

**Recherche vectorielle (proximitÃ©)** :
```sql
SELECT * FROM documents
ORDER BY embedding <=> query_vector
LIMIT 10;
-- Retourne les 10 PLUS PROCHES (approximation acceptable)
```

### Le dÃ©fi : Performance Ã  grande Ã©chelle

| Nombre de vecteurs | Sans index | Avec index IVFFlat | Avec index HNSW |
|-------------------|------------|-------------------|-----------------|
| 1 000 | 0.01 s | 0.002 s | 0.001 s |
| 10 000 | 0.1 s | 0.005 s | 0.002 s |
| 100 000 | 1 s | 0.01 s | 0.005 s |
| 1 000 000 | 15 s | 0.05 s | 0.01 s |
| 10 000 000 | 150 s | 0.5 s | 0.05 s |

**Conclusion** : Au-delÃ  de 10 000 vecteurs, les index sont **indispensables**.

---

## Index IVFFlat

### Qu'est-ce que IVFFlat ?

**IVF** = Inverted File (Fichier inversÃ©)
**Flat** = Vecteurs stockÃ©s tels quels (non compressÃ©s)

**Principe** : Regrouper les vecteurs similaires en **clusters** (groupes), puis chercher uniquement dans les clusters les plus proches.

### Analogie : Villes et quartiers

Imaginez que vous cherchez une pizzeria Ã  Paris :

**Sans index** :
- VÃ©rifier les 15 000 restaurants de Paris un par un
- Temps : Des heures

**Avec IVFFlat** :
1. Paris est divisÃ©e en 20 quartiers (clusters)
2. Votre position : "Je suis dans le Marais"
3. Chercher uniquement dans le Marais + 1-2 quartiers voisins
4. Temps : Quelques minutes

**IVFFlat fait pareil avec vos vecteurs !**

### Comment Ã§a fonctionne

#### Ã‰tape 1 : Construction de l'index (clustering)

```
Vecteurs dans la table :
â€¢ â€¢ â€¢    â€¢ â€¢ â€¢    â€¢ â€¢ â€¢
â€¢ â€¢ â€¢    â€¢ â€¢ â€¢    â€¢ â€¢ â€¢
â€¢ â€¢ â€¢    â€¢ â€¢ â€¢    â€¢ â€¢ â€¢

     â†“ K-means clustering â†“

Clusters formÃ©s (lists) :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Cluster 1â”‚  â”‚Cluster 2â”‚  â”‚Cluster 3â”‚
â”‚  â€¢ â€¢ â€¢  â”‚  â”‚  â€¢ â€¢ â€¢  â”‚  â”‚  â€¢ â€¢ â€¢  â”‚
â”‚  â€¢ â€¢ â€¢  â”‚  â”‚  â€¢ â€¢ â€¢  â”‚  â”‚  â€¢ â€¢ â€¢  â”‚
â”‚  â˜…      â”‚  â”‚    â˜…    â”‚  â”‚      â˜…  â”‚
â”‚centroid â”‚  â”‚centroid â”‚  â”‚centroid â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Chaque cluster a un **centroid** (centre) qui le reprÃ©sente.

#### Ã‰tape 2 : Recherche

```
1. RequÃªte : Vecteur de recherche Q
             ğŸ”

2. Trouver les clusters les plus proches de Q
   (comparer Q avec les centroids)

   ğŸ” est proche de Cluster 2 et Cluster 3

3. Scanner uniquement ces clusters

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Cluster 1â”‚  â”‚Cluster 2â”‚  â”‚Cluster 3â”‚
   â”‚         â”‚  â”‚  âœ“âœ“âœ“âœ“  â”‚  â”‚  âœ“âœ“âœ“âœ“  â”‚ â† ScannÃ©s
   â”‚ (ignorÃ©)â”‚  â”‚  âœ“âœ“âœ“âœ“  â”‚  â”‚  âœ“âœ“âœ“âœ“  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. Retourner les k plus proches vecteurs
```

### CrÃ©ation d'un index IVFFlat

#### Syntaxe SQL

```sql
CREATE INDEX nom_index ON table_name
USING ivfflat (colonne_vector ops_class)
WITH (lists = nombre_clusters);
```

**ParamÃ¨tre clÃ© : `lists`**

Le nombre de clusters (listes) Ã  crÃ©er.

**RÃ¨gle gÃ©nÃ©rale** :
```
lists = âˆš(nombre_de_lignes)

Exemples :
- 10 000 lignes    â†’ lists = 100
- 100 000 lignes   â†’ lists = 316
- 1 000 000 lignes â†’ lists = 1000
- 10 000 000 lignesâ†’ lists = 3162
```

#### Exemples concrets

**Pour distance L2 (euclidienne)** :

```sql
CREATE INDEX idx_produits_embedding_l2
ON produits
USING ivfflat (embedding vector_l2_ops)
WITH (lists = 100);
```

**Pour distance cosine** :

```sql
CREATE INDEX idx_documents_embedding_cosine
ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 1000);
```

**Pour inner product** :

```sql
CREATE INDEX idx_items_embedding_ip
ON items
USING ivfflat (embedding vector_ip_ops)
WITH (lists = 316);
```

### Configuration de la recherche

#### ParamÃ¨tre : ivfflat.probes

**`probes`** = Nombre de clusters Ã  scanner lors de la recherche

```sql
-- Par dÃ©faut : probes = 1 (trÃ¨s rapide, moins prÃ©cis)
SET ivfflat.probes = 1;

-- RecommandÃ© : probes = 10-20 (bon Ã©quilibre)
SET ivfflat.probes = 10;

-- Maximum prÃ©cision : probes = lists (Ã©quivaut Ã  scan complet)
SET ivfflat.probes = 100;
```

**Trade-off** :

| Probes | Vitesse | PrÃ©cision | Cas d'usage |
|--------|---------|-----------|-------------|
| 1 | ğŸŸ¢ğŸŸ¢ğŸŸ¢ Ultra-rapide | ğŸ”´ Faible (~50%) | Exploration rapide |
| 10 | ğŸŸ¢ğŸŸ¢ Rapide | ğŸŸ¢ğŸŸ¢ Bon (~95%) | Production (recommandÃ©) |
| 20 | ğŸŸ¢ Moyen | ğŸŸ¢ğŸŸ¢ğŸŸ¢ TrÃ¨s bon (~98%) | Haute prÃ©cision |
| = lists | ğŸ”´ Lent | ğŸŸ¢ğŸŸ¢ğŸŸ¢ Parfait (100%) | Debug uniquement |

**Exemple** :

```sql
-- Session courante
SET ivfflat.probes = 10;

SELECT
    id,
    nom,
    embedding <=> '[0.1, 0.2, ..., 0.9]'::vector AS distance
FROM produits
ORDER BY distance
LIMIT 10;
```

**Configuration permanente** (postgresql.conf) :

```ini
# postgresql.conf
ivfflat.probes = 10
```

### Avantages d'IVFFlat

âœ… **Simple Ã  comprendre** : Concept de clustering intuitif

âœ… **Rapide Ã  construire** : Index crÃ©Ã© en quelques minutes

âœ… **Ã‰conome en espace** : Overhead modÃ©rÃ© (~20-30% de la taille des donnÃ©es)

âœ… **Bon pour datasets moyens** : 10K - 1M vecteurs

âœ… **PrÃ©cision ajustable** : ParamÃ¨tre `probes` pour trade-off vitesse/prÃ©cision

### Limitations d'IVFFlat

âŒ **PrÃ©cision limitÃ©e** : ~95% de recall avec probes=10 (peut manquer les vrais plus proches)

âŒ **Sensible Ã  la distribution** : Si les vecteurs sont mal rÃ©partis, certains clusters seront surchargÃ©s

âŒ **NÃ©cessite des donnÃ©es pour construction** : Il faut avoir des donnÃ©es dans la table avant de crÃ©er l'index

âŒ **Performance dÃ©gradÃ©e sur gros volumes** : Au-delÃ  de 10M vecteurs, HNSW est meilleur

### Quand utiliser IVFFlat

âœ… **Utilisez IVFFlat quand** :
- Dataset de taille moyenne (10K - 1M vecteurs)
- Contraintes d'espace disque (index plus compact que HNSW)
- Construction rapide nÃ©cessaire (prototypage, tests)
- Rappel de ~95% acceptable

âŒ **N'utilisez PAS IVFFlat quand** :
- Vous avez besoin de trÃ¨s haute prÃ©cision (>98%)
- Dataset trÃ¨s volumineux (>10M vecteurs)
- Performance critique (<10ms par requÃªte)

---

## Index HNSW

### Qu'est-ce que HNSW ?

**HNSW** = Hierarchical Navigable Small World

**Principe** : CrÃ©er un graphe multi-niveaux oÃ¹ chaque vecteur est connectÃ© Ã  ses voisins les plus proches, permettant une navigation ultra-rapide.

### Analogie : RÃ©seau autoroutier

**IVFFlat** = Routes dÃ©partementales avec villages (clusters)
- Vous allez dans le bon village, puis cherchez la maison

**HNSW** = RÃ©seau autoroutier multi-niveaux
- Niveau 1 : Autoroutes (connexions longue distance)
- Niveau 2 : Nationales (connexions moyenne distance)
- Niveau 3 : DÃ©partementales (connexions courte distance)
- Niveau 4 : Rues (voisinage immÃ©diat)

Vous naviguez intelligemment de niveau en niveau pour atteindre votre destination ultra-rapidement !

### Comment Ã§a fonctionne

#### Structure hiÃ©rarchique

```
Niveau 3 (le plus haut, peu de nÅ“uds)
    â€¢â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â€¢
    â”‚                â”‚
    â”‚                â”‚
Niveau 2 (nÅ“uds intermÃ©diaires)
    â€¢â”€â”€â”€â”€â€¢â”€â”€â”€â”€â€¢â”€â”€â”€â”€â”€â”€â€¢â”€â”€â”€â”€â€¢â”€â”€â”€â”€â€¢
    â”‚    â”‚    â”‚      â”‚    â”‚    â”‚
    â”‚    â”‚    â”‚      â”‚    â”‚    â”‚
Niveau 1 (beaucoup de nÅ“uds)
    â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢â”€â”€â€¢
    â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚
    â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚
Niveau 0 (tous les vecteurs)
    â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢

Chaque â€¢ est un vecteur
Les liens â”€â”€ reprÃ©sentent les connexions vers voisins proches
```

#### Processus de recherche

```
1. Point de dÃ©part : NÅ“ud d'entrÃ©e au niveau le plus haut

   Niveau 3:  ğŸ” START
                â€¢

2. Descendre progressivement en suivant les voisins les plus proches

   Niveau 2:    â€¢
              / | \
             â€¢  â€¢  â€¢
                ğŸ” Descend ici

3. Niveau 1: Navigation plus fine

   Niveau 1:  â€¢ â€¢ â€¢ â€¢
              â€¢ â€¢ğŸ”â€¢ â€¢
              â€¢ â€¢ â€¢ â€¢

4. Niveau 0: Trouver les k plus proches dans le voisinage final

   Niveau 0:  â€¢â€¢â€¢
              â€¢ğŸ¯â€¢ â† RÃ©sultat !
              â€¢â€¢â€¢
```

**ComplexitÃ©** : O(log N) au lieu de O(N) pour un scan complet

### CrÃ©ation d'un index HNSW

#### Syntaxe SQL

```sql
CREATE INDEX nom_index ON table_name
USING hnsw (colonne_vector ops_class)
WITH (m = connections, ef_construction = build_param);
```

**ParamÃ¨tres clÃ©s** :

1. **`m`** : Nombre de connexions par nÅ“ud (par niveau)
2. **`ef_construction`** : Taille de la file de prioritÃ© lors de la construction

#### Exemples concrets

**Configuration standard (recommandÃ©e)** :

```sql
CREATE INDEX idx_documents_embedding_hnsw
ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**Configuration haute performance** :

```sql
CREATE INDEX idx_produits_embedding_hnsw
ON produits
USING hnsw (embedding vector_l2_ops)
WITH (m = 32, ef_construction = 128);
```

**Configuration Ã©conome en espace** :

```sql
CREATE INDEX idx_items_embedding_hnsw
ON items
USING hnsw (embedding vector_cosine_ops)
WITH (m = 8, ef_construction = 32);
```

### ParamÃ¨tres de l'index

#### ParamÃ¨tre `m` (connexions)

**DÃ©finition** : Nombre maximal de connexions bidirectionnelles par nÅ“ud (par couche).

**Impact** :

| Valeur m | Taille index | Vitesse recherche | PrÃ©cision | Recommandation |
|----------|-------------|------------------|-----------|----------------|
| 8 | Petit | Rapide | Bonne | Datasets compacts |
| 16 | Moyen | TrÃ¨s rapide | TrÃ¨s bonne | **DÃ©faut (recommandÃ©)** |
| 32 | Grand | Ultra-rapide | Excellente | Haute prÃ©cision |
| 64 | TrÃ¨s grand | Ultra-rapide | Parfaite | Cas critiques |

**RÃ¨gle gÃ©nÃ©rale** :
- Commencez avec `m = 16`
- Augmentez Ã  `m = 32` si vous avez besoin de plus de prÃ©cision
- Diminuez Ã  `m = 8` si l'espace disque est limitÃ©

**Formule espace disque** :
```
Taille index â‰ˆ taille_vecteurs Ã— m Ã— 1.5
```

#### ParamÃ¨tre `ef_construction` (construction)

**DÃ©finition** : Taille de la file de candidats explorÃ©s lors de l'insertion d'un nouveau vecteur.

**Impact** :

| Valeur ef_construction | Temps construction | QualitÃ© index | Recommandation |
|------------------------|-------------------|---------------|----------------|
| 32 | Rapide | Acceptable | Prototypage |
| 64 | Moyen | Bonne | **DÃ©faut** |
| 128 | Lent | TrÃ¨s bonne | Production |
| 256 | TrÃ¨s lent | Excellente | DonnÃ©es critiques |

**RÃ¨gle gÃ©nÃ©rale** :
- `ef_construction >= 2 Ã— m` (minimum)
- Standard : `ef_construction = 64` pour `m = 16`
- Haute qualitÃ© : `ef_construction = 128` ou plus

**Trade-off** :
```
ef_construction Ã©levÃ© â†’ Construction plus lente, mais index de meilleure qualitÃ©
ef_construction faible â†’ Construction rapide, mais index moins optimal
```

### Configuration de la recherche

#### ParamÃ¨tre : hnsw.ef_search

**`ef_search`** = Taille de la liste de candidats explorÃ©s lors d'une recherche

```sql
-- Par dÃ©faut : ef_search = 40
SET hnsw.ef_search = 40;

-- Haute prÃ©cision
SET hnsw.ef_search = 100;

-- Vitesse maximale (prÃ©cision rÃ©duite)
SET hnsw.ef_search = 20;
```

**Impact** :

| ef_search | Vitesse | PrÃ©cision | Cas d'usage |
|-----------|---------|-----------|-------------|
| 20 | ğŸŸ¢ğŸŸ¢ğŸŸ¢ TrÃ¨s rapide | ğŸŸ¡ Moyenne (~90%) | Exploration rapide |
| 40 | ğŸŸ¢ğŸŸ¢ Rapide | ğŸŸ¢ğŸŸ¢ Bonne (~98%) | **Production (dÃ©faut)** |
| 100 | ğŸŸ¢ Moyen | ğŸŸ¢ğŸŸ¢ğŸŸ¢ Excellente (~99.5%) | Haute prÃ©cision |
| 200 | ğŸŸ¡ Lent | ğŸŸ¢ğŸŸ¢ğŸŸ¢ Parfaite (~99.9%) | Validation |

**RÃ¨gle gÃ©nÃ©rale** :
```
ef_search >= k (nombre de rÃ©sultats demandÃ©s)

Si LIMIT 10 â†’ ef_search >= 10 (mais 40 recommandÃ©)
Si LIMIT 100 â†’ ef_search >= 100
```

**Exemple** :

```sql
-- Recherche haute prÃ©cision
SET hnsw.ef_search = 100;

SELECT
    id,
    titre,
    embedding <=> '[0.1, 0.2, ..., 0.9]'::vector AS distance
FROM documents
ORDER BY distance
LIMIT 10;
```

### Avantages de HNSW

âœ… **Performance exceptionnelle** : Le plus rapide des index vectoriels (~10-50Ã— plus rapide qu'IVFFlat)

âœ… **Haute prÃ©cision** : Recall de ~98-99% par dÃ©faut

âœ… **ScalabilitÃ©** : Fonctionne bien mÃªme avec 100M+ vecteurs

âœ… **Robuste** : Peu sensible Ã  la distribution des donnÃ©es

âœ… **Pas besoin de donnÃ©es d'entraÃ®nement** : Peut Ãªtre crÃ©Ã© sur table vide (contrairement Ã  IVFFlat)

âœ… **Inserts efficaces** : Ajout de nouveaux vecteurs rapide

### Limitations de HNSW

âŒ **Espace disque important** : Index peut Ãªtre 2-3Ã— la taille des donnÃ©es

âŒ **Construction lente** : Peut prendre des heures pour 10M+ vecteurs

âŒ **RAM intensive** : NÃ©cessite beaucoup de mÃ©moire pour performances optimales

âŒ **ParamÃ¨tres complexes** : NÃ©cessite tuning (m, ef_construction, ef_search)

### Quand utiliser HNSW

âœ… **Utilisez HNSW quand** :
- Dataset volumineux (>1M vecteurs)
- Performance critique (<10ms par requÃªte)
- Haute prÃ©cision nÃ©cessaire (>98% recall)
- Espace disque disponible
- Production Ã  grande Ã©chelle

âŒ **N'utilisez PAS HNSW quand** :
- Dataset trÃ¨s petit (<10K vecteurs) â†’ Scan sÃ©quentiel suffit
- Contraintes d'espace disque sÃ©vÃ¨res â†’ Utilisez IVFFlat
- Prototypage rapide nÃ©cessaire â†’ IVFFlat plus rapide Ã  construire

---

## Comparaison IVFFlat vs HNSW

### Tableau rÃ©capitulatif

| CritÃ¨re | IVFFlat | HNSW |
|---------|---------|------|
| **Algorithme** | Clustering (K-means) | Graphe multi-niveaux |
| **Vitesse recherche** | ğŸŸ¢ğŸŸ¢ Rapide | ğŸŸ¢ğŸŸ¢ğŸŸ¢ Ultra-rapide |
| **PrÃ©cision (recall)** | ğŸŸ¡ ~95% (probes=10) | ğŸŸ¢ğŸŸ¢ğŸŸ¢ ~98-99% |
| **Temps construction** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ Rapide (minutes) | ğŸŸ¡ Lent (heures) |
| **Espace disque** | ğŸŸ¢ğŸŸ¢ ModÃ©rÃ© (+20-30%) | ğŸ”´ Important (+100-200%) |
| **RAM nÃ©cessaire** | ğŸŸ¢ğŸŸ¢ ModÃ©rÃ©e | ğŸ”´ Ã‰levÃ©e |
| **ScalabilitÃ©** | ğŸŸ¡ Jusqu'Ã  ~1-10M | ğŸŸ¢ğŸŸ¢ğŸŸ¢ 100M+ |
| **Tuning complexitÃ©** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ Simple (1 param) | ğŸŸ¡ Moyen (3 params) |
| **Inserts** | ğŸŸ¡ CoÃ»t moyen | ğŸŸ¢ğŸŸ¢ Rapides |
| **Dataset requis** | âœ… Oui (pour clustering) | âŒ Non |

### Performance comparÃ©e

**Benchmark** : 1 million de vecteurs de 1536 dimensions

| MÃ©trique | Sans index | IVFFlat (probes=10) | HNSW (ef_search=40) |
|----------|------------|---------------------|---------------------|
| **Temps recherche** | 15 000 ms | 50 ms | 10 ms |
| **Recall@10** | 100% | 95% | 98.5% |
| **Temps construction** | 0 ms | 5 minutes | 2 heures |
| **Taille index** | 0 GB | 1.5 GB | 3.0 GB |
| **RAM optimale** | 2 GB | 4 GB | 8 GB |

### Graphique de dÃ©cision

```
Avez-vous < 10 000 vecteurs ?
â”‚
â”œâ”€ Oui â†’ Pas besoin d'index (scan sÃ©quentiel suffit)
â”‚
â””â”€ Non
    â”‚
    â”œâ”€ < 100 000 vecteurs ?
    â”‚   â”‚
    â”‚   â””â”€ IVFFlat ou HNSW (au choix)
    â”‚
    â””â”€ > 100 000 vecteurs ?
        â”‚
        â”œâ”€ Contraintes d'espace disque ?
        â”‚   â”‚
        â”‚   â”œâ”€ Oui â†’ IVFFlat (lists = âˆšN)
        â”‚   â”‚
        â”‚   â””â”€ Non
        â”‚       â”‚
        â”‚       â”œâ”€ Performance critique ?
        â”‚       â”‚   â”‚
        â”‚       â”‚   â”œâ”€ Oui â†’ HNSW (m=16-32, ef_construction=64-128)
        â”‚       â”‚   â”‚
        â”‚       â”‚   â””â”€ Non â†’ IVFFlat suffit
        â”‚       â”‚
        â”‚       â””â”€ TrÃ¨s haute prÃ©cision (>98%) ?
        â”‚           â”‚
        â”‚           â””â”€ Oui â†’ HNSW obligatoire
```

---

## Configuration et Tuning

### Dimensionnement des ressources

#### RAM nÃ©cessaire

**IVFFlat** :
```
RAM minimale = taille_donnÃ©es Ã— 1.5
RAM recommandÃ©e = taille_donnÃ©es Ã— 2
```

**HNSW** :
```
RAM minimale = taille_donnÃ©es Ã— 2
RAM recommandÃ©e = taille_donnÃ©es Ã— 3
```

**Exemple** :
- 1M vecteurs de 1536 dimensions = ~6 GB de donnÃ©es
- IVFFlat : 9 GB RAM recommandÃ©e
- HNSW : 18 GB RAM recommandÃ©e

#### Espace disque

**IVFFlat** :
```
Espace index = taille_donnÃ©es Ã— 0.3
```

**HNSW** :
```
Espace index = taille_donnÃ©es Ã— (1 + m/10)

m=8  â†’ +80% de la taille des donnÃ©es
m=16 â†’ +160% de la taille des donnÃ©es
m=32 â†’ +320% de la taille des donnÃ©es
```

**Exemple** :
- 1M vecteurs de 1536 dimensions = ~6 GB
- IVFFlat : ~1.8 GB index
- HNSW (m=16) : ~9.6 GB index

### Optimisation IVFFlat

#### Choix du nombre de lists

**Formule de base** :
```
lists = âˆš(nombre_de_lignes)
```

**Affinement** :

```sql
-- Pour datasets trÃ¨s grands (>1M)
lists = nombre_de_lignes / 1000

-- Exemple : 10M vecteurs
lists = 10000000 / 1000 = 10000
```

**Test empirique** :

```sql
-- Tester diffÃ©rentes valeurs
CREATE INDEX idx_test_100 ON produits
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

CREATE INDEX idx_test_316 ON produits
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 316);

CREATE INDEX idx_test_1000 ON produits
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 1000);

-- Comparer les performances
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM produits
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;
```

#### Ajustement de probes

**StratÃ©gie progressive** :

```sql
-- DÃ©marrer avec probes faible
SET ivfflat.probes = 1;
-- Mesurer recall et temps

-- Augmenter progressivement
SET ivfflat.probes = 5;
SET ivfflat.probes = 10;  -- Bon compromis
SET ivfflat.probes = 20;  -- Haute prÃ©cision

-- Trouver le sweet spot pour votre cas d'usage
```

**RÃ¨gle pratique** :
```
probes = max(10, lists / 100)

Exemples :
- lists = 100  â†’ probes = 10
- lists = 1000 â†’ probes = 10
- lists = 10000 â†’ probes = 100
```

### Optimisation HNSW

#### Choix de m

**Par dataset** :

| Taille dataset | m recommandÃ© | Justification |
|---------------|-------------|---------------|
| < 100K | 8 | Ã‰conomie d'espace |
| 100K - 1M | 16 | **DÃ©faut optimal** |
| 1M - 10M | 16-24 | Bon Ã©quilibre |
| > 10M | 24-32 | Haute prÃ©cision |

**Par cas d'usage** :

```sql
-- Prototypage / Dev
WITH (m = 8, ef_construction = 32)

-- Production standard
WITH (m = 16, ef_construction = 64)  -- RecommandÃ©

-- Production haute performance
WITH (m = 24, ef_construction = 96)

-- Critique / Financier
WITH (m = 32, ef_construction = 128)
```

#### Choix de ef_construction

**RÃ¨gle** :
```
ef_construction = 4 Ã— m (minimum)
ef_construction = 8 Ã— m (recommandÃ©)

Exemples :
- m=8  â†’ ef_construction = 64
- m=16 â†’ ef_construction = 128
- m=32 â†’ ef_construction = 256
```

#### Choix de ef_search

**Par latence cible** :

```sql
-- < 5ms par requÃªte (vitesse max)
SET hnsw.ef_search = 20;

-- < 10ms (production standard)
SET hnsw.ef_search = 40;  -- DÃ©faut recommandÃ©

-- < 50ms (haute prÃ©cision)
SET hnsw.ef_search = 100;

-- PrÃ©cision maximale (peu importe le temps)
SET hnsw.ef_search = 200;
```

---

## Exemples Pratiques Complets

### Exemple 1 : Startup avec 50K documents

**Contexte** : Base de connaissances avec recherche sÃ©mantique

```sql
-- CrÃ©er la table
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    titre TEXT,
    contenu TEXT,
    embedding vector(1536)
);

-- InsÃ©rer 50 000 documents (via application)
-- ...

-- Choix : IVFFlat (dataset moyen, Ã©conomie d'espace)
CREATE INDEX idx_documents_embedding
ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 224);  -- âˆš50000 â‰ˆ 224

-- Configuration de recherche
SET ivfflat.probes = 10;

-- Recherche
SELECT
    titre,
    LEFT(contenu, 100) AS apercu,
    embedding <=> '[...]'::vector(1536) AS distance
FROM documents
ORDER BY distance
LIMIT 5;

-- RÃ©sultat : ~20ms par requÃªte, recall ~95%
```

### Exemple 2 : E-commerce avec 500K produits

**Contexte** : Recommandation de produits similaires

```sql
-- CrÃ©er la table
CREATE TABLE produits (
    id SERIAL PRIMARY KEY,
    nom TEXT,
    description TEXT,
    categorie TEXT,
    prix NUMERIC,
    embedding vector(768)  -- Sentence-BERT
);

-- InsÃ©rer 500 000 produits
-- ...

-- Choix : HNSW (haute performance souhaitÃ©e)
CREATE INDEX idx_produits_embedding
ON produits
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Construction : ~30 minutes

-- Configuration de recherche
SET hnsw.ef_search = 40;

-- Recherche de produits similaires
SELECT
    p2.id,
    p2.nom,
    p2.prix,
    p1.embedding <=> p2.embedding AS distance
FROM produits p1
CROSS JOIN produits p2
WHERE p1.id = 12345  -- Produit de rÃ©fÃ©rence
  AND p2.id != 12345
ORDER BY distance
LIMIT 10;

-- RÃ©sultat : ~5ms par requÃªte, recall ~98%
```

### Exemple 3 : Archives avec 10M de documents

**Contexte** : Recherche dans archives historiques

```sql
-- CrÃ©er la table
CREATE TABLE archives (
    id SERIAL PRIMARY KEY,
    annee INTEGER,
    type_document TEXT,
    texte TEXT,
    embedding vector(1536)
);

-- InsÃ©rer 10 millions de documents
-- ...

-- Choix : HNSW haute performance
CREATE INDEX idx_archives_embedding
ON archives
USING hnsw (embedding vector_cosine_ops)
WITH (m = 24, ef_construction = 96);

-- Construction : ~6 heures (parallÃ©lisation recommandÃ©e)
SET max_parallel_maintenance_workers = 4;

-- Configuration de recherche optimisÃ©e
SET hnsw.ef_search = 60;

-- Recherche avec filtres
SELECT
    id,
    annee,
    type_document,
    LEFT(texte, 150) AS extrait,
    embedding <=> '[...]'::vector(1536) AS distance
FROM archives
WHERE annee BETWEEN 1990 AND 2000  -- Pre-filtre PostgreSQL
ORDER BY distance
LIMIT 20;

-- RÃ©sultat : ~15ms par requÃªte, recall ~98.5%
```

### Exemple 4 : Migration IVFFlat â†’ HNSW

**Contexte** : Croissance du dataset nÃ©cessite upgrade

```sql
-- Situation initiale : 100K vecteurs avec IVFFlat
-- Le dataset a grandi Ã  2M vecteurs â†’ performance dÃ©gradÃ©e

-- Ã‰tape 1 : CrÃ©er nouvel index HNSW en parallÃ¨le
CREATE INDEX CONCURRENTLY idx_documents_hnsw
ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Construction : ~1h30 (CONCURRENTLY n'impacte pas les requÃªtes)

-- Ã‰tape 2 : Tester le nouvel index
SET enable_seqscan = off;  -- Forcer utilisation index
SET hnsw.ef_search = 40;

EXPLAIN (ANALYZE)
SELECT * FROM documents
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;

-- VÃ©rifier : "Index Scan using idx_documents_hnsw"

-- Ã‰tape 3 : Si OK, supprimer ancien index IVFFlat
DROP INDEX idx_documents_ivfflat;

-- Ã‰tape 4 : Configurer par dÃ©faut
ALTER DATABASE ma_base SET hnsw.ef_search = 40;
```

---

## Maintenance des Index

### Monitoring de la santÃ©

#### Taille des index

```sql
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    pg_size_pretty(pg_table_size(schemaname||'.'||tablename)) AS table_size
FROM pg_stat_user_indexes
WHERE indexname LIKE '%embedding%'
ORDER BY pg_relation_size(indexrelid) DESC;
```

**RÃ©sultat exemple** :

```
 schemaname | tablename  |       indexname        | index_size | table_size
------------+------------+------------------------+------------+------------
 public     | documents  | idx_documents_hnsw     | 9.2 GB     | 6.1 GB
 public     | produits   | idx_produits_ivfflat   | 1.8 GB     | 5.9 GB
```

#### Utilisation des index

```sql
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan AS nombre_utilisations,
    idx_tup_read AS lignes_lues,
    idx_tup_fetch AS lignes_recuperees
FROM pg_stat_user_indexes
WHERE indexname LIKE '%embedding%'
ORDER BY idx_scan DESC;
```

### Reconstruction d'index

#### Quand reconstruire ?

**IVFFlat** :
- AprÃ¨s insertion/suppression de >20% des donnÃ©es
- Changement de distribution des donnÃ©es
- DÃ©gradation des performances constatÃ©e

**HNSW** :
- Rarement nÃ©cessaire (auto-maintenance)
- AprÃ¨s insertion/suppression massive (>50% des donnÃ©es)
- Changement radical de distribution

#### Comment reconstruire

```sql
-- Reconstruction simple (bloque la table)
REINDEX INDEX idx_documents_embedding;

-- Reconstruction sans bloquer les requÃªtes
REINDEX INDEX CONCURRENTLY idx_documents_embedding;

-- Reconstruire tous les index d'une table
REINDEX TABLE CONCURRENTLY documents;
```

### Vacuum et maintenance

```sql
-- Vacuum rÃ©gulier (recommandÃ© quotidien/hebdomadaire)
VACUUM ANALYZE documents;

-- Si beaucoup de suppressions, vacuum full
VACUUM FULL ANALYZE documents;
-- Attention : bloque la table, long !

-- Statistiques Ã  jour pour le planificateur
ANALYZE documents;
```

---

## Troubleshooting

### ProblÃ¨me 1 : Index non utilisÃ©

**SymptÃ´me** : EXPLAIN montre "Seq Scan" au lieu de "Index Scan"

**Diagnostic** :

```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM documents
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;
```

**Causes possibles** :

1. **Index pas crÃ©Ã© ou invalide**

```sql
-- VÃ©rifier les index
SELECT indexname, indexdef
FROM pg_indexes
WHERE tablename = 'documents';
```

2. **Mauvais operator class**

```sql
-- âŒ Mauvais
CREATE INDEX ... USING hnsw (embedding vector_l2_ops);  -- Pour L2
-- Mais requÃªte utilise cosine (<=>)

-- âœ… Bon
CREATE INDEX ... USING hnsw (embedding vector_cosine_ops);  -- Pour cosine
```

3. **ParamÃ¨tres de recherche non dÃ©finis**

```sql
-- IVFFlat
SET ivfflat.probes = 10;

-- HNSW
SET hnsw.ef_search = 40;
```

4. **Sequential scan forcÃ©**

```sql
-- DÃ©sactiver temporairement
SET enable_seqscan = off;
```

### ProblÃ¨me 2 : Construction d'index Ã©choue

**SymptÃ´me** : ERROR lors de CREATE INDEX

**Erreur : Out of memory**

```sql
-- Solution : Augmenter work_mem temporairement
SET maintenance_work_mem = '4GB';

CREATE INDEX ...;

-- RÃ©initialiser
RESET maintenance_work_mem;
```

**Erreur : Cannot create IVFFlat index (not enough data)**

```sql
-- IVFFlat nÃ©cessite des donnÃ©es pour clustering
-- Solution : InsÃ©rer des donnÃ©es d'abord

-- Ou utiliser HNSW qui n'a pas cette limitation
CREATE INDEX ... USING hnsw ...;
```

### ProblÃ¨me 3 : Performances dÃ©gradÃ©es

**SymptÃ´me** : Recherches de plus en plus lentes

**Diagnostic** :

```sql
-- VÃ©rifier le bloat de la table
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    n_live_tup AS lignes_vivantes,
    n_dead_tup AS lignes_mortes,
    round(100.0 * n_dead_tup / nullif(n_live_tup + n_dead_tup, 0), 1) AS pct_dead
FROM pg_stat_user_tables
WHERE tablename = 'documents';
```

**Solutions** :

```sql
-- Si pct_dead > 10%
VACUUM ANALYZE documents;

-- Si pct_dead > 30%
REINDEX INDEX CONCURRENTLY idx_documents_embedding;
```

### ProblÃ¨me 4 : PrÃ©cision insuffisante

**SymptÃ´me** : RÃ©sultats ne semblent pas pertinents

**Solutions IVFFlat** :

```sql
-- Augmenter probes
SET ivfflat.probes = 20;  -- Au lieu de 10
SET ivfflat.probes = 50;  -- Encore plus

-- Ou recrÃ©er avec plus de lists
DROP INDEX idx_documents_embedding;
CREATE INDEX idx_documents_embedding
ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 500);  -- Au lieu de 100
```

**Solutions HNSW** :

```sql
-- Augmenter ef_search
SET hnsw.ef_search = 100;  -- Au lieu de 40
SET hnsw.ef_search = 200;  -- Encore plus

-- Ou recrÃ©er avec m plus Ã©levÃ©
DROP INDEX idx_documents_embedding;
CREATE INDEX idx_documents_embedding
ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 32, ef_construction = 128);  -- Au lieu de m=16
```

---

## Checklist de Production

### Avant dÃ©ploiement

âœ… **Dimensionnement** :
- [ ] RAM suffisante (2-3Ã— la taille des donnÃ©es pour HNSW)
- [ ] Espace disque (2-3Ã— pour index HNSW)
- [ ] CPU multi-core pour construction parallÃ¨le

âœ… **Configuration** :
- [ ] `shared_buffers` â‰¥ 25% de la RAM
- [ ] `effective_cache_size` â‰¥ 50% de la RAM
- [ ] `maintenance_work_mem` â‰¥ 2GB pour construction
- [ ] `max_parallel_maintenance_workers` = 4-8

âœ… **Choix d'index** :
- [ ] IVFFlat pour <1M vecteurs OU contraintes d'espace
- [ ] HNSW pour >1M vecteurs OU haute performance

âœ… **ParamÃ¨tres** :
- [ ] IVFFlat : `lists = âˆšN`, `probes = 10`
- [ ] HNSW : `m = 16`, `ef_construction = 64`, `ef_search = 40`

### Monitoring continu

âœ… **MÃ©triques Ã  surveiller** :
- [ ] Temps de rÃ©ponse moyen des recherches
- [ ] Taux d'utilisation des index (pg_stat_user_indexes)
- [ ] Taille des index (croissance)
- [ ] Bloat des tables/index (dead tuples)

âœ… **Alertes** :
- [ ] Temps de recherche > 100ms
- [ ] Dead tuples > 10%
- [ ] Index > 200% de la taille des donnÃ©es

### Maintenance rÃ©guliÃ¨re

âœ… **Quotidien** :
- [ ] VACUUM ANALYZE automatique (autovacuum activÃ©)

âœ… **Hebdomadaire** :
- [ ] VÃ©rifier les statistiques de performance
- [ ] Analyser les requÃªtes lentes (pg_stat_statements)

âœ… **Mensuel** :
- [ ] VÃ©rifier la croissance des index
- [ ] Tester la qualitÃ© des rÃ©sultats (recall)
- [ ] Ajuster les paramÃ¨tres si nÃ©cessaire

âœ… **AprÃ¨s changements majeurs** :
- [ ] REINDEX si >20% de donnÃ©es changÃ©es (IVFFlat)
- [ ] ANALYZE aprÃ¨s insertions massives
- [ ] Benchmark des performances

---

## Conclusion

### Points clÃ©s Ã  retenir

âœ… **Les index vectoriels sont essentiels** pour la performance au-delÃ  de 10K vecteurs

âœ… **IVFFlat** : Simple, rapide Ã  construire, bon pour datasets moyens
- Clustering des vecteurs similaires
- `lists = âˆšN`, `probes = 10` (dÃ©faut)
- ~95% recall, trÃ¨s rapide

âœ… **HNSW** : Ultra-performant, prÃ©cis, idÃ©al pour production
- Graphe multi-niveaux navigable
- `m = 16`, `ef_construction = 64`, `ef_search = 40`
- ~98-99% recall, ultra-rapide

âœ… **Choix de l'index** :
- < 100K vecteurs : IVFFlat ou pas d'index
- 100K - 1M : IVFFlat (Ã©conomie) ou HNSW (performance)
- > 1M : HNSW obligatoire

âš ï¸ **Trade-offs** : Vitesse â†” PrÃ©cision â†” Espace

âš ï¸ **Tuning essentiel** : Les paramÃ¨tres par dÃ©faut ne sont pas toujours optimaux

ğŸ¯ Avec un bon index, recherche de vecteurs = **1500Ã— plus rapide** ! ğŸš€

### Recommandations finales

**Pour dÃ©butants** :
1. Commencez avec HNSW defaults (`m=16, ef_construction=64`)
2. Ne sur-optimisez pas dÃ¨s le dÃ©but
3. Mesurez avant d'ajuster

**Pour production** :
1. HNSW pour >100K vecteurs
2. Dimensionner la RAM (3Ã— les donnÃ©es)
3. Monitorer et ajuster itÃ©rativement

**Pour datasets massifs** :
1. HNSW obligatoire
2. Construction parallÃ¨le (`max_parallel_maintenance_workers`)
3. Partitionnement si >100M vecteurs

### Prochaines Ã©tapes

Pour aller plus loin :
1. **Benchmarker** : Tester les deux index sur vos donnÃ©es rÃ©elles
2. **Tuner** : Ajuster les paramÃ¨tres selon vos mÃ©triques
3. **Monitorer** : Mettre en place monitoring continu
4. **Optimiser** : ItÃ©rer sur la configuration

### Ressources

- [pgvector Documentation](https://github.com/pgvector/pgvector#indexing)
- [HNSW Paper](https://arxiv.org/abs/1603.09320) - Article scientifique original
- [Benchmarks pgvector](https://github.com/pgvector/pgvector#performance)
- [ANN Benchmarks](http://ann-benchmarks.com/) - Comparaison d'algorithmes ANN

---


â­ï¸ [Cas d'usage : RAG, Semantic Search](/18-extensions-et-integrations/06.3-cas-usage-rag.md)
