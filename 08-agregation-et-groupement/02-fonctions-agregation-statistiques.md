üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.2. Fonctions d'Agr√©gation Statistiques (STDDEV, VARIANCE, CORR, PERCENTILE)

## Introduction aux Statistiques en SQL

Dans la section pr√©c√©dente, nous avons explor√© les fonctions d'agr√©gation de base (COUNT, SUM, AVG, MIN, MAX). Ces fonctions sont essentielles, mais elles ne racontent qu'une partie de l'histoire des donn√©es.

PostgreSQL propose des **fonctions d'agr√©gation statistiques avanc√©es** qui permettent d'analyser plus finement vos donn√©es : mesurer la dispersion, identifier des tendances, d√©tecter des corr√©lations, et comprendre la distribution des valeurs.

### Pourquoi les Statistiques en Base de Donn√©es ?

Traditionnellement, les analyses statistiques se font dans des outils comme Excel, Python ou R. Mais effectuer ces calculs directement en SQL pr√©sente des avantages majeurs :

- ‚úÖ **Performance** : Calculs effectu√©s au plus pr√®s des donn√©es, sans transfert r√©seau
- ‚úÖ **Simplicit√©** : Pas besoin d'exporter puis r√©importer les r√©sultats
- ‚úÖ **Coh√©rence** : Garantie transactionnelle sur les donn√©es analys√©es
- ‚úÖ **Scalabilit√©** : PostgreSQL optimise les calculs sur des millions de lignes

---

## Vue d'Ensemble des Fonctions Statistiques

PostgreSQL offre un ensemble complet de fonctions statistiques :

| Cat√©gorie | Fonctions | Usage |
|-----------|-----------|-------|
| **Dispersion** | STDDEV, VARIANCE | Mesurer l'√©cart par rapport √† la moyenne |
| **Corr√©lation** | CORR, COVAR_POP, COVAR_SAMP | Relations entre deux variables |
| **R√©gression** | REGR_SLOPE, REGR_INTERCEPT | Analyse de tendance lin√©aire |
| **Distributions** | PERCENTILE_CONT, PERCENTILE_DISC | M√©diane, quartiles, centiles |

Nous allons explorer les plus importantes dans cette section.

---

## 1. VARIANCE - La Variance

### Qu'est-ce que la Variance ?

La variance mesure **√† quel point les valeurs sont dispers√©es autour de la moyenne**. C'est un indicateur fondamental de variabilit√© des donn√©es.

- **Variance faible** : Les valeurs sont proches de la moyenne (donn√©es homog√®nes)
- **Variance √©lev√©e** : Les valeurs sont tr√®s dispers√©es (donn√©es h√©t√©rog√®nes)

### Formule Math√©matique

Pour une population :

```
Variance = Œ£(xi - moyenne)¬≤ / N
```

O√π :
- `xi` = chaque valeur
- `moyenne` = moyenne des valeurs
- `N` = nombre total de valeurs

### Syntaxe PostgreSQL

PostgreSQL propose deux variantes :

```sql
-- Variance d'√©chantillon (Sample Variance) - LA PLUS COURANTE
VAR_SAMP(colonne)
VARIANCE(colonne)  -- Alias de VAR_SAMP

-- Variance de population (Population Variance)
VAR_POP(colonne)
```

**Quelle version utiliser ?**

- **VAR_SAMP / VARIANCE** : Utiliser **dans 99% des cas** (donn√©es = √©chantillon d'une population plus large)
- **VAR_POP** : Seulement si vos donn√©es repr√©sentent la **totalit√©** d'une population (rare en pratique)

### Exemple Th√©orique

Imaginons une table `salaires_employes` :

| employe_id | nom      | salaire |
|------------|----------|---------|
| 1          | Alice    | 35000   |
| 2          | Bob      | 38000   |
| 3          | Charlie  | 36000   |
| 4          | Diana    | 37000   |
| 5          | Eve      | 34000   |

**Calcul de la variance :**

```sql
SELECT
    AVG(salaire) AS salaire_moyen,
    VARIANCE(salaire) AS variance_salaire
FROM salaires_employes;
```

**R√©sultat th√©orique :**

| salaire_moyen | variance_salaire |
|---------------|------------------|
| 36000         | 2500000          |

**Interpr√©tation :**
- La moyenne est de 36 000 ‚Ç¨
- La variance est de 2 500 000 (en ‚Ç¨¬≤)
- Cette valeur seule est difficile √† interpr√©ter ‚Üí c'est pourquoi on utilise l'√©cart-type !

### Cas d'Usage

- **Finance** : Volatilit√© des prix, risque de portefeuille
- **Qualit√©** : Coh√©rence de la production industrielle
- **Performance** : Variabilit√© des temps de r√©ponse d'une API
- **Marketing** : Dispersion des comportements d'achat

---

## 2. STDDEV - L'√âcart-Type (Standard Deviation)

### Qu'est-ce que l'√âcart-Type ?

L'√©cart-type est la **racine carr√©e de la variance**. C'est la mesure de dispersion la plus utilis√©e car elle est exprim√©e **dans la m√™me unit√© que les donn√©es originales**.

### Pourquoi l'√âcart-Type est Plus Intuitif que la Variance ?

Reprenons l'exemple des salaires :
- Variance : 2 500 000 **‚Ç¨¬≤** (unit√© difficile √† interpr√©ter)
- √âcart-type : ‚àö2 500 000 ‚âà 1 581 **‚Ç¨** (unit√© claire : euros)

**Interpr√©tation** : "En moyenne, les salaires s'√©cartent de 1 581 ‚Ç¨ par rapport √† la moyenne de 36 000 ‚Ç¨"

### Syntaxe PostgreSQL

```sql
-- √âcart-type d'√©chantillon (Sample Standard Deviation) - LA PLUS COURANTE
STDDEV_SAMP(colonne)
STDDEV(colonne)  -- Alias de STDDEV_SAMP

-- √âcart-type de population (Population Standard Deviation)
STDDEV_POP(colonne)
```

### Exemple Th√©orique

```sql
SELECT
    AVG(salaire) AS salaire_moyen,
    STDDEV(salaire) AS ecart_type_salaire,
    VARIANCE(salaire) AS variance_salaire
FROM salaires_employes;
```

**R√©sultat :**

| salaire_moyen | ecart_type_salaire | variance_salaire |
|---------------|-------------------|------------------|
| 36000         | 1581.14           | 2500000          |

### Interpr√©tation de l'√âcart-Type : La R√®gle des 68-95-99.7

Pour une distribution normale (en cloche) :

- **68%** des valeurs se situent √† ¬±1 √©cart-type de la moyenne
- **95%** des valeurs se situent √† ¬±2 √©carts-types de la moyenne
- **99.7%** des valeurs se situent √† ¬±3 √©carts-types de la moyenne

**Exemple avec nos salaires** (moyenne = 36 000, √©cart-type = 1 581) :

- **68%** des salaires devraient √™tre entre 34 419 ‚Ç¨ et 37 581 ‚Ç¨
- **95%** des salaires devraient √™tre entre 32 838 ‚Ç¨ et 39 162 ‚Ç¨

### Comparaison de Dispersion

Imaginons deux d√©partements :

**D√©partement A :**
```sql
-- Salaires : 35k, 36k, 37k (tr√®s homog√®nes)
-- Moyenne : 36k, √âcart-type : ~817‚Ç¨
```

**D√©partement B :**
```sql
-- Salaires : 25k, 36k, 47k (tr√®s dispers√©s)
-- Moyenne : 36k, √âcart-type : ~9000‚Ç¨
```

**Observation** : M√™me moyenne, mais dispersion radicalement diff√©rente !

### D√©tection d'Anomalies avec l'√âcart-Type

Un usage classique : identifier les valeurs aberrantes (outliers)

```sql
-- Trouver les salaires "anormaux" (> 3 √©carts-types de la moyenne)
WITH stats AS (
    SELECT
        AVG(salaire) AS moyenne,
        STDDEV(salaire) AS ecart_type
    FROM salaires_employes
)
SELECT e.*
FROM salaires_employes e, stats s
WHERE e.salaire > s.moyenne + (3 * s.ecart_type)
   OR e.salaire < s.moyenne - (3 * s.ecart_type);
```

Cette requ√™te identifie les salaires qui s'√©cartent de plus de 3 œÉ (sigma) de la moyenne, ce qui est statistiquement tr√®s rare (<0.3% si distribution normale).

---

## 3. Corr√©lation et Covariance

### 3.1. Covariance (COVAR)

#### Qu'est-ce que la Covariance ?

La covariance mesure **dans quelle mesure deux variables varient ensemble** :

- **Covariance positive** : Quand X augmente, Y augmente aussi
- **Covariance n√©gative** : Quand X augmente, Y diminue
- **Covariance proche de z√©ro** : Aucune relation lin√©aire √©vidente

#### Syntaxe PostgreSQL

```sql
-- Covariance d'√©chantillon
COVAR_SAMP(Y, X)

-- Covariance de population
COVAR_POP(Y, X)
```

‚ö†Ô∏è **Ordre des arguments** : `COVAR(Y, X)` ‚Üí Y est la variable d√©pendante, X la variable ind√©pendante

#### Exemple Th√©orique

Table `ventes_marketing` :

| mois | budget_pub | ventes |
|------|------------|--------|
| 1    | 1000       | 15000  |
| 2    | 1500       | 18000  |
| 3    | 2000       | 21000  |
| 4    | 1200       | 16000  |
| 5    | 1800       | 20000  |

```sql
SELECT COVAR_SAMP(ventes, budget_pub) AS covariance
FROM ventes_marketing;
-- R√©sultat positif ‚Üí relation positive entre budget pub et ventes
```

#### Limite de la Covariance

**Probl√®me** : La valeur de la covariance d√©pend de l'√©chelle des variables. Une covariance de 1000 est-elle forte ou faible ? Impossible √† dire sans contexte !

**Solution** : Utiliser le coefficient de corr√©lation (standardis√©).

---

### 3.2. Corr√©lation (CORR)

#### Qu'est-ce que le Coefficient de Corr√©lation ?

Le coefficient de corr√©lation (de Pearson) est une **version standardis√©e de la covariance**. Il est toujours compris entre **-1 et +1** :

- **+1** : Corr√©lation positive parfaite (relation lin√©aire croissante parfaite)
- **0** : Aucune corr√©lation lin√©aire
- **-1** : Corr√©lation n√©gative parfaite (relation lin√©aire d√©croissante parfaite)

#### Formule

```
CORR = COVAR(X,Y) / (STDDEV(X) * STDDEV(Y))
```

#### Syntaxe PostgreSQL

```sql
CORR(Y, X)
```

#### Interpr√©tation des Valeurs

| Valeur de CORR | Interpr√©tation |
|----------------|----------------|
| 0.9 √† 1.0      | Corr√©lation tr√®s forte positive |
| 0.7 √† 0.9      | Corr√©lation forte positive |
| 0.4 √† 0.7      | Corr√©lation mod√©r√©e positive |
| 0.0 √† 0.4      | Corr√©lation faible ou nulle |
| -0.4 √† 0.0     | Corr√©lation faible n√©gative |
| -0.7 √† -0.4    | Corr√©lation mod√©r√©e n√©gative |
| -0.9 √† -0.7    | Corr√©lation forte n√©gative |
| -1.0 √† -0.9    | Corr√©lation tr√®s forte n√©gative |

#### Exemple Th√©orique

```sql
SELECT
    CORR(ventes, budget_pub) AS correlation_ventes_pub,
    COVAR_SAMP(ventes, budget_pub) AS covariance
FROM ventes_marketing;
```

**R√©sultat hypoth√©tique :**

| correlation_ventes_pub | covariance |
|------------------------|------------|
| 0.95                   | 2500000    |

**Interpr√©tation** :
- Corr√©lation de 0.95 ‚Üí **relation tr√®s forte** entre budget pub et ventes
- Quand le budget augmente, les ventes augmentent de fa√ßon quasi-lin√©aire

#### Cas d'Usage R√©els

**E-commerce :**
```sql
-- Y a-t-il une corr√©lation entre le nombre de produits consult√©s
-- et le montant du panier final ?
SELECT CORR(montant_panier, nb_produits_vus) AS correlation
FROM sessions_utilisateurs;
```

**Performance Web :**
```sql
-- Le temps de chargement impacte-t-il le taux de rebond ?
SELECT CORR(taux_rebond, temps_chargement_ms) AS correlation
FROM analytics_pages;
-- R√©sultat attendu : corr√©lation positive (+ de temps = + de rebond)
```

**RH :**
```sql
-- Anciennet√© vs salaire : quelle corr√©lation ?
SELECT CORR(salaire, annees_anciennete) AS correlation
FROM employes;
```

#### ‚ö†Ô∏è Attention : Corr√©lation ‚â† Causalit√© !

**TR√àS IMPORTANT** : Une forte corr√©lation ne signifie PAS qu'il y a un lien de cause √† effet !

Exemple classique :
- Corr√©lation entre ventes de glace et noyades en √©t√© : **forte**
- Cause r√©elle : La temp√©rature (variable cach√©e)

Toujours analyser le contexte m√©tier avant de conclure !

---

## 4. Percentiles et Distribution

### Qu'est-ce qu'un Percentile ?

Un **percentile** est une valeur qui s√©pare les donn√©es en pourcentages :

- **M√©diane** = 50·µâ percentile (50% des valeurs en dessous, 50% au-dessus)
- **Premier quartile (Q1)** = 25·µâ percentile
- **Troisi√®me quartile (Q3)** = 75·µâ percentile
- **95·µâ percentile** = 95% des valeurs sont inf√©rieures

### Pourquoi les Percentiles ?

La **moyenne est sensible aux valeurs extr√™mes**. Les percentiles sont plus robustes :

**Exemple :**
- 9 personnes gagnent 30 000 ‚Ç¨
- 1 personne (PDG) gagne 1 000 000 ‚Ç¨

Statistiques :
- **Moyenne** : 127 000 ‚Ç¨ (ne repr√©sente PERSONNE !)
- **M√©diane (50·µâ percentile)** : 30 000 ‚Ç¨ (repr√©sentative)

### Syntaxe PostgreSQL

PostgreSQL propose deux fonctions de percentile :

```sql
-- PERCENTILE_CONT : Interpolation continue (peut retourner une valeur qui n'existe pas)
PERCENTILE_CONT(percentile) WITHIN GROUP (ORDER BY colonne)

-- PERCENTILE_DISC : Valeur discr√®te (retourne une valeur r√©elle du dataset)
PERCENTILE_DISC(percentile) WITHIN GROUP (ORDER BY colonne)
```

**Param√®tre `percentile`** : Valeur entre 0 et 1
- 0.5 = m√©diane
- 0.25 = premier quartile
- 0.75 = troisi√®me quartile
- 0.95 = 95·µâ percentile

### Diff√©rence entre CONT et DISC

**Table exemple `notes_examen` :**

| etudiant_id | note |
|-------------|------|
| 1           | 10   |
| 2           | 12   |
| 3           | 14   |
| 4           | 16   |
| 5           | 18   |

```sql
SELECT
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY note) AS mediane_cont,
    PERCENTILE_DISC(0.5) WITHIN GROUP (ORDER BY note) AS mediane_disc
FROM notes_examen;
```

**R√©sultat :**

| mediane_cont | mediane_disc |
|--------------|--------------|
| 14.0         | 14           |

**Cas avec nombre pair de valeurs :**

Si on ajoute une 6·µâ note de 20 :

| mediane_cont | mediane_disc |
|--------------|--------------|
| 15.0         | 14 ou 16     |

- **CONT** : Interpole entre 14 et 16 ‚Üí 15 (valeur qui n'existe pas dans le dataset)
- **DISC** : Choisit une valeur r√©elle (g√©n√©ralement la plus basse des deux)

**Quand utiliser quoi ?**

- **PERCENTILE_CONT** : Pour des donn√©es continues (salaires, temp√©ratures, temps)
- **PERCENTILE_DISC** : Pour des donn√©es discr√®tes ou quand vous voulez une valeur r√©elle

### Exemple : Analyse Salariale Compl√®te

```sql
SELECT
    MIN(salaire) AS salaire_min,
    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY salaire) AS q1_25,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salaire) AS mediane,
    AVG(salaire) AS moyenne,
    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY salaire) AS q3_75,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY salaire) AS p95,
    MAX(salaire) AS salaire_max,
    STDDEV(salaire) AS ecart_type
FROM salaires_employes;
```

**R√©sultat th√©orique :**

| salaire_min | q1_25  | mediane | moyenne | q3_75  | p95    | salaire_max | ecart_type |
|-------------|--------|---------|---------|--------|--------|-------------|------------|
| 25000       | 35000  | 42000   | 48000   | 55000  | 85000  | 150000      | 18000      |

**Interpr√©tation :**
- La **m√©diane** (42k) est bien inf√©rieure √† la **moyenne** (48k) ‚Üí distribution asym√©trique avec quelques tr√®s hauts salaires
- 25% des employ√©s gagnent moins de 35k
- 95% des employ√©s gagnent moins de 85k
- L'√©cart-type de 18k montre une forte dispersion

### Percentiles Multiples : Analyse de Performance Web

```sql
SELECT
    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY temps_reponse_ms) AS p50_mediane,
    PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY temps_reponse_ms) AS p90,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY temps_reponse_ms) AS p95,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY temps_reponse_ms) AS p99
FROM logs_requetes_api;
```

**R√©sultat :**

| p50_mediane | p90  | p95  | p99  |
|-------------|------|------|------|
| 120         | 350  | 520  | 1850 |

**Interpr√©tation (SLA Web typique) :**
- **50% des requ√™tes** r√©pondent en moins de 120ms (exp√©rience majoritaire)
- **90% des requ√™tes** r√©pondent en moins de 350ms (bon)
- **5% des requ√™tes** prennent plus de 520ms (acceptable)
- **1% des requ√™tes** prennent plus de 1.8s (cas extr√™mes √† investiguer)

**Pourquoi P95/P99 plut√¥t que la moyenne ?**

Une moyenne de 200ms peut cacher :
- Cas A : Toutes les requ√™tes entre 150-250ms (excellent)
- Cas B : 90% √† 100ms, 10% √† 1000ms+ (probl√©matique pour les utilisateurs)

Les percentiles r√©v√®lent cette disparit√© !

---

## 5. Autres Fonctions Statistiques Utiles

### 5.1. Analyse de R√©gression Lin√©aire

PostgreSQL peut calculer automatiquement les param√®tres d'une droite de r√©gression (y = ax + b) :

```sql
-- Pente de la droite (coefficient a)
REGR_SLOPE(Y, X)

-- Ordonn√©e √† l'origine (coefficient b)
REGR_INTERCEPT(Y, X)

-- Coefficient de d√©termination R¬≤ (qualit√© de l'ajustement)
REGR_R2(Y, X)
```

**Exemple : Pr√©dire les ventes en fonction du budget pub**

```sql
SELECT
    REGR_SLOPE(ventes, budget_pub) AS pente,
    REGR_INTERCEPT(ventes, budget_pub) AS ordonnee,
    REGR_R2(ventes, budget_pub) AS r_carre,
    CORR(ventes, budget_pub) AS correlation
FROM ventes_marketing;
```

**R√©sultat th√©orique :**

| pente | ordonnee | r_carre | correlation |
|-------|----------|---------|-------------|
| 8.5   | 6500     | 0.90    | 0.95        |

**Interpr√©tation :**
- **√âquation de r√©gression** : `Ventes = 8.5 √ó Budget_pub + 6500`
- Pour chaque euro investi en pub, on g√©n√®re 8.5‚Ç¨ de ventes suppl√©mentaires
- R¬≤ de 0.90 signifie que 90% de la variance des ventes est expliqu√©e par le budget pub
- **Pr√©diction** : Si budget = 2000‚Ç¨ ‚Üí Ventes pr√©dites = 8.5√ó2000 + 6500 = 23 500‚Ç¨

### 5.2. Fonctions d'Agr√©gation Statistiques par Groupe

Toutes ces fonctions peuvent √™tre combin√©es avec GROUP BY :

```sql
SELECT
    departement,
    COUNT(*) AS nb_employes,
    AVG(salaire) AS salaire_moyen,
    STDDEV(salaire) AS ecart_type,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salaire) AS mediane
FROM employes
GROUP BY departement
ORDER BY salaire_moyen DESC;
```

**R√©sultat th√©orique :**

| departement | nb_employes | salaire_moyen | ecart_type | mediane |
|-------------|-------------|---------------|------------|---------|
| IT          | 25          | 55000         | 12000      | 52000   |
| Finance     | 18          | 52000         | 8000       | 50000   |
| Marketing   | 30          | 42000         | 6000       | 41000   |
| RH          | 12          | 38000         | 4000       | 37500   |

**Observations :**
- IT a le salaire moyen le plus √©lev√© mais aussi la plus forte dispersion (12k)
- RH a une faible dispersion (4k) ‚Üí salaires tr√®s homog√®nes
- Dans IT, moyenne (55k) > m√©diane (52k) ‚Üí quelques tr√®s hauts salaires tirent la moyenne vers le haut

---

## Tableau R√©capitulatif des Fonctions Statistiques

| Fonction | Objectif | R√©sultat Typique | Interpr√©tation |
|----------|----------|------------------|----------------|
| **VARIANCE(col)** | Dispersion des valeurs | Nombre positif (unit√©¬≤) | Plus √©lev√© = plus dispers√© |
| **STDDEV(col)** | √âcart-type (‚àövariance) | Nombre positif (m√™me unit√© que col) | "Distance moyenne" √† la moyenne |
| **COVAR_SAMP(Y,X)** | Covariation entre X et Y | Nombre (peut √™tre n√©gatif) | Relation (mais d√©pend de l'√©chelle) |
| **CORR(Y,X)** | Corr√©lation de Pearson | -1 √† +1 | Force et sens de la relation lin√©aire |
| **PERCENTILE_CONT(p)** | Percentile continu | Valeur (peut √™tre interpol√©e) | Seuil : p% en dessous |
| **PERCENTILE_DISC(p)** | Percentile discret | Valeur r√©elle du dataset | Seuil : p% en dessous |
| **REGR_SLOPE(Y,X)** | Pente de r√©gression | Nombre | Coefficient directeur de la droite |
| **REGR_INTERCEPT(Y,X)** | Ordonn√©e origine | Nombre | Valeur de Y quand X=0 |
| **REGR_R2(Y,X)** | Qualit√© ajustement | 0 √† 1 | % de variance expliqu√©e |

---

## Cas d'Usage Pratiques par Domaine

### üìä Finance & Trading

```sql
-- Analyse de volatilit√© d'un actif financier
SELECT
    ticker,
    AVG(prix_cloture) AS prix_moyen,
    STDDEV(prix_cloture) AS volatilite,
    (STDDEV(prix_cloture) / AVG(prix_cloture)) * 100 AS coeff_variation_pct
FROM cours_bourse
WHERE date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY ticker
ORDER BY volatilite DESC;
```

### üè• Sant√© & Biologie

```sql
-- Distribution des temps d'attente aux urgences
SELECT
    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY duree_attente_min) AS q1,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY duree_attente_min) AS mediane,
    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY duree_attente_min) AS q3,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY duree_attente_min) AS p95
FROM admissions_urgences
WHERE date_admission >= CURRENT_DATE - INTERVAL '7 days';
```

### üåê Performance Web & SRE

```sql
-- SLA monitoring : percentiles de latence
SELECT
    endpoint,
    COUNT(*) AS nb_requetes,
    ROUND(AVG(latence_ms), 2) AS latence_moyenne,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY latence_ms) AS p50,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latence_ms) AS p95,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY latence_ms) AS p99
FROM logs_http
WHERE timestamp >= NOW() - INTERVAL '1 hour'
GROUP BY endpoint
HAVING COUNT(*) > 100  -- Minimum de requ√™tes pour statistiques fiables
ORDER BY p95 DESC;
```

### üéì √âducation

```sql
-- Analyse de la distribution des notes par mati√®re
SELECT
    matiere,
    AVG(note) AS note_moyenne,
    STDDEV(note) AS ecart_type,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY note) AS mediane,
    -- √âcart entre moyenne et m√©diane (asym√©trie)
    AVG(note) - PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY note) AS skew_indicator
FROM resultats_examens
WHERE annee_scolaire = '2024-2025'
GROUP BY matiere;
```

### üõí E-commerce & Marketing

```sql
-- Corr√©lation entre comportement de navigation et conversion
SELECT
    CORR(montant_achat, nb_pages_vues) AS corr_pages_achat,
    CORR(montant_achat, duree_session_sec) AS corr_duree_achat,
    CORR(montant_achat, nb_produits_favoris) AS corr_favoris_achat
FROM sessions_utilisateurs
WHERE a_achete = TRUE
  AND date_session >= CURRENT_DATE - INTERVAL '90 days';
```

---

## Bonnes Pratiques et Pi√®ges √† √âviter

### ‚úÖ Bonnes Pratiques

1. **Toujours combiner moyenne et m√©diane pour d√©tecter l'asym√©trie**
   ```sql
   SELECT
       AVG(prix) AS moyenne,
       PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY prix) AS mediane
   FROM produits;
   -- Si moyenne >> m√©diane ‚Üí quelques valeurs tr√®s √©lev√©es
   ```

2. **Utiliser STDDEV_SAMP (ou STDDEV) par d√©faut**
   - Sauf si vous avez vraiment la population totale (tr√®s rare)

3. **Pr√©f√©rer les percentiles aux moyennes pour les SLA**
   - P95, P99 r√©v√®lent l'exp√©rience des utilisateurs "malchanceux"

4. **V√©rifier la taille de l'√©chantillon avant d'interpr√©ter les statistiques**
   ```sql
   SELECT
       COUNT(*) AS taille_echantillon,
       STDDEV(mesure) AS ecart_type
   FROM donnees
   HAVING COUNT(*) > 30;  -- Minimum statistique
   ```

5. **Arrondir les r√©sultats pour la lisibilit√©**
   ```sql
   SELECT ROUND(STDDEV(prix), 2) AS ecart_type
   FROM produits;
   ```

### ‚ùå Pi√®ges √† √âviter

1. **Confondre corr√©lation et causalit√©**
   - CORR(X,Y) = 0.95 ne signifie PAS que X cause Y !

2. **Utiliser VAR_POP/STDDEV_POP par erreur**
   - Dans le doute, utilisez VAR_SAMP/STDDEV_SAMP

3. **Interpr√©ter la variance sans contexte**
   - La variance seule (en unit√©¬≤) est difficile √† comprendre ‚Üí utilisez l'√©cart-type

4. **Ignorer les valeurs NULL**
   - Ces fonctions ignorent automatiquement les NULL
   - V√©rifiez si c'est le comportement souhait√© !

5. **Statistiques sur des petits √©chantillons**
   - Avec moins de 30 valeurs, les r√©sultats sont peu fiables
   - Toujours afficher COUNT(*) √† c√¥t√© des statistiques

6. **Oublier WITHIN GROUP pour PERCENTILE_CONT/DISC**
   ```sql
   -- ‚ùå ERREUR
   SELECT PERCENTILE_CONT(0.5, prix) FROM produits;

   -- ‚úÖ CORRECT
   SELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY prix) FROM produits;
   ```

---

## Performance et Optimisation

### Co√ªt de Calcul

Les fonctions statistiques n√©cessitent de **parcourir toutes les lignes** (full table scan) :

- **COUNT, SUM, AVG** : Scan simple (rapide)
- **STDDEV, VARIANCE** : Deux passes (moyenne d'abord, puis variance)
- **PERCENTILE** : Tri complet des donn√©es (le plus co√ªteux)
- **CORR, COVAR** : Calculs crois√©s sur deux colonnes

### Optimisations

1. **Filtrer avec WHERE avant d'agr√©ger**
   ```sql
   -- ‚úÖ Bon : filtrer d'abord
   SELECT STDDEV(prix)
   FROM produits
   WHERE categorie = '√âlectronique'
     AND date_ajout >= '2024-01-01';

   -- ‚ùå Moins bon : agr√©ger puis filtrer
   SELECT STDDEV(prix)
   FROM produits
   HAVING STDDEV(prix) > 100;  -- Calcul sur toute la table !
   ```

2. **Utiliser des index pour les pr√©filtres**
   - Index sur colonnes utilis√©es dans WHERE avant agr√©gation

3. **Mat√©rialiser les statistiques dans des tables de r√©sum√©**
   ```sql
   -- Pour des dashboards, pr√©calculer quotidiennement :
   CREATE TABLE stats_ventes_quotidiennes AS
   SELECT
       date_vente::DATE AS jour,
       COUNT(*) AS nb_ventes,
       AVG(montant) AS panier_moyen,
       STDDEV(montant) AS ecart_type_panier,
       PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY montant) AS mediane
   FROM ventes
   GROUP BY date_vente::DATE;
   ```

4. **Approximations pour les tr√®s grandes tables**
   - PostgreSQL 18+ : Certaines extensions proposent des statistiques approximatives (HyperLogLog)
   - Pour des milliards de lignes, consid√©rer l'√©chantillonnage

---

## Exemples Avanc√©s : Combinaison de Fonctions

### Analyse de Distribution Compl√®te

```sql
-- "Bo√Æte √† moustaches" (Box plot) en SQL
WITH stats AS (
    SELECT
        MIN(salaire) AS minimum,
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY salaire) AS q1,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salaire) AS mediane,
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY salaire) AS q3,
        MAX(salaire) AS maximum,
        AVG(salaire) AS moyenne,
        STDDEV(salaire) AS ecart_type
    FROM employes
)
SELECT
    minimum,
    q1,
    mediane,
    moyenne,
    q3,
    maximum,
    ecart_type,
    -- √âcart interquartile (robuste aux outliers)
    (q3 - q1) AS iqr,
    -- Coefficient de variation (√©cart-type relatif)
    (ecart_type / moyenne) * 100 AS coeff_variation_pct
FROM stats;
```

### D√©tection d'Outliers avec Z-Score

```sql
-- Identifier les valeurs aberrantes (> 3 √©carts-types)
WITH stats AS (
    SELECT
        AVG(prix) AS moyenne,
        STDDEV(prix) AS ecart_type
    FROM produits
)
SELECT
    p.id_produit,
    p.nom,
    p.prix,
    -- Z-score : nombre d'√©carts-types par rapport √† la moyenne
    (p.prix - s.moyenne) / s.ecart_type AS z_score
FROM produits p, stats s
WHERE ABS((p.prix - s.moyenne) / s.ecart_type) > 3
ORDER BY ABS((p.prix - s.moyenne) / s.ecart_type) DESC;
```

### Analyse de Tendance Temporelle

```sql
-- R√©gression lin√©aire : les ventes augmentent-elles avec le temps ?
WITH series AS (
    SELECT
        date_vente,
        EXTRACT(EPOCH FROM date_vente) AS temps_unix,  -- Convertir date en nombre
        montant_vente
    FROM ventes
    WHERE date_vente >= '2024-01-01'
)
SELECT
    REGR_SLOPE(montant_vente, temps_unix) AS tendance_journaliere,
    REGR_INTERCEPT(montant_vente, temps_unix) AS base,
    REGR_R2(montant_vente, temps_unix) AS qualite_fit,
    CORR(montant_vente, temps_unix) AS correlation
FROM series;

-- Si tendance_journaliere > 0 ‚Üí ventes en croissance
-- Si R¬≤ proche de 1 ‚Üí tendance lin√©aire claire
```

---

## √Ä Retenir

1. **VARIANCE et STDDEV** mesurent la dispersion des donn√©es (STDDEV est plus intuitif)
2. **CORR** (entre -1 et +1) r√©v√®le les relations entre variables
3. **Corr√©lation ‚â† Causalit√©** : toujours analyser le contexte m√©tier
4. **PERCENTILE** est plus robuste que la moyenne pour les distributions asym√©triques
5. **PERCENTILE_CONT** = interpolation, **PERCENTILE_DISC** = valeur r√©elle
6. Les fonctions de **r√©gression** (REGR_*) permettent de pr√©dire et d√©tecter des tendances
7. Toujours v√©rifier la **taille de l'√©chantillon** (>30 pour fiabilit√©)
8. Pr√©f√©rer **STDDEV_SAMP** et **VAR_SAMP** (√©chantillon) sauf cas tr√®s sp√©cifiques

---

## Prochaines √âtapes

Maintenant que vous ma√Ætrisez les fonctions d'agr√©gation statistiques, vous √™tes pr√™t pour :

- **Section 8.3** : GROUP BY et HAVING - Agr√©ger par groupes et filtrer les r√©sultats
- **Section 8.4** : Extensions de groupement (ROLLUP, CUBE, GROUPING SETS)
- **Section 10** : Window Functions - Agr√©gations sans perdre les d√©tails de chaque ligne !

Les statistiques en SQL sont un **superpouvoir** pour l'analyse de donn√©es. PostgreSQL vous donne les outils d'un data scientist directement dans votre base de donn√©es !

‚è≠Ô∏è [GROUP BY et HAVING : Filtrage post-agr√©gation](/08-agregation-et-groupement/03-group-by-et-having.md)
