ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 13.6. Le Planificateur de RequÃªtes et les Statistiques (pg_stats)

## Introduction

Le **planificateur de requÃªtes** (Query Planner ou Query Optimizer) est le "cerveau" de PostgreSQL. Quand vous exÃ©cutez une requÃªte SQL, le planificateur analyse toutes les faÃ§ons possibles de l'exÃ©cuter et choisit le **plan d'exÃ©cution** le plus efficace.

Pour prendre ces dÃ©cisions, le planificateur s'appuie sur des **statistiques** dÃ©taillÃ©es sur vos donnÃ©es, stockÃ©es dans la vue systÃ¨me `pg_stats`.

**Analogie** : Imaginez que vous planifiez un trajet en voiture. Vous avez plusieurs routes possibles. Le GPS (planificateur) utilise des statistiques (trafic, limitations de vitesse, distance) pour choisir le meilleur itinÃ©raire. Sans statistiques Ã  jour, le GPS pourrait vous envoyer sur une route embouteillÃ©e !

**PrÃ©requis** : Avoir lu les sections 13.1 Ã  13.3 sur les stratÃ©gies de scan et les index.

---

## 1. Qu'est-ce que le Planificateur de RequÃªtes ?

### 1.1. RÃ´le du Planificateur

Le planificateur transforme votre requÃªte SQL (dÃ©clarative) en un **plan d'exÃ©cution** (procÃ©dural).

```
RequÃªte SQL                    Plan d'exÃ©cution
(Que veux-tu ?)               (Comment l'obtenir ?)
    â†“                              â†“
SELECT * FROM clients     â†’    Index Scan on idx_client
WHERE id = 12345               Index Cond: (id = 12345)
                               Estimated cost: 8.44
```

### 1.2. Le Processus de Planification

```
1. Analyse syntaxique (Parser)
   â†“
2. RÃ©Ã©criture (Rewriter) : Application des vues, rÃ¨gles
   â†“
3. Planification (Planner) : GÃ©nÃ©ration des plans possibles
   â†“
4. Optimisation : SÃ©lection du meilleur plan
   â†“
5. ExÃ©cution (Executor)
```

**Phase critique** : L'Ã©tape 3-4 oÃ¹ le planificateur doit choisir parmi **potentiellement des millions** de plans possibles.

### 1.3. Exemple Simple

```sql
SELECT c.nom, o.montant
FROM clients c
JOIN commandes o ON c.id = o.client_id
WHERE c.ville = 'Paris';
```

**Plans possibles** (simplifiÃ©s) :

**Plan A** : Seq Scan clients â†’ Filter Paris â†’ Join avec commandes
**Plan B** : Index Scan sur idx_ville â†’ Join avec commandes
**Plan C** : Seq Scan commandes â†’ Hash Join avec clients filtrÃ©s

**Question** : Lequel choisir ?

**RÃ©ponse** : Ã‡a dÃ©pend des statistiques !
- Combien de clients Ã  Paris ? (10 ou 100 000 ?)
- Taille de la table commandes ?
- Index disponibles ?
- Distribution des donnÃ©es ?

â†’ Le planificateur utilise les **statistiques** pour calculer le coÃ»t de chaque plan et choisir le meilleur.

---

## 2. Le ModÃ¨le de CoÃ»t PostgreSQL

### 2.1. Concept de CoÃ»t

PostgreSQL attribue un **coÃ»t** (cost) Ã  chaque opÃ©ration. Le coÃ»t est une unitÃ© **abstraite** qui combine :
- Lectures disque (I/O)
- Calculs CPU
- MÃ©moire utilisÃ©e

**Important** : Le coÃ»t n'est PAS un temps en secondes, c'est une valeur relative pour comparer les plans.

### 2.2. UnitÃ©s de CoÃ»t

PostgreSQL dÃ©finit des coÃ»ts de base :

```sql
-- CoÃ»t de lecture d'une page sÃ©quentielle (default: 1.0)
SHOW seq_page_cost;

-- CoÃ»t de lecture d'une page alÃ©atoire (default: 4.0)
SHOW random_page_cost;

-- CoÃ»t du traitement CPU par ligne (default: 0.01)
SHOW cpu_tuple_cost;

-- CoÃ»t d'un opÃ©rateur CPU (default: 0.0025)
SHOW cpu_operator_cost;
```

**InterprÃ©tation** :
- `random_page_cost = 4.0` : Une lecture alÃ©atoire coÃ»te 4Ã— plus qu'une lecture sÃ©quentielle
- Disques SSD : Souvent configurÃ© Ã  `random_page_cost = 1.1-1.5` (lectures alÃ©atoires quasi aussi rapides)

### 2.3. Calcul du CoÃ»t d'un Seq Scan

```
CoÃ»t = (Nombre de pages Ã— seq_page_cost) + (Nombre de lignes Ã— cpu_tuple_cost)
```

**Exemple** :
- Table de 1000 pages (8 MB)
- 100 000 lignes

```
CoÃ»t = (1000 Ã— 1.0) + (100000 Ã— 0.01)
     = 1000 + 1000
     = 2000
```

### 2.4. Calcul du CoÃ»t d'un Index Scan

```
CoÃ»t = (Pages index Ã— random_page_cost)
     + (Pages table Ã— random_page_cost)
     + (Lignes Ã— cpu_tuple_cost)
```

**Exemple** : Recherche de 100 lignes via index
- 10 pages d'index
- 100 pages de table (1 ligne par page en moyenne)

```
CoÃ»t = (10 Ã— 4.0) + (100 Ã— 4.0) + (100 Ã— 0.01)
     = 40 + 400 + 1
     = 441
```

**Comparaison** :
- Seq Scan : 2000
- Index Scan : 441

â†’ PostgreSQL choisit l'Index Scan ! âœ…

---

## 3. Les Statistiques : La Base des DÃ©cisions

### 3.1. Pourquoi les Statistiques sont Cruciales

Sans statistiques prÃ©cises, le planificateur est **aveugle** :

```sql
-- Sans statistiques
SELECT * FROM clients WHERE ville = 'Paris';

-- PostgreSQL devine : "Peut-Ãªtre 10% des lignes ?"
-- En rÃ©alitÃ© : 90% des clients sont Ã  Paris !

â†’ Mauvais choix de plan â†’ RequÃªte lente
```

**Principe** : Garbage In, Garbage Out
- Statistiques obsolÃ¨tes â†’ Mauvais plans â†’ Mauvaises performances

### 3.2. Types de Statistiques CollectÃ©es

PostgreSQL collecte plusieurs types de statistiques :

1. **CardinalitÃ©** : Nombre total de lignes
2. **Valeurs distinctes** : Nombre de valeurs uniques (n_distinct)
3. **NULL frequency** : Proportion de NULL (null_frac)
4. **Histogrammes** : Distribution des valeurs
5. **Most Common Values (MCV)** : Valeurs les plus frÃ©quentes
6. **CorrÃ©lation** : Ordre physique vs ordre logique

### 3.3. La Vue pg_stats

`pg_stats` est une vue qui expose les statistiques de chaque colonne :

```sql
SELECT
    schemaname,
    tablename,
    attname,           -- Nom de la colonne
    n_distinct,        -- Nombre de valeurs distinctes
    null_frac,         -- Fraction de NULL
    avg_width,         -- Taille moyenne en octets
    most_common_vals,  -- Valeurs les plus communes
    most_common_freqs  -- FrÃ©quences correspondantes
FROM pg_stats
WHERE tablename = 'clients';
```

---

## 4. Comprendre pg_stats en DÃ©tail

### 4.1. Colonnes Essentielles

#### n_distinct : CardinalitÃ©

Nombre de valeurs distinctes dans la colonne.

```sql
SELECT attname, n_distinct
FROM pg_stats
WHERE tablename = 'clients';
```

**Exemple** :
```
 attname  | n_distinct
----------|------------
 id       | -1.0        â† -1 = 100% des lignes sont uniques (PRIMARY KEY)
 ville    | 450         â† 450 villes distinctes
 age      | 80          â† 80 Ã¢ges diffÃ©rents
 sexe     | 2           â† 2 valeurs (M/F)
```

**InterprÃ©tation** :
- `n_distinct = -1` : Toutes les lignes sont uniques (ratio 1:1)
- `n_distinct > 0` : Nombre absolu de valeurs distinctes
- `n_distinct < 0` : Fraction (ex: -0.5 = 50% des lignes sont uniques)

**Usage par le planificateur** :
- Faible n_distinct (2-10) â†’ Index moins utile, sauf index partiel
- Ã‰levÃ© n_distinct â†’ Index trÃ¨s sÃ©lectif â†’ Index Scan prÃ©fÃ©rÃ©

#### null_frac : Proportion de NULL

```sql
SELECT attname, null_frac
FROM pg_stats
WHERE tablename = 'clients';
```

**Exemple** :
```
 attname     | null_frac
-------------|----------
 id          | 0.0       â† Aucun NULL (NOT NULL)
 telephone   | 0.15      â† 15% de NULL
 email       | 0.02      â† 2% de NULL
```

**Usage par le planificateur** :
```sql
SELECT * FROM clients WHERE telephone IS NULL;
-- PostgreSQL sait : 15% des lignes â†’ Estime 15,000 lignes sur 100,000
```

#### avg_width : Taille Moyenne

Taille moyenne des valeurs en octets.

```sql
SELECT attname, avg_width
FROM pg_stats
WHERE tablename = 'clients';
```

**Exemple** :
```
 attname  | avg_width
----------|----------
 id       | 4         â† INTEGER (4 octets)
 nom      | 12        â† VARCHAR, moyenne 12 caractÃ¨res
 email    | 28        â† Emails plus longs
```

**Usage par le planificateur** :
- Estime la quantitÃ© de mÃ©moire nÃ©cessaire pour les hash tables, sorts, etc.

### 4.2. Histogrammes et Distribution

#### most_common_vals et most_common_freqs

Liste des valeurs les plus frÃ©quentes et leurs proportions.

```sql
SELECT
    attname,
    most_common_vals,
    most_common_freqs
FROM pg_stats
WHERE tablename = 'clients' AND attname = 'ville';
```

**RÃ©sultat** :
```
attname | most_common_vals                  | most_common_freqs
--------|-----------------------------------|------------------
ville   | {Paris,Lyon,Marseille,Toulouse}   | {0.35,0.15,0.12,0.08}
```

**InterprÃ©tation** :
- 35% des clients sont Ã  Paris
- 15% Ã  Lyon
- 12% Ã  Marseille
- 8% Ã  Toulouse
- 30% rÃ©partis dans les autres villes

**Usage par le planificateur** :

```sql
SELECT * FROM clients WHERE ville = 'Paris';
-- PostgreSQL calcule : 35% Ã— 100,000 = 35,000 lignes attendues
-- â†’ Trop pour un Index Scan â†’ PrÃ©fÃ¨re Seq Scan ou Bitmap Scan
```

```sql
SELECT * FROM clients WHERE ville = 'Dijon';
-- Dijon n'est pas dans les MCV â†’ Estimation par dÃ©faut (ex: 0.1%)
-- â†’ 0.1% Ã— 100,000 = 100 lignes
-- â†’ Index Scan optimal
```

#### histogram_bounds : Distribution ComplÃ¨te

Pour les valeurs non couvertes par MCV, PostgreSQL construit un histogramme.

```sql
SELECT attname, histogram_bounds
FROM pg_stats
WHERE tablename = 'commandes' AND attname = 'montant';
```

**RÃ©sultat** :
```
attname  | histogram_bounds
---------|--------------------------------------------------
montant  | {10,25,50,75,100,150,200,300,500,1000,5000}
```

**InterprÃ©tation** : Les buckets (seaux) d'histogramme :
- Bucket 1 : [10, 25[ â†’ ~10% des lignes
- Bucket 2 : [25, 50[ â†’ ~10% des lignes
- ...
- Bucket 10 : [1000, 5000] â†’ ~10% des lignes

**Usage par le planificateur** :

```sql
SELECT * FROM commandes WHERE montant BETWEEN 100 AND 200;
-- PostgreSQL utilise l'histogramme :
-- Bucket [100,150] + Bucket [150,200] â‰ˆ 20% des lignes
-- â†’ Estime 20,000 lignes sur 100,000
```

### 4.3. CorrÃ©lation Physique

```sql
SELECT attname, correlation
FROM pg_stats
WHERE tablename = 'commandes';
```

**RÃ©sultat** :
```
 attname        | correlation
----------------|------------
 id             | 1.0        â† Parfaitement corrÃ©lÃ©
 created_at     | 0.98       â† Quasi-corrÃ©lÃ©
 client_id      | 0.05       â† Aucune corrÃ©lation
```

**InterprÃ©tation** :

**CorrÃ©lation = 1.0** : Les valeurs sont physiquement triÃ©es sur le disque dans le mÃªme ordre que les valeurs logiques.

```
Ordre logique : id = 1, 2, 3, 4, 5, 6...
Ordre physique : [Bloc 1: id=1,2,3] [Bloc 2: id=4,5,6]...
â†’ Lecture sÃ©quentielle efficace
```

**CorrÃ©lation = 0.0** : Aucun ordre, valeurs dispersÃ©es alÃ©atoirement.

```
Ordre logique : client_id = 1, 2, 3, 4, 5...
Ordre physique : [Bloc 1: id=783,45,2] [Bloc 2: id=1,456,99]...
â†’ Lectures alÃ©atoires (Random I/O)
```

**Usage par le planificateur** :

```sql
SELECT * FROM commandes ORDER BY created_at LIMIT 100;
```

- Si `correlation(created_at) = 0.98` â†’ Les premiÃ¨res valeurs sont dans les premiers blocs â†’ Index Scan trÃ¨s rapide
- Si `correlation(created_at) = 0.05` â†’ Valeurs Ã©parpillÃ©es â†’ Index Scan avec beaucoup de Random I/O

---

## 5. ANALYZE : Mise Ã  Jour des Statistiques

### 5.1. Qu'est-ce que ANALYZE ?

`ANALYZE` est la commande qui collecte les statistiques sur les tables.

```sql
-- Analyser une table spÃ©cifique
ANALYZE clients;

-- Analyser toutes les tables de la base
ANALYZE;

-- Analyser et obtenir des dÃ©tails
ANALYZE VERBOSE clients;
```

### 5.2. Fonctionnement d'ANALYZE

1. **Ã‰chantillonnage** : ANALYZE ne lit PAS toute la table, il Ã©chantillonne un sous-ensemble de lignes

```
Table : 10 millions de lignes
ANALYZE lit : ~30,000 lignes (Ã©chantillon)
â†’ TrÃ¨s rapide, mÃªme sur grandes tables
```

2. **Calcul des statistiques** : Ã€ partir de l'Ã©chantillon, PostgreSQL calcule :
   - n_distinct (estimation)
   - Histogrammes
   - MCV (Most Common Values)
   - null_frac
   - etc.

3. **Stockage** : Les statistiques sont stockÃ©es dans `pg_statistic` (vue `pg_stats`)

### 5.3. Taille de l'Ã‰chantillon

ContrÃ´lÃ© par le paramÃ¨tre `default_statistics_target` (default: 100).

```sql
-- Afficher la valeur actuelle
SHOW default_statistics_target;

-- Modifier globalement
ALTER DATABASE mabase SET default_statistics_target = 200;

-- Modifier pour une colonne spÃ©cifique
ALTER TABLE clients ALTER COLUMN ville SET STATISTICS 500;
```

**Valeurs** :
- `100` (default) : Bon compromis (Ã©chantillon de ~30,000 lignes)
- `1000` : Maximum (Ã©chantillon de ~300,000 lignes) â†’ Plus prÃ©cis, mais ANALYZE plus lent
- `10` : Minimum â†’ ANALYZE trÃ¨s rapide, mais statistiques imprÃ©cises

**Quand augmenter** :
- Colonnes avec distributions trÃ¨s irrÃ©guliÃ¨res
- Tables critiques avec requÃªtes complexes
- AprÃ¨s augmentation : `ANALYZE clients;`

### 5.4. Quand ExÃ©cuter ANALYZE ?

#### Automatique : Autovacuum

PostgreSQL exÃ©cute automatiquement `ANALYZE` via le processus **autovacuum**.

```sql
-- VÃ©rifier le dernier ANALYZE
SELECT
    schemaname,
    relname,
    last_analyze,
    last_autoanalyze,
    n_mod_since_analyze  -- Nombre de modifications depuis dernier ANALYZE
FROM pg_stat_user_tables
WHERE relname = 'clients';
```

**RÃ©sultat** :
```
 schemaname | relname  | last_analyze        | last_autoanalyze    | n_mod_since_analyze
------------|----------|---------------------|---------------------|--------------------
 public     | clients  | 2025-11-20 10:15:00 | 2025-11-21 08:30:00 | 1234
```

**Autovacuum dÃ©clenche ANALYZE quand** :
```
n_mod_since_analyze > autovacuum_analyze_threshold + (autovacuum_analyze_scale_factor Ã— nombre_lignes)
```

**Valeurs par dÃ©faut** :
- `autovacuum_analyze_threshold = 50`
- `autovacuum_analyze_scale_factor = 0.1` (10%)

**Exemple** : Table de 100,000 lignes
```
Seuil = 50 + (0.1 Ã— 100,000) = 10,050 modifications
```

AprÃ¨s 10,050 INSERT/UPDATE/DELETE, autovacuum dÃ©clenche ANALYZE.

#### Manuel : Quand Forcer ANALYZE

ExÃ©cutez manuellement `ANALYZE` dans ces cas :

1. **AprÃ¨s un chargement massif de donnÃ©es** :
```sql
COPY clients FROM '/data/clients.csv';
ANALYZE clients;
```

2. **AprÃ¨s une modification importante du schÃ©ma** :
```sql
ALTER TABLE clients ADD COLUMN new_field VARCHAR(100);
UPDATE clients SET new_field = ...;
ANALYZE clients;
```

3. **Avant une requÃªte critique** (rare) :
```sql
ANALYZE clients;
-- RequÃªte complexe importante
SELECT ...
```

4. **AprÃ¨s dÃ©tection de mauvais plans** :
```sql
-- Si EXPLAIN montre des estimations trÃ¨s fausses
ANALYZE clients;
ANALYZE commandes;
```

---

## 6. Lecture d'un Plan avec les Statistiques

### 6.1. EXPLAIN : Voir les Estimations

```sql
EXPLAIN SELECT * FROM clients WHERE ville = 'Paris';
```

**RÃ©sultat** :
```
Seq Scan on clients  (cost=0.00..2123.00 rows=35000 width=50)
  Filter: (ville = 'Paris'::text)
```

**InterprÃ©tation** :
- `cost=0.00..2123.00` : CoÃ»t estimÃ© (startup..total)
- `rows=35000` : **Estimation basÃ©e sur pg_stats** (35% Ã— 100,000)
- `width=50` : Taille moyenne des lignes en octets

### 6.2. EXPLAIN ANALYZE : Comparer Estimations vs RÃ©alitÃ©

```sql
EXPLAIN ANALYZE SELECT * FROM clients WHERE ville = 'Paris';
```

**RÃ©sultat** :
```
Seq Scan on clients  (cost=0.00..2123.00 rows=35000 width=50)
                     (actual time=0.045..23.456 rows=34987 loops=1)
  Filter: (ville = 'Paris'::text)
  Rows Removed by Filter: 65013
Planning Time: 0.234 ms
Execution Time: 25.891 ms
```

**Comparaison** :
- **EstimÃ©** : `rows=35000`
- **RÃ©el** : `actual ... rows=34987`
- **Ã‰cart** : 0.04% â†’ Excellente estimation ! âœ…

### 6.3. DÃ©tecter les Mauvaises Estimations

```sql
EXPLAIN ANALYZE SELECT * FROM clients WHERE ville = 'Dijon';
```

**RÃ©sultat** :
```
Index Scan using idx_ville on clients  (cost=0.42..8.44 rows=1 width=50)
                                       (actual time=0.123..456.789 rows=25000 loops=1)
  Index Cond: (ville = 'Dijon'::text)
```

**ProblÃ¨me** :
- **EstimÃ©** : `rows=1` (0.001%)
- **RÃ©el** : `actual ... rows=25000` (25%)
- **Ã‰cart** : 2,500,000% ! ğŸ”´

**Cause** : Statistiques obsolÃ¨tes (Dijon Ã©tait rare, maintenant frÃ©quent)

**Solution** :
```sql
ANALYZE clients;
```

---

## 7. ParamÃ¨tres du Planificateur

### 7.1. ParamÃ¨tres de CoÃ»t

#### seq_page_cost et random_page_cost

```sql
-- Afficher les valeurs
SHOW seq_page_cost;      -- Default: 1.0
SHOW random_page_cost;   -- Default: 4.0
```

**Ajustement pour SSD** :
```sql
-- Dans postgresql.conf ou par session
SET random_page_cost = 1.1;  -- SSD : accÃ¨s alÃ©atoire presque aussi rapide
```

**Impact** : Rend les Index Scans plus attractifs.

#### effective_cache_size

MÃ©moire que PostgreSQL suppose disponible pour le cache OS.

```sql
SHOW effective_cache_size;  -- Default: 4GB
```

**Recommandation** : 50-75% de la RAM totale

```sql
-- Serveur avec 64 GB RAM
ALTER SYSTEM SET effective_cache_size = '48GB';
SELECT pg_reload_conf();
```

**Impact** : Influence le choix entre Index Scan et Seq Scan (planificateur suppose que les donnÃ©es frÃ©quentes sont en cache).

### 7.2. DÃ©sactiver Temporairement des StratÃ©gies

Pour dÃ©boguer ou forcer un plan spÃ©cifique :

```sql
-- DÃ©sactiver Seq Scan (force index si possible)
SET enable_seqscan = off;

-- DÃ©sactiver Index Scan
SET enable_indexscan = off;

-- DÃ©sactiver Bitmap Scan
SET enable_bitmapscan = off;

-- DÃ©sactiver Nested Loop Join
SET enable_nestloop = off;
```

**âš ï¸ Attention** : Ã€ utiliser uniquement pour **tests/debug**. Ne jamais dÃ©sactiver en production !

### 7.3. Forcer la Replanification

Par dÃ©faut, PostgreSQL met en cache les plans (Prepared Statements).

```sql
-- Invalider le cache de plans
DISCARD PLANS;

-- Ou re-prÃ©parer aprÃ¨s ANALYZE
DEALLOCATE ALL;
```

---

## 8. ProblÃ¨mes Courants et Solutions

### 8.1. ProblÃ¨me : Statistiques ObsolÃ¨tes

**SymptÃ´me** :
- RequÃªtes soudainement lentes
- EXPLAIN montre des estimations trÃ¨s fausses

**Diagnostic** :
```sql
SELECT
    schemaname,
    relname,
    n_live_tup,
    n_mod_since_analyze,
    last_autoanalyze
FROM pg_stat_user_tables
WHERE n_mod_since_analyze > n_live_tup * 0.2  -- Plus de 20% de modifications
ORDER BY n_mod_since_analyze DESC;
```

**Solution** :
```sql
ANALYZE;  -- Sur toute la base
-- Ou spÃ©cifique
ANALYZE table_problematique;
```

### 8.2. ProblÃ¨me : Distribution TrÃ¨s IrrÃ©guliÃ¨re

**SymptÃ´me** :
- Certaines valeurs ont des millions de lignes, d'autres 1-10
- Plans suboptimaux pour les valeurs rares

**Exemple** :
```sql
-- Table logs avec colonne 'level'
-- 'INFO': 99.9% des lignes
-- 'ERROR': 0.1% des lignes

SELECT * FROM logs WHERE level = 'ERROR';  -- Devrait Ãªtre rapide (100 lignes)
-- Mais PostgreSQL estime mal car INFO domine les statistiques
```

**Solution 1** : Augmenter statistics_target
```sql
ALTER TABLE logs ALTER COLUMN level SET STATISTICS 1000;
ANALYZE logs;
```

**Solution 2** : Index partiel
```sql
CREATE INDEX idx_logs_errors ON logs(timestamp) WHERE level = 'ERROR';
```

### 8.3. ProblÃ¨me : Fonctions Utilisateur Opaques

**SymptÃ´me** :
PostgreSQL ne peut pas estimer la sÃ©lectivitÃ© des fonctions personnalisÃ©es.

```sql
SELECT * FROM clients WHERE ma_fonction_custom(nom) = true;
-- PostgreSQL devine : 0.5% par dÃ©faut (souvent faux)
```

**Solution** : DÃ©clarer la volatilitÃ© et la sÃ©lectivitÃ© de la fonction
```sql
CREATE OR REPLACE FUNCTION ma_fonction_custom(nom TEXT) RETURNS BOOLEAN AS $$
    ...
$$ LANGUAGE plpgsql
IMMUTABLE  -- ou STABLE
COST 100   -- CoÃ»t CPU estimÃ©
ROWS 50;   -- Nombre de lignes attendues en sortie (pour fonctions set-returning)
```

### 8.4. ProblÃ¨me : Jointures avec Mauvaises Estimations

**SymptÃ´me** :
```sql
EXPLAIN ANALYZE
SELECT * FROM clients c
JOIN commandes o ON c.id = o.client_id
WHERE c.ville = 'Paris';

-- Estimation : 100 lignes
-- RÃ©el : 10,000 lignes
```

**Solution** : ANALYZE les deux tables
```sql
ANALYZE clients;
ANALYZE commandes;
```

Si problÃ¨me persiste, vÃ©rifier les statistiques de corrÃ©lation :
```sql
SELECT
    tablename,
    attname,
    n_distinct,
    correlation
FROM pg_stats
WHERE tablename IN ('clients', 'commandes');
```

---

## 9. Monitoring et Maintenance des Statistiques

### 9.1. Surveiller la FraÃ®cheur des Statistiques

**RequÃªte de monitoring** :
```sql
SELECT
    schemaname,
    relname AS table_name,
    n_live_tup AS live_rows,
    n_mod_since_analyze AS modifications,
    last_autoanalyze,
    CASE
        WHEN n_mod_since_analyze > n_live_tup * 0.2 THEN 'âš ï¸ URGENT'
        WHEN n_mod_since_analyze > n_live_tup * 0.1 THEN 'âš ï¸ Soon'
        ELSE 'âœ“ OK'
    END AS status
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY n_mod_since_analyze DESC
LIMIT 20;
```

### 9.2. Script de Maintenance Automatique

```sql
-- CrÃ©er une fonction pour forcer ANALYZE sur les tables "stale"
CREATE OR REPLACE FUNCTION maintain_statistics() RETURNS void AS $$
BEGIN
    EXECUTE (
        SELECT string_agg('ANALYZE ' || schemaname || '.' || relname || ';', E'\n')
        FROM pg_stat_user_tables
        WHERE n_mod_since_analyze > n_live_tup * 0.1
    );
    RAISE NOTICE 'Statistics updated';
END;
$$ LANGUAGE plpgsql;

-- Appel pÃ©riodique (via cron ou pg_cron)
SELECT maintain_statistics();
```

### 9.3. NouveautÃ© PostgreSQL 18 : Statistiques VACUUM/ANALYZE

PostgreSQL 18 enrichit `pg_stat_all_tables` avec des statistiques dÃ©taillÃ©es :

```sql
SELECT
    schemaname,
    relname,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze,
    vacuum_count,        -- NouveautÃ© PG 18
    autovacuum_count,    -- NouveautÃ© PG 18
    analyze_count,       -- NouveautÃ© PG 18
    autoanalyze_count    -- NouveautÃ© PG 18
FROM pg_stat_all_tables
WHERE schemaname = 'public';
```

**UtilitÃ©** : Suivre la frÃ©quence de maintenance et dÃ©tecter les tables sous-maintenues.

---

## 10. Outils d'Analyse des Statistiques

### 10.1. Extension pg_qualstats

**Installation** :
```sql
CREATE EXTENSION pg_qualstats;
```

**Fonction** : Collecte des statistiques sur les prÃ©dicats (WHERE clauses) les plus frÃ©quents.

**UtilitÃ©** : Identifier quelles colonnes bÃ©nÃ©ficieraient le plus d'index.

### 10.2. Extension HypoPG (Hypothetical Indexes)

```sql
CREATE EXTENSION hypopg;

-- CrÃ©er un index hypothÃ©tique (pas rÃ©ellement crÃ©Ã©)
SELECT hypopg_create_index('CREATE INDEX ON clients(ville)');

-- Tester le plan
EXPLAIN SELECT * FROM clients WHERE ville = 'Paris';

-- Voir que PostgreSQL considÃ¨re l'index hypothÃ©tique !

-- Supprimer l'index hypothÃ©tique
SELECT hypopg_drop_index(indexrelid) FROM hypopg_list_indexes;
```

**UtilitÃ©** : Tester l'impact d'un index **avant de le crÃ©er** (pas de coÃ»t de crÃ©ation).

### 10.3. pgAdmin : Visualisation des Statistiques

pgAdmin propose une interface graphique pour visualiser :
- Histogrammes de pg_stats
- Distribution des valeurs
- MCV (Most Common Values)

**AccÃ¨s** : pgAdmin â†’ Table â†’ Statistics

---

## 11. Exemple Complet : Diagnostic et Optimisation

### 11.1. ScÃ©nario : RequÃªte Lente

```sql
-- RequÃªte problÃ©matique (7 secondes)
SELECT c.nom, COUNT(o.id)
FROM clients c
JOIN commandes o ON c.id = o.client_id
WHERE c.ville = 'Paris'
  AND o.created_at > '2024-01-01'
GROUP BY c.nom;
```

### 11.2. Ã‰tape 1 : EXPLAIN ANALYZE

```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.nom, COUNT(o.id)
FROM clients c
JOIN commandes o ON c.id = o.client_id
WHERE c.ville = 'Paris'
  AND o.created_at > '2024-01-01'
GROUP BY c.nom;
```

**RÃ©sultat** :
```
HashAggregate  (cost=250000.00..250500.00 rows=50000 width=20)
               (actual time=7234.567..7235.123 rows=5 loops=1)
  Group Key: c.nom
  ->  Hash Join  (cost=15000.00..240000.00 rows=500000 width=12)
                 (actual time=123.456..7000.234 rows=5000 loops=1)
        Hash Cond: (o.client_id = c.id)
        ->  Seq Scan on commandes o  (cost=0.00..180000.00 rows=500000 width=8)
                                     (actual time=0.012..3456.789 rows=500000 loops=1)
              Filter: (created_at > '2024-01-01')
              Rows Removed by Filter: 500000
        ->  Hash  (cost=12000.00..12000.00 rows=50000 width=12)
                  (actual time=120.234..120.234 rows=35000 loops=1)
              Buckets: 65536  Batches: 1  Memory Usage: 2048kB
              ->  Seq Scan on clients c  (cost=0.00..12000.00 rows=50000 width=12)
                                        (actual time=0.023..98.765 rows=35000 loops=1)
                    Filter: (ville = 'Paris')
                    Rows Removed by Filter: 65000
Planning Time: 1.234 ms
Execution Time: 7235.456 ms
```

### 11.3. Ã‰tape 2 : Analyser les Estimations

**ProblÃ¨mes dÃ©tectÃ©s** :

1. **Seq Scan sur commandes** :
   - EstimÃ© : 500,000 lignes
   - RÃ©el : 500,000 lignes
   - âœ… Bonne estimation, mais pas d'index sur `created_at`

2. **Seq Scan sur clients** :
   - EstimÃ© : 50,000 lignes pour `ville='Paris'`
   - RÃ©el : 35,000 lignes
   - âœ… Estimation correcte

3. **Pas d'index utilisÃ©** : Aucun index disponible

### 11.4. Ã‰tape 3 : VÃ©rifier les Statistiques

```sql
-- Statistiques sur commandes.created_at
SELECT
    attname,
    n_distinct,
    null_frac,
    correlation
FROM pg_stats
WHERE tablename = 'commandes' AND attname = 'created_at';
```

**RÃ©sultat** :
```
 attname     | n_distinct | null_frac | correlation
-------------|------------|-----------|------------
 created_at  | 365        | 0.0       | 0.95
```

**InterprÃ©tation** :
- `correlation = 0.95` : Dates physiquement triÃ©es â†’ Index trÃ¨s efficace
- `n_distinct = 365` : Une annÃ©e de dates

### 11.5. Ã‰tape 4 : CrÃ©er les Index AppropriÃ©s

```sql
-- Index 1 : Sur clients.ville (faible cardinalitÃ© â†’ index partiel meilleur)
CREATE INDEX idx_clients_paris ON clients(id) WHERE ville = 'Paris';

-- Index 2 : Sur commandes.created_at (pour le range)
CREATE INDEX idx_commandes_date ON commandes(created_at);

-- Mettre Ã  jour les statistiques
ANALYZE clients;
ANALYZE commandes;
```

### 11.6. Ã‰tape 5 : Retester

```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.nom, COUNT(o.id)
FROM clients c
JOIN commandes o ON c.id = o.client_id
WHERE c.ville = 'Paris'
  AND o.created_at > '2024-01-01'
GROUP BY c.nom;
```

**Nouveau plan** :
```
HashAggregate  (cost=8500.00..8550.00 rows=5000 width=20)
               (actual time=123.456..123.567 rows=5 loops=1)
  Group Key: c.nom
  ->  Hash Join  (cost=4000.00..8000.00 rows=5000 width=12)
                 (actual time=45.123..120.234 rows=5000 loops=1)
        Hash Cond: (o.client_id = c.id)
        ->  Index Scan using idx_commandes_date on commandes o
              (cost=0.43..3500.00 rows=50000 width=8)
              (actual time=0.012..80.123 rows=50000 loops=1)
              Index Cond: (created_at > '2024-01-01')
        ->  Hash  (cost=3800.00..3800.00 rows=35000 width=12)
                  (actual time=40.234..40.234 rows=35000 loops=1)
              ->  Index Scan using idx_clients_paris on clients c
                    (cost=0.42..3800.00 rows=35000 width=12)
                    (actual time=0.023..30.567 rows=35000 loops=1)
                    Index Cond: (ville = 'Paris')
Planning Time: 0.345 ms
Execution Time: 124.123 ms
```

**RÃ©sultat** :
- **Avant** : 7235 ms
- **AprÃ¨s** : 124 ms
- **Gain** : **58Ã—** plus rapide ! ğŸš€

**ClÃ©s du succÃ¨s** :
1. Index bien placÃ©s
2. Statistiques Ã  jour
3. Planificateur a choisi les bons plans grÃ¢ce aux statistiques

---

## Points ClÃ©s Ã  Retenir

ğŸ”‘ **Le planificateur est le cerveau de PostgreSQL** : Il choisit le plan d'exÃ©cution optimal basÃ© sur les statistiques.

ğŸ”‘ **pg_stats = base de dÃ©cision** : Contient toutes les statistiques utilisÃ©es par le planificateur (n_distinct, MCV, histogrammes, corrÃ©lation).

ğŸ”‘ **ANALYZE rÃ©guliÃ¨rement** : AprÃ¨s chargements massifs, modifications de schÃ©ma, ou si les estimations sont fausses.

ğŸ”‘ **Autovacuum s'occupe de l'automatisation** : Mais vÃ©rifiez qu'il s'exÃ©cute rÃ©guliÃ¨rement avec `pg_stat_user_tables`.

ğŸ”‘ **Comparaison estimations vs rÃ©alitÃ©** : Utilisez `EXPLAIN ANALYZE` pour dÃ©tecter les mauvaises estimations (signe de statistiques obsolÃ¨tes).

ğŸ”‘ **default_statistics_target** : Augmentez pour colonnes critiques avec distributions complexes.

ğŸ”‘ **CorrÃ©lation physique** : Impact majeur sur le choix Index Scan vs Seq Scan pour les ranges et ORDER BY.

ğŸ”‘ **Monitoring proactif** : Surveillez `n_mod_since_analyze` pour anticiper les besoins de maintenance.

ğŸ”‘ **Index + Statistiques = Duo gagnant** : Un index sans statistiques Ã  jour est sous-utilisÃ©.

---

## Ressources pour Aller Plus Loin

- **Documentation PostgreSQL** : [Planner Statistics](https://www.postgresql.org/docs/current/planner-stats.html)
- **Section prÃ©cÃ©dente** : 13.5. StratÃ©gies d'indexation avancÃ©es
- **Section suivante** : 13.7. Lecture et analyse d'un EXPLAIN
- **Livre recommandÃ©** : "The Art of PostgreSQL" par Dimitri Fontaine

---


â­ï¸ [Lecture et analyse d'un EXPLAIN (ANALYZE, BUFFERS, VERBOSE, FORMAT JSON)](/13-indexation-et-optimisation/07-lecture-analyse-explain.md)
