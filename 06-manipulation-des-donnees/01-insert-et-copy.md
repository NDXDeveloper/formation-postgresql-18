üîù Retour au [Sommaire](/SOMMAIRE.md)

# 6.1. INSERT : Insertion simple, multiple, et import via COPY

## Introduction

L'insertion de donn√©es est l'une des op√©rations fondamentales dans toute base de donn√©es. Dans PostgreSQL, la commande `INSERT` permet d'ajouter de nouvelles lignes dans une table, tandis que la commande `COPY` offre une solution optimis√©e pour l'importation massive de donn√©es. Cette section vous guidera √† travers les diff√©rentes fa√ßons d'ins√©rer des donn√©es, de la plus simple √† la plus performante.

---

## Concepts de base

Avant de commencer, rappelons quelques notions essentielles :

- **Une table** contient des lignes (enregistrements) et des colonnes (attributs)
- **Une insertion** ajoute une ou plusieurs nouvelles lignes dans une table
- **Les types de donn√©es** de chaque colonne doivent √™tre respect√©s
- **Les contraintes** (NOT NULL, UNIQUE, CHECK, etc.) sont v√©rifi√©es √† chaque insertion

---

## 6.1.1. Insertion simple : La commande INSERT basique

### Syntaxe g√©n√©rale

La forme la plus simple de `INSERT` permet d'ajouter une seule ligne √† la fois :

```sql
INSERT INTO nom_table (colonne1, colonne2, colonne3)
VALUES (valeur1, valeur2, valeur3);
```

### Exemple concret

Imaginons une table `employes` avec la structure suivante :

```sql
CREATE TABLE employes (
    id SERIAL PRIMARY KEY,
    nom VARCHAR(100) NOT NULL,
    prenom VARCHAR(100) NOT NULL,
    email VARCHAR(255) UNIQUE,
    salaire NUMERIC(10, 2),
    date_embauche DATE DEFAULT CURRENT_DATE
);
```

Pour ins√©rer un nouvel employ√© :

```sql
INSERT INTO employes (nom, prenom, email, salaire, date_embauche)
VALUES ('Dupont', 'Marie', 'marie.dupont@example.com', 45000.00, '2025-01-15');
```

### Insertion sans sp√©cifier toutes les colonnes

Vous n'√™tes pas oblig√© de sp√©cifier toutes les colonnes :

```sql
INSERT INTO employes (nom, prenom, email)
VALUES ('Martin', 'Pierre', 'pierre.martin@example.com');
```

Dans cet exemple :
- La colonne `id` sera g√©n√©r√©e automatiquement (SERIAL)
- La colonne `salaire` recevra NULL (si autoris√©)
- La colonne `date_embauche` prendra la valeur par d√©faut (CURRENT_DATE)

### Insertion sans sp√©cifier les colonnes

Si vous fournissez des valeurs pour **toutes** les colonnes dans le bon ordre, vous pouvez omettre la liste des colonnes :

```sql
INSERT INTO employes
VALUES (DEFAULT, 'Durand', 'Sophie', 'sophie.durand@example.com', 48000.00, '2025-02-01');
```

> **Note** : Cette syntaxe est d√©conseill√©e car elle rend le code fragile. Si la structure de la table change (ajout/suppression de colonne), votre requ√™te pourrait √©chouer.

### Gestion des valeurs NULL et DEFAULT

Plusieurs fa√ßons d'ins√©rer des valeurs NULL ou par d√©faut :

```sql
-- Utiliser NULL explicitement
INSERT INTO employes (nom, prenom, email, salaire)
VALUES ('Bernard', 'Luc', 'luc.bernard@example.com', NULL);

-- Utiliser DEFAULT pour invoquer la valeur par d√©faut
INSERT INTO employes (nom, prenom, email, date_embauche)
VALUES ('Petit', 'Anne', 'anne.petit@example.com', DEFAULT);

-- Omettre les colonnes (elles prendront NULL ou DEFAULT)
INSERT INTO employes (nom, prenom, email)
VALUES ('Roux', 'Thomas', 'thomas.roux@example.com');
```

---

## 6.1.2. Insertion multiple : Plusieurs lignes en une seule commande

### Pourquoi ins√©rer plusieurs lignes √† la fois ?

L'insertion multiple pr√©sente plusieurs avantages :

1. **Performance** : Beaucoup plus rapide que plusieurs INSERT s√©par√©s
2. **Transactionnel** : Toutes les insertions r√©ussissent ou √©chouent ensemble
3. **Lisibilit√©** : Code plus compact et plus clair
4. **√âconomie r√©seau** : Un seul aller-retour avec le serveur

### Syntaxe de l'insertion multiple

```sql
INSERT INTO nom_table (colonne1, colonne2, colonne3)
VALUES
    (valeur1a, valeur2a, valeur3a),
    (valeur1b, valeur2b, valeur3b),
    (valeur1c, valeur2c, valeur3c);
```

### Exemple pratique

Insertion de plusieurs employ√©s en une seule commande :

```sql
INSERT INTO employes (nom, prenom, email, salaire, date_embauche)
VALUES
    ('Moreau', 'Julie', 'julie.moreau@example.com', 42000.00, '2025-03-01'),
    ('Simon', 'Marc', 'marc.simon@example.com', 51000.00, '2025-03-01'),
    ('Laurent', 'Emma', 'emma.laurent@example.com', 47000.00, '2025-03-15'),
    ('Bertrand', 'Paul', 'paul.bertrand@example.com', 39000.00, '2025-03-20');
```

Cette unique requ√™te ins√®re 4 employ√©s en une seule transaction.

### Comparaison de performance

**M√©thode inefficace** (4 requ√™tes s√©par√©es) :
```sql
INSERT INTO employes (nom, prenom) VALUES ('Moreau', 'Julie');
INSERT INTO employes (nom, prenom) VALUES ('Simon', 'Marc');
INSERT INTO employes (nom, prenom) VALUES ('Laurent', 'Emma');
INSERT INTO employes (nom, prenom) VALUES ('Bertrand', 'Paul');
```

**M√©thode efficace** (1 seule requ√™te) :
```sql
INSERT INTO employes (nom, prenom)
VALUES
    ('Moreau', 'Julie'),
    ('Simon', 'Marc'),
    ('Laurent', 'Emma'),
    ('Bertrand', 'Paul');
```

> **Gain de performance** : L'insertion multiple peut √™tre 5 √† 10 fois plus rapide pour de petits volumes, et le gain augmente avec le nombre de lignes.

### Limites pratiques

Bien que PostgreSQL n'impose pas de limite stricte au nombre de lignes dans un INSERT multiple, il existe des consid√©rations pratiques :

- **M√©moire** : Chaque ligne consomme de la m√©moire
- **Lisibilit√©** : Au-del√† de quelques dizaines de lignes, le code devient difficile √† lire
- **Timeout** : Une tr√®s longue requ√™te peut d√©passer les timeouts r√©seau ou applicatifs

Pour des volumes importants (milliers de lignes ou plus), pr√©f√©rez la commande `COPY` d√©crite plus loin.

---

## 6.1.3. Insertion √† partir d'une autre table : INSERT ... SELECT

### Concept

PostgreSQL permet d'ins√©rer des donn√©es en les s√©lectionnant depuis une autre table (ou la m√™me table). C'est tr√®s utile pour :

- Copier des donn√©es d'une table √† une autre
- Cr√©er des tables de travail ou d'historique
- Transformer des donn√©es lors de l'insertion

### Syntaxe

```sql
INSERT INTO table_destination (colonne1, colonne2, colonne3)
SELECT colonne_a, colonne_b, colonne_c
FROM table_source
WHERE condition;
```

### Exemple : Cr√©ation d'une table d'archive

Supposons que vous vouliez archiver les employ√©s qui ont quitt√© l'entreprise :

```sql
-- Table d'archive
CREATE TABLE employes_archives (
    id INTEGER,
    nom VARCHAR(100),
    prenom VARCHAR(100),
    email VARCHAR(255),
    date_depart DATE DEFAULT CURRENT_DATE
);

-- Archiver les employ√©s dont le contrat se termine
INSERT INTO employes_archives (id, nom, prenom, email)
SELECT id, nom, prenom, email
FROM employes
WHERE date_fin_contrat < CURRENT_DATE;
```

### Exemple : Transformation de donn√©es

Vous pouvez transformer les donn√©es lors de l'insertion :

```sql
-- Cr√©er des noms d'utilisateur en combinant pr√©nom et nom
INSERT INTO utilisateurs (username, email)
SELECT
    LOWER(prenom || '.' || nom) AS username,
    email
FROM employes
WHERE email IS NOT NULL;
```

Cette requ√™te cr√©e des noms d'utilisateur en minuscules du type "marie.dupont".

### Exemple : Insertion avec jointure

Vous pouvez m√™me utiliser des jointures :

```sql
-- Table des d√©partements
CREATE TABLE departements (
    id SERIAL PRIMARY KEY,
    nom VARCHAR(100)
);

-- Table des affectations
CREATE TABLE affectations (
    employe_id INTEGER,
    departement_id INTEGER,
    date_affectation DATE
);

-- Affecter tous les employ√©s au d√©partement "Ventes"
INSERT INTO affectations (employe_id, departement_id, date_affectation)
SELECT
    e.id,
    d.id,
    CURRENT_DATE
FROM employes e
CROSS JOIN departements d
WHERE d.nom = 'Ventes';
```

---

## 6.1.4. Import massif de donn√©es avec COPY

### Qu'est-ce que COPY ?

`COPY` est une commande PostgreSQL sp√©cialement con√ßue pour l'importation et l'exportation de donn√©es en masse. Elle est **beaucoup plus rapide** que des INSERT multiples pour les raisons suivantes :

1. **Contournement du parseur SQL** : Les donn√©es sont trait√©es directement
2. **Optimisation du WAL** : √âcriture group√©e dans les journaux de transactions
3. **Moins de overhead** : Pas de pr√©paration de requ√™te pour chaque ligne
4. **Format binaire optionnel** : Encore plus rapide que le format texte

### Quand utiliser COPY ?

- **Import initial** : Chargement de millions de lignes lors de la cr√©ation d'une base
- **Migrations** : Transfert de donn√©es entre syst√®mes
- **Chargements ETL** : Extraction, transformation, chargement de donn√©es
- **Restaurations** : Rechargement de sauvegardes

**R√®gle empirique** : √Ä partir de quelques milliers de lignes, COPY devient significativement plus performant que INSERT.

### Syntaxe de base

Il existe deux variantes de COPY :

#### 1. COPY c√¥t√© serveur (depuis un fichier sur le serveur)

```sql
COPY nom_table (colonne1, colonne2, colonne3)
FROM '/chemin/vers/fichier.csv'
WITH (FORMAT csv, HEADER true, DELIMITER ',');
```

> **Important** : Le fichier doit √™tre accessible par le processus PostgreSQL (droits de lecture). Cette commande n√©cessite g√©n√©ralement des privil√®ges superutilisateur.

#### 2. \copy c√¥t√© client (depuis psql)

```sql
\copy nom_table (colonne1, colonne2, colonne3)
FROM '/chemin/local/fichier.csv'
WITH (FORMAT csv, HEADER true, DELIMITER ',');
```

> **Note** : `\copy` est une commande **psql** (l'outil en ligne de commande), pas une commande SQL. Elle transf√®re les donn√©es depuis le client vers le serveur.

### Format CSV (le plus courant)

#### Structure d'un fichier CSV

Exemple de fichier `employes.csv` :

```csv
nom,prenom,email,salaire,date_embauche
Dupont,Marie,marie.dupont@example.com,45000.00,2025-01-15
Martin,Pierre,pierre.martin@example.com,52000.00,2025-01-20
Durand,Sophie,sophie.durand@example.com,48000.00,2025-02-01
Bernard,Luc,luc.bernard@example.com,41000.00,2025-02-10
```

#### Importation basique

```sql
COPY employes (nom, prenom, email, salaire, date_embauche)
FROM '/tmp/employes.csv'
WITH (FORMAT csv, HEADER true);
```

Explications :
- `FORMAT csv` : Indique que le fichier est au format CSV
- `HEADER true` : La premi√®re ligne contient les noms de colonnes (elle sera ignor√©e)

#### Options courantes de COPY

PostgreSQL offre de nombreuses options pour personnaliser l'importation :

```sql
COPY employes (nom, prenom, email, salaire)
FROM '/tmp/employes.csv'
WITH (
    FORMAT csv,              -- Format du fichier
    HEADER true,             -- Premi√®re ligne = en-t√™tes
    DELIMITER ',',           -- S√©parateur (virgule par d√©faut)
    QUOTE '"',               -- Caract√®re de citation
    ESCAPE '"',              -- Caract√®re d'√©chappement
    NULL 'NULL',             -- Repr√©sentation de NULL dans le fichier
    ENCODING 'UTF8'          -- Encodage du fichier
);
```

### Gestion des cas particuliers

#### Fichier sans en-t√™te

Si votre fichier ne contient pas de ligne d'en-t√™te :

```sql
COPY employes (nom, prenom, email, salaire)
FROM '/tmp/employes_sans_entete.csv'
WITH (FORMAT csv, HEADER false);
```

#### S√©parateur personnalis√© (TSV, pipe, etc.)

Pour un fichier d√©limit√© par des tabulations (TSV) :

```sql
COPY employes (nom, prenom, email)
FROM '/tmp/employes.tsv'
WITH (FORMAT csv, DELIMITER E'\t');
```

Pour un fichier d√©limit√© par des pipes (|) :

```sql
COPY employes (nom, prenom, email)
FROM '/tmp/employes.txt'
WITH (FORMAT csv, DELIMITER '|');
```

#### Gestion des valeurs NULL

Par d√©faut, une cha√Æne vide ('') dans un fichier CSV est import√©e comme cha√Æne vide, pas comme NULL. Pour traiter certaines valeurs comme NULL :

```sql
COPY employes (nom, prenom, salaire)
FROM '/tmp/employes.csv'
WITH (FORMAT csv, NULL 'NULL');
```

Dans le fichier, les cellules contenant exactement `NULL` seront import√©es comme NULL SQL.

#### Gestion des guillemets et caract√®res sp√©ciaux

Si vos donn√©es contiennent des virgules ou des retours √† la ligne, utilisez des guillemets :

Fichier `employes_complexe.csv` :
```csv
nom,prenom,commentaire
"Dupont",Marie,"Excellente employ√©e, tr√®s motiv√©e"
"Martin",Pierre,"Expert en SQL
et PostgreSQL"
```

Import :
```sql
COPY employes (nom, prenom, commentaire)
FROM '/tmp/employes_complexe.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"');
```

### Format texte (format par d√©faut de PostgreSQL)

Le format texte est le format historique de PostgreSQL, moins courant que CSV mais toujours support√© :

```sql
COPY employes (nom, prenom, email)
FROM '/tmp/employes.txt'
WITH (FORMAT text, DELIMITER E'\t', NULL '\N');
```

Caract√©ristiques :
- D√©limiteur : tabulation par d√©faut
- NULL repr√©sent√© par `\N`
- Moins flexible que CSV pour les cas complexes

### Format binaire (le plus performant)

Pour des performances maximales, notamment avec des donn√©es volumineuses :

```sql
COPY employes (nom, prenom, salaire)
FROM '/tmp/employes.bin'
WITH (FORMAT binary);
```

**Avantages** :
- Vitesse d'importation maximale
- Pas de conversion de types
- Donn√©es stock√©es directement au format interne PostgreSQL

**Inconv√©nients** :
- Fichiers non lisibles par un humain
- D√©pendance √† l'architecture (peu portable entre syst√®mes diff√©rents)
- Difficile √† g√©n√©rer manuellement

### Exportation avec COPY (bonus)

`COPY` permet aussi d'exporter des donn√©es :

```sql
-- Exporter toute la table
COPY employes TO '/tmp/export_employes.csv'
WITH (FORMAT csv, HEADER true);

-- Exporter avec une requ√™te
COPY (
    SELECT nom, prenom, salaire
    FROM employes
    WHERE salaire > 45000
    ORDER BY salaire DESC
) TO '/tmp/employes_hauts_salaires.csv'
WITH (FORMAT csv, HEADER true);
```

### Nouveaut√©s PostgreSQL 18 : Am√©lioration de COPY

PostgreSQL 18 apporte des am√©liorations importantes √† la commande COPY :

#### 1. Gestion am√©lior√©e du marqueur de fin `\.` en CSV

Dans les versions pr√©c√©dentes, le marqueur de fin `\.` (backslash point) utilis√© dans le format texte pouvait causer des probl√®mes s'il apparaissait dans les donn√©es CSV. PostgreSQL 18 am√©liore la gestion de ce cas :

```sql
-- D√©sormais plus robuste face au \. dans les donn√©es CSV
COPY employes FROM '/tmp/data.csv'
WITH (FORMAT csv);
```

Cette am√©lioration rend COPY plus fiable lors de l'importation de fichiers CSV contenant des caract√®res sp√©ciaux.

#### 2. Meilleures performances

PostgreSQL 18 optimise le traitement interne de COPY, rendant les importations encore plus rapides, particuli√®rement pour :
- Les fichiers volumineux (plusieurs Go)
- Les types de donn√©es complexes (JSONB, ARRAY)
- Les tables avec de nombreux index

### Comparaison de performances : INSERT vs COPY

Voici des ordres de grandeur typiques pour l'insertion d'1 million de lignes :

| M√©thode | Temps approximatif | Cas d'usage |
|---------|-------------------|-------------|
| INSERT simple (1M requ√™tes) | ~2h-4h | √Ä √©viter pour du volume |
| INSERT multiple (1000 lignes/requ√™te) | ~5-10 min | Migration, petits volumes |
| COPY (format CSV) | ~10-30 sec | Import massif (recommand√©) |
| COPY (format binaire) | ~5-15 sec | Import massif haute performance |

> **Conclusion** : COPY peut √™tre **100 √† 500 fois plus rapide** que des INSERT pour de gros volumes.

### Bonnes pratiques pour les imports massifs

#### 1. D√©sactiver temporairement les index

Pour des imports tr√®s volumineux, recr√©er les index apr√®s l'import est souvent plus rapide :

```sql
-- Avant l'import
DROP INDEX IF EXISTS idx_employes_email;
DROP INDEX IF EXISTS idx_employes_nom;

-- Import massif
COPY employes FROM '/tmp/gros_fichier.csv' WITH (FORMAT csv);

-- Recr√©er les index
CREATE INDEX idx_employes_email ON employes(email);
CREATE INDEX idx_employes_nom ON employes(nom);
```

#### 2. D√©sactiver temporairement les contraintes (avec pr√©caution)

Pour des imports de donn√©es d√©j√† valid√©es :

```sql
-- D√©sactiver les triggers
ALTER TABLE employes DISABLE TRIGGER ALL;

-- Import
COPY employes FROM '/tmp/data.csv' WITH (FORMAT csv);

-- R√©activer les triggers
ALTER TABLE employes ENABLE TRIGGER ALL;
```

> **Attention** : √Ä utiliser uniquement si vous √™tes certain de la qualit√© des donn√©es.

#### 3. Augmenter temporairement maintenance_work_mem

```sql
-- Augmenter la m√©moire pour les op√©rations de maintenance
SET maintenance_work_mem = '1GB';

-- Effectuer l'import
COPY employes FROM '/tmp/data.csv' WITH (FORMAT csv);

-- R√©initialiser (ou laisser la session se fermer)
RESET maintenance_work_mem;
```

#### 4. Utiliser des transactions

Encapsuler l'import dans une transaction pour garantir l'atomicit√© :

```sql
BEGIN;

COPY employes FROM '/tmp/data1.csv' WITH (FORMAT csv);
COPY departements FROM '/tmp/data2.csv' WITH (FORMAT csv);
COPY affectations FROM '/tmp/data3.csv' WITH (FORMAT csv);

COMMIT;
```

Si une erreur survient, toutes les insertions sont annul√©es.

---

## 6.1.5. Gestion des erreurs et validation

### Contraintes et INSERT

Lors d'une insertion, PostgreSQL v√©rifie toutes les contraintes :

```sql
-- Cette insertion √©chouera si l'email existe d√©j√† (contrainte UNIQUE)
INSERT INTO employes (nom, prenom, email)
VALUES ('Test', 'Test', 'marie.dupont@example.com');
-- ERROR: duplicate key value violates unique constraint "employes_email_key"

-- Cette insertion √©chouera si nom est NULL (contrainte NOT NULL)
INSERT INTO employes (prenom, email)
VALUES ('Jean', 'jean@example.com');
-- ERROR: null value in column "nom" violates not-null constraint
```

### Comportement transactionnel

Par d√©faut, chaque commande SQL est une transaction :

```sql
-- Insertion r√©ussie (automatiquement committ√©e)
INSERT INTO employes (nom, prenom) VALUES ('Test1', 'Test1');

-- Insertion √©chou√©e (automatiquement rollback)
INSERT INTO employes (nom, prenom, email) VALUES ('Test2', 'Test2', 'marie.dupont@example.com');
-- La premi√®re insertion reste en base, la seconde est annul√©e
```

Pour grouper plusieurs insertions dans une transaction :

```sql
BEGIN;

INSERT INTO employes (nom, prenom) VALUES ('Test1', 'Test1');
INSERT INTO employes (nom, prenom) VALUES ('Test2', 'Test2');
INSERT INTO employes (nom, prenom) VALUES ('Test3', 'Test3');

-- Si tout s'est bien pass√©
COMMIT;

-- Ou en cas de probl√®me
-- ROLLBACK;
```

### Gestion des erreurs avec COPY

Contrairement √† INSERT, COPY s'arr√™te √† la premi√®re erreur par d√©faut :

```sql
COPY employes FROM '/tmp/data.csv' WITH (FORMAT csv);
-- Si la ligne 5000 contient une erreur, les 4999 premi√®res lignes ne seront PAS ins√©r√©es
```

**Solution** : Valider vos donn√©es avant l'import, ou utiliser une table de staging :

```sql
-- 1. Cr√©er une table temporaire sans contraintes
CREATE TEMP TABLE employes_staging (
    nom TEXT,
    prenom TEXT,
    email TEXT,
    salaire TEXT  -- Notez : TEXT pour accepter n'importe quoi
);

-- 2. Importer dans la table temporaire
COPY employes_staging FROM '/tmp/data.csv' WITH (FORMAT csv);

-- 3. Valider et ins√©rer dans la table finale
INSERT INTO employes (nom, prenom, email, salaire)
SELECT
    nom,
    prenom,
    email,
    salaire::NUMERIC  -- Conversion avec gestion d'erreur
FROM employes_staging
WHERE email ~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$'  -- Validation
    AND salaire ~ '^[0-9]+\.?[0-9]*$';  -- Validation num√©rique
```

---

## R√©capitulatif et recommandations

### Quand utiliser quelle m√©thode ?

| Situation | M√©thode recommand√©e | Raison |
|-----------|---------------------|--------|
| 1 √† 10 lignes | INSERT simple | Simplicit√©, clart√© |
| 10 √† 1000 lignes | INSERT multiple | Bon compromis performance/lisibilit√© |
| 1000 √† 10000 lignes | INSERT multiple ou COPY | COPY commence √† √™tre int√©ressant |
| 10000+ lignes | COPY (CSV) | Performance maximale |
| Millions de lignes | COPY (binaire) + optimisations | Performance critique |
| Copie entre tables | INSERT ... SELECT | Transformation √† la vol√©e possible |

### Points cl√©s √† retenir

1. **INSERT simple** : Pour des insertions ponctuelles, lisible et flexible
2. **INSERT multiple** : Toujours pr√©f√©rer √† plusieurs INSERT simples
3. **INSERT ... SELECT** : Id√©al pour dupliquer ou transformer des donn√©es existantes
4. **COPY** : L'outil de r√©f√©rence pour les imports massifs
5. **PostgreSQL 18** : Am√©liorations de COPY pour plus de robustesse

### Checklist avant un import massif

- [ ] Les types de donn√©es correspondent-ils √† la structure de la table ?
- [ ] Les contraintes (PK, FK, UNIQUE) sont-elles compatibles avec les donn√©es ?
- [ ] L'encodage du fichier est-il correct (UTF-8 recommand√©) ?
- [ ] Les index peuvent-ils √™tre temporairement supprim√©s ?
- [ ] Une table de staging est-elle n√©cessaire pour valider les donn√©es ?
- [ ] Une transaction globale est-elle n√©cessaire ?
- [ ] Les performances du syst√®me permettent-elles l'import (I/O, m√©moire) ?

---

## Exemple complet : Pipeline d'importation

Voici un exemple complet d'importation de donn√©es avec validation :

```sql
-- 1. Cr√©er la table finale
CREATE TABLE employes (
    id SERIAL PRIMARY KEY,
    nom VARCHAR(100) NOT NULL,
    prenom VARCHAR(100) NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    salaire NUMERIC(10, 2) CHECK (salaire > 0),
    date_embauche DATE DEFAULT CURRENT_DATE
);

-- 2. Cr√©er une table de staging (sans contraintes)
CREATE TEMP TABLE employes_staging (
    nom TEXT,
    prenom TEXT,
    email TEXT,
    salaire TEXT,
    date_embauche TEXT
);

-- 3. Importer les donn√©es brutes
COPY employes_staging
FROM '/tmp/employes.csv'
WITH (FORMAT csv, HEADER true);

-- 4. Analyser les donn√©es invalides
SELECT
    nom, prenom, email, salaire,
    CASE
        WHEN nom IS NULL OR nom = '' THEN 'Nom manquant'
        WHEN prenom IS NULL OR prenom = '' THEN 'Pr√©nom manquant'
        WHEN email !~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$' THEN 'Email invalide'
        WHEN salaire !~ '^[0-9]+\.?[0-9]*$' THEN 'Salaire invalide'
        ELSE 'OK'
    END AS statut_validation
FROM employes_staging
WHERE nom IS NULL OR nom = ''
   OR prenom IS NULL OR prenom = ''
   OR email !~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$'
   OR salaire !~ '^[0-9]+\.?[0-9]*$';

-- 5. Ins√©rer uniquement les donn√©es valides
INSERT INTO employes (nom, prenom, email, salaire, date_embauche)
SELECT
    TRIM(nom),
    TRIM(prenom),
    LOWER(TRIM(email)),
    salaire::NUMERIC,
    COALESCE(date_embauche::DATE, CURRENT_DATE)
FROM employes_staging
WHERE nom IS NOT NULL AND nom != ''
  AND prenom IS NOT NULL AND prenom != ''
  AND email ~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$'
  AND salaire ~ '^[0-9]+\.?[0-9]*$';

-- 6. V√©rifier le r√©sultat
SELECT
    (SELECT COUNT(*) FROM employes_staging) AS lignes_importees,
    (SELECT COUNT(*) FROM employes) AS lignes_valides,
    (SELECT COUNT(*) FROM employes_staging) - (SELECT COUNT(*) FROM employes) AS lignes_rejetees;
```

---

## Conclusion

L'insertion de donn√©es dans PostgreSQL offre une grande flexibilit√© :

- **INSERT** pour les op√©rations courantes et les petits volumes
- **INSERT multiple** pour am√©liorer les performances avec des volumes moyens
- **INSERT ... SELECT** pour transformer et dupliquer des donn√©es
- **COPY** pour les imports massifs avec des performances optimales

Avec PostgreSQL 18, les am√©liorations apport√©es √† COPY renforcent encore sa robustesse pour traiter des fichiers CSV complexes.

Le choix de la m√©thode d√©pend avant tout du volume de donn√©es, des contraintes de performance, et de la complexit√© des validations n√©cessaires.

---


‚è≠Ô∏è [Nouveaut√© PG 18 : Am√©liorations COPY et gestion du marqueur de fin \. en CSV](/06-manipulation-des-donnees/02-ameliorations-copy-pg18.md)
